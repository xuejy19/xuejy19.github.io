<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>贝叶斯理论</title>
    <url>/2020/07/23/bayes/</url>
    <content><![CDATA[<hr>
<p>该部分按照以下层次进行组织：</p>
<blockquote>
<ul>
<li>从贝叶斯公式谈起</li>
<li>贝叶斯决策 <span id="more"></span>
</li>
</ul>
<hr>
<h2 id="贝叶斯公式"><a href="#贝叶斯公式" class="headerlink" title="贝叶斯公式"></a>贝叶斯公式</h2><p><strong>概念介绍</strong>(From 维基百科)：</p>
<ul>
<li><strong>条件概率</strong>：条件概率就是事件A在事件B发生条件下的概率，记做$P(A|B)$.</li>
<li><strong>先验概率</strong>：先验概率是指在考虑“观测数据”之前，对某一不确定量的估计,如$P(A)$</li>
<li><strong>后验概率</strong>：在贝叶斯统计中，一个随机事件或者一个不确定事件的后验概率是在考虑和给出相关证据或数据后所得到的条件概率，“后验”指代考虑了被测试事件的相关证据，如$P(B|A)$可以看作事件B的后验概率</li>
</ul>
</blockquote>
<p>贝叶斯公式形式如下：</p>
<script type="math/tex; mode=display">P(A|B) = \frac{P(A)P(A|B)}{P(B)}</script><p>再根据全概率公式：</p>
<script type="math/tex; mode=display">P(B) = \sum_j P(B|A_j)P(A_j)</script><p>可以得到贝叶斯公式另一种形式：</p>
<script type="math/tex; mode=display">P(A_i|B) = \frac{P(A_i)P(B|A_i)}{\sum_j P(B|A_j)P(A_j) }</script><blockquote>
<p>公式分析：在现实世界中，我们往往期望通过一些观察到的事件来对一些不可以直接观测的事件进行推断，公式中的$B$变量指代可以直接观测到的事件，而我们的目的则是希望通过$B$事件与$A$事件之间的关联(因果性,相关性)来间接对A事件进行观测，贝叶斯公式便为我们搭起了这样一做桥梁。</p>
</blockquote>
<p>从公式角度出发，可以看出这样进行推理是有代价的，或者是必须拥有某些知识：</p>
<blockquote>
<ul>
<li>先验概率$P(A)$</li>
<li>类条件概率$P(B|A)$</li>
</ul>
<hr>
</blockquote>
<h2 id="贝叶斯决策"><a href="#贝叶斯决策" class="headerlink" title="贝叶斯决策"></a>贝叶斯决策</h2><p>这部分主要介绍三种基于贝叶斯理论的决策策略：</p>
<blockquote>
<ul>
<li>基于最小错误率的贝叶斯决策</li>
<li>基于最小风险的贝叶斯决策</li>
<li>在限定一类错误率条件下使另一类错误率为最小的两类别决策</li>
</ul>
<hr>
<h3 id="最小错误率贝叶斯决策"><a href="#最小错误率贝叶斯决策" class="headerlink" title="最小错误率贝叶斯决策"></a>最小错误率贝叶斯决策</h3><p>从贝叶斯公式出发，通过比较后验概率大小，选择后验概率大的类别作为label。以而分类问题为例，$\omega_i(i=1,2)$是类别标签，$x$为特征相量，由贝叶斯公式，可得$P(\omega_i|x)$：</p>
<script type="math/tex; mode=display">P(\omega_i|x) = \frac{P(x|\omega_i)P(\omega_i)}{\sum_{j=1}^2 P(x|\omega_j)P(\omega_j)}</script><p>最小错误率下等价的决策规则有：</p>
<ul>
<li>若$P(\omega<em>i|x) = max</em>{j=1,2}P(\omega_j|x)$,则$x \in \omega_i$</li>
<li>若$P(x|\omega<em>i)P(\omega_i) = max</em>{j=1,2}P(x|\omega_j)P(\omega_j)$,则$x \in \omega_i$</li>
<li>对于二分类问题，若$l(x) = \frac{P(x|\omega_1)}{P(x|\omega_2)} &gt; \frac{P(\omega_2)}{P(\omega_1)}$,则$x \in \omega_1$</li>
</ul>
</blockquote>
<p>下面证明该种决策策略为最小错误率，首先给出平均错误率公式：</p>
<script type="math/tex; mode=display">P(e) = \int_{-\infty}^{\infty}P(e,x)dx = \int_{-\infty}^{\infty} P(e|x)p(x)dx</script><p>由上面给出的决策规则可知：</p>
<script type="math/tex; mode=display">P(e|x) = \begin{cases} P(\omega_1|x),if P(\omega_2|x) > P(\omega_1|x) \\ 
P(\omega_2|x),if P(\omega_1|x) > P(\omega_2|x) \end{cases}</script><p>若$t$为两类的决策分界面，在该分界面上$P(\omega_1|x) = P(\omega_2|x)$，$t$将整个决策空间分为了两部分$\mathcal{R_1}$和$\mathcal{R_2}$,分别对应将$x$归为$\omega_1$和$\omega_2$,据此平均错误率可以写为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
P(e) &= P(x \in \mathcal{R_1},\omega_2) + P(x \in \mathcal{R_2},\omega_1) \\
&= P(x\in \mathcal{R_1}|\omega_2) P(\omega_2) + P(x \in \mathcal{R_2}|\omega_1) P(\omega_1) \\
&= P(\omega_2) \int_{\mathcal{R_1}} p(x|\omega_2)dx + P(\omega_1)\int_{\mathcal{R_2}}p(x|\omega_1)dx \\
&= P(\omega_2) P_2(e) + P(\omega_1) P_1(e)
\end{aligned}</script><p><img src="https://raw.githubusercontent.com/xuejy19/Images/master/bayes2.png" alt="最小错误率"></p>
<p>图中斜线部分代表$P(e)$的第一项，纹线部分代表第二项，而从最小错误率公式来看，若要使平均错误率$P(e)$最小，只需要对于任意的$x$，保证$P(e|x)$最小，而这恰恰是贝叶斯最小错误率决策规则。</p>
<h3 id="最小风险贝叶斯决策"><a href="#最小风险贝叶斯决策" class="headerlink" title="最小风险贝叶斯决策"></a>最小风险贝叶斯决策</h3><p>最小风险贝叶斯决策，或者称为最小损失贝叶斯决策，这种决策思想也是非常朴素：</p>
<blockquote>
<p>同样是决策错误，但不同的错误带来的损失并不相同，有时甚至天差地别，比如去医院看病，对于早起癌症，漏警要比虚警严重的多，可能会让患者失去早期治疗的时机。</p>
</blockquote>
<p>最小风险错误率准则正是考虑各种错误造成损失不同而提出的一种决策规则，若将决策空间记做$\mathcal{A}$,而每个决策都将带来一定的损失，它通常是决策和自然状态的函数，比如$\lambda(a_i,\omega_j)$则指代在$x$处于状态$\omega_j$而做出$a_i$决策时的损失，下面给出数学符号定义：</p>
<ul>
<li>观测向量$x$为$d$维随机向量<script type="math/tex; mode=display">x = [x_1, x_2 , \dots, x_d]^T</script></li>
<li>状态空间$\Omega$由$c$个自然状态(c类)组成<script type="math/tex; mode=display">\Omega = \{ \omega_1, \dots, \omega_c \}</script></li>
<li>决策空间由$n$个决策组成<script type="math/tex; mode=display">\mathcal{A} = \{ a_1, \dots, a_n \}</script></li>
<li>决策表，决策表中第$i$行$j$列为相应损失值$\lambda(a_i,\omega_j)$</li>
</ul>
<p>由于引入了损失的概念，在进行决策时便不能够只根据后验概率大小来做决策，必须考虑所采取的决策是否使得损失最小。对于给定的$x$，如果我们采取决策$a_i$,其对应$c$种可能的损失$\lambda(a_i,\omega_j)$,每种损失出现的概率为$P(\omega_i|x)$,由此可以计算条件期望损失$R(a_i|x)$:</p>
<script type="math/tex; mode=display">
    R(a_i|x) = E(\lambda(a_i,\omega_j)) = \sum_{j=1}^c \lambda(a_i,\omega_j) P(\omega_j|x), i=1,\dots,n</script><p>在决策论种$R(a_i|x)$被称作条件风险，由于$x$是随机向量的观察值，因此对于不同的$x$，采取决策$a_i$时，其条件风险是不同的，所以最终采取何种决策应当与$x$有关，在这种意义下，可以将决策$a$看作是$x$的函数，记做$a(x)$,可以定义期望风险$R$为：</p>
<script type="math/tex; mode=display">
    R = \int R(a(x)|x) p(x)dx</script><p>若想使得期望风险$R$最小，只需要保证对于任意的$x$，$R(a(x)|x)$最小，因此最小损失贝叶斯决策规则为：</p>
<script type="math/tex; mode=display">
    if R(a_k|x) = \min \limits_{i=1,\dots,n}R(a_i|x) \Rightarrow a = a_k</script><h3 id="在限定一类错误率条件下，使得另一类错误率最小"><a href="#在限定一类错误率条件下，使得另一类错误率最小" class="headerlink" title="在限定一类错误率条件下，使得另一类错误率最小"></a>在限定一类错误率条件下，使得另一类错误率最小</h3><p>在两类别决策问题中，有两种错误分类的可能性,分别对应两个错误率$P_1(e)$和$P_2(e)$,而在实际应用中，我们往往期望某一个错误率不大于某个常数，而使另一类错误率尽可能小。比如在癌症诊断中，我们认识到将异常判断为正常非常严重，我们期望这类错误率为一个很小的值$P_2(e) = \epsilon_0$,在满足该条件下，期望另一类错误率$P_1(e)$尽可能低，这其实是一个带有等式约束的优化问题，可以用拉格朗日乘子法进行求解，拉格朗日函数$L$为:</p>
<script type="math/tex; mode=display">
    L = P_1(e) + \lambda(P_2(e) - \epsilon_0)</script><p>其中$P_1(e)$为：</p>
<script type="math/tex; mode=display">
    P_1(e) = \int_{\mathcal{R_2}} p(x|\omega_1)dx</script><p>$P_2(e)$类似，因此拉格朗日函数可以写做：</p>
<script type="math/tex; mode=display">
\begin{aligned}
    L &= \int_{\mathcal{R_2}} p(x|\omega_1) + \lambda(\int_{\mathcal{R_1}} p(x|\omega_2)dx - \epsilon_0)  \\
    &= 1-\lambda \epsilon_0 + \int_{\mathcal{R_1}} [\lambda  p(x|\omega_2) - p(x|\omega_1)dx]
\end{aligned}</script><p>$L$分别对分界点$t$和$\lambda$求导，可得：</p>
<script type="math/tex; mode=display">
 \begin{cases}
    \frac{\partial L}{\partial t} = 0 \Rightarrow \lambda = \frac{p(t|\omega_1)}{p(t|\omega_2)} \\
    \frac{\partial L}{\partial \lambda} = 0 \Rightarrow P_2(e) = \epsilon_0
 \end{cases}</script><p>由此便可得到Neyman-Pearson决策准则：</p>
<script type="math/tex; mode=display">
    if \frac{p(x|\omega_1)}{p(x|omega_2)} > \lambda \Rightarrow x \in \omega_1</script>]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
  </entry>
  <entry>
    <title>Domain generalization</title>
    <url>/2022/10/28/domain-generalization/</url>
    <content><![CDATA[<p>本篇文章是对文章<a href="https://arxiv.org/pdf/2103.03097.pdf">Generalizing to Unseen Domains: A Survey on<br>Domain Generalization</a>的研读介绍，旨在对域泛化(domain generalization)领域研究现状有粗略了解，考虑将该领域的一些研究思想迁移到故障检测/溯源/软测量等任务上去。<span id="more"></span> </p>
<h3 id="出发点"><a href="#出发点" class="headerlink" title="出发点"></a>出发点</h3><ul>
<li><p>现有算法面临的挑战<br>传统的机器学习算法的泛化能力依赖于训练域与测试域的独立同分布(i.i.d)假设，而在现实数据中，这样的假设往往无法得到满足。</p>
</li>
<li><p>目的<br>如果我们已经拥有了一个/多个域的数据，希望让训练得到的模型在未知域上仍能有良好的泛化能力。 </p>
</li>
</ul>
<h3 id="问题数学描述"><a href="#问题数学描述" class="headerlink" title="问题数学描述"></a>问题数学描述</h3><blockquote>
<ul>
<li><p>domain: 记$\mathcal{X}$为非空的输入空间，$\mathcal{Y}$为输出空间，输入输出之间的关系通过联合概率分布$P<em>{XY}$来描述，域则由从该分布中采样得到的样本组成$S = {(x_i,y_i)}</em>{i=1}^n \sim P_{XY}$。</p>
</li>
<li><p>domain generalization: 在域泛化任务中，我们有$M$个训练/源域的数据</p>
<script type="math/tex; mode=display">
  S_{train} = {S_i|i=1,...,M}, where \quad S^i = \{(x_j^i, y_j^i)\}_{j=1}^{n_i} \quad denotes \quad i_{th} \quad domain</script><p>不同域的数据具有不同的联合概率分布，即$P<em>{XY}^i \neq P</em>{XY}^j $；域泛化的目标是学习到一个<strong>鲁棒且可泛化的预测方程</strong>$h: \mathcal{X} \rightarrow \mathcal{Y}$, 该模型在未知域$S_{test}$上的预测误差要尽可能小: </p>
<script type="math/tex; mode=display">
  \min_{h} \mathbb{E}_{(x,y) \in S_{test}} [\ell(h(x),y)]</script></li>
</ul>
</blockquote>
<h3 id="相关研究领域介绍"><a href="#相关研究领域介绍" class="headerlink" title="相关研究领域介绍"></a>相关研究领域介绍</h3><ul>
<li><strong>多任务学习(Multi-task learning)</strong>: 在多个任务上联合优化模型，目的是为了提高模型在原始任务上的泛化能力，多域学习(multi-domain learning)可以看作多任务学习的一种特例。</li>
<li><strong>迁移学习(Transfer learning)</strong>: 在源任务/域上训练得到模型，目的在于提高模型在目标任务/域上的性能，迁移学习最广泛的应用就是<strong>预训练模型+微调</strong>的范式，与域泛化的区别在于迁移学习中目标域的数据是可获取的。</li>
<li><strong>域适应(domain adaptation)</strong>: 该领域可以看作是迁移学习的一个分支，也是需要能够获取目标域的数据。 </li>
<li><strong>元学习(Meta-learning)</strong>: 学习学习算法，即learning to learn, 元学习是一种通用的学习策略可以用于实现域泛化。 </li>
<li><strong>终身学习/持续学习</strong>: 随着任务/数据域的不断更新，模型需要不断利用新的知识来更新模型参数。 </li>
<li><strong>零样本学习(Zero-shot learning)</strong>: 利用已有类别的数据学习模型，对新类别的样本仍能分辨出来。 </li>
</ul>
<h3 id="方法分类"><a href="#方法分类" class="headerlink" title="方法分类"></a>方法分类</h3><p><img src="/.io//%E6%96%B9%E6%B3%95%E5%88%86%E7%B1%BB.png" alt></p>
<p>目前域泛化的方法可以分为三类： </p>
<ul>
<li><strong>数据操纵</strong>: 基本思路是提高训练数据的涵盖范围，常用的思路有两个: <ul>
<li>数据扩充: 数据扩展/随机变换 </li>
<li>数据生成: 生成更具多样性的样本 </li>
</ul>
</li>
<li><strong>表征学习</strong>: 基本思想是学习到一些稳定的特征，可细分为两个方向: <ul>
<li>域不变表征学习 </li>
<li>特征解偶</li>
</ul>
</li>
<li><strong>学习策略</strong>: 探索一般性的学习策略以提升模型泛化能力，常用思路有: <ul>
<li>集成学习</li>
<li>元学习 </li>
<li>梯度操作 </li>
<li>分布鲁棒优化 </li>
<li>自监督学习 </li>
</ul>
</li>
</ul>
<h4 id="数据操纵-data-manipulation"><a href="#数据操纵-data-manipulation" class="headerlink" title="数据操纵(data manipulation)"></a>数据操纵(data manipulation)</h4><p>提高训练数据的多样性，数据增强的有效性在于增强过后的数据未来有可能出现在测试域中，<strong>能否考虑应用一些机理知识来进行数据增强，类似于反事实的概念</strong>。 </p>
<h5 id="基于数据扩充的域泛化"><a href="#基于数据扩充的域泛化" class="headerlink" title="基于数据扩充的域泛化"></a>基于数据扩充的域泛化</h5><p>常用的数据扩充操作有翻转、旋转、裁剪、添加噪声等</p>
<ul>
<li>域随机化: 改变目标大小/位置/光线/随机噪声 </li>
<li>对抗数据增广: 实现有效数据增广，同标签，沿差异大的方向扩充样本 </li>
</ul>
<h5 id="基于数据生成的域泛化"><a href="#基于数据生成的域泛化" class="headerlink" title="基于数据生成的域泛化"></a>基于数据生成的域泛化</h5><p>一般是通过VAE或者GAN来实现数据增强</p>
<h4 id="表征学习"><a href="#表征学习" class="headerlink" title="表征学习"></a>表征学习</h4><p>将预测方程$h$拆分未$h = f \cdot g$, 表征学习的目标为: </p>
<script type="math/tex; mode=display">
\min _{f, g} \mathbb{E}_{\mathbf{x}, y} \ell(f(g(\mathbf{x})), y)+\lambda \ell_{\mathrm{reg}}</script><h5 id="基于域不变性表征学习的域泛化"><a href="#基于域不变性表征学习的域泛化" class="headerlink" title="基于域不变性表征学习的域泛化"></a>基于域不变性表征学习的域泛化</h5><p>理论保证: 如果不同数据域的表征相同，那么说明该表征具有一般性并且可以迁移到其他域，在该表征函数下，源域的数据和目标域的数据更接近了，使得泛化误差上界更紧。</p>
<ul>
<li>基于核的方法(Kernel-based methods): 将原始数据映射到高维空间，通过核函数可以在不知道样本高维坐标情况下计算两样本内积，将不同域样本映射到高维空间，分布一致。</li>
<li>域对抗学习(Domain adversarial learning): 判别器来识别数据属于不同域，生成器用来学习不变表征让判别器分辨不出来。</li>
<li>显式特征对齐(Explicit feature alignment): 在学习的过程显式让特征对齐 </li>
<li>不变风险最小化(Invariant risk minimization): </li>
</ul>
<h5 id="基于特征解耦的域泛化"><a href="#基于特征解耦的域泛化" class="headerlink" title="基于特征解耦的域泛化"></a>基于特征解耦的域泛化</h5><p>将原始数据投影到特征空间，将特征分为domain-shared feature 和 domain-specific feature, 目标函数一般为如下形式: </p>
<script type="math/tex; mode=display">
\min _{g_c, g_s, f} \mathbb{E}_{\mathbf{x}, y} \ell\left(f\left(g_c(\mathbf{x})\right), y\right)+\lambda \ell_{\mathrm{reg}}+\mu \ell_{\mathrm{recon}}\left(\left[g_c(\mathbf{x}), g_s(\mathbf{x})\right], \mathbf{x}\right)</script><ul>
<li>多成分分析: 用不同的特征提取器来提取数据中的不同成分 </li>
<li>生成模型: Domain-invariant VAE </li>
<li>因果启发的方法: </li>
</ul>
<h4 id="学习策略"><a href="#学习策略" class="headerlink" title="学习策略"></a>学习策略</h4><h5 id="基于集成学习的域泛化"><a href="#基于集成学习的域泛化" class="headerlink" title="基于集成学习的域泛化"></a>基于集成学习的域泛化</h5><p>每个域都有一个模型，结合输出结果 </p>
<h5 id="基于元学习的域泛化"><a href="#基于元学习的域泛化" class="headerlink" title="基于元学习的域泛化"></a>基于元学习的域泛化</h5><p>元学习的关键思想是从多个任务中学习一个通用的模型</p>
<h5 id="基于梯度操作的域泛化"><a href="#基于梯度操作的域泛化" class="headerlink" title="基于梯度操作的域泛化"></a>基于梯度操作的域泛化</h5><p>self-challenging训练算法 </p>
<h5 id="基于分布鲁棒优化的方法"><a href="#基于分布鲁棒优化的方法" class="headerlink" title="基于分布鲁棒优化的方法"></a>基于分布鲁棒优化的方法</h5><h5 id="基于自监督学习的域泛化"><a href="#基于自监督学习的域泛化" class="headerlink" title="基于自监督学习的域泛化"></a>基于自监督学习的域泛化</h5>]]></content>
      <categories>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>前沿方向</tag>
      </tags>
  </entry>
  <entry>
    <title>EM</title>
    <url>/2020/07/30/em/</url>
    <content><![CDATA[<p>在前面概率密度函数估计中，若概率模型的变量都是可观测变量，那么给定数据，便可以直接用极大似然估计法或者贝叶斯估计法来直接估计模型参数。但是当模型中含有隐变量时，便不能直接使用这些估计方法，<strong>EM算法就是含有隐变量的概率模型参数的极大似然估计法</strong><span id="more"></span>,本文便围绕EM算法展开，主要包含以下几部分：</p>
<ul>
<li>算法引入</li>
<li>算法定义</li>
<li>算法导出</li>
<li>算法收敛性分析</li>
<li>算法应用-高斯混合模型(GMM)</li>
</ul>
<h3 id="算法引入"><a href="#算法引入" class="headerlink" title="算法引入"></a>算法引入</h3><p>首先介绍一个使用EM算法的栗子，引出EM算法应用场景:</p>
<blockquote>
<p>三硬币模型： 假设有三枚硬币A,B,C。这三枚硬币出现正面的概率分别为$\pi,p,q$。现进行如下掷币实验：首先掷出硬币A,根据其结果选出硬币B或硬币C，正面选硬币B,反面选硬币C；然后掷选出的硬币，掷硬币的结果，正面记做1，反面记做0,独立的重复$n$次实验，得到实验结果为$(x_1,\dots,x_n)$<br><strong>问题</strong>：根据实验结果估计三枚硬币参数(正面朝上概率)</p>
</blockquote>
<p>这个问题的特殊性在于，我们只能够观察到最终实验结果，但是对于中间变量(硬币A的投掷结果)则没有记录，是隐变量，所以该问题是在有隐变量情况下的参数估计问题。下面首先尝试使用极大似然估计方法，做如下标记：</p>
<ul>
<li>待估计参数$\theta = (\pi,p,q)$</li>
<li>观测变量$y$:最终掷硬币结果</li>
<li>隐含变量$z$:每次实验掷硬币A的结果</li>
</ul>
<p>若直接采用最大似然估计，我们希望能够写出似然概率$P(y|\theta)$，但这个概率并不能够直接写出，需要引入隐含变量$z$，因此考虑将似然概率写成</p>
<script type="math/tex; mode=display">
    \begin{aligned}
         P(y|\theta) &= \sum P(y,z|\theta) = \sum_{z} P(z|\theta) P(y|\theta,z) \\\\
         &= \pi p^y (1-p)^{1-y} + (1-\pi)q^y(1-q)^{1-y}
    \end{aligned}</script><p>将观测数据记做$Y = (Y_1,\dots, Y_n)^T$,未观测数据记做$Z = (Z_1,\dots, Z_n)^T$,则似然函数可以写做：</p>
<script type="math/tex; mode=display">
    L = P(Y|\theta) = \prod_{j=1}^n[\pi p^{y_j} (1-p)^{1-y_j} + (1-\pi)q^{y_j}(1-q)^{1-y_j}]</script><p>对数似然函数则是:</p>
<script type="math/tex; mode=display">
    logL = \sum_{j=1}^nlog[\pi p^{y_j} (1-p)^{1-y_j} + (1-\pi)q^{y_j}(1-q)^{1-y_j}]</script><p>直接极大化对数似然函数并不能得到解析解，该问题只能通过EM算法迭代求解</p>
<h3 id="算法推导"><a href="#算法推导" class="headerlink" title="算法推导"></a>算法推导</h3><p>首先给出算法定义：<br><strong>EM算法</strong>:</p>
<blockquote>
<p>  输入： 观测变量数据$Y$,隐变量数据$Z$，联合分布$P(Y,Z|\theta)$,条件分布$P(Z|Y,\theta$<br>  输出： 模型参数$\theta$</p>
</blockquote>
<ol>
<li>选择参数初始值$\theta^0$,开始迭代</li>
<li>E步：记$\theta^i$为第$i$次迭代参数$\theta$的估计值，在第$i+1$次迭代的E步，计算：</li>
</ol>
<script type="math/tex; mode=display">
    \begin{aligned}
        Q(\theta,\theta^i) &= E_Z[logP(Y,Z|\theta)|Y,\theta^i] \\\\
            &= \sum_Z log P(Y,Z|\theta) P(Z|Y,\theta^i)
    \end{aligned}</script><ol>
<li>M步： 求使得$Q(\theta,\theta^i)$极大化的$\theta$,确定第$i+1$次迭代的参数的估计值$\theta^{i+1}$ <script type="math/tex; mode=display">\theta^{i+1} = argmax_{\theta}Q(\theta,\theta^i)</script></li>
<li>重复第2,3步，直到算法收敛</li>
</ol>
<p>从形式上来看，$Q$函数与极大似然函数其实是一样的，不同之处在于$P(Z|Y,\theta^i)$中使用的是参数迭代估计值，用该迭代估计值代替真值，$Q$函数可以看作是：</p>
<blockquote>
<p>完全数据的对数似然函数$logP(Y,Z|\theta)$关于在给定观测数据$Y$和当前参数$\theta^i$下对未观测数据$Z$的的条件概率分布$P(Z|Y,\theta^i)$的期望。</p>
</blockquote>
<p>我们这样使用$Q$函数来近似优化最大似然函数，需要证明这样的迭代优化是有效的</p>
<h3 id="算法导出"><a href="#算法导出" class="headerlink" title="算法导出"></a>算法导出</h3><p>对数似然形式前面已经讨论过，形式为：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        L(\theta) &= log P(Y|\theta) = log \sum_Z P(Y,Z|\theta) \\
        &= log(\sum_Z P(Y|\theta,Z) P(Z|\theta))
    \end{aligned}</script><p>直接极大化对数似然函数困难之处在于两点：</p>
<ul>
<li>含有隐变量$Z$</li>
<li>对数似然函数是和的对数的形式</li>
</ul>
<p>假设在第$i$次迭代后参数$\theta$估计值为$\theta^i$,新的估计值是$\theta$，我们期望新的估计值$\theta$能够使得对数似然函数增大，因此，考虑计算两者的差：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        L(\theta) - L(\theta^i) &= log(\sum_Z P(Y|\theta,Z) P(Z|\theta)) - logP(Y|\theta^i) 
        \\\\
        &= log(\sum_Z P(Z|Y,\theta^i) \frac{P(Y|Z,\theta)P(Z|\theta)}{P(Z|Y,\theta^i)}) - logP(Y|\theta^i) 
        \\\\
        &\geq \sum_Z P(Z|Y,\theta^i) log \frac{P(Y|Z,\theta)P(Z|\theta)}{P(Z|Y,\theta^i)} - logP(Y|\theta^i)  (Jensen不等式)  
        \\\\
        &= \sum_Z P(Z|Y,\theta^i) log \frac{P(Y|Z,\theta)P(Z|\theta)}{P(Z|Y,\theta^i)P(Y|\theta^i)}
    \end{aligned}</script><p>令 </p>
<script type="math/tex; mode=display">
    B(\theta,\theta^i) = L(\theta^i) + \sum_Z P(Z|Y,\theta^i) log \frac{P(Y|Z,\theta)P(Z|\theta)}{P(Z|Y,\theta^i)P(Y|\theta^i)}</script><p>则有：</p>
<script type="math/tex; mode=display">
    L(\theta) \geq B(\theta,\theta^i)</script><p>至此，我们找到了对数似然函数的一个下界，同时在点$\theta^i$处，有：</p>
<script type="math/tex; mode=display">
    L(\theta^i) = B(\theta^i,\theta^i)</script><p>因此若我们可以找到$\theta^{i+1}$,使得$B(\theta^{i+1},\theta^i)&gt;B(\theta^i,<br>\theta^i)$,则有：</p>
<script type="math/tex; mode=display">
    L(\theta^{i+1}) \geq B(\theta^{i+1},\theta^i) > B(\theta^i,\theta^i) = L(\theta^i)</script><p>因此我们可以考虑优化$B(\theta,\theta^i)$，从而变相使原始似然函数增大。接下来考虑$B(\theta,\theta^i)$中需要优化的具体是哪一项:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \theta^{i+1} &= argmax(L(\theta^i) +  \sum_Z P(Z|Y,\theta^i) log \frac{P(Y|Z,\theta)P(Z|\theta)}{P(Z|Y,\theta^i)P(Y|\theta^i)})  \\\\
        &= argmax  \sum_Z P(Z|Y,\theta^i) log \frac{P(Y|Z,\theta)P(Z|\theta)}{P(Z|Y,\theta^i)P(Y|\theta^i)} \\\\
        &= argmax \sum_Z P(Z|Y,\theta^i) log(P(Y|Z,\theta) P(Z|\theta)) \\\\
        &= argmax \sum_Z P(Z|Y,\theta^i) log P(Y,Z|\theta) \\\\
        &= argmax Q(\theta,\theta^i)
    \end{aligned}</script><p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/EM.png" alt="EM"></p>
<p>图中下方曲线为$B(\theta,\theta^i)$，上方曲线为$L(\theta)$,在$\theta^n$处，两者相等，当对$B(\theta,\theta^n)$进行优化时，似然函数也得到了优化，同样，这种迭代算法只能够保证每次迭代都会使得似然函数增加，但并不能保证为全局最优。</p>
<h3 id="算法收敛性分析"><a href="#算法收敛性分析" class="headerlink" title="算法收敛性分析"></a>算法收敛性分析</h3><p>该部分只给出一些结论，证明过程略过</p>
<blockquote>
<p><strong>定理1</strong>:设$P(Y|\theta)$为观测数据的似然函数，$\theta^i$为EM算法得到的参数估计序列，$P(Y|\theta^i)$为对应的似然函数序列，则$P(Y|\theta_i)$是单调递增的，即：</p>
<script type="math/tex; mode=display">
P(Y|\theta^{i+1}) \geq P(Y|\theta^i)</script><p><strong>定理2</strong>:设$L(\theta) = log P(Y|\theta)$为观测数据的对数似然函数，$\theta^i$为EM算法得到的参数估计序列，$L(\theta^i)$为对应的对数似然函数序列 </p>
<ol>
<li>如果$P(Y|\theta)$有上界,则$L(\theta^i) = log P(Y|\theta^i)$ 收敛到某一值$L^*$</li>
<li>在函数$Q(\theta,\theta^{‘})$与$L(\theta)$满足一定条件下，由EM算法得到的参数估计序列$<br>\theta^i$的收敛点$\theta^*$是$L(\theta)$的稳定点</li>
</ol>
</blockquote>
<h3 id="算法应用-高斯混合模型-GMM"><a href="#算法应用-高斯混合模型-GMM" class="headerlink" title="算法应用-高斯混合模型(GMM)"></a>算法应用-高斯混合模型(GMM)</h3><p>首先给出高斯混合模型定义:</p>
<blockquote>
<p>高斯混合模型是指具有如下形式的概率分布模型：</p>
<script type="math/tex; mode=display">
    P(y|\theta) = \sum_{k=1}^K \alpha_k \phi(y|\theta_k)</script><p>其中,$\alpha_k$是系数，$\alpha_k \geq 0$,$\sum \alpha_k = 1$;$\phi(y|\theta_k)$是高斯概率密度函数，$\theta_k = (\mu_k,\sigma_k^2)$,称为第$k$个分模型</p>
</blockquote>
<p>高斯模型是描述数据分布的一种常见模型，但在有时候单一的高斯模型并不足以对数据进行描述，因此便考虑该数据分布有没有可能用多个高斯模型来描述，即任意一个数据点可能来自于某一个分模型。假设观测数据$y_1,y_2,\dots,y_N$由高斯混合模型生成：</p>
<script type="math/tex; mode=display">
      P(y|\theta) = \sum_{k=1}^K \alpha_k \phi(y|\theta_k)</script><p>其中$\theta = (\alpha_1,\dots,\alpha_K;\theta_1,\dots,\theta_K)$,我们现在期望利用观测数据将这些参数估计出来。</p>
<h4 id="隐变量定义"><a href="#隐变量定义" class="headerlink" title="隐变量定义"></a>隐变量定义</h4><p>首先来看对于这样一个模型，隐变量是什么，数据是这样产生的：首先依概率$\alpha<em>k$选择第$k$个高斯分布分模型，然后依第$k$个分模型的概率分布生成观测数据$y$。观测数据$y$是已知的，但是$y$究竟来自于哪个分模型是未知的，记该变量为隐变量$\gamma</em>{jk}$,其定义如下：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \gamma_{jk} &= \begin{cases}
            1,& 第j个观测来自第k个分模型 \\
            0,& other
        \end{cases}   
        \\\\
        j &= 1,\dots,N;k = 1,\dots,K
    \end{aligned}</script><p>目前，我们的观测数据为$y<em>j$,未观测数据是$\gamma</em>{jk}$,完全数据是：</p>
<script type="math/tex; mode=display">
    (y_j,\gamma_{j_1},\dots,\gamma_{jk}),j=1,\dots,N</script><p>于是，可以写出完全数据的对数似然函数：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
         P(y,\gamma|\theta) &= \prod_{j=1}^N P(y_j,\gamma_{j1},\dots,\gamma_{jk}|\theta) \\\\
         &= \prod_{k=1}^K \prod_{j=1}^N [\alpha_k \phi(y_j|\theta_k)]^{\gamma_{jk} } \\\\
         &= \prod_{k=1}^K \alpha_k^{n_k} \prod_{j=1}^N [\alpha_k \phi(y_j|\theta_k)]^{\gamma_{jk} } \\\\
         &= \prod_{k=1}^K \alpha_k^{n_k} \prod_{j=1}^N [\frac{1}{\sqrt{2\pi}\sigma_k} exp(-\frac{(y_j-\mu_k)^2}{2\sigma_k^2})]^{\gamma_{jk}}
    \end{aligned}</script><p>公式中$n<em>k = \sum</em>{j=1}^N \gamma<em>{jk},\sum</em>{k=1}^K n_k = N$,由此，便可以写出完全数据的对数似然函数：</p>
<script type="math/tex; mode=display">
 logP(y,\gamma|\theta) = \sum_{k=1}^K \{ n_klog\alpha_k + \sum_{j=1}^N \gamma_{jk}[log(\frac{1}{\sqrt{2\pi}})-log\sigma_k - \frac{1}{2\sigma_k^2} (y_j-\mu_k)^2]\}</script><p><strong>E步</strong>：其实就是要在已知上次迭代参数估计值$\theta$和观测值$y$的情况下将$\gamma<em>{jk}$估计出来，然后代回完全数据的对数似然函数，下面就求解下$E(\gamma</em>{jk}|y,\theta)$:</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \hat{\gamma}_{jk} &= E(\gamma_{jk}|y,\theta) = P(\gamma_{jk}|y,\theta)\\\\
    &= \frac{P(\gamma_{jk = 1,y|\theta})}{\sum_{k=1}^K P(\gamma_{jk}=1,y_j|\theta)} \\\\
    &= \frac{P(y_j|\gamma_{jk}=1,\theta)P(\gamma_{jk}=1|\theta)}{\sum_{k=1}^K P(y_j|\gamma_{jk}=1,\theta)P(\gamma_{jk}=1|\theta)} \\\\
    &= \frac{\alpha_k \phi(y_j|\theta_k)}{\sum_{k=1}^K \alpha_k \phi(y_j|\theta_k)}
\end{aligned}</script><p>将该估计值代回完全数据的对数似然函数，便得到了$Q$函数：</p>
<script type="math/tex; mode=display">
    Q(\theta,\theta^i) =  logP(y,\gamma|\theta) = \sum_{k=1}^K \{ n_klog\alpha_k + \sum_{j=1}^N \hat{\gamma}_{jk}[log(\frac{1}{\sqrt{2\pi}})-log\sigma_k - \frac{1}{2\sigma_k^2} (y_j-\mu_k)^2]\}</script><p><strong>M步</strong>：迭代的M步是求函数$Q(\theta,\theta^i)$对$\theta$的极大值，即求新一轮迭代的模型参数:</p>
<script type="math/tex; mode=display">
    \theta^{i+1} = \arg max_{\theta} Q(\theta,\theta^i)</script><p>该步只需分别对$\alpha<em>K,\mu_k,\sigma_k$求偏导，令偏导等于0,注意在求解$\alpha_k$时需要利用$\alpha_k$天然的约束条件$\sum</em>{k=1}^K \alpha_k = 1$,最终求解结果为:</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \hat{\mu}_k &= \frac{\sum_{j=1}^N \hat{\gamma}_{jk}y_j}{\sum_{j=1}^N \hat{\gamma}_{jk}} \\\\
    \hat{\sigma}_k^2 &= \frac{\sum_{j=1}^N \hat{\gamma}_{jk}(y_j - \mu_k)^2}{\sum_{j=1}^N \hat{\gamma}_{jk}} \\\\
    \hat{\alpha}_k &= \frac{n_k}{N} = \frac{\sum_{j=1}^N \hat{\gamma}_{jk}}{N}
\end{aligned}</script><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>该部分就高斯混合模型的EM算法进行总结</p>
<ul>
<li>取参数的初始值开始迭代</li>
<li>E步：根据当前模型参数，计算分模型$k$对观测数据$y_j$的响应度</li>
<li>M步：计算新一轮迭代的模型参数 </li>
<li>重复直到算法收敛</li>
</ul>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>EM算法,隐变量,高斯混合模型</tag>
      </tags>
  </entry>
  <entry>
    <title>隐马尔可夫模型</title>
    <url>/2020/08/17/hmm/</url>
    <content><![CDATA[<p>在这一部分，我将对隐马尔可夫模型(HMM)做简要介绍,该章节分为以下几个部分进行组织:</p>
<ul>
<li>基本概念</li>
<li>概率计算算法</li>
<li>学习算法</li>
<li>预测算法</li>
</ul>
<span id="more"></span>
<h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>首先给出隐马尔可夫模型的定义：</p>
<blockquote>
<p><strong>隐马尔可夫模型</strong>:隐马尔可夫模型是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的随机状态序列,再由各个状态生成一个观测从而产生观测随机序列的过程。隐藏的马尔可夫链随机生成的状态序列称为状态序列；每个状态生成一个观测，而由此产生的观测的随机序列，称为观测序列，序列的每一个位置又可以看作是一个时刻。</p>
</blockquote>
<p>隐马尔可夫模型的形式定义如下:设$Q$是所有可能的状态的集合,$V$是所有可能的观测的集合:</p>
<script type="math/tex; mode=display">
Q = (q_1,q_1,\dots,q_N),V = (v_1,v_2,\dots,v_M)</script><p>其中,$N$是可能的状态数，$M$是可能的观测数。$I$是长度为$T$的状态序列,$O$是对应的观测序列:</p>
<script type="math/tex; mode=display">
I = (i_1,i_2,\dots,i_T),O = (o_1,o_2,\dots,o_T)</script><p>$A$是状态转移概率矩阵:</p>
<script type="math/tex; mode=display">
A = [a_{ij}]_{N \times N}</script><p>其中:</p>
<script type="math/tex; mode=display">
a_{ij} = P(i_{t+1} = q_j | i_t = q_i),i=1,\dots,N;j=1,\dots,N</script><p>指代在时刻$t$处于状态$q_i$条件下,在时刻$t+1$转移到$q_j$的概率，$B$是观测概率矩阵:</p>
<script type="math/tex; mode=display">
B = [b_j(k)]_{N\times M}</script><p>其中:</p>
<script type="math/tex; mode=display">
b_j(k) = P(o_t = v_k|i_t = q_j),\quad k=1,2,\dots,M;\quad,j=1,2,\dots,N</script><p>指代在时刻$t$处于状态$q_j$条件下生成观测$v_k$的概率。$\pi$是初始是初始状态概率向量:</p>
<script type="math/tex; mode=display">
\pi = (\pi_i)</script><p>其中:</p>
<script type="math/tex; mode=display">
\pi_i = P(i_1 = q_i),\quad i =1,2,\dots,N</script><p>指代初始时刻处于状态$q_i$的概率。隐马尔可夫模型由初始状态概率向量$\pi$,状态转移概率矩阵$A$和观测概率矩阵$B$决定。$\pi$和$A$决定状态序列,$B$决定观测序列。因此，隐马尔可夫模型可以用三元符号表示:</p>
<script type="math/tex; mode=display">
\lambda = (\pi,A,B)</script><p>状态转移矩阵$A$与初始状态向量$\pi$确定了隐藏的马尔可夫链，生成不可观测的状态序列。观测概率矩阵$B$确定了如何从状态生成观测，与状态序列综合确定了如何产生观测序列。从定义来看，隐马尔可夫模型做了两个基本假设：</p>
<ol>
<li>齐次马尔可夫性假设，即假设隐藏的马尔可夫链在任意时刻$t$的状态只依赖于前一时刻的状态，与其他时刻的状态及观测无关，也与$t$无关：</li>
</ol>
<script type="math/tex; mode=display">
P(i_t| i_{t-1},o_{t-1},\dots,i_1,t_1) = P(i_t|i_{t-1}),\quad t = 1,2,\dots,T</script><ol>
<li>观测独立性假设,即假设在任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关:</li>
</ol>
<script type="math/tex; mode=display">
P(o_t|i_t,i_{t-1},o_{t-1},\dots,i_1,t_1) = P(o_t|i_t)</script><p>隐马尔可夫模型可用于标注,这时状态对应着标记。标注问题是给定观测的序列预测其对应的标记序列。可以假设标注问题的数据是由隐马尔可夫模型生成的。这样我们可以利用隐马尔可夫模型的学习与预测算法进行标注。</p>
<h4 id="观测序列的生成过程"><a href="#观测序列的生成过程" class="headerlink" title="观测序列的生成过程"></a>观测序列的生成过程</h4><p>根据隐马尔可夫模型定义,可以将一个长度为$T$的观测序列$O = (o_1,o_2,\dots,o_T)$的生成过程描述如下:</p>
<blockquote>
<p>输入： 隐马尔可夫模型$\lambda = (A,B,\pi)$,观测序列长度$T$<br>输出： 观测序列$O = (o_1,o_2,\dots,o_T)$</p>
<ol>
<li>按照初始状态分布$\pi$产生状态$i_1$</li>
<li>令$t=1$</li>
<li>按照状态$i<em>t$的观测概率分布$b</em>{i_t}(k)$生成$o_t$</li>
<li>按照状态$i<em>t$的状态转移概率分布${a</em>{i<em>t,i</em>{t+1}}}$产生状态$i_{t+1}$</li>
<li>令$t = t+1$,如果$t&lt;T$,转步(3),否则，终止</li>
</ol>
</blockquote>
<h4 id="隐马尔可夫模型的3个基本问题"><a href="#隐马尔可夫模型的3个基本问题" class="headerlink" title="隐马尔可夫模型的3个基本问题"></a>隐马尔可夫模型的3个基本问题</h4><p>隐马尔可夫模型有3个基本问题:</p>
<ul>
<li>概率计算问题,给定模型$\lambda = (A,B,\pi)$和观测序列$O = (o_1,o_2,\dots,o_T)$,计算在模型$\lambda$下观测序列$O$出现的概率$P(O|\lambda)$</li>
<li>学习问题，已知观测序列$O = (o_1,o_2,\dots,o_T)$,估计模型$\lambda = (A,B,\pi)$参数，使得在该模型下观测序列概率$P(O|\lambda)$。即用极大似然估计的方法估计参数。</li>
<li>预测问题，也称为解码问题。已知模型$\lambda = (A,B,\pi)$和观测序列$O = (o_1,o_2,\dots,o_T)$,求对给定观测序列条件概率$P(I|O)$最大的状态序列$I = (i_1,i_2,\dots,i_T)$。即给定观测序列，求最有可能的对应的状态序列。</li>
</ul>
<h3 id="概率计算算法"><a href="#概率计算算法" class="headerlink" title="概率计算算法"></a>概率计算算法</h3><h4 id="直接计算法"><a href="#直接计算法" class="headerlink" title="直接计算法"></a>直接计算法</h4><p>首先介绍最直观的直接计算法，给定模型和观测序列后，计算观测序列出现的概率的直接方法便是按照概率公式直接计算。通过列举所有可能的长度为$T$的状态序列，求各个状态序列$I$与观测序列$O$的联合概率$P(I,O|\lambda)$,然后对所有可能的状态序列求和，得到$P(O|\lambda)$。</p>
<p>状态序列$I = (i_1,i_2,\dots,i_T)$的概率是:</p>
<script type="math/tex; mode=display">
P(I|\lambda) = \pi_{i1}a_{i_1 i_2} a_{i_2 i_3} \dots a_{i_{T-1} i_T}</script><p>对固定的状态序列$I = (i_1,i_2,\dots,i_T)$,观测序列$O = (o_1,o_2,\dots,o_T)$的概率是:</p>
<script type="math/tex; mode=display">
P(O|I,\lambda) = b_{i_1}(o_1) b_{i_2}(o_2) \dots b_{i_T}(o_T)</script><p>$O$和$I$同时出现的联合概率为:</p>
<script type="math/tex; mode=display">
\begin{aligned}
         P(O,I|\lambda) &= P(O|I,\lambda) P(I|\lambda) \\\\
            &= \pi_{i_1}b_{i_1}(o_1) a_{i_1 i_2} b_{i_2}(o_2) \dots a_{i_{T-1}i_T} b_{i_T}(o_T)
    \end{aligned}</script><p>然后，对所有可能的状态序列$I$求和，得到观测序列$O$的概率$P(O|\lambda)$，即:</p>
<script type="math/tex; mode=display">
\begin{aligned}
         P(O,I|\lambda) &= \sum_{I} P(O|I,\lambda) P(I|\lambda) \\\\
            &= \sum_{i_1,i_2,\dots,i_T} \pi_{i_1}b_{i_1}(o_1) a_{i_1 i_2} b_{i_2}(o_2) \dots a_{i_{T-1}i_T} b_{i_T}(o_T)
    \end{aligned}</script><p>这种直接计算的复杂度是$O(TN^T)$,在实际中并不可行。</p>
<h4 id="前向算法"><a href="#前向算法" class="headerlink" title="前向算法"></a>前向算法</h4><p>首先定义前向概率：</p>
<blockquote>
<p>前向概率:给定隐马尔可夫模型$\lambda$,定义到时刻$t$部分观测序列为$o_1,o_2,\dots,o_t$且状态为$q_i$的概率为前向概率，记做：</p>
<script type="math/tex; mode=display">
\alpha_t(i) = P(o_1,o_2,\dots,o_t,i_t = q_i|\lambda)</script><p>由此便可以递推求得前向概率$\alpha_t(i)$和观测序列概率$P(O|\lambda)$</p>
<p><strong>观测序列概率的前向算法</strong><br>输入：隐马尔可夫模型$\lambda$,观测序列$O$<br>输出: 观测序列概率$P(O|\lambda)$</p>
<ul>
<li>初值：<script type="math/tex; mode=display">
\alpha_1(i) = \pi_i b_i(o_1),\quad i = 1,2,\dots, N</script></li>
<li>递推：对$t=1,2,\dots,T-1$<script type="math/tex; mode=display">
\alpha_{t+1}(i) = [\sum_{j=1}^N \alpha_t(j) a_{ji}] b_i(o_{t+1}),\quad i= 1,2,\dots,N</script></li>
<li>终止:<script type="math/tex; mode=display">
P(O|\lambda) = \sum_{i=1}^N \alpha_T(i)</script></li>
</ul>
</blockquote>
<p>前向算法实际上是基于“状态序列的路径结构”递推计算$P(O|\lambda)$的算法。前向算法高效的关键在于其局部计算前向概率，然后利用路径结构将前向概率递推到全局,得到$P(O|\lambda)$。</p>
<h4 id="后向算法"><a href="#后向算法" class="headerlink" title="后向算法"></a>后向算法</h4><p>首先给出后向概率的定义:</p>
<blockquote>
<p><strong>后向概率</strong>：给定隐马尔可夫模型$\Lambda$,定义在时刻$t$状态为$q<em>i$的条件下，从$t+1$到$T$的部分观测序列为$o</em>{t+1},o_{t+2},\dots,o_T$的概率为后向概率，记做：</p>
<script type="math/tex; mode=display">
\beta_t(i) = P(o_{t+1},o_{t+2},\dots,o_T|i_t = q_i,\lambda)</script></blockquote>
<p>与前向概率计算类似,后向概率的计算也可以采用递推算法:</p>
<blockquote>
<p><strong>观测序列概率的后向算法</strong><br>输入：隐马尔可夫模型$\lambda$,观测序列$O$<br>输出：观测序列概率$P(O|\lambda)$</p>
<ul>
<li>初始化:<script type="math/tex; mode=display">
\beta_T(i) = 1,\quad i =1,2,\dots,N</script></li>
<li>对$t = T-1,T-2,\dots,1$<script type="math/tex; mode=display">
\beta_t(i) = \sum_{j=1}^N a_{ij} b_j(o_{t+1})\beta_{t+1}(j),
\quad i=1,2,\dots,N</script></li>
<li>终止：<script type="math/tex; mode=display">
P(O|\lambda) = \sum_{i=1}^N \pi_i b_i(o_1)\beta_1(i)</script></li>
</ul>
</blockquote>
<p>利用前向概率与后向概率的定义可以将观测序列概率统一写成:</p>
<script type="math/tex; mode=display">
P(O|\lambda) =\sum_{i=1}^N \alpha_t(i) \beta_t(i) =\sum_{i=1}^N \sum_{j=1}^N \alpha_t(i)
    a_{ij} b_j(o_{t+1}) \beta_{t+1}(j)</script><p>该联合概率公式告诉我们，若我们知道了某一个时刻所有状态下的前向概率，同时知道下一个时刻所有状态下的后向概率，则可以直接计算出观测序列概率。前面介绍的三个计算观测序列概率的公式实际上为我们提供了三种递推思路:</p>
<ul>
<li>前向概率递推，即从前向后递推</li>
<li>后向概率递推，即从后向前递推</li>
<li>前向后向概率递推，即从两个方向开始递推</li>
</ul>
<p>这三种方法的计算复杂度均为$O(TN^2)$级别，对比直接计算的$O(TN^T)$级别，计算复杂度大大降低。</p>
<h4 id="一些概率与期望值的计算"><a href="#一些概率与期望值的计算" class="headerlink" title="一些概率与期望值的计算"></a>一些概率与期望值的计算</h4><p>利用前向概率和后向概率，可以得到关于单个状态和两个状态概率的计算公式。</p>
<ol>
<li>给定模型$\lambda$和观测$O$,在时刻$t$处于状态$q_i$的概率,记：<script type="math/tex; mode=display">
\gamma_t(i) = P(i_t = q_i|O,\lambda)</script>可以通过前向后向概率计算,由贝叶斯公式可得:<script type="math/tex; mode=display">
\gamma_t(i) = P(i_t = q_i|O,\lambda) = \frac{P(i_t = q_i,O|\lambda)}{P(O|\lambda)}</script>由此可以得到：<script type="math/tex; mode=display">
\gamma_t(i) = \frac{\alpha_t(i) \beta_t(i)}{\sum_{j=1}^N \alpha_t(j)\beta_t(j)}</script></li>
<li>给定模型$\lambda$和观测$O$,在时刻$t$处于状态$q_i$且在时刻$t+1$处于状态$q_j$的概率为：<script type="math/tex; mode=display">
\xi_t(i,j) = P(i_t = q_i, i_{t+1} = q_j | O,\lambda)</script>由贝叶斯公式可得：<script type="math/tex; mode=display">
\begin{aligned}
  \xi_t(i,j)  &= \frac{P(i_t = q_i,i_{t+1} = q_j, O|\lambda)}{P(O|\lambda)} \\\\
  &= \frac{P(i_t = q_i,i_{t+1} = q_j, O|\lambda)}{\sum_{i=1}^N \sum_{j=1}^N P(i_t = q_i,i_{t+1} = q_j, O|\lambda)}
\end{aligned}</script>公式中$P(i<em>t = q_i,i</em>{t+1} = q_j, O|\lambda)$计算公式为:<script type="math/tex; mode=display">
P(i_t = q_i,i_{t+1} = q_j, O|\lambda) = \alpha_t(i) a_{ij} b_j (o_{t+1}) \beta_{t+1}(j)</script></li>
<li>将$\gamma_t(i)$和$\xi_t(i,j)$对各个时刻$t$求和，可以得到一些期望值：</li>
</ol>
<ul>
<li>在观测$O$下状态$i$出现的期望值：<script type="math/tex; mode=display">
\sum_{t=1}^T \gamma_t(i)</script></li>
<li>在观测$O$下由状态$i$转移的期望值:<script type="math/tex; mode=display">
\sum_{t=1}^{T-1} \gamma_t(i)</script></li>
<li>在观测$O$下由状态$i$转移到状态$j$的期望值：<script type="math/tex; mode=display">
\sum_{t=1}^{T-1} \xi_t(i,j)</script></li>
</ul>
<h3 id="学习算法"><a href="#学习算法" class="headerlink" title="学习算法"></a>学习算法</h3><p>隐马尔可夫的学习算法可以根据数据类型分为两种：</p>
<ul>
<li>训练数据包含观测序列和状态序列, 此时可采用监督学习算法</li>
<li>训练数据仅有观测序列，此时需采用无监督学习算法</li>
</ul>
<h4 id="监督学习方法"><a href="#监督学习方法" class="headerlink" title="监督学习方法"></a>监督学习方法</h4><p>假设已给训练数据包含$s$个长度相同的观测序列和对应的状态序列${ (O_1,I_1),\dots,<br>(O_S,I_S)}$,那么可以直接采用极大似然法来估计马尔可夫参数,具体方法如下:</p>
<ol>
<li>转移概率$a<em>{ij}$的估计：设样本中时刻$t$处于状态$i$,而时刻$t+1$处于状态$j$出现<br>的频数为$A</em>{ij}$,那么状态转移概率$a_{ij}$的估计为：<script type="math/tex; mode=display">
\hat{a}_{ij} = \frac{A_{ij} }{\sum_{j=1}^N A_{ij} }</script>这其实就是一个伯努利分布的最大似然估计问题，计算比较简单。</li>
<li>观测概率$b<em>j(k)$的估计,设样本中状态为$j$并且观测为$k$的频数是$B</em>{jk}$,那么状态为$j$观测为$k$的估计是：<script type="math/tex; mode=display">
\hat{b}_j(k) = \frac{B_{jk}}{\sum_{k=1}^M B_{jk}}</script></li>
<li>初始状态概率$\pi_i$的极大似然估计为$S$个样本中初始状态为$q_i$的频率</li>
</ol>
<h3 id="无监督学习方法-BW算法"><a href="#无监督学习方法-BW算法" class="headerlink" title="无监督学习方法-BW算法"></a>无监督学习方法-BW算法</h3><p>假设训练数据只包含$S$个长度为$T$的观测序列${ O_1,O_2,\dots, O_S}$<br>而没有相应的状态序列，学习的目标是学习隐马尔可夫模型的参数。我们将观测序列<br>看做观测数据$O$,状态序列数据看做不可观测的隐数据$I$,那么隐马尔可夫实际上是<br>一个含有隐变量概率模型：</p>
<script type="math/tex; mode=display">
P(O|\lambda) = \sum_{I} P(O|I,\lambda)P(I|\lambda)</script><p>这是在EM算法解决框架下，可以按照EM算法步骤进行计算</p>
<ul>
<li>确定完全数据的对数似然函数，所有的观测数据写成$O = (o_1,o_2,\dots,o_T)$,<br>所有隐数据写成$I = (i_1,i_2,\dots,i_T)$。完全数据的对数似然函数是<br>$log P(O,I|\lambda)$</li>
<li>EM算法的E步:求$Q$函数$Q(\lambda,\bar{\lambda})$<script type="math/tex; mode=display">
\begin{aligned}
      Q(\lambda,\bar{\lambda}) &= E_I[logP(O,I|\lambda)P(O,I|\bar{\lambda})] \\\\
      &= \sum_I log P(O,I|\lambda) P(I|O,\bar{\lambda}) \\\\
      &= \sum_I log P(O,I|\lambda) \frac{P(I,O|\bar{\lambda})}{P(O|\bar{\lambda})}
\end{aligned}</script>又因为$P(O|\bar{\lambda})$与$\lambda$无关，而在接下来M步我们要做的是找到合适的<br>$\lambda$极大化$Q$函数，因此可以考虑将该项略去，将$Q$函数写做:<script type="math/tex; mode=display">
Q(\lambda,\bar{\lambda}) = \sum_I log P(O,I|\lambda) P(I,O|\bar{\lambda})</script>其中,$\bar{\lambda}$是隐马尔可夫模型的当前参数估计值,$\lambda$是要极大化的隐马尔<br>可夫模型参数。<script type="math/tex; mode=display">
P(O,I|\lambda) = \pi_{i_1} b_{i_1}(o_1) a_{i_1,i_2} b_{i_2}(o_2)
  \dots a_{i_{T-1}i_T} b_{i_T}(o_T)</script>于是$Q$函数可以写做:<script type="math/tex; mode=display">
\begin{aligned}
      Q(\lambda,\bar{\lambda}) &= \sum_I log \pi_{i_1} P(O,I|\bar{\lambda}) + \sum_I (\sum_{t=1}^{T-1} log a_{i_t i_{t+1}})
      P(O,I|\bar{\lambda})\\ &+ \sum_{I}(\sum_{t=1}^T log b_{i_t}(o_t))P(O,I|\bar{\lambda})
  \end{aligned}</script></li>
<li>EM算法M步：极大化$Q$函数$Q(\lambda,\bar{\lambda})$求模型参数$A,B,\pi$<br>由最终$Q$函数的写法可以看出，要极大化参数单独出现在三项中，因此只需对各项<br>分别极大化</li>
</ul>
<ol>
<li>求$\pi_{i_1}$估计值，第一项可以重写为：<script type="math/tex; mode=display">
\sum_I log \pi_{i_1} P(O,I|\bar{\lambda}) = \sum_{i=1}^N log \pi_{i} P(O,i_1 = i|\bar{\lambda})</script>同时需要注意到关于$\pi<em>i$的天然约束$\sum</em>{i=1}^N \pi_i = 1$,该优化问题可以通过<br>Lagrange乘子法进行求解，最终求解值为:<script type="math/tex; mode=display">
\pi_i = \frac{P(O,i_1 = i|\bar{\lambda})}{P(O|\bar{\lambda})}
 = \gamma_1(i)</script></li>
<li>求$a_{ij}$估计值，第二项可以重写为：<script type="math/tex; mode=display">
\sum_I (\sum_{t=1}^{T-1} log a_{i_t i_{t+1}})P(O,I|\bar{\lambda}) = 
 \sum_{i=1}^N \sum_{j=1}^N \sum_{t=1}^{T-1} log a_{i j} P(O,i_t = i,i_{t+1} = j|\bar{\lambda})</script>注意存在约束条件$\sum<em>{j=1}^N a</em>{ij} = 1$,应用Lagrange乘子法可得:<script type="math/tex; mode=display">
a_{ij} = \frac{\sum_{t=1}^{T-1} P(O,i_t = i,i_{t+1} = j|\bar{\lambda})}{\sum_{t=1}^{T-1} P(O,i_t = i|\bar{\lambda})}
  = \frac{\sum_{t=1}^{T-1} \xi_t(i,j)}{\sum_{t=1}^{T-1} \gamma_t(i)}</script></li>
<li>求$b_j(k)$的估计值，首先将第三项重写为:<script type="math/tex; mode=display">
\sum_{I}(\sum_{t=1}^T log b_{i_t}(o_t))P(O,I|\bar{\lambda}) = 
 \sum_{j=1}^N \sum_{t=1}^{T} log b_j(o_t) P(O,i_t = j|\bar{\lambda})</script>约束条件是$\sum_{k=1}^M b_j(k) = 1$。只有在$o_t = v_k$时,$b_j(o_t)$对$b_j(k)$的<br>偏导数才不为0,以$I(o_t = v_k)$表示,求得:<script type="math/tex; mode=display">
b_j(k) = \frac{\sum_{t=1}^T P(O,i_t =j|\bar{\lambda})I(o_t = v_k)}{\sum_{t=1}^T P(O,i_t = j|\bar{\lambda})}
 = \frac{\sum_{t=1,o_t = v_k}^T \gamma_t(j)}{\sum_{t=1}^T \gamma_t(j)}</script><blockquote>
<p>Baum-Welch算法：<br>输入：观测数据$O = (o_1,o_2,\dots,o_T)$<br>输出：隐马尔可夫模型参数</p>
<ul>
<li>初始化:对$n=0$,选取$a_{ij}^{(0)}, b_j(k)^{(0)},\pi_i^{(0)}$，得到模型<br>$\lambda^{(0)} = (A^{(0)},B^{(0)},\pi^{(0)})$</li>
<li>根据上面给出的公式进行递推</li>
<li>重复E步和M步。直到算法收敛</li>
</ul>
</blockquote>
</li>
</ol>
<h3 id="预测算法"><a href="#预测算法" class="headerlink" title="预测算法"></a>预测算法</h3><p>下面介绍两种隐马尔可夫模型的预测算法：近似算法与维特比算法。</p>
<h4 id="近似算法"><a href="#近似算法" class="headerlink" title="近似算法"></a>近似算法</h4><p>近似算法的想法是，在每个时刻$t$选择在该时刻最有可能出现的状态$i_t^*$,从而<br>得到一个状态序列$I^\ast = (i_1^\ast,i_2^\ast,\dots,i_T^\ast)$,将该序列作为预测的结果。<br>给定隐马尔可夫模型$\lambda$和观测序列$O$,在时刻$t$处于状态$q_i$的概率<br>$\gamma_t(i)$是：</p>
<script type="math/tex; mode=display">
\gamma_t(i) = \frac{\alpha_t(i)\beta_t(i)}{P(O|\lambda)} = 
 \frac{\alpha_t(i)\beta_t(i)}{\sum_{j=1}^N \alpha_t(j)\beta_t(j)}</script><p>在每一时刻$t$最有可能的状态$i_t^*$是:</p>
<script type="math/tex; mode=display">
i_t^* = argmax_{1 \leq i \leq N} [\gamma_t(i)],\quad t = 1,2,\dots,T</script><p>进而得到状态序列</p>
<script type="math/tex; mode=display">
I^* = (i_1^*,i_2^*,\dots,i_T^*)</script><p>近似算法优点是计算简单，其缺点是不能够保证预测的序列整体是最有可能的状态序列，这是因为预测的状态序列可能有实际不发生的部分。</p>
<h4 id="维特比算法"><a href="#维特比算法" class="headerlink" title="维特比算法"></a>维特比算法</h4><p>维特比算法实际上是用动态规划来解隐马尔可夫模型的预测问题，即用动态规划来求概率最大路径(最优路径)。这时一条路径对应着一个最优序列。<br>首先导入两个变量$\delta,\varPhi$,定义在时刻$t$状态为$i$的所有单个路径$(i_1,i_2,\dots,i_t)$中概率最大值为:</p>
<script type="math/tex; mode=display">
    \delta_t(i) = \max_{i_1,i_2,\dots,i_{t-1}} P(i_t = i,i_{t-1},\dots,i_1,o_t,\dots,o_1|\lambda)</script><p>由定义可知变量$\delta$的递推公式：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
     \delta_{t+1}(i) &= \max_{i_1,i_2,\dots,i_{t}} P(i_{t+1} = i,i_{t},\dots,i_1,o_{t+1},\dots,o_1|\lambda) \\
    &= max_{1 \leq j \leq N} [\delta_t(j) a_{ji}]b_i(o_{t+1})
    \end{aligned}</script><p>定义在时刻$t$状态为$i$的所有单个路径$(i<em>1,i_2,\dots,i</em>{t-1},i)$中概率最大的路径的第<br>$t-1$个结点为：</p>
<script type="math/tex; mode=display">
    \varPhi_t(i) = argmax_{1 \leq j \leq N}[\delta_{t-1}(j) a_{ji}],\quad i=1,\dots,N</script><p>下面给出维特比算法的流程:</p>
<blockquote>
<p><strong>维特比算法：</strong></p>
<ul>
<li>输入： 模型$\lambda = (A,B,\pi)$和观测$O = (o_1,o_2,\dots,o_T)$</li>
<li>输出： 最优路径$I^\ast -= (i_1^\ast,i_2^\ast,\dots,i_T^\ast)$</li>
</ul>
<ol>
<li>初始化<script type="math/tex; mode=display">
\delta_1(i) = \pi_i b_i(o_1),\varPhi_1(i) = 0</script></li>
<li>递推：对$t = 2,3,\dots,T$<script type="math/tex; mode=display">
\begin{aligned}
\delta_{t+1}(i) &= \max_{1 \leq j \leq N} [\delta_t(j) a_{ji}]b_i(o_{t+1}) \\
\varPhi_t(i) &= argmax_{1 \leq j \leq N}[\delta_{t-1}(j) a_{ji}]
\end{aligned}</script></li>
<li>终止<script type="math/tex; mode=display">
P^* = \max_{1 \leq i \leq N} \delta_T(i), i_T^* = argmax_{1 \leq i \leq N}
[\delta_T(i)]</script></li>
<li>最优路径回溯。对$t = T-1,T-2,\dots,1$<script type="math/tex; mode=display">
i_t^* = \varPhi_{t+1}(i_{t+1}^*)</script>求得最优路径$I^{\ast} = (i_1^\ast,i_2^\ast,\dots,i_T^\ast)$</li>
</ol>
</blockquote>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>概率模型，HMM</tag>
      </tags>
  </entry>
  <entry>
    <title>马尔可夫网络</title>
    <url>/2020/07/25/markov-network/</url>
    <content><![CDATA[<p>在这一部分我将介绍另一种常见的概率图模型:马尔可夫网络，或称马尔可夫随机场。接下来分为以下几部分进行组织<span id="more"></span>：</p>
<ul>
<li>马尔可夫网络</li>
<li>独立性假设</li>
<li>势函数</li>
</ul>
<h3 id="马尔可夫网络"><a href="#马尔可夫网络" class="headerlink" title="马尔可夫网络"></a>马尔可夫网络</h3><p>首先给出维基百科上关于马尔可夫网络的定义：</p>
<blockquote>
<p>马尔可夫网络是一组有马尔可夫性质随机变量$X$的全联合概率分布模型。马尔可夫网络类似贝叶斯网络用于表示依赖关系。但是，一方面它可以表示贝叶斯网络无法表示的一些关系，如循环依赖；另一方面，它不能表示贝叶斯网络能够表示的某些关系，如推导关系。</p>
</blockquote>
<p>马尔可夫网络具有以下特征：</p>
<ul>
<li>无向图$H = (V,E)$</li>
<li>每个顶点$v \in V$表示一个在集合$X$的随机变量，每条边${u,v}\in E$ 表示随机变量$u$和$v$之间的依赖关系</li>
</ul>
<h3 id="独立性假设"><a href="#独立性假设" class="headerlink" title="独立性假设"></a>独立性假设</h3><p>马尔可夫网络与贝叶斯网络类似，以图的形式对独立性假设进行编码，首先给出图中激活路径的概念：</p>
<ul>
<li>激活路径：一个路径$X_1,X_2,\dots,X_n$是激活的 $\Leftrightarrow$ 没有路径上的变量被观测到  </li>
</ul>
<p>有了激活路径概念之后，便可以讨论图中的条件独立关系：</p>
<ul>
<li>在图$H$中，节点集$X$与节点集$Y$相对于是节点集$Z$是分离的 $\Leftrightarrow$ $X$与$Y$之间不存在激活路径</li>
<li>表示为$sep_H(X;Y|Z)$,栗子如下图所示。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/xuejy19/Images/master/mav1.png" alt="栗子"></p>
<h3 id="势函数"><a href="#势函数" class="headerlink" title="势函数"></a>势函数</h3><p>在贝叶斯网络中，节点之间的关系通过条件概率进行表征，而在马尔可夫网络中，节点之间的关系通过势函数来表征，势函数定义如下：</p>
<blockquote>
<p>一个函数集合$f_k$(也称为因子或者团因子有时也称为特征)，每一个$f_k$的定义域是图$G$的团或子团$k$,每一个$f_k$是从可能的特定联合的指派(到元素$k$)到非负实数的映射。</p>
</blockquote>
<p>总结而言，势函数具有以下特征：</p>
<blockquote>
<ul>
<li>非负</li>
<li>与条件概率不同，其求和不必为1</li>
</ul>
</blockquote>
<h3 id="吉布斯分布"><a href="#吉布斯分布" class="headerlink" title="吉布斯分布"></a>吉布斯分布</h3><p>我们引入该图模型的目的在于：<strong>通过马尔可夫网络来对变量之间的独立性关系进行编码，然后获得对于联合概率分布更加紧凑的表示形式</strong>，而吉布斯分布便是将联合概率与势函数相连接的桥梁。<br>一个概率分布$P$可以分解为图$H$：</p>
<blockquote>
<ul>
<li>$H$可以分为若干子团$D_i$</li>
<li>在每个子团上相应定义了势函数$\pi_i$</li>
</ul>
</blockquote>
<p>由此便可以写出吉布斯分布形式：</p>
<script type="math/tex; mode=display">
\begin{aligned}
     P(X_1,X_2,\dots,X_n) = \frac{1}{Z} f(X_1,X_2,\dots,X_n) 
\end{aligned}</script><p>其中:</p>
<blockquote>
<ul>
<li>$f(X<em>1,X_2,\dots,X_n) = \prod</em>{i=1}^m \pi_i(D_i)$</li>
<li>$Z = \sum_{X_1,\dots,X_n} f(X_1,\dots,X_n)$</li>
</ul>
</blockquote>
<p>每一个势函数定义了一个映射:$Sub(X) \rightarrow \mathcal{R^+}$ ,一个势函数的定义域相当于是一个集合，而这个集合中的变量彼此之间是直接依赖关系，从这个视角来看，条件概率可以看作是势函数的特例(仅仅表征两个变量之间依赖关系)。</p>
<p>下面我们讨论下一个势函数(因子)应该定义在一个多大的集合上，首先考虑如果在每条边上均定义一个势函数，那么马尔可夫网络能否表征联合概率分布？答案是并不行，为此我以一个7个节点(均为二值变量)的全连接网络为例，分别讨论两种情况下具有的独立参数的数量：</p>
<ul>
<li>联合概率分布：$2^7 - 1 = 127$</li>
<li>边上势函数：$4*C_7^2 = 84$</li>
</ul>
<p>显然对于全连接网络，若给予每个边一个势函数并不足以表征联合概率分布，在前面已经说明一个势函数定义域中的变量应当是两两直接相关，因此势函数的定义域应当是一个团(clique)。<br>$\Rightarrow$ <strong>马尔可夫网络中的局部结构是团</strong></p>
<h3 id="马尔可夫网络分解"><a href="#马尔可夫网络分解" class="headerlink" title="马尔可夫网络分解"></a>马尔可夫网络分解</h3><p>首先给出$I-Map$的概念:$H$为一个马尔可夫网络，$P$为联合概率分布，若有$I(H) \subseteq I(P)$，则称马尔可夫网络$H$为分布$P$的一个$I-Map$。 </p>
<p>记$D_i$为马尔可夫网络$H$中的子团，Hammersley-Clifford定理如下：</p>
<blockquote>
<p>对于一个无向图$H$和分布$P$,$P$可以被分解成$P(X) = \frac{1}{Z}\prod \pi_i (D_i) \Leftrightarrow$ $H$是$P$的$I-Map$</p>
</blockquote>
<p>在实际进行分解时一般都是在最大团上定义势函数</p>
<h3 id="对数表示"><a href="#对数表示" class="headerlink" title="对数表示"></a>对数表示</h3><p>在马尔可夫网络中，联合分布除了可以利用吉布斯分布来进行表示，也可以采取对数表示的方法，将原始的势函数$\pi_i(D_i)$ 表示成$exp(-\epsilon(D_i))$的形式，其中$\epsilon(D_i) = -log(\pi_i(D_i))$,据此，联合概率分布可以表示成：</p>
<script type="math/tex; mode=display">
    P(X_1,X_2,\dots,X_n) = \frac{1}{Z} exp(-\sum_{i=1}^m \epsilon(D_i))</script><p>这种表示方法将连乘变成了连家，计算更加方便，同时有定理证明，若无向图$H$是分布$P$的一个独立映射，那么$\epsilon(D_i) = \omega_i \phi_i(D_i)$,此时$\phi$被称作特征函数，与势函数关系为：</p>
<script type="math/tex; mode=display">
    \pi_i(D_i) = exp(\omega_i \phi_i(D_i))</script>]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>无向图</tag>
      </tags>
  </entry>
  <entry>
    <title>SVM</title>
    <url>/2020/08/12/svm/</url>
    <content><![CDATA[<p>这部分将介绍支持向量机(SVM)算法，该部分将按照以下几部分进行组织：</p>
<ul>
<li>算法历史</li>
<li>线性可分支持向量机与硬间隔最大化</li>
<li>线性支持向量机与软间隔最大化</li>
<li>非线性支持向量机与核函数</li>
<li>SVDD<span id="more"></span>
</li>
</ul>
<h3 id="算法历史"><a href="#算法历史" class="headerlink" title="算法历史"></a>算法历史</h3><p>支持向量机算法是在机器学习领域非常著名的算法，在神经网络算法得到普及之前，支持向量机算法可以说是统治了机器学习领域的半壁江山，该算法由Vapnik在贝尔实验室开发，根据Vapnik和Chervonekis提出的统计学习框架或VC理论，它提出了一种最可靠的预测方法（ 1974年）和瓦普尼克（Vapnik）（1982年，1995年）。给定一组训练示例，每个训练示例都标记为属于两个类别中的一个或另一个，则SVM训练算法会构建一个模型，该模型将新示例分配给一个类别或另一个类别，使其成为非概率 二进制 线性分类器（尽管方法例如Platt缩放存在以在概率分类设置中使用SVM）。SVM模型是将示例表示为空间中的点，并进行了映射，以使各个类别的示例被尽可能宽的明显间隙分开。然后，将新示例映射到相同的空间，并根据它们落入的间隙的侧面来预测属于一个类别。<br>除执行线性分类外，SVM还可以使用所谓的内核技巧有效地执行非线性分类，将其输入隐式映射到高维特征空间。</p>
<h3 id="线性可分支持向量机与硬间隔最大化"><a href="#线性可分支持向量机与硬间隔最大化" class="headerlink" title="线性可分支持向量机与硬间隔最大化"></a>线性可分支持向量机与硬间隔最大化</h3><p>对于线性可分数据，上一部分介绍的感知机算法便可以处理，但需要注意的是，感知机算法学习得到的超平面可能有无穷多个，那么这些超平面中哪个是最优的呢？支持向量机算法便回答了这一问题，该算法认为使两类样本点间隔最大的超平面是最优超平面。首先给出线性可分支持向量机的定义：</p>
<blockquote>
<p>{\ast}线性可分支持向量机{\ast}:给定线性可分训练数据集，通过间隔最大化或者等价地求解相应的凸二次规划问题学习得到的分离超平面为：</p>
<script type="math/tex; mode=display">
    \omega^{\ast} \cdot x + b^{\ast} = 0</script><p>以及相应的分类决策函数:</p>
<script type="math/tex; mode=display">f(x) = sign(\omega^{\ast} \cdot x + b^{\ast})</script></blockquote>
<p>下面就结合下图来对支持向量机的算法思想进行阐述,图中红点与蓝点分别代表两个类别，我们现在期望找到一个超平面，使得两个类别的样本点都能够尽可能离该超平面距离远，也就是希望中间的margin尽可能大。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/SVM.png" alt="SVM"><br>这便是支持向量机的思想，下一步需要做的便是将这种想法翻译成一个数学问题，在这里首先引入两个间隔的概念：</p>
<blockquote>
<ul>
<li>几何间隔：所谓几何间隔就是样本点$(x_i,y_i)$到超平面的实际距离，其计算公式为(此时样本点已经被超平面正确分类)：<script type="math/tex; mode=display">d = y_i \frac{\omega x_i + b}{||\omega||}</script></li>
<li>函数间隔：不考虑几何间隔中$||\omega||$便得到了函数间隔：<script type="math/tex; mode=display">d = y_i(\omega x_i +b)</script></li>
</ul>
</blockquote>
<p>需要注意的是，函数间隔可以表示分类预测的正确性及确信度，在感知机学习中，我们便是使用函数间隔，这是由于数据线性可分，最终目标函数都会收敛到0，使用几何间隔与函数间隔最终效果并无不同(两种间隔符号一致)。但在支持向量机算法中，我们希望间隔最大，这时显然函数间隔是不够的，因为只要成比例的增大$\omega,b$，超平面并没有改变，但是函数间隔却便为两倍，因此在该问题中，我们应当使用几何间隔,至此支持向量机的思想可以写成如下优化问题的形式：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &max_{\omega,b} \quad \gamma  \\
        &s.t. \quad y_i \frac{\omega x_i +b}{||\omega||} \geq \gamma,\quad i = 1,2,\dots,N
    \end{aligned}</script><p>上面是优化问题的原始形式，下面尝试对该优化问题进行等价转换以便于求解，首先根据几何间隔与函数间隔的关系，将优化问题转化为：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
         &max_{\omega,b} \quad \frac{\hat{\gamma}}{||\omega||}  \\
        &s.t. \quad y_i (\omega x_i +b) \geq \hat{\gamma},\quad i = 1,2,\dots,N
    \end{aligned}</script><p>此时可以注意到函数间隔$\hat{\gamma}$并不影响该优化问题求解，因此考虑将$\hat{\gamma}$置为1，注意到最大化$\frac{1}{||\omega||}$等价于最小化$\frac{1}{2}||\omega||^2$,因此优化问题最终可以表述为:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &min_{\omega,b} \quad \frac{1}{2} ||\omega||^2 \\\\
        &s.t. \quad y_i (\omega x_i +b) \geq 1,\quad i = 1,2,\dots, N
    \end{aligned}</script><p>这是一个典型的凸二次规划问题，运用凸优化知识可进行求解。</p>
<p>下面给出一个定理来说明最大间隔分离超平面唯一的定理：</p>
<blockquote>
<p>定理：若训练数据集$T$线性可分，则可将训练数据集中的样本点完全分开的最大间隔分离超平面存在且唯一</p>
</blockquote>
<h4 id="支持向量与间隔边界"><a href="#支持向量与间隔边界" class="headerlink" title="支持向量与间隔边界"></a>支持向量与间隔边界</h4><p>首先给出支持向量的定义:</p>
<blockquote>
<p>在线性可分情况下，训练数据集中样本点中与分离超平面距离最近的样本点的实例称为支持向量。</p>
</blockquote>
<p>反映在优化问题中，支持向量满足约束条件的等号,支持向量在超平面:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
         H_1&: \omega \cdot x +b =1  \\
         H_2&: \omega \cdot x +b = -1
    \end{aligned}</script><p>两个支撑超平面之间的距离称为间隔，该间隔距离为：</p>
<script type="math/tex; mode=display">
    d = \frac{2}{||\omega||}</script><p>在决定分离超平面时只有支持向量起作用，而其他实例点并不起作用。</p>
<h4 id="学习的对偶算法"><a href="#学习的对偶算法" class="headerlink" title="学习的对偶算法"></a>学习的对偶算法</h4><p>在进行求解时，我们往往考虑不直接求解原问题，而是求解原问题的对偶问题, 又因为原问题是一个凸优化问题，同时满足Slater约束品性，因此考虑求解其对偶问题。首先写出Lagrange函数：</p>
<script type="math/tex; mode=display">
    L(\omega,b,\alpha) = \frac{1}{2}||\omega^2|| - \sum_{i=1}^N \alpha_i y_i (\omega \cdot x_i +b) + \sum_{i=1}^N \alpha_i</script><p>接下来求解对偶函数，对偶函数$g(\alpha)$表示为：</p>
<script type="math/tex; mode=display">
    g(\alpha) = \min_{\omega,b} L(\omega,b,\alpha)</script><p>因为$L(\omega,b,\alpha)$是凸函数，因此只需要对$\omega,b$求偏导，令偏导等于0即可：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \frac{\partial L(\omega,b,\alpha)}{\partial \omega} &= \omega - \sum_{i=1}^N \alpha_i y_i x_i = 0 \rightarrow \omega =  \sum_{i=1}^N \alpha_i y_i x_i  \\\\
        \frac{\partial L(\omega,b,\alpha)}{\partial b} &= -\sum_{i=1}^N \alpha_i y_i = 0 \rightarrow \sum_{i=1}^N \alpha_i y_i = 0
    \end{aligned}</script><p>回代拉格朗日函数，可得对偶函数：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
          g(\alpha) &= \frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_i x_i^T x_j - \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_i x_i^T x_j + \sum_{i=1}^N \alpha_i  \\\\
          &= -\frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_i x_i^T x_j + \sum_{i=1}^N \alpha_i
    \end{aligned}</script><p>所以，对偶优化问题可以写做：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &\max_{\alpha} \quad -\frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_i x_i^T x_j + \sum_{i=1}^N \alpha_i \\\\
        &s.t. \quad \sum_{i=1}^N \alpha_i y_i =0;\alpha_i \geq 0,i=1,\dots,N
    \end{aligned}</script><p>对于该问题的求解可以通过SMO(序列最小优化)算法进行求解，因为强对偶性成立,KKT条件满足：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &\nabla_{\omega} L(\omega^{\ast},b^{\ast},\alpha^{\ast}) = \omega^{\ast} - \sum_{i=1}^N \alpha_i^{\ast} y_i x_i = 0 \\
        &\nabla_{b} L(\omega^{\ast},b^{\ast},\alpha^{\ast}) = -\sum_{i=1}^N \alpha_i^{\ast} y_i = 0 \\
        &\alpha_i^{\ast} (y_i(\omega^{\ast}x_i+b^{\ast})-1) = 0 \\
       &y_i(\omega^{\ast} x_i +b^{\ast}) - 1 \geq 0 \\
        &\alpha_i^{\ast} \geq 0 
    \end{aligned}</script><p>由此便可建立对偶问题最优解$\alpha^{\ast}$与原问题最优解$\omega^{\ast},b^{\ast}$之间的关系，首先至少有一个$\alpha_j^{\ast}&gt;0$,这是因为若$\alpha^{\ast}$均为0，则$\omega^{\ast}$为0,这不是原始最优化问题的解，假设$\alpha_j^{\ast}&gt;0$,则由互补松弛条件，此时有$y_j(\omega^{\ast} x_j +b^{\ast}) = 1$,而$\omega^{\ast}$表达式是知道的，由此可得$\omega^{\ast},b^{\ast}$表达式为：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \omega^{\ast} &= \sum_{i=1}^N \alpha_i^{\ast} y_i x_i \\
        b^{\ast} &=  y_j - \sum_{i=1}^N \alpha_i^{\ast} y_i(x_i\cdot x_j)
    \end{aligned}</script><p>至此，我们便通过求解对偶问题得到了原始问题的最优解，得到了超平面方程以及判决方程：</p>
<script type="math/tex; mode=display">
\begin{aligned}
    &\omega^{\ast} \cdot x + b^{\ast} = 0 \\
    &f(x) = sign(\omega^{\ast} \cdot x + b^{\ast})
\end{aligned}</script><p>通过引入对偶问题，我们便可以从数学的角度导出支持向量:</p>
<blockquote>
<p>训练数据集中对应于$\alpha_i^{\ast} &gt;0$的样本点称为支持向量</p>
</blockquote>
<h3 id="线性支持向量机与软间隔最大化"><a href="#线性支持向量机与软间隔最大化" class="headerlink" title="线性支持向量机与软间隔最大化"></a>线性支持向量机与软间隔最大化</h3><h4 id="原始问题"><a href="#原始问题" class="headerlink" title="原始问题"></a>原始问题</h4><p>前面介绍的算法是针对线性可分数据,那么对于大部分线性可分的数据集，支持向量机能否处理呢？答案是可以，但是需要对原始优化问题做适当变换,对于线性可分的数据，我们要求各个样本点到分类超平面的函数间隔都要大于1，对于不可分数据点，我们直观上的想法是考虑能否将该约束放松，因此我们考虑为每一个样本点引入一个松弛变量$\xi_i$,使得函数间隔加上松弛变量等于1。这样，约束条件变为:</p>
<script type="math/tex; mode=display">
    y_i(\omega \cdot x_i +b) \geq 1 - \xi_i</script><p>但需要注意的人，该松弛变量的引入是有代价的，需要在目标函数中进行惩罚，因此考虑在目标函数中加入惩罚项$\xi_i$，将目标函数改写为：</p>
<script type="math/tex; mode=display">
    \frac{1}{2} ||\omega||^2  + C\sum_{i=1}^N \xi_i</script><p>其中$C$是惩罚系数，$C$值大时对误分类惩罚增大。最小化该目标函数包含两层含义：使间隔尽量大；使误分类点尽量少。线性不可分支持向量机的学习问题变为如下凸二次规划问题：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &\min_{\omega,b,\xi} \quad \frac{1}{2} ||\omega||^2 + C \sum_{i=1}^N \xi_i \\\\
        &s.t. \quad y_i(\omega x_i +b) \geq 1- \xi_i,i=1,2,\dots,N \\\\
        &\qquad \xi_i \geq 0,i=1,2,\dots,N
    \end{aligned}</script><p>对于该原始问题，可以证明$\omega$的解是唯一的，但$b$的解可能不唯一，而是存在一个区间。</p>
<h4 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h4><p>在该部分便不进行对偶问题推导了，步骤与上一部分一致，最终得到的对偶问题形式为：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &\max_{\alpha} \quad -\frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_i x_i^T x_j + \sum_{i=1}^N \alpha_i \\\\
        &s.t. \quad \sum_{i=1}^N \alpha_i y_i =0,i=1,\dots,N  \\\\
        & \qquad 0 \leq \alpha_i \leq C \quad i=1,2,\dots,N
    \end{aligned}</script><p>可以看到引入松弛变量后对偶问题形式基本未发生变化，仅仅约束条件中$\alpha_i$范围变了。需要注意的是将原始问题转化为对偶问题的过程中，引入了两个Lagrange算子$\alpha_i,\mu_i$，但由于存在$<br>\alpha_i + \mu_i = C $以及$\alpha_i \geq 0, \mu_i \geq 0 $,因此将这些约束条件简化为$0 \leq \alpha_i \leq C$。<br>下面讨论如何根据对偶问题最优解求解原问题最优解，与硬间隔支持向量机不同，在该问题中，互补松弛条件有两个:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &\alpha_i^{\ast} (y_i(\omega^{\ast}x_i+b^{\ast})-1 + \xi_i) = 0  \\
        &\mu_i \xi_i = 0 
    \end{aligned}</script><p>在求解$b^{\ast}$时，关键是要将支持向量确定出来，首先支持向量应当在支撑超平面上，这就要求$\alpha_i&gt;0$,同时松弛间隔$\xi_i$应当为0，由第二个互补松弛条件可知$\mu_i$不能够为0，因此$\alpha_i$必须小于$C$,换句话说，$\alpha^{\ast} = C$所对应的点均在支撑超平面以内，若$\xi_i&lt;1$,则仍能分类正确，若大于1，则就会分类错误。$\omega^{\ast}$和$b^{\ast}$表达式可以写做：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \omega^{\ast} &= \sum_{i=1}^N \alpha_i^{\ast} y_i x_i \\
        b^{\ast} &= y_j - \sum_{i=1}^N y_i \alpha_i^{\ast} (x_i \cdot x_j)
    \end{aligned}</script><h4 id="非线性支持向量机与核函数"><a href="#非线性支持向量机与核函数" class="headerlink" title="非线性支持向量机与核函数"></a>非线性支持向量机与核函数</h4><p>支持向量机是解决线性分类问题的一种有效方法，但并不能解决非线性分类问题，那么非线性的数据就不能用线性的方法解决么？ 直观上我们有这样一个方法，考虑降维度线性不可分的数据映射到高维度，使映射后的数据在高维度线性可分，由此便引出了本节的核函数。</p>
<h4 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h4><p>首先先举一个空间变换的栗子，设原空间为$\mathcal{X} \subset R^2,x = (x^1,x^2)^T$,新空间为$\mathcal{Z} \subset R^2,z = (z^1,z^2)^T$,定义从原空间到新空间的映射：</p>
<script type="math/tex; mode=display">
    z = \phi(x) = ((x^1)^2,(x^2)^2)^T</script><p>经过这样一个变换原空间中的椭圆：</p>
<script type="math/tex; mode=display">
    w_1 (x^1)^2 + w_2 (x^2)^2 +b = 0</script><p>变换为了新空间中的直线：</p>
<script type="math/tex; mode=display">
    w_1 z^1 + w_2 z^2 + b = 0</script><p>这样，原空间的非线性可分问题就变成了新空间的线性可分问题。从该问题出发，我们可以总结出用线性分类方法求解非线性分类问题的步骤：</p>
<ul>
<li>首先使用一个变换将原空间中的数据映射到新空间</li>
<li>在新空间中使用线性分类学习方法从训练数据中学习分类模型</li>
</ul>
<p>而在支持向量机中，达到这一目的的方法应用核技巧，下面首先给出核函数的定义：</p>
<blockquote>
<p>核函数：设$\mathcal{X}$是输入空间，又设$\mathcal{H}$为特征空间(希尔伯特空间),如果存在一个从$\mathcal{X}$到$\mathcal{H}$的映射：</p>
<script type="math/tex; mode=display">
    \phi(x):\mathcal{X} \rightarrow \mathcal{H}</script><p>使得对所有$x,z \in \mathcal{X}$,函数$K(x,z)$满足条件:</p>
<script type="math/tex; mode=display">
    K(x,z) = \phi(x) \cdot \phi(z)</script><p>则称$K(x,z)$为核函数，$\phi(x)$为映射函数</p>
</blockquote>
<p>核技巧的想法是，在学习与预测中只定义核函数$K(x,z)$,而不显式的定义映射函数$\phi$。同时，对于一个核$K(x,z)$,特征空间$\mathcal{H}$和映射函数$\phi$的取法并不唯一</p>
<h4 id="非线性支持向量机"><a href="#非线性支持向量机" class="headerlink" title="非线性支持向量机"></a>非线性支持向量机</h4><p>在线性支持向量机的对偶问题中,无论是目标函数还是决策函数中均只包含实例的内积的形式，因此若用$K(x,y)$代替$x\cdot y$,实际上便是在对高维空间中的特征点设计线性分类器。那现在的关键问题便在于如何选择合适的核函数。</p>
<p>关于核函数这部分的理论我后面会另开一个章节进行介绍学习，在这一部分便直接给出一些常用的核函数：</p>
<ul>
<li>多项式核函数:<script type="math/tex; mode=display">K(x,z) = (x\cdot z +1)^p</script></li>
<li>高斯核函数(径向基函数)<script type="math/tex; mode=display">K(x,z) = exp(- \frac{||x-z||^2}{2\sigma^2})</script></li>
</ul>
<p>需要注意的是，在引入核函数后，又多引入了超参数，比如高斯核函数中的$\sigma$,而这些超参数的选择也会对分类效果产生影响。</p>
<h3 id="一类分类器设计"><a href="#一类分类器设计" class="headerlink" title="一类分类器设计"></a>一类分类器设计</h3><p>在前面介绍的支持向量机算法中，针对的都是二分类情况，但当我们做故障检测时，往往就只有大量的正常样本点，现在我们需要根据这些正常样本点来设计一个分类器以对未出现的异常样本点进行检测。在这一部分介绍两种算法：</p>
<ul>
<li>OCSVM</li>
<li>SVDD</li>
</ul>
<h4 id="OCSVM"><a href="#OCSVM" class="headerlink" title="OCSVM"></a>OCSVM</h4><p>在OCSVM中，将坐标原点作为唯一的异常点,最大化最优超平面到远点的距离，若记$\rho$为从原点到超平面的距离，$\xi_i$为松弛变量，则优化问题可以写做：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &\max_{\omega,\rho,\xi_i} \rho - C\sum_{i=1}^N \xi_i \\
        & s.t. \quad \omega \cdot x_i \geq \rho - \xi_i,\xi_i \geq 0,||\omega|| = 1
    \end{aligned}</script><h4 id="SVDD"><a href="#SVDD" class="headerlink" title="SVDD"></a>SVDD</h4><p>SVDD的基本思想则是，对于$n$维空间中的数据点集，寻找最小超球面，使其成为所有点的边界，其对应优化问题的原问题为:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
         &\min_{a,R,\xi} \quad R^2 + C\sum_{i=1}^N \xi_i \\
         &s.t. \quad ||x_i -a||^2 \leq R^2 + \xi_i \\
         &\qquad \quad \xi_i \geq 0 
    \end{aligned}</script>]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>支持向量机</tag>
      </tags>
  </entry>
  <entry>
    <title>SVM补充</title>
    <url>/2020/10/05/svm-bu-chong/</url>
    <content><![CDATA[<p>之前章节关于<a href="https://soundofwind.top/2020/08/12/svm/">支持向量机</a>的介绍已经比较详细了，最近发现有一些部分细节理解差一些意思，同时少了一部分内容，今天就在这里补充下，该部分章节按照以下结构组织:</p>
<ul>
<li>优化问题等价 </li>
<li>从硬间隔svm到软间隔svm </li>
<li>svm应用于多分类问题 </li>
<li>支持向量回归svr<span id="more"></span>
<h3 id="优化问题等价"><a href="#优化问题等价" class="headerlink" title="优化问题等价"></a>优化问题等价</h3>在求解优化问题时，我们往往考虑会将优化问题进行等价转换，以使得优化问题的求解更加容易，在进行极大似然估计时我们转化为求解对数似然函数极大就是一个典型的例子。这部分就系统的总结一下如何进行优化问题的等价转换,这里首先给出等价优化问题的定义:<blockquote>
<p><strong>等价优化问题:</strong> 对于两个优化问题，如果从一个优化问题的解可以很容易得到另一个优化问题的解，反之亦然，则称两个优化问题是等价的。 </p>
</blockquote>
</li>
</ul>
<p>一般优化问题的形式为:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &\min \quad f_0(x)  \\
        & \ s.t. \quad f_i(x) \leq 0,i=1,2,\dots,m \\
        &   \qquad \ \;  h_i(x)  = 0 , i =1,2,\dots, p
    \end{aligned}</script><p>下面给出将其转化为一个等价优化问题的几种转化思路。 </p>
<h4 id="变量替换"><a href="#变量替换" class="headerlink" title="变量替换"></a>变量替换</h4><p>假设存在函数$\phi: R^n \rightarrow R^n$, 并且是一个<strong>双射</strong>(one-map-one),同时该函数的值域可以覆盖原优化问题的定义域$\mathcal{D}$，即$\mathcal{D} \subseteq \phi(\rm{dom} \phi)$,此时定义函数$\tilde{f}_i, \tilde{h}_i$:</p>
<script type="math/tex; mode=display">
\tilde{f}_{i}(z)=f_{i}(\phi(z)), \quad i=0, \ldots, m, \quad \tilde{h}_{i}(z)=h_{i}(\phi(z)), \quad i=1, \ldots, p</script><p>则可以得到优化问题: </p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\operatorname{minimize} & \tilde{f}_{0}(z) \\
\text { subject to } & \tilde{f}_{i}(z) \leq 0, \quad i=1, \ldots, m \\
& \tilde{h}_{i}(z)=0, \quad i=1, \ldots, p
\end{array}</script><p>$x$与$z$之间的关系为$x = \phi(z)$, 假设$x$是原始优化问题的解，则$z = \phi^{-1}(x)$便是上述优化问题的解，同理，如果$z$是上述优化问题的解，则$x = \phi(z)$就是原始优化问题的解。</p>
<h4 id="转换优化目标函数和约束函数"><a href="#转换优化目标函数和约束函数" class="headerlink" title="转换优化目标函数和约束函数"></a>转换优化目标函数和约束函数</h4><p>假设存在函数$\psi<em>0:\mathbf{R} \rightarrow \mathbf{R}$是单调递增的，同时存在函数$\psi_1, \psi_2, \dots, \psi_m: \mathbf{R} \rightarrow \mathbf{R}$ 满足$\psi_i(\mu) \leq 0$当且仅当$\mu \leq 0$; 并且存在$\psi</em>{m+1}, \psi<em>{m+2}, \dots, \psi</em>{m+p}: \mathbf{R} \rightarrow \mathbf{R}$满足$\psi_i(\mu) = 0$当且仅当$\mu = 0$。定义函数$\tilde{f}_i, \tilde{h}_i$如下:</p>
<script type="math/tex; mode=display">
\tilde{f}_{i}(x)=\psi_{i}\left(f_{i}(x)\right), \quad i=0, \ldots, m, \quad \tilde{h}_{i}(x)=\psi_{m+i}\left(h_{i}(x)\right)</script><p>变换后的优化问题表示为:</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\operatorname{minimize} & \tilde{f}_{0}(x) \\
\text { subject to } & \tilde{f}_{i}(x) \leq 0, \quad i=1, \ldots, m \\
& \tilde{h}_{i}(x)=0, \quad i=1, \ldots, p
\end{array}</script><p>该优化问题与原始优化问题是一致的，实际上，该优化问题与原始优化问题有着相同的可行集和最优解，在求解极大似然函数时我们转化为求解对数似然函数极大便是这样的等价思路。</p>
<h4 id="引入松弛变量"><a href="#引入松弛变量" class="headerlink" title="引入松弛变量"></a>引入松弛变量</h4><p>在进行优化时我们往往更加喜欢等式约束，求解更加容易，对于不等式约束:</p>
<script type="math/tex; mode=display">
    f_i(x) \leq 0, i = 1,2,\dots,m</script><p>可以考虑引入松弛变量$s_i$，将上述约束等价为下面的约束条件:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        f_i(x) + s_i &= 0， i= 1, 2, \dots, m \\
        s_i &\geq 0，i = 1,2,\dots, m
    \end{aligned}</script><p>通过引入松弛变量，将$m$个一般的不等式约束转化为$m$个等式约束和$m$个非负约束，使得求解更加容易。同时在某些情况下引入松弛变量可以起到放松约束，增大可行域范围的作用，比如在SVM中，原始的不等式约束为:</p>
<script type="math/tex; mode=display">
    y_i w^T x_i \geq 1</script><p>通过引入松弛变量$\xi_i$,可以将上述不等式约束放松为:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        y_i w^T x_i &\geq 1 - \xi_i \\  
        \xi_i  & \geq 0, i = 1,2, \dots, N
    \end{aligned}</script><p>这样就拓宽了可行域，使得算法容许存在在支撑超平面之内的点，导出了软间隔支持向量机算法。 </p>
<h4 id="消除等式约束"><a href="#消除等式约束" class="headerlink" title="消除等式约束"></a>消除等式约束</h4><p>这种等价思路是这样的，对于某些等式约束，我们可以闭式的构造出函数$\phi(z)$，使得等式约束可以得到固有满足$f_i(\phi(z)) = 0$,由此便可得到等价的优化问题: </p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\text { minimize } & \tilde{f}_{0}(z)=f_{0}(\phi(z)) \\
\text { subject to } & \tilde{f}_{i}(z)=f_{i}(\phi(z)) \leq 0
\end{array}</script><p>对于凸优化问题，等式约束都是线性约束，等式约束记为$A x = b$，假设存在矩阵$F \in \mathbf{R}^{n \times k}$满足$\mathcal{R}(F) = \mathbf{N}(A)$，那么假设我们有原始等式约束的一个可行解$x_0$，那么所有满足等式约束的解都可以写成如下形式:</p>
<script type="math/tex; mode=display">
    x = Fz + x_0</script><p>对于这样的$x$，等式约束是固有满足的，因此就将原始优化问题转化为:</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\operatorname{minimize} & f_{0}\left(F z+x_{0}\right) \\
\text { subject to } & f_{i}\left(F z+x_{0}\right) \leq 0, \quad i=1, \ldots, m
\end{array}</script><h3 id="从硬间隔SVM到软间隔SVM"><a href="#从硬间隔SVM到软间隔SVM" class="headerlink" title="从硬间隔SVM到软间隔SVM"></a>从硬间隔SVM到软间隔SVM</h3><p>在之前介绍从硬间隔SVM到软间隔SVM时，更多地是从几何直观角度，直接引入了松弛变量导出了软间隔SVM的形式，今天这部分以更加细致的角度来介绍这一转化过程。</p>
<p>如果将SVM原始优化问题转化为无约束优化问题，则可以写做:</p>
<script type="math/tex; mode=display">
    \min_{w, b}  \frac{1}{2} ||w||^2 + \sum_{i=1}^N l_{0-\infty} (y_i (w^T x_i + b))</script><p>其中:</p>
<script type="math/tex; mode=display">
    l_{0-\infty} (b) = \begin{cases}
        \infty & if \ b < 0 \\
        0 & if  \ b > 0 
    \end{cases}</script><p>这样的惩罚项相当于是对于不满足约束的样本零容忍，只要不满足约束，则施加一个$\infty$的惩罚，现在我们期望将惩罚系数放松一下，即便存在不满足约束的点，仍然可以进行优化，那么惩罚函数最直接想到的便是$l_{0-1}$: </p>
<script type="math/tex; mode=display">
    l_{0-1}(b) =  \begin{cases}
        1 & if \ b < 0 \\
        0 & if  \ b > 0 
    \end{cases}</script><p>但采用这样一个惩罚函数会导致优化问题非凸，而我们是期望求解一个凸优化问题的，因此便考虑$l<em>{0-1}$的凸近似，常用的凸近似有$l</em>{lin}$和$l<em>{quad}$,如下图所示:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/hinge.png" alt="损失函数"><br>若记$f(x) = w^T x + b$，则$l</em>{lin}$和$l_{quad}$在该问题中的表达式为:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        l_{lin}(yf(x)) &= \max(0, 1 - yf(x)) \\ 
        l_{quad}(yf(x)) &= \max(0, (1-yf(x))^2)
    \end{aligned}</script><p>可以看到，第一个损失函数是分段线性的，也被称为合页损失,凸函数，不光滑；第二个损失函数也是凸函数，且光滑。<br>因此此时目标函数可以写做:</p>
<script type="math/tex; mode=display">
    \min_{w,b} \quad \frac{1}{2} ||w||^2 + \sum_{i=1}^N \xi_i</script><p>其中$\xi_i = \max(0, 1- y_i f(x_i))$， 该优化问题等价于:</p>
<script type="math/tex; mode=display">
    \begin{array}{ll}
        \min  &\frac{1}{2} ||w||^2 + \sum_{i=1}^N \xi_i  \\
        s.t. & y_i f(x_i) \geq 1 - \xi_i, i = 1,2,\dots, N \\ 
         & \xi_i \geq 0, i =1,2,\dots, N
    \end{array}</script><p>这便是我们熟悉的软间隔支持向量机原始优化问题的形式。</p>
<h3 id="SVM应用于多分类问题"><a href="#SVM应用于多分类问题" class="headerlink" title="SVM应用于多分类问题"></a>SVM应用于多分类问题</h3><p>SVM最常用的场景是二分类场景，但这并不意味着SVM不能应用于多分类问题，将SVM应用于多分类问题有如下几个解决思路:</p>
<ul>
<li>训练多个$one \ vs \ all$分类器 </li>
<li>训练多个$one \ vs \ one$分类器 </li>
<li>训练一个联合分类器 </li>
</ul>
<p>下面就分别讲解下这三种实现多分类器构建的思路。</p>
<h4 id="训练多个-one-vs-all-分类器"><a href="#训练多个-one-vs-all-分类器" class="headerlink" title="训练多个$one \ vs \ all$分类器"></a>训练多个$one \ vs \ all$分类器</h4><p>思路也是简单的，有$k$个类别我就训练$k$个分类器，在第$i$个分类器训练时将第$i$类样本看作一类，将剩余的其他样本看作另一类。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/onevsall.png" alt="onevsall"></p>
<p>采用这种思路容易碰到两个问题:</p>
<ul>
<li>$k$个分类器的超平面参数$(w_k, b_k)$未必在一个尺度下，因为将$w_k$和$b_k$同时放大或者缩小$d$倍并不影响该超平面的分类结果，但会导致$w_k^T x + b_k$成倍放大或缩小。 </li>
<li>在模型学习时因为是$one \ vs \ all$，就会导致正负样本数不平衡，使得分类器不能得到充分训练。 </li>
</ul>
<h4 id="训练多个-one-vs-one-分类器"><a href="#训练多个-one-vs-one-分类器" class="headerlink" title="训练多个 $one \ vs \ one$分类器"></a>训练多个 $one \ vs \ one$分类器</h4><p>在这种思路下，共需要训练$\frac{k(k-1)}{2}$个分类器，在进行决策时通过投票的方式决定将一个样本划分为哪一类。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/onevsone.png" alt="onevsone"> </p>
<p>这种思路存在的问题主要有:</p>
<ul>
<li>随着类别数目的增多，需要训练的分类器的数量是以$k^2$的速度增长的。</li>
<li>基于投票进行决策经常会出现冲突。</li>
</ul>
<h4 id="训练一个联合分类器"><a href="#训练一个联合分类器" class="headerlink" title="训练一个联合分类器"></a>训练一个联合分类器</h4><p>前面两种解决思路都是分开训练多个超平面参数然后再联合起来决策，但其实也可以在一个优化问题求解中将多个超平面参数同时学出来，其实本质上就是$one \ vs \ all$思路,优化问题可以写做:</p>
<script type="math/tex; mode=display">
    \begin{array}{ll}
    \min_{w,b}  & \frac{1}{2}  \sum_{y} ||w_y||^2 + C \sum_{i=1}^N \sum_{y \neq y_i} \xi_{iy}  \\ 
    s.t. & w_{y_i}^T x_i + b_{y_i} \geq w_y^T x_i + b_y + 1 -\xi_{iy}, \forall i,\forall y \neq y_i \\ 
    & \xi_{iy} \geq 0, \forall i,\forall y \neq y_i
    \end{array}</script><p>在进行决策时:</p>
<script type="math/tex; mode=display">
    \hat{y} = \argmax_{k} (w_k^T x + b_k)</script><h3 id="支持向量回归-SVR"><a href="#支持向量回归-SVR" class="headerlink" title="支持向量回归(SVR)"></a>支持向量回归(SVR)</h3><p>支持向量机的思路也可以用于回归问题上，对于样本$(x,y)$,传统的回归模型通常直接基于模型输出$f(x)$与真实输出$y$之间的差别来计算损失，当且仅当$f(x)$与$y$完全相同时损失才为0。与此不同，支持向量回归假设我们能够容忍$f(x)$与$y$之间最多有$\epsilon$的偏差，即仅当$f(x)$与$y$之间的差别绝对值大于$\epsilon$时才计算损失，如下图所示。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/SVR.png" alt="SVR"><br>我们期望$\epsilon$能够尽可能小，同时希望在误差带不变大的情况下能够包含尽可能多的样本点，也就是希望几何间隔能够尽可能大一些，也就是说我们期望在函数间隔尽可能小的情况下几何间隔能够尽可能大，根据几何间隔与函数间隔的关系:</p>
<script type="math/tex; mode=display">
    gap_{geo} = \frac{gap_{func}}{||w||}</script><p>因此SVR问题可形式化为:</p>
<script type="math/tex; mode=display">
    \min_{w,b} \frac{1}{2} ||w||^2 + C \sum_{i=1}^m l_{\epsilon} (f(x_i) - y_i)</script><p>其中$C$为正则化常数，$l_\epsilon$表示为:</p>
<script type="math/tex; mode=display">
    l_\epsilon(z) = \begin{cases}
        0, & if |z| \leq 0 \\ 
        |z| - \epsilon, & otherwise
    \end{cases}</script><p>在进行回归时，往往会存在一些离群点，此时这些点我们并不期望它们出现在$2 \epsilon$之内，因此考虑引入两个松弛变量，将优化问题转化为:</p>
<script type="math/tex; mode=display">
    \begin{array}{ll}
        \min_{w,b,\xi_i,\hat{\xi}_i} \frac{1}{2} &||w||^2 + C \sum_{i=1}^n (\xi_i + \hat{\xi}_i)  \\
        s.t. & f(x_i) - y_i \leq \epsilon + \xi_i \\ 
        & y_i - f(x_i) \leq \epsilon + \hat{\xi}_i \\
        & \xi_i \geq 0, \hat{\xi}_i \geq 0
    \end{array}</script><p>后面求解也是转为对偶问题进行求解，同时因为优化问题的独特形式，使得最终进行回归时只会计算样本点之间的点积，因此可以很方便地引入核技巧，完成非线性回归任务。 </p>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>SVM,补充</tag>
      </tags>
  </entry>
  <entry>
    <title>贝叶斯网络</title>
    <url>/2020/07/24/bayes-network/</url>
    <content><![CDATA[<p>在该部分对贝叶斯网络进行介绍，按照递进关系总结以下知识点：<span id="more"></span></p>
<ul>
<li>条件独立性</li>
<li>条件参数化</li>
<li>朴素贝叶斯模型</li>
<li><strong>贝叶斯网络</strong></li>
</ul>
<hr>
<h3 id="问题来源"><a href="#问题来源" class="headerlink" title="问题来源"></a>问题来源</h3><p>首先探讨下为什么我们需要利用变量之间的条件独立性性质，假设我们要描述的对象为$n$个二值变量：$X_1,\dots,X_n$,这些变量的联合分布为$P$,那么我们需要$\bf{2^n - 1}$个参数来描述联合分布$P$，所需参数量是$O(2^n)$级别，我们便考虑能否利用变量之间的某种性质使得$P$可以用更少的参数来描述，由此便引出了变量之间的独立性性质。</p>
<h3 id="独立性"><a href="#独立性" class="headerlink" title="独立性"></a>独立性</h3><p>下面给出一些独立性等价的定义:</p>
<blockquote>
<ul>
<li>若$P(X = x|Y = y) = P(X=x)$对于任意的$x,y$均成立 $\Rightarrow$ 变量$X$与$Y$相互独立 </li>
<li>若$P(X,Y) = P(X|Y)P(Y) = P(X)P(Y)$ $\Rightarrow$ 变量$X$与$Y$相互独立 </li>
</ul>
</blockquote>
<p>若问题来源中的$n$个变量相互独立，则联合分布:</p>
<script type="math/tex; mode=display">
    P(X_1,X_2,\dots,X_n) = P(X_1) P(X_2) \dots P(X_n)</script><p>此时仅需$O(n)$个变量来对联合分布进行描述，参数花销大大减少，但在实际中，独立性是一个非常强的假设，往往不能够得到满足，由此便引出了条件独立性性质。</p>
<h3 id="条件独立性"><a href="#条件独立性" class="headerlink" title="条件独立性"></a>条件独立性</h3><blockquote>
<p>定义： 两个变量$X$和$Y$关于变量$Z$是条件独立的 $\Leftrightarrow$ 对于$\forall x,y,z$,$P(X = x|Y = y, Z = z) = P(X = x|Z = z)$ $\Leftrightarrow$ $P(X = x,Y = y|Z = z) = P(X = x|Z = z) \cdot P(Y=y|Z= z)$</p>
</blockquote>
<p>这里需要特别说明的是条件独立性并不能推出独立性，独立性也并不能推出条件独立性，下面给出两个反例：</p>
<ul>
<li>独立性 $\nRightarrow$ 条件独立性: 有两枚正反概率均为$50\%$的硬币,设事件A为第一枚硬币为正面，事件B为第二枚硬币为正面，事件C为两枚硬币同面，若不考虑事件C，事件A与事件B显然独立;但若事件C已经发生，则此时A与B便不再独立，即A与B关于C不条件独立。</li>
<li>条件独立性 $\nRightarrow$ 独立性: 有两枚硬币，一枚正面概率为$90\%$,另一枚反面概率为$90\%$,随机拿出一枚抛掷硬币两次, 事件A表示第一次为正面，事件B表示第二次为正面，事件C表示选择的是第一枚硬币，则抛开事件C，事件A与事件B并不独立($0.5 = P(B) \neq P(B|A) = 0.9802$),但若事件C发生，则相当于进行了两次独立重复实验，此时事件A与事件B独立。</li>
</ul>
<p>条件独立性符号表示：</p>
<ul>
<li>$Ind(X;Y|Z)$ or $(X \perp Y|Z)$</li>
</ul>
<h3 id="条件参数化"><a href="#条件参数化" class="headerlink" title="条件参数化"></a>条件参数化</h3><p>在了解了变量条件独立性后，下面以一个例子分析如何利用变量之间的条件独立性性质来减少描述联合分布所需的参数。</p>
<div align="center">

![栗子](https://raw.githubusercontent.com/xuejy19/Images/master/Ind.png)
</div>

<p>图中大写字母均代表随机变量，含义如下：</p>
<ul>
<li>$D:$课程难度，$Val(D) = {d^0, d^1}$</li>
<li>$I:$智力，$Val(I) = {i^0,i^1}$</li>
<li>$S:$SAT分数，$Val(S) = {s^0,s^1}$</li>
<li>$G:$课程成绩，$Val(G) = {g^0,g^1, g^2}$</li>
<li>$L:$推荐信，$Val(L) = {l^0,l^1}$</li>
</ul>
<p>假设$G$和$S$关于$I$条件独立，下面我们分析两种情况的条件参数化</p>
<p>首先以$I$和$S$两个变量为例，我们既可以通过联合分布$P(I,S)$来进行描述，也可以通过$P(I)$和$P(S|I)$进行描述，两种描述均是三个独立参数，如下图所示。<br><img src="https://raw.githubusercontent.com/xuejy19/Images/master/eg2.png" alt></p>
<p>接下来分析$I、D、G$三个变量的条件参数化，其中$I$与$D$相互独立，下面分析两种表示方法所需的参数个数：</p>
<ul>
<li>联合分布: $P(I,D,G)$,所需参数个数为$2 \times 2 \times 3 - 1=11$</li>
<li>利用独立性条件: $P(I,D,G) = P(I)P(D)P(G|I,D)$,所需独立参数为$1+1+2\times 2 \times (3-1) =10 $<br>$\Rightarrow$ <strong>利用独立性可以减少表示联合分布所需的参数个数</strong></li>
</ul>
<h3 id="朴素贝叶斯模型"><a href="#朴素贝叶斯模型" class="headerlink" title="朴素贝叶斯模型"></a>朴素贝叶斯模型</h3><p>在这一部分对朴素贝叶斯模型做简要介绍，首先我们有两组变量：</p>
<ul>
<li>$C$:类别变量，$C = {c_1,\dots, c_k}$</li>
<li>观测变量：$X_1,X_2,\dots, X_d$</li>
</ul>
<p>在朴素贝叶斯模型中，我们的目标便是利用观测变量来对类别进行预测/推理。所有这些变量其实可以看做一个联合概率分布$P(C,X_1,\dots,X_d)$,然而该概率分布很难计算，所需的参数量是指数级别，因此在朴素贝叶斯模型中有一个很强的假设：</p>
<blockquote>
<p>观测变量彼此之间关于类别变量$C$是相互独立的，据此联合概率分布便很容易计算：</p>
<script type="math/tex; mode=display">P(C,X_1,\dots,X_d) = P(X_1,\dots,X_d|C) P(C) = P(X_1|C)\dots P(X_d|C) P(C)</script></blockquote>
<p>这是一个很强的假设，在真实世界中往往不能满足，同时因为没有充分利用变量之间的相关性性质，也造成了计算上的浪费。</p>
<h3 id="贝叶斯网络"><a href="#贝叶斯网络" class="headerlink" title="贝叶斯网络"></a>贝叶斯网络</h3><blockquote>
<p>贝叶斯网路定义：贝叶斯网络，又称信念网络，是一种概率图模型，记做$(G,P)$,借由有向无环图表示一组随机变量及它们之间的条件概率分布。</p>
</blockquote>
<p>贝叶斯网络是一种以有向无环图方式对独立性假设进行编码的手段，在贝叶斯网络中，任意变量与它的非后代变量对于其父节点变量是条件独立的：</p>
<script type="math/tex; mode=display">
    (X_i \perp Nondesc(X_i)|Pa(X_i))</script><p><strong>独立性映射(I-Maps):</strong> 记$P$为一组变量$\mathbf{X}$的联合概率分布，$I(P)$为表征$P$中独立性的集合</p>
<blockquote>
<p>定义：$G$为贝叶斯网路，若$I(G) \subset I(P)$,则称$G$为$P$的一个独立映射</p>
<p>分解定理：若$G$是$P$的独立映射 $\Leftrightarrow$ $P(X<em>1,\dots,X_d) = \prod \limits</em>{i=1}^d P(X_i|Pa(X_i))$,通过该分解定理可以将全局的概率分布用局部的条件概率来表示</p>
</blockquote>
<p>下面分析下与联合概率分布相比，贝叶斯网络所需参数,以$n$个二值变量为例：</p>
<ul>
<li>联合概率分布：$2^n$</li>
<li>贝叶斯网络(限制各个节点入度为$k$):$n2^k$</li>
</ul>
<h3 id="d-Separation-有向分离"><a href="#d-Separation-有向分离" class="headerlink" title="d-Separation(有向分离)"></a>d-Separation(有向分离)</h3><p>在前面我们已经讨论了贝叶斯网络$G$编码了局部独立性假设，现在我们希望能够了解$G$是否还编码了其他独立性假设，因此我们需要一个方法来挖掘出$G$中所有的独立性假设<br>$\Rightarrow$ <strong>d-Separation</strong><br>下面分别讨论不分离两种情况：</p>
<ul>
<li>不分离<ul>
<li>两个节点直接相连：此时不存在一个节点使得这两个节点关于该节点条件独立<br>$e.g. X \rightarrow Y$</li>
<li>两个节点间接相连：head2tail,head2head,tail2tail</li>
<li>一般情况：对于图$G$中的路径$X_1 \leftrightarrow \dots \leftrightarrow X_n$关于节点集合$E$是激活的如果<ul>
<li>对于每个V状结构$X<em>{i-1} \rightarrow X_i \leftarrow X</em>{i+1},X_i$或者其后代<br>在集合$E$中</li>
<li>路径上的点不在集合$E$中</li>
</ul>
</li>
</ul>
</li>
<li>分离：在贝叶斯网络$G$中，$X$和$Y$在给定$Z$条件下是d分离的$d-sep_G(X;Y|Z)$,如果<strong>不存在</strong>从集合$X$到$Y$的激活路径</li>
</ul>
<p>由此可以通过d分离来找到贝叶斯网络中所有独立性关系：</p>
<script type="math/tex; mode=display">
    I(G) = \{ (\mathbf{X \perp Y |Z}): d-sep_G(\mathbf{X;Y|Z})\}</script><p>简单总结而言，如果两个节点之间的路径被阻隔，则需要满足以下两个条件其一：</p>
<ul>
<li>若存在V形结构，则冲撞点及其后代不能出现在条件集中</li>
<li>有路径中的点(非碰撞点)出现在条件集合中</li>
</ul>
<h3 id="Forward-VS-Backward"><a href="#Forward-VS-Backward" class="headerlink" title="Forward VS Backward"></a>Forward VS Backward</h3><p>直观上感觉，贝叶斯网络的反向过程(给出结果，推理原因)要比前向过程困难不少，这是因为子节点会激活其父母之间的路径，而这种相关性会进一步向上传播。<br><strong>最小独立映射</strong>：对于一个图$G$和一个分布$P$，我们在图中哪怕仅仅去掉一个边都会导致$G$不再是$P$的一个独立映射，则称$G$是最小独立映射。<br><strong>最佳映射</strong>：对于一个图$G$和一个分布$P$，若有$I(P) = I(G)$，则称图$G$是$P$的一个最佳映射</p>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>概率图模型，有向图</tag>
      </tags>
  </entry>
  <entry>
    <title>我与历史之缘</title>
    <url>/2020/01/12/blog/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉, 这个密码看着不太对, 请再试试." data-whm="抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容.">
  <script id="hbeData" type="hbeData" data-hmacdigest="31367dac80ab9cf0d98610bb2a722664192c9be1931b5caa7e794382919c9910">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-blink">
      <input class="hbe hbe-input-field hbe-input-field-blink" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-blink" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-blink" data-content="需要密码,请前往B站关注up爱玩赛尔号的思考猫,私聊up主即可获得密码.">需要密码,请前往B站关注up爱玩赛尔号的思考猫,私聊up主即可获得密码.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>闲谈</category>
      </categories>
      <tags>
        <tag>历史，回溯</tag>
      </tags>
  </entry>
  <entry>
    <title>logistic回归与最大熵模型</title>
    <url>/2020/08/23/logistic-hui-gui-yu-zui-da-shang-mo-xing/</url>
    <content><![CDATA[<p>在学习李航老师《统计学习》条件随机场章节时，对于学习算法感到有些陌生，后来发现在书中第六章“logistic回归与最大熵模型”有过一些介绍，因此本章节便总结一下相关知识，其中logistic回归模型做简要介绍，重点放在最大熵模型的学习算法上，本文按照如下结构组织：</p>
<ul>
<li>logistic回归</li>
<li>最大熵模型<span id="more"></span>
<h3 id="logistic回归"><a href="#logistic回归" class="headerlink" title="logistic回归"></a>logistic回归</h3><h4 id="logistic分布"><a href="#logistic分布" class="headerlink" title="logistic分布"></a>logistic分布</h4>首先介绍下logistic分布：<blockquote>
<p><strong>logistic分布</strong>:设$X$是连续变量，$X$服从logistic分布是指$X$具有下列分布函数和密度函数：</p>
<script type="math/tex; mode=display">
  \begin{aligned}
      F(x) &= P(X \leq x) = \frac{1}{1 + e^{-\frac{x-\mu}{\gamma}}} \\
      f(x) &= F'(x) = \frac{e^{-\frac{x-\mu}{\gamma}}}{\gamma(1+e^{-\frac{x-\mu}{\gamma}})^2}
  \end{aligned}</script><p>式中，$\mu$为位置参数，$\gamma&gt;0$为形状参数 </p>
</blockquote>
</li>
</ul>
<p>对于logistic分布，其概率密度函数和分布函数如下图所示：<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/logistic.jpeg" alt="logistic"><br>分布函数的图形是一条$S$形曲线，该曲线以点$(\mu,\frac{1}{2})$为中心对称，即满足:</p>
<script type="math/tex; mode=display">
    F(-x+\mu) - \frac{1}{2} = -F(x+\mu) +\frac{1}{2}</script><p>曲线在中心增长速度较快，在两端增长速度慢，形状参数$\gamma$的值越小，曲线在中心附近增长得越快。</p>
<h4 id="二项logistic回归模型"><a href="#二项logistic回归模型" class="headerlink" title="二项logistic回归模型"></a>二项logistic回归模型</h4><p>二项logistic回归模型是一种二分类模型，由条件概率分布$P(Y|X)$表示，形式为参数化的logistic分布，随机变量$X$的取值为实数，随机变量$Y$取值为1或0，下面给出logistic回归模型定义：</p>
<blockquote>
<p><strong>logistic回归模型</strong>：二项logistic回归模型是如下条件概率分布：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        P(Y=1|x) &= \frac{exp(w \cdot x + b)}{1 + exp(w \cdot x + b)} \\
        P(Y=0|x) &= \frac{1}{1 + exp(w \cdot x + b)} 
    \end{aligned}</script><p>其中，$x \in R^n$是输入，$Y \in {0,1}$是输出，$w \in R^n,b \in R$是参数。</p>
</blockquote>
<p>若我们已经有了logistic模型，则判断样本点$x$属于哪一类只需要比较两个概率值的大小，下面给出对数几率的定义:</p>
<blockquote>
<p><strong>对数几率</strong>：一个事件的几率是指该事件发生的概率与该事件不发生的概率的比值，如果一个事件发生的概率是$p$,那么该事件的几率是$\frac{p}{1-p}$,该事件的对数几率或logit函数是:</p>
<script type="math/tex; mode=display">
    logit(p) = log \frac{p}{1-p}</script></blockquote>
<p>对于logistic回归而言，事件$(Y=1|X)$的对数几率为：</p>
<script type="math/tex; mode=display">
    log \frac{P(Y=1|x)}{1 - P(Y=1|x)} = w \cdot x</script><p>这说明，logistic回归模型可以看做是用线性回归模型去逼近真实标记的对数几率。因此logistic回归模型也被称为对数几率回归，可以看作是经过了如下的映射环节，将$R^n$空间中的$x$映射到了其标记的概率：</p>
<script type="math/tex; mode=display">
    x \in R^n  \rightarrow w \cdot x \in R \rightarrow P(Y=1|x) \in [0,1]</script><h4 id="模型参数估计"><a href="#模型参数估计" class="headerlink" title="模型参数估计"></a>模型参数估计</h4><p>对于logistic回归模型，需要估计的参数是$w,b$,可以考虑将它们合并为一个$n+1$维向量:</p>
<script type="math/tex; mode=display">
    w = [w;b]</script><p>同时，给输入向量加一维，表示为:</p>
<script type="math/tex; mode=display">
    x = [x;1]</script><p>这样logistic回归模型就可以表示成更加紧凑的形式:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        P(Y=1|x) &=  \frac{exp(w \cdot x) }{1+exp(w \cdot x)} \\
        P(Y=0|x) &=  \frac{1}{1 + exp(w \cdot x)}
    \end{aligned}</script><p>logistic模型参数学习属于有监督的模型学习问题范畴，利用极大似然法就可以解决，设：</p>
<script type="math/tex; mode=display">
    P(Y=1|x) = \pi(x), \quad P(Y=0|x) = 1- \pi(x)</script><p>似然函数可以写成:</p>
<script type="math/tex; mode=display">
    \prod_{i=1}^N [\pi(x_i)]^{y_i} [1 - \pi(x_i)]^{1-y_i}</script><p>对数似然函数为:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        L(w) &= \sum_{i=1}^N [y_i log \pi(x_i) + (1-y_i)log(1-\pi(x_i))] \\
            &= \sum_{i=1}^N [y_i log \frac{\pi(x_i)}{1 - \pi(x_i)} + log(1-\pi(x_i))] \\
            &= \sum_{i=1}^N [y_i(w \cdot x) - log(1 + exp(w \cdot x))]
    \end{aligned}</script><p>对$L(w)$求极大值，得到$w$的估计值，常用梯度下降法及拟牛顿法求解(后面专开一章讲解)。</p>
<h4 id="多项logistic回归"><a href="#多项logistic回归" class="headerlink" title="多项logistic回归"></a>多项logistic回归</h4><p>上面介绍的是二项logistic模型，适用于二分类，可以将其推广为多项logistic分类模型，用于多类分类。假设离散型随机变量$Y$的取值集合是${1,2,\dots,K}$,那么多项logistic回归的模型是:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        P(Y=k|x) &= \frac{\exp(w_k \cdot x)}{1 + \sum_{k=1}^{K-1} \exp(w_k \cdot x)} \\
        P(Y=K|x) &= \frac{1}{1 + \sum_{k=1}^{K-1} \exp(w_k \cdot x)}
    \end{aligned}</script><p>这里$x \in R^{n+1},w_k \in R^{n+1}$。二项logistic回归的参数估计法也可以推广到多项logistic回归</p>
<h3 id="最大熵模型"><a href="#最大熵模型" class="headerlink" title="最大熵模型"></a>最大熵模型</h3><p>最大熵模型，是由最大熵原理推导实现。本部分按照以下结构组织:</p>
<ul>
<li>最大熵原理</li>
<li>最大熵模型推导</li>
<li>最大熵模型学习</li>
</ul>
<h4 id="最大熵原理"><a href="#最大熵原理" class="headerlink" title="最大熵原理"></a>最大熵原理</h4><p>最大熵原理是概率模型学习的一个准则，最大熵原理认为：</p>
<blockquote>
<p>学习概率模型时，在所有可能的概率模型中，熵最大的模型是最好的模型。通常用约束条件来确定概率模型的集合，所以，最大熵原理也可以表述为在满足约束条件的模型集合中选取熵最大的模型。</p>
</blockquote>
<p>我们首先来复习下信息论中关于熵的定义：</p>
<blockquote>
<p>在信息论与概率统计中，熵是表示<strong>随机变量不确定性</strong>的度量，设$X$是一个取有限个值的离散随机变量，其概率分布为:</p>
<script type="math/tex; mode=display">
    P(X = x_i) = p_i, \quad i =1,2,\dots,n</script><p>则随机变量$X$的熵定义为:</p>
<script type="math/tex; mode=display">
    H(X) = - \sum_{i=1}^n p_i \log p_i</script></blockquote>
<p>若$p_i = 0$,则定义$0\log 0 =0$,式中的对数一般取以2为底或者以$e$为底，这时熵的单位被称作比特或纳特，由定义可知，熵只依赖于$X$的分布，而与$X$的取值无关，因此也可将$X$的熵记作$H(p)$,熵越大，随机变量的不确定性越大。因为$p_i \leq 0$,由$H(p)$函数性质(凹函数，应用拉格朗日乘子法可求最大值)可知:</p>
<script type="math/tex; mode=display">
    0 \leq H(p) \leq \log n</script><p>当且仅当$X$是均匀分布时右侧等号成立,也就是说，当$X$服从均匀分布时，熵最大，该随机变量的不确定性最大。下面给出条件熵的定义:</p>
<blockquote>
<p>设有随机变量$(X,Y)$,其联合概率分布为：</p>
<script type="math/tex; mode=display">
    P(X = x_i,Y = y_i) = p_{ij}\quad i = 1,2,\dots,n;\quad j = 1,2,\dots,m</script><p>条件熵$H(Y|X)$表示在已知随机变量$X$条件下随机变量$Y$的不确定性。随机变量$X$给定的条件下随机变量$Y$的条件熵$H(Y|X)$,定义为$X$给定条件下$Y$的条件概率分布的熵对$X$的数学期望：</p>
<script type="math/tex; mode=display">
    H(Y|X) = \sum_{i=1}^n p_i H(Y|X = x_i)</script><p>当熵和条件熵中的概率由数据估计得到时，所对应的熵与条件熵分别称为经验熵和经验条件熵</p>
</blockquote>
<p>直观的，最大熵原理认为要选择的概率模型首先必须满足已有的事实，即约束条件。在没有更多信息情况下，那些不确定的部分都是“等可能的”,最大熵原理通过熵的最大化来表示等可能性。下面通过一个简单的例子来介绍最大熵原理：</p>
<blockquote>
<p>🌰：假设随机变量$X$有五个取值${A,B,C,D,E }$,要估计取各个值的概率$P(A),P(B),P(C),P(D),P(E)$</p>
<ul>
<li>不提供任何额外约束，则只有这些概率的固有约束<script type="math/tex; mode=display">
  P(A) + P(B) + P(C) + P(D) + P(E) = 1</script>因为没有任何额外的信息，则根据最大熵原理，只能够认为该概率分布为均匀分布：<script type="math/tex; mode=display">
  P(A) = P(B) = P(C) = P(D) = P(E) = \frac{1}{5}</script></li>
<li>从一些先验知识中得到了一些对概率值的约束条件，如$P(A) + P(B) = \frac{3}{10}$,满足约束的概率分布仍旧有无穷多个，在缺少其他信息的情况下，可以认为$A$和$B$是等概率的，$C,D,E$等概率。</li>
</ul>
</blockquote>
<p>实际上，最大熵原理就是为我们提供了一种选择最优概率模型的准则(保守)</p>
<h4 id="最大熵模型的定义"><a href="#最大熵模型的定义" class="headerlink" title="最大熵模型的定义"></a>最大熵模型的定义</h4><p>最大熵原理是统计学习的一般原理，将它应用到分类得到最大熵模型。<br>假设分类模型是一个条件概率分布$P(Y|X)$,$X \in \mathcal{X} \subseteq R^n$表示输入，$Y \in \mathcal{Y}$表示输出，$\mathcal{X}$和$\mathcal{Y}$分别是输入和输出的集合，这个模型表示的是对于给定的输入$X$，以条件概率$P(Y|X)$输出$Y$。<br>给定一个训练数据集:</p>
<script type="math/tex; mode=display">
    T = \{  (x_1,y_1), (x_2,y_2), \dots, (x_N,y_N)\}</script><p>学习的目标是应用最大熵模型选择最好的分类模型。首先考虑模型应该满足的条件，即该数据集为模型添加了哪些约束，给定训练数据集后，我们可以确定联合分布$P(X,Y)$的经验分布和边缘分布$P(X)$的经验分布，分别以$\tilde{P}(X,Y)$和$\tilde{P}(X)$表示:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \tilde{P}(X= x,Y=y) &= \frac{\nu(X = x,Y = y)}{N} \\
        \tilde{P}(X = x) &= \frac{\nu(X = x)}{N} 
    \end{aligned}</script><p>式中$\nu(\cdot)$是频数统计函数，$N$表示训练样本容量。用特征函数$f(x,y)$描述输入$x$和输出$y$之间的某一个事实，其定义是:</p>
<script type="math/tex; mode=display">
    f(x,y) = \begin{cases}
        1,  &x和y满足某一事实 \\
        0,  &else 
    \end{cases}</script><p>特征函数$f(x,y)$关于经验分布$\tilde{P}(X,Y)$的期望值，用$E_{\tilde{P}}(f)$表示：</p>
<script type="math/tex; mode=display">
    E_{\tilde{P}}(f) = \sum_{x,y} \tilde{P}(x,y) f(x,y)</script><p>特征函数$f(x,y)$关于模型$P(Y|X)$i与经验分布$\tilde{P}(X)$的期望值，用$E_P(f)$表示：</p>
<script type="math/tex; mode=display">
    E_P(f) = \sum_{x,y} \tilde{P}(x) P(y|x) f(x,y)</script><p>如果模型能够获取训练数据中的信息，那么就可以假设这两个期望值相等，即：</p>
<script type="math/tex; mode=display">
    E_P(f) = E_{\tilde{P}}(f)</script><p>将这作为模型学习的约束条件，假如有$n$个特征函数$f_i(x,y),i=1,2,\dots,n$,那么就有$n$个约束条件，下面给出最大熵模型的定义:</p>
<blockquote>
<p>最大熵模型:假设满足所有约束条件的模型集合为:</p>
<script type="math/tex; mode=display">
    C \equiv \{ P \in \mathcal{P} |E_P(f_i) = E_{\tilde{P}}(f_i), i = 1,2,\dots,n\}</script><p>定义在条件概率分布$P(Y|X)$上的条件熵为：</p>
<script type="math/tex; mode=display">
    H(P) = -\sum_{x,y}  \tilde{P}(x)P(y|x) log P(y|x)</script><p>则模型集合$C$中条件熵$H(P)$最大的模型称为最大熵模型</p>
</blockquote>
<p>从定义可以看出，最大熵模型是基于这样一种思想:</p>
<blockquote>
<p>当我们需要对一个事件(变量)的概率分布进行预测时，最大熵原理告诉我们所有的预测应当满足全部已知的条件(约束)，而对未知的情况不要做任何主观假设，保留模型最大的不确定性。</p>
</blockquote>
<h4 id="最大熵模型的学习"><a href="#最大熵模型的学习" class="headerlink" title="最大熵模型的学习"></a>最大熵模型的学习</h4><p>最大熵模型的学习过程就是求解最大熵模型的过程。最大熵模型学习可以形式化为约束最优化问题。<br>对于给定的训练数据集$T = { (x_1,y_1), (x_2,y_2),\dots, (x_N,y_N)}$以及特征函数$f_i(x,y),i=1,2,\dots,n$,最大熵模型的学习等价于求解最优化问题:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &\max_{P \in C} \quad H(P) = -\sum_{x,y}  \tilde{P}(x)P(y|x) log P(y|x) \\
        &s.t. \quad E_P(f_i) = E_{\tilde{P}}(f_i),\quad i =1,2,\dots,n \\  
        & \quad \quad \sum_y P(y|x) =1
    \end{aligned}</script><p>按照最优化问题的习惯，将求解最大值问题改为等价的求最小值问题:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &\min_{P \in C} \quad -H(P) = \sum_{x,y}  \tilde{P}(x)P(y|x) log P(y|x) \\
        &s.t. \quad E_P(f_i) - E_{\tilde{P}}(f_i) = 0,\quad i =1,2,\dots,n \\  
        & \quad \quad \sum_y P(y|x) =1
    \end{aligned}</script><p><strong>该优化问题按照李航老师《统计学习》中的说法是满足强对偶性的，但书中只是一带而过，并没有进行详细说明，此处留坑，后面的推导就先默认该优化问题满足强对偶性，后面我搞懂了再来填坑</strong></p>
<hr>
<p><strong>这个问题我又思考了一下，自变量是一个分布看似是一个很虚的东西，但它也不过是一个函数，若$X,Y$都是离散取值变量，那么这个条件概率分布只是一个有限长度的向量，而若$X,Y$取值连续，则该条件概率密度函数可以看作一个无限长的向量，这样来看原始待优化函数其实就是$\boldsymbol{x} \cdot \log \boldsymbol{x}$,这显然是一个凸函数，而约束条件也不过是待优化参数的线性组合，这显然是一个凸优化问题</strong></p>
<hr>
<p>该优化问题共有$n+1$个等式约束，因此考虑引入拉格朗日乘子$w_0,w_1,\dots,w_n$,定义拉格朗日函数$L(P,w)$:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        L(P,w) &= -H(P) + w_0 (1 - \sum_y P(y|x)) + \sum_{i=1}^n w_i (E_{\tilde{P}}(f_i) - E_P(f_i)) \\
        &= \sum_{x,y}  \tilde{P}(x)P(y|x) log P(y|x)  + w_0 (1 - \sum_y P(y|x)) \\
        &+ \sum_{i=1}^n w_i(\sum_{x,y} \tilde{P}(x,y) f(x,y) - \sum_{x,y} \tilde{P}(x) P(y|x) f(x,y))
    \end{aligned}</script><p>原始优化问题的对偶问题写作：</p>
<script type="math/tex; mode=display">
    \max_{w} \min_{P} L(P,w)</script><p>首先求解对偶函数$\phi(w)$,因为$L(P,w)$关于$P$是凸函数，因此直接通过求导令导数为0即可：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \frac{ \partial L(P,w)}{\partial P(y|x)} &=  log P(y|x) +1 - w_0 - \sum_{i=1}^n w_i f_i (x,y) = 0 
    \end{aligned}</script><p>在求导这一部分我不太认同李航老师书中的写法，因为$P(y|x)$本身可以看作是一个向量，因此求导相当于对该向量某个分量求导。由此可得$P(y|x)$的解析表达式:</p>
<script type="math/tex; mode=display">
    P(y|x) = \exp(\sum_{i=1}^n w_i f_i(x,y) + w_0 -1) = \frac{\exp(\sum_{i=1}^n w_i f_i(x,y))}{\exp(1-w_0)}</script><p>又因为有概率密度函数的固有约束$\sum_y P(y|x) = 1$,可得:</p>
<script type="math/tex; mode=display">\exp(1-w_0) = \sum_y \exp(\sum_{i=1}^n w_i f_i(x,y))</script><p>因此，$P_w(y|x)$的解析表达式写作:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        P_w(y|x) &= \frac{1}{Z_w(x)} \exp(\sum_{i=1}^n w_i f_i(x,y)) \\
        Z_w(x) &= \sum_y \exp(\sum_{i=1}^n w_i f_i(x,y))
    \end{aligned}</script><p>至此，我们得到了对偶函数$\phi(w)$表达式：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \phi(w) &= \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i f_i(x,y) + \sum_{x,y} \tilde{P}(x)P_w(y|x)(\log P_w(y|x) - \sum_{i=1}^n w_i f_i(x,y)) \\
        &= \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i f_i(x,y) - \sum_{x,y} \tilde{P}(x)P_w(y|x) \log Z_w(x) \\
        &= \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i f_i(x,y) - \sum_x \tilde{P}(x) \log Z_w(x)
    \end{aligned}</script><p>因此接下来便是求解对偶优化问题:</p>
<script type="math/tex; mode=display">
    \max \phi(w)</script><p>得到$w^\ast$,然后回代$P_w(y|x)$,得到最大熵模型表达式:</p>
<script type="math/tex; mode=display">
    P_{w^\ast}(y|x)</script><h4 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h4><p>这一部分旨在证明一条性质:</p>
<blockquote>
<p>最大熵模型求解过程中，对偶函数的极大化等价于最大熵模型的极大似然估计</p>
</blockquote>
<p>首先写出对数似然函数的形式:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
         L_{\tilde{P}}(P_w) &= \log \prod_{x,y} P(y|x)^{\tilde{P}(x,y)} = \sum_{x,y} \tilde{P}(x,y) \log P(y|x) \\
         &= \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i f_i(x,)  - \sum_{x,y} \tilde{P}(x,y) \log Z_w(x) \\
         &= \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i f_i(x,y)  - \sum_{x} \tilde{P}(x) \log Z_w(x)
    \end{aligned}</script><p>与对偶函数$\phi(w)$一致，这说明对对偶函数求最大等价于求最大熵模型的极大似然估计。<br>最大熵模型与logistic回归模型有类似的形式，它们又称为对数线性模型。模型学习就是对模型进行极大似然估计或者正则化的极大似然估计</p>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>logistic回归, 最大熵模型, 优化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>conda介绍及常用命令</title>
    <url>/2022/10/17/conda-jie-shao-ji-chang-yong-ming-ling/</url>
    <content><![CDATA[<p>随着机器学习、深度学习的爆火，大量的python第三方库也如雨后春笋一般冒了出来，这给开发者带来了极大便利的同时，也使得管理这些库成为了一件复杂度极高的事情，相信很多人都有过为了处理库冲突而抓狂的时刻，为了简化python包管理的工作，Anaconda应运而生。<span id="more"></span></p>
<h5 id="Anaconda"><a href="#Anaconda" class="headerlink" title="Anaconda"></a>Anaconda</h5><p>Anaconda可以看作是包含python、conda、numpy、notebook等常用包的一个集合，具有如下特点： </p>
<ul>
<li>安装过程简单 </li>
<li>高性能使用python和R语言 </li>
<li>免费的社区支持</li>
</ul>
<p>对于大多数用户来说，下载Anaconda的目的主要有两个: </p>
<ul>
<li>高效简单的配置python开发环境(python+一些基础常用包) </li>
<li><strong>后续通过<code>conda</code>这个神器来进行包管理和虚拟环境管理</strong></li>
</ul>
<h5 id="Conda"><a href="#Conda" class="headerlink" title="Conda"></a>Conda</h5><p><code>conda</code>是包及其依赖项和环境的管理工具: </p>
<ul>
<li>适用语言: Python, R, Ruby, Lua, Scala, Java, JavaScript, C/C++, FORTRAN </li>
<li>适用平台: Windows, Macos, Linux </li>
<li>优点 <ul>
<li>快速安装、运行和升级包及其依赖项</li>
<li>在计算机中便捷地创建、保存、加载和切换环境 <blockquote>
<p>如果你需要的包要求不同版本的Python，你无需切换到不同的环境，因为conda同样是一个环境管理器。仅需要几条命令，你可以创建一个完全独立的环境来运行不同的Python版本，同时继续在你常规的环境中使用你常用的Python版本。——Conda官方网站</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<p><strong>conda常用命令</strong>: </p>
<pre class="line-numbers language-lang-shell"><code class="language-lang-shell">conda activate xxxx #开启xxxx环境
conda deactivate #关闭环境
​
conda env list #显示所有的虚拟环境
conda info --envs #显示所有的虚拟环境
conda info -e #显示所有已经创建的环境
​
conda update -n base conda #update最新版本的conda
​
conda create -n xxxx python=3.6 #创建python3.6的xxxx虚拟环境
​
conda remove --name xxxx  --all #彻底删除旧环境
​
conda remove -n tensorflow --all  #彻底删除旧环境
​
#Conda是没有重命名环境的功能, 要实现这个基本需求, 可以通过克隆-删除的过程。
#切记不要直接mv移动环境的文件夹来重命名, 会导致一系列无法想象的错误的发生!
conda create --name newname --clone oldname //克隆环境
conda remove --name oldname --all //彻底删除旧环境
​
conda list          #查看已经安装的文件包
conda list -n xxx   #指定查看xxx虚拟环境下安装的package
conda update xxx    #更新xxx文件包
conda uninstall xxx #卸载xxx文件包
​
#pip 安装本地包
pip install   ～/Downloads/a.whl
#conda 安装本地包
conda install --use-local  ~/Downloads/a.tar.bz2
​
​
#显示目前conda的数据源有哪些
conda config --show channels
​
#添加数据源：例如, 添加清华anaconda镜像：
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
conda config --set show_channel_urls yes
​
#删除数据源
conda config --remove channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
​
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="conda配置国内镜像源"><a href="#conda配置国内镜像源" class="headerlink" title="conda配置国内镜像源"></a><code>conda</code>配置国内镜像源</h5><ul>
<li><p>方法1: 用<code>vim</code>打开文件，添加以下镜像源</p>
<pre class="line-numbers language-lang-shell"><code class="language-lang-shell">  vim ~/.condarc
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>  修改文件内容: </p>
<pre class="line-numbers language-lang-shell"><code class="language-lang-shell">      #清华源
  channels:
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/
  ssl_verify: true
  #中科大源
  channels:
  - https://mirrors.ustc.edu.cn/anaconda/pkgs/main/
  - https://mirrors.ustc.edu.cn/anaconda/pkgs/free/
  - https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/
  ssl_verify: true
  #上交大源
  channels:
  - https://mirrors.sjtug.sjtu.edu.cn/anaconda/pkgs/main/
  - https://mirrors.sjtug.sjtu.edu.cn/anaconda/pkgs/free/
  - https://mirrors.sjtug.sjtu.edu.cn/anaconda/cloud/conda-forge/
  ssl_verify: true
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li>方法2: 直接通过终端命令修改 <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">  ​# 中科大镜像源
  conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/
  conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/
  conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/
  conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/
  conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/
  conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/menpo/
  conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/
  ​
  # 阿里镜像源
  conda config --add channels https://mirrors.aliyun.com/pypi/simple/
  ​
  # 豆瓣的python的源
  ​
  conda config --add channels http://pypi.douban.com/simple/ 
  ​
  # 显示检索路径，每次安装包时会将包源路径显示出来
  ​
  conda config --set show_channel_urls yes
  ​
  conda config --set always_yes True
  ​
  # 显示所有镜像通道路径命令
  ​
  conda config --show channels
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
</ul>
]]></content>
      <categories>
        <category>环境配置</category>
      </categories>
      <tags>
        <tag>命令行</tag>
      </tags>
  </entry>
  <entry>
    <title>python数据处理之时间变换</title>
    <url>/2020/09/19/python-shu-ju-chu-li-zhi-shi-jian-bian-huan/</url>
    <content><![CDATA[<p>本文将就<code>python</code>中对时间标识的处理做一点讲解，在进行数据分析时，有些时候我们需要对时间序列数据进行处理，比如像下面这样一组数据<span id="more"></span>:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Time</th>
<th style="text-align:center">feature1</th>
<th style="text-align:center">…</th>
<th style="text-align:center">feature n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">2013年-01月-01日: 00时00分00秒</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
</tr>
<tr>
<td style="text-align:center">2013年-01月-01日: 02时00分00秒</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
</tr>
<tr>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
</tr>
<tr>
<td style="text-align:center">2015年-01月-01日: 00时00分00秒</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
<td style="text-align:center">…</td>
</tr>
</tbody>
</table>
</div>
<p>对于这样一段时序数据，采样间隔2小时。当我们拿到这组数据之后，首先要考虑的问题就是这组数据有没有缺失，而判断数据记录有无缺失的关键在于其时间序列<code>Time</code>是否连续。我们一般采用<code>pandas.read_csv()</code>函数来进行<code>csv</code>文件中数据的读取，读取得到的第一列是一个字符串形式，通过这些字符串来判断时间是否连续是比较困难的，需要重新写一个函数来对字符串进行处理。但幸运的是，其实已经有函数可以帮我们完成这样一项工作了，下面介绍下本文的关键对象—-<code>unix时间戳</code>：</p>
<blockquote>
<p><strong>unix时间戳:</strong> unix时间戳是一种跟踪时间（以秒为单位）的方式。此计数从1970年1月1日UTC的Unix Epoch开始。因此，unix时间戳仅仅是特定日期与Unix纪元之间的秒数。</p>
</blockquote>
<p>简而言之，unix时间戳就是一个<code>int</code>型的数据，其值代表了某个时间点距离<code>1997-01-01: 00:00:00</code>的秒数，那么如果我们能够将我们的时间字符串转换成unix时间戳，那么后面的数据拆分、数据缺失定位就更加得心应手了。本文按照以下结构进行组织:</p>
<ul>
<li>常见日期时间类型 </li>
<li>日期格式转换 </li>
<li>总结</li>
</ul>
<h3 id="常见日期时间类型"><a href="#常见日期时间类型" class="headerlink" title="常见日期时间类型"></a>常见日期时间类型</h3><p>在进行时间序列数据处理时，常见的日期时间类型大概有以下四种:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">类型</th>
<th style="text-align:left">格式</th>
<th style="text-align:center">示例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">time</td>
<td style="text-align:left">时间格式</td>
<td style="text-align:center">17:00:00</td>
</tr>
<tr>
<td style="text-align:left">date</td>
<td style="text-align:left">日期格式</td>
<td style="text-align:center">2019-09-19</td>
</tr>
<tr>
<td style="text-align:left">datetime</td>
<td style="text-align:left">日期时间格式</td>
<td style="text-align:center">2019-09-19: 17:00:00</td>
</tr>
<tr>
<td style="text-align:left">timestamp</td>
<td style="text-align:left">时间戳格式</td>
<td style="text-align:center">1568912400</td>
</tr>
</tbody>
</table>
</div>
<p>实际上以上四种类型可以粗分为两个类型: 字符串类型和时间戳格式，时间字符串直接转时间戳格式并不自然，因此在python中实现两者转化还需借助一个中间变量类型<code>struct_time</code>，时间格式变换流程如下:</p>
<script type="math/tex; mode=display">
    str \Leftrightarrow struct \, time \Leftrightarrow stamp</script><p>字符串格式和时间戳格式通过我上面的讲解大家应该可以有一个基本认识，下面重点介绍下<code>struct_time</code>类型，它是一个具有命名元祖接口的对象:可以通过索引和属性名访问值，存在以下值:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">index</th>
<th style="text-align:center">attribute</th>
<th style="text-align:center">values</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">tm-year</td>
<td style="text-align:center">年份</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">tm-mon</td>
<td style="text-align:center">月份range(1,12)</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">tm-mday</td>
<td style="text-align:center">天数range(1,31)</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">tm-hour</td>
<td style="text-align:center">小时range(0,23)</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">tm-min</td>
<td style="text-align:center">分钟range(0,59)</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">tm-sec</td>
<td style="text-align:center">秒数range(0,59)</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">tm-wday</td>
<td style="text-align:center">星期range(0,6)</td>
</tr>
<tr>
<td style="text-align:center">7</td>
<td style="text-align:center">tm-yday</td>
<td style="text-align:center">年中的一天range(1,366)</td>
</tr>
</tbody>
</table>
</div>
<p>而要实现这样的变换，则就要提到<code>python</code>中两个专门与时间打交道的模块<code>time</code>和<code>datetime</code>。</p>
<h3 id="日期和格式转换"><a href="#日期和格式转换" class="headerlink" title="日期和格式转换"></a>日期和格式转换</h3><p>这部份将介绍以下<code>time</code>以及<code>datetime</code>中常用的一些方法。</p>
<h4 id="time模块"><a href="#time模块" class="headerlink" title="time模块"></a><code>time</code>模块</h4><p><a href="https://docs.python.org/3/library/time.html"><code>time</code></a>模块是操作系统层面上的， 与<code>os</code>模块类似，主要提供一些系统层面的与时间有关的操作，该模块是其他所有与时间相关模块的基础，我们用到该模块比较多的方法主要有以下几个:</p>
<ul>
<li><p><code>time.time()</code>: 返回当前时间的时间戳 </p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">>>>: 
print(time.time())
>>>: 
1600502127.7830698
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p><code>time.loacltime()</code>: 将一个<code>unix stamp</code>转换为本地时间(东八区)的<code>struct_time</code>类型 </p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">>>>: 
print(time.localtime(time.time())) 
>>>: 
time.struct_time(tm_year=2020, tm_mon=9, tm_mday=19, tm_hour=16, tm_min=2, tm_sec=55, tm_wday=5, tm_yday=263, tm_isdst=0)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><code>time.gmtime()</code>: 将一个<code>unix stamp</code>转换为格林威治时间的<code>struct_time</code>类型 <pre class="line-numbers language-lang-python"><code class="language-lang-python">>>>: 
print(time.gmtime(time.time()))
>>>: 
time.struct_time(tm_year=2020, tm_mon=9, tm_mday=19, tm_hour=8, tm_min=5, tm_sec=31, tm_wday=5, tm_yday=263, tm_isdst=0)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><code>time.strftime(format, struct_time)</code>: 将一个<code>struct_time</code>类型输出转换为指定格式的字符串  <pre class="line-numbers language-lang-python"><code class="language-lang-python">>>>: 
format = '%Y-%m-%d: %H:%M:%S' 
struct_time = time.localtime(time.time()) 
print(time.strftime(format, struct_time)) 
>>>: 
2020-09-19: 16:10:42
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p><code>time.strptime(str, format)</code>: 与<code>strftime</code>作用相反，将一个时间字符串按照<code>format</code>格式解析成<code>struct_time</code>类型 </p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">>>>: 
format = '%Y-%m-%d: %H:%M:%S'  
time_str = '2020-9-19: 16:17:00' 
print(time.strptime(time_str, format))  
>>>: 
time.struct_time(tm_year=2020, tm_mon=9, tm_mday=19, tm_hour=16, tm_min=17, tm_sec=0, tm_wday=5, tm_yday=263, tm_isdst=-1)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p><code>time.mktime(struct_time)</code>: 将一个<code>struct_time</code>类型数据转化成<code>unxi_stample</code>, 该操作是<code>time.localtime()</code>的反操作，因此其默认输入的<code>struct_time</code>是本地时间</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">>>>: 
format = '%Y-%m-%d: %H:%M:%S'  
time_str = '2020-9-19: 16:17:00' 
time_struct = time.strptime(time_str, format) 
print(time_struct)
print(time.mktime(time_struct)) 
print(time.localtime(time.mktime(time_struct)))
>>>:
time.struct_time(tm_year=2020, tm_mon=9, tm_mday=19, tm_hour=16, tm_min=17, tm_sec=0, tm_wday=5, tm_yday=263, tm_isdst=-1)
1600503420.0
time.struct_time(tm_year=2020, tm_mon=9, tm_mday=19, tm_hour=16, tm_min=17, tm_sec=0, tm_wday=5, tm_yday=263, tm_isdst=0)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
</ul>
<p>上面这些方法实际上就已经完全可以实现我们的功能，大致是下面这样一张图:</p>
<p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/time.png" alt="转换方法"></p>
<h4 id="datetime模块"><a href="#datetime模块" class="headerlink" title="datetime模块"></a><code>datetime</code>模块</h4><p><code>datetime</code>模块可以看作是对<code>time</code>模块的一个封装和扩展，上面提到的<code>time</code>中常用方法在<code>datetime</code>中均有对应, 在<code>datetime</code>下主要有以下几个类：</p>
<ul>
<li><code>date</code>: 处理与日期相关的数据，属性: year, month, day </li>
<li><code>time</code>: 处理与某天时间相对应的数据， 属性: hour, minute, second, microsecond, tzinfo </li>
<li><code>datetime</code>: 日期和时间的组合，属性: year, month, day, hour, minute, second, microsecond, tzinfo </li>
<li><code>timedelta</code>: 与持续时间计算有关  </li>
<li><code>tzinfo</code>: 时区信息类  </li>
</ul>
<p><code>datetime</code>类基本已经可以实现上面<code>time</code>模块所能实现的功能，具体对应大家可以去官网<a href="https://docs.python.org/2/library/datetime.html">datetime</a>查看，我后面如果需要用到也会进行总结。 </p>
<h4 id="pandas-to-datetime"><a href="#pandas-to-datetime" class="headerlink" title="pandas.to_datetime()"></a><code>pandas.to_datetime()</code></h4><p>我们读取数据往往需要使用<code>pandas</code>库，得到<code>Dateframe</code>类型的数据，读取之后往往某一列就是时间序列，若用前面的方法来做转换，需要对每一个时间字符串操作，比较麻烦。为了解决该问题，就需要使用<code>pandas.to_datetime()</code>方法，使用该方法可以将变量变为<code>datetime</code>类型，方便后面进行操作。</p>
<ul>
<li>字符串时间转时间戳<pre class="line-numbers language-lang-python"><code class="language-lang-python">data.time = pandas.to_datetime(data.time) 
data.time = data.time.apply(lambda x: time.mktime(x.tuple))
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</li>
<li>时间戳转字符串 <pre class="line-numbers language-lang-python"><code class="language-lang-python">data.time = pandas.to_datetime(data.time) 
data.time = data.time.apply(lambda x: time.strftime(format, x.tuple))
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在进行数据处理的时候我们往往不能够默认数据是“好数据”，因此就必须通过程序来对数据进行验证，而对于时序数据，时间信息的处理是绕不过去的，掌握了<code>python</code>中常用的对时间处理方法，后面处理时序数据可以更加得心应手。</p>
]]></content>
      <categories>
        <category>python学习</category>
      </categories>
      <tags>
        <tag>编程技能， 时序数据</tag>
      </tags>
  </entry>
  <entry>
    <title>transformer_self-attention机制学习</title>
    <url>/2020/11/13/transformer-self-attention-ji-zhi-xue-xi/</url>
    <content><![CDATA[<p>基于RNN的网络结构(LSTM,gru等)在nlp领域有着广泛应用，但RNN这样的网络结构使其固有长程梯度消失的问题，对于较长的句子，我们很难寄希望于将输入的序列转化为定长的向量(embedding)而保存所有有效的信息。 为了解决这一由长序列到定长向量转化而造成信息损失的瓶颈，attention机制诞生了。<br><span id="more"></span><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/transformer.gif" alt="self-attention"> </p>
<p>上面的<code>gif</code>给出了self-attention机制的直观演示，对于传统的RNN网络，网络结构本身就导致经过Encoder之后的向量中更多包含后面样本的信息，而前面样本的信息被稀释了，而self-attention机制可以无差别的注意到序列中的任意一个单位。 </p>
<h4 id="Transformer-详解"><a href="#Transformer-详解" class="headerlink" title="Transformer 详解"></a>Transformer 详解</h4><blockquote>
<p><strong>关于transformer结构的详解请参考这篇博文:</strong><br><a href="http://jalammar.github.io/illustrated-transformer/">图解transformer</a></p>
</blockquote>
<h4 id="实验部分"><a href="#实验部分" class="headerlink" title="实验部分"></a>实验部分</h4><p>后面会补一个实验，先挖坑在这</p>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>transformer, self-attention机制</tag>
      </tags>
  </entry>
  <entry>
    <title>《刘擎西方现代思想讲义》读后感</title>
    <url>/2021/11/30/liu-qing-xi-fang-xian-dai-si-xiang-jiang-yi-du-hou-gan/</url>
    <content><![CDATA[<p>最近阅读了《刘擎西方现代思想讲义》，对20世纪以来的一些西方哲学家的思想有了粗略的了解，本文就按照刘擎老师的叙述脉络来总结一下书中内容。 <span id="more"></span> </p>
<p>本书的篇章并不是单单以人物来划分章节，而是<strong>以问题为核心，以人物的线索来编排组织，同时大致考虑了由远及近的年代时序。</strong> </p>
<p>书中的思想任务，都或多或少围绕着一个共同的核心问题-<strong>现代性问题</strong>，而作者提到，学习本书的目的在于学会做一个<strong>清醒的现代人</strong>。 </p>
<p>在导论中，作者论述了一个老生常谈的问题，也是像我这的理工科学生经常陷入的思考：</p>
<blockquote>
<p><strong>思想究竟有什么现实意义？</strong> </p>
</blockquote>
<p>为了回答这个问题，作者举了一个购物的例子，从<strong>购买习惯</strong>，到背后的<strong>性价比最优</strong>逻辑，再到<strong>经济理性人</strong>模型，再到<strong>自利、理性</strong>，这样一步步由表及里，剥开了现实生活这层外衣，看到了内在的思想本质。 </p>
<h3 id="现代、现代化与现代性"><a href="#现代、现代化与现代性" class="headerlink" title="现代、现代化与现代性"></a>现代、现代化与现代性</h3><p><strong>现代、现代化与现代性</strong>，这几个词我们几乎天天都会见到，但我们可能从未思考过这几个词背后真正的含义是什么，本文作者认真思考了这几个词的含义，力图将<strong>现代性问题</strong>定义清晰。 </p>
<ul>
<li><strong>现代</strong> <ul>
<li>代表着一种对传统的否定甚至决裂的态度。 </li>
<li>时间观念的转变，推动我们从“厚古薄今”转向“厚今薄古”。 </li>
<li>对人的创造性和主体性的肯定，人类从循环历史宿命的束缚中解放出来，成为自由的、有目的的创造者，成为主宰自己命运的个体。  </li>
</ul>
</li>
<li><strong>现代化</strong><ul>
<li>从古代到现代转变的历史过程 </li>
</ul>
</li>
<li><strong>现代性</strong> <ul>
<li>西方现代化的结果 </li>
</ul>
</li>
</ul>
<p>在阐述了与“今”相关的三个词的内在含义之后，作者又从三个方面总结了“古今之变”： </p>
<ul>
<li>过去我们更重视事务内在的客观价值，主观意见不能轻易动摇这种客观价值，而现在，个人主观赋予的价值变得极其重要，有时甚至能压倒其他一切标准。 </li>
<li>人们观念中的自然秩序被理性打破了 </li>
<li>理性秩序的诞生</li>
</ul>
<p>从思想领域来看待“古今之变”，主要有两层变化： </p>
<ul>
<li>人类中心主义的转变 </li>
<li>个人主义的转向</li>
</ul>
<h3 id="现代思想的成年"><a href="#现代思想的成年" class="headerlink" title="现代思想的成年"></a>现代思想的成年</h3><h4 id="马克思-cdot-韦伯-1864-1920"><a href="#马克思-cdot-韦伯-1864-1920" class="headerlink" title="马克思$\cdot$韦伯(1864-1920)"></a>马克思$\cdot$韦伯(1864-1920)</h4><p>如果进行粗略总结，韦伯的思想主要包含两部分内容： </p>
<ul>
<li>看清“理性化”：现代化背后的思想动力是“理性主义”。 </li>
<li>反思“理性化”：科学理性的局限性 </li>
</ul>
<h5 id="世界的祛魅"><a href="#世界的祛魅" class="headerlink" title="世界的祛魅"></a>世界的祛魅</h5><p>祛魅作为一种理性化的取向，所要拷问的是所有超验的、神秘的东西，带来的结果就是，自然世界客观化了，不再具有神性和灵性了，成为可以用冷冰冰的因果规律解释的物质世界了。 </p>
<blockquote>
<p>我们的时代，是一个理性化、理智化， 尤其是将世界之迷魅加以祛除的时代；我们这个时代的宿命，便是一切终极而最崇高的价值，已自公共领域隐没…… </p>
</blockquote>
<p>一方面，这个祛魅的“梦醒时分”，对许多人来说，在精神上是格外荒凉的，会让人茫然若失，信仰失去了以往神秘的根基，而理性主义的科学不能够为生命的意义提供根本依据。 </p>
<p>另一方面，世界的祛魅是现代的真相，高兴也罢，失落也罢，我们都必须直面这个真相。 </p>
<h5 id="诸神之争-价值观之争"><a href="#诸神之争-价值观之争" class="headerlink" title="诸神之争-价值观之争"></a>诸神之争-价值观之争</h5><p>科学可以回答“事实判断”领域的诸多问题，但确无法给出“价值判断”领域的标准答案，我们进入了一个“价值多元化”的困境。</p>
<blockquote>
<p>人是悬挂在自己编织的意义之网上的动物。 </p>
</blockquote>
<p>我们每个人必须自己决定，哪一个是上帝，哪一个是魔鬼。自由变成了沉重的负担，我们可能会变得茫然失措，不知如何选择，或者采取所谓“决断论”的方式，听凭自己的意志，随心所欲地做选择，这是现代性困境的重要标志。 </p>
<h5 id="工具理性与价值理性"><a href="#工具理性与价值理性" class="headerlink" title="工具理性与价值理性"></a>工具理性与价值理性</h5><p>韦伯将人的理性分成了两类：</p>
<ul>
<li>工具理性： 找做事的手段，即一件事怎么做才是有效的。 </li>
<li>价值理性： 做一件对不对，要不要去做这一件事 </li>
</ul>
<p>在韦伯看来，工具理性的不断扩张，导致了社会制度的官僚化。在我们的传统印象里，官僚制是效率低下的代名词，但这是个人的感受，在全局来说，有时个人体验不佳恰恰是系统追求高效的结果。 </p>
<p>一个理想的官僚系统效率高，执行力强，这种强大的能力源于官僚制的基本特征-“非个人化”，将人简化成了可以被量化的指标，这样一来，无法被计算的复杂个人就变成了可以计算的数据。 </p>
<p>但是工具理性的过分发展，淹没了对价值理性的思考，对手段的追求压倒了对目的的追求。</p>
<h5 id="现代的铁笼"><a href="#现代的铁笼" class="headerlink" title="现代的铁笼"></a>现代的铁笼</h5><p>官僚制并不只有优越的一面，以公司为例，“非个人化”在赋予一家公司强大的执行力和效率的同时，也让公司内部变得机械坚硬、冷酷无情，宛若机器。社会呈现出机器的属性，人则被“非人化”，韦伯将这个特征称为“铁笼”。 </p>
<p>“铁笼”有两个弊端： </p>
<ul>
<li>片面的社会文化： 对工具理性的极致追求 </li>
<li>片面的社会关系： 人与人、人与组织之间逐渐变成了一种商业的供求关系。 </li>
</ul>
<p>但是，也需要认识到，铁笼一方面禁锢了人的灵性，但另一方面也保护了我们。铁笼是冷酷的，但它同时又是现代生活的基础和保障。</p>
<h3 id="现代人的精神危机"><a href="#现代人的精神危机" class="headerlink" title="现代人的精神危机"></a>现代人的精神危机</h3><blockquote>
<p>我真正缺少的东西就是要在我内心弄清楚：我到底要做什么事情？ 问题在于，要找到一个对我来说确实的真理，找到一个我能够为此而生，为此而死的信念。 </p>
</blockquote>
<p>信仰需要理由么？思考这样一个问题往往会带来痛苦，这让我很羡慕那些对某些理论不加证明一辈子深信不疑的人。在信仰与真理之间存在在一个逻辑断裂，这让你无法去用对错来衡量一个信仰。</p>
<p>对于信仰，你只能够选择“纵身一跃”，才有可能跨越信仰与真理之间的鸿沟，这完全是一种冒险，所以说，信仰需要极大地勇气。 </p>
<p>如果说信仰是心灵的故乡，那么对于许许多多达不到信仰的现代人来说，就陷入了心灵无家可归的困境，这种困境就是“现代人的精神危机”。 </p>
<h4 id="尼采-1844-1900"><a href="#尼采-1844-1900" class="headerlink" title="尼采(1844-1900)"></a>尼采(1844-1900)</h4><p>尼采生平有一个关键词-<strong>叛逆</strong>，他反叛基督教，反叛自己的家庭与成长环境，反叛他学术出身的学院派。 </p>
<h5 id="上帝死了"><a href="#上帝死了" class="headerlink" title="上帝死了"></a>上帝死了</h5><p>尼采有一个非常著名的宣言-“上帝死了”，很多人认为这是一句欢呼，欢呼上帝死了，人类进入了一个新的时代。 </p>
<p>但是实际上，尼采在宣告“上帝死了”之后，下一句话就是“是我们杀死了上帝！”，他说：“这个世界上最神圣、最万能的上帝，现在已经倒在了我们刀下”。他还质问：“我们这些最残忍的凶手，如何才能洗清我们身上的血迹？” </p>
<p>尼采的宣告仿佛十分痛心，这是因为他认识到了“上帝死了”所将带来的严重后果，对于当时的西方人而言，否定了上帝，信仰的大厦完全倒塌，生命找不到意义，人们就会陷入虚无主义之中。 </p>
<p>而至于为什么是“我们杀死了上帝”，目前学界仍未有定论，刘擎老师认为，尼采的意思是，人们用虚假的教义去理解救世主的启示，最终让这个信仰变得不可信。在这个意义上，是人们杀死了上帝。</p>
<p>而尼采所提到的“虚假的思想”指的是形而上学，尼采概括说，形而上学有三大信念： </p>
<ul>
<li>相信在感知的表象世界背后有一个更加真实的本质世界 </li>
<li>相信这个混乱的世界实际上是有目的的 </li>
<li>相信这个纷乱多样的世界背后有一种统一性 </li>
</ul>
<p>尼采认为，那个所谓更真实的、有目的的、有统一性的本质世界并不存在，认为这是形而上学的编造。 这些虚假的思想纯粹是为了带来安慰，否认了原始的生命欲望，但尼采认为，生命欲望是真实的，也是正当的。在尼采看来，那些看上去高尚典雅、充满确定感的形而上学才是虚无主义的真正根源。 </p>
<h5 id="超人理论"><a href="#超人理论" class="headerlink" title="超人理论"></a>超人理论</h5><p>在“上帝已死”之后，人们失去了绝对可靠的信念，陷入了虚无主义的困境。但尼采认为，这并不是意味着悲惨、可怕的处境，如果能直面虚无主义的真相，那就不会陷入绝望，反而会激发出一种创造力量。</p>
<p>孙周兴老师概括尼采思想的三大命题： 人生虚无，理论虚假，生命强健。 而“超人”正是掌握着生命本身的强健力量，掌握着人唯一拥有的真实的东西，掌握着战胜虚无的武器。 </p>
<blockquote>
<p>尼采认为，面对无意义的世界和无意义的生命，人应该立足于现实，直面无意义的荒谬，以强大的生命本能舞蹈，在生命活动中创造出价值。  </p>
</blockquote>
<p>西西弗斯的命运是悲惨的，需要日复一日的将石头推上山顶，永无尽头，这象征了本无意义的人生，而在加缪笔下，西西弗斯又是幸福的，西西弗斯勇敢无畏地、精神焕发地去推动那块巨石，以生命的本能去承认和藐视那不可摆脱的悲剧命运。 </p>
<p>尼采说，人类的高贵在于自身有决定价值的能力，不需要别人同意，他懂得给自己的事物以荣耀。每个人都是西西弗斯，面对虚无的人生，有两种截然不同的选择，即主人道德和奴隶道德： </p>
<ul>
<li>奴隶道德： 放弃自己生命的激情，用虚假的思想约束自己、安慰自己，把人生的希望寄托在虚妄的观念之中。 </li>
<li>主人道德： 放弃一切幻觉，直面虚无和荒谬，像西西弗斯那样用生命的激情去自我创造，做一个荒谬的英雄。 </li>
</ul>
<p>对于大多数人而言，后者太难了，尼采呼唤一种新的人类-超人，在尼采的心中，超人能够在上帝死后，自己成为自己的主人，用自己的生命意志去创造，追求自身生命力量的增长和完满，最终确认和实现自己的生命意义。 </p>
<h5 id="人生本无真相"><a href="#人生本无真相" class="headerlink" title="人生本无真相"></a>人生本无真相</h5><p>尼采认为，客观的事实真相可能根本并不存在，没有事实，只有阐释。尼采认为对于同一件事情，不同的视角将带来不同的观点，视角决定事实，我们进入了一个<strong>后真相</strong>的时代。 </p>
<blockquote>
<p>人不是看到了真相，而是制造了真相。 </p>
</blockquote>
<p>而对于那些公认的事实(比如天上有一个太阳)，尼采认为，这种客观性不过是一种错觉，只是因为人们有着“共同视角”。</p>
<p>在这样一个后真相的时代，我们能做些什么呢？尼采在《道德的谱系》这本书中写到： </p>
<blockquote>
<p>我们越是运用更多的眼睛、不同的眼睛去观察同一个东西，我们对这个东西的概念就越完整，我们也能够越客观。 </p>
</blockquote>
<p>视角主义教给我们的，不是分裂的必然，而是谦逊的必要。</p>
<h4 id="弗洛伊德-1856-1939"><a href="#弗洛伊德-1856-1939" class="headerlink" title="弗洛伊德(1856-1939)"></a>弗洛伊德(1856-1939)</h4><h5 id="精神结构的黑暗领域"><a href="#精神结构的黑暗领域" class="headerlink" title="精神结构的黑暗领域"></a>精神结构的黑暗领域</h5><p>弗洛伊德是一名心理医生，他发现人类心理结构中存在一个黑暗地带，叫做“无意识”，他认为人的精神结构就像一座冰山，人能意识到的只是浮出水面的一小部分，在水面下还有巨大的一部分，就是无意识。</p>
<p>无意识部分蕴含着巨大的精神能量，潜藏在无意识中的欲望本能往往比表层意识中的理性思考更具能量。 </p>
<p>弗洛伊德没有办法直接证明无意识的存在，但他医生的身份使他可以给出一个个心理疾病的案例来证明无意识的存在，使他发展出了一套精神分析学说。 </p>
<h5 id="三元——本我、自我、超我"><a href="#三元——本我、自我、超我" class="headerlink" title="三元——本我、自我、超我"></a>三元——本我、自我、超我</h5><ul>
<li>本我： 最根本的自我，是人格的最底层，这里就是“无意识”的领地，主要是人的本能的原始欲望。这些与生俱来的欲望要寻求即刻的满足，不论是非对错，只要满足了欲望就很快乐。 </li>
<li>自我： 这就是我们能够意识到的那个自己。自我有理性，会正视社会现实，重视常识和规则，它能够感受到本我的欲望，但会用理性甄别本我的要求。 </li>
<li>超我： 超越自我的那一部分，是我们心中的理想化人格。它是在人与“道德”的接触与理解中形成的，把来自家庭和社会的种种道德权威内在化成心灵的一部分。</li>
</ul>
<p>在弗洛伊德的理论中，本我与自我的关系类似于马和骑手的关系，当骑手能够正常指挥马的时候，人的精神状况就很健康，当骑手被马拖着走时，就偏离了正常的精神状况，久而久之就会发展成为心理疾病。</p>
<h5 id="弗洛伊德理论的科学性"><a href="#弗洛伊德理论的科学性" class="headerlink" title="弗洛伊德理论的科学性"></a>弗洛伊德理论的科学性</h5><p>首先谈一下弗洛伊德的贡献： </p>
<blockquote>
<p>弗洛伊德并不是发现无意识本能的第一人，他的重要贡献在于综合前人的思想，以科学的名义提出了一套系统化的心理结构理论。</p>
</blockquote>
<p>但在学术界，主流观点认为弗洛伊德的理论并不是科学，弗洛伊德建立的理论大厦很辉煌，但大厦的事实基础却不够牢固。</p>
<blockquote>
<p>著名的哲学家波普尔曾经提过，科学理论有一个重要的特征叫做“可证伪性”。</p>
</blockquote>
<p>而精神分析学说有一种怎么样都能自圆其说的倾向。到了现代，弗洛伊德的学说作为一种对人类精神活动的阐释，更多地以一种哲学或文化理论的形式出现。</p>
<blockquote>
<p>无论弗洛伊德是如何被人理解或者误解的，他永久地改变了我们理解人性的方式。 </p>
</blockquote>
<h4 id="萨特-1905-1980"><a href="#萨特-1905-1980" class="headerlink" title="萨特(1905-1980)"></a>萨特(1905-1980)</h4><p>萨特的思想中有两个重要的观念，一个是自由选择，一个是积极行动，但萨特又有一句非常有名的话：</p>
<blockquote>
<p>存在就是虚无 </p>
</blockquote>
<h5 id="虚无的存在"><a href="#虚无的存在" class="headerlink" title="虚无的存在"></a>虚无的存在</h5><p>萨特认为，人的存在就是意识，而意识本身是虚无，那么人的存在也就是虚无。萨特还用了一堆概念来区分物的存在和人的存在，他把物的那种被决定的、不能改变的存在叫作“自在”的存在，而人的“有待形成”的不固定的存在叫作“自为”的存在。</p>
<p>人的存在本质上是虚无，这赋予了人一个永恒的需求，人厌恶虚空，厌恶虚空背后的缺失和不确定性，所以我们总是需要去填补自己的虚无，去获得某种本质。 </p>
<h5 id="徒劳的激情"><a href="#徒劳的激情" class="headerlink" title="徒劳的激情"></a>徒劳的激情</h5><p>人如何才能获得自己的本质呢？最直接的做法是去模仿物，通过占有物的存在，我们可以得到一个确定的本质，但是这样的做法只是局部地暂时地满足了对确定性的需求，根本上的虚无是无法改变的。</p>
<p>人是自为的存在，会不断地为自己寻求本质，而因为<strong>存在结构会溢出我们所占有的对象</strong>，通过占有物，人无法获得固定的、填满的、不变的本质，所以说<strong>人是一种徒劳的激情</strong>。 </p>
<h5 id="自由选择"><a href="#自由选择" class="headerlink" title="自由选择"></a>自由选择</h5><p>人永远不“是”什么，人永远都在“成为”什么,在这个意义上，人是自由的，甚至人就是自由本身。所以萨特说： </p>
<blockquote>
<p>人是被判定为自由的，自由是人的命运，人惟一的不自由就是不能摆脱自由。 </p>
</blockquote>
<h5 id="自由是沉重的负担"><a href="#自由是沉重的负担" class="headerlink" title="自由是沉重的负担"></a>自由是沉重的负担</h5><p>自由之所以会成为负担，是因为选择必然会带来结果，只有自己能够承担这个结果。所以说： </p>
<blockquote>
<p>人在拥有绝对的自由的同时，也拥有着绝对的责任，人是自己生命的孤证。</p>
</blockquote>
<p>我们生活在一个有他人存在的世界里，每个人都是自由的，但我们不可能实现那种理想中的共同自由，因为每个人都承认自己的主体性，无法调和人的主体性与人的对象性，人与人之间只有永恒的斗争。</p>
<h3 id="20世纪的教训"><a href="#20世纪的教训" class="headerlink" title="20世纪的教训"></a>20世纪的教训</h3><h4 id="20世纪的灾难"><a href="#20世纪的灾难" class="headerlink" title="20世纪的灾难"></a>20世纪的灾难</h4><p>本章将内容由现代人的心灵生活转到现代人的政治生活，为什么我们需要政治权威呢？政治学有两个基本假设： </p>
<ul>
<li>资源匮乏： 人类生活所需的资源总是匮乏的，若资源无限，则秩序很容易形成，也就不需要政治权威保障公共秩序。 </li>
<li>人性自利： 每个人都会优先考虑自身的利益实现 </li>
</ul>
<p>资源匮乏与人性自利两个假设，是社会现实状况的反映，也意味着公共秩序无法自然形成，需要某种强制的政治权威建立和维护。而公共秩序则要求： </p>
<ul>
<li>一套公共的规则：常体现为习俗或法律 </li>
<li>政治权威：提供落实规则的执行力 </li>
</ul>
<p>政治权威的统治有两大特点： </p>
<ul>
<li>强制性：依赖军队与暴力</li>
<li>合法性 </li>
</ul>
<p>从古至今，政治合法性发生了重大变化，古代的统治依赖于自然等级结构，人们相信自己天生处在高低贵贱的不同等级之中。而在启蒙运动之后，“神意”与“天道”被祛魅了，自然的等级结构被瓦解了，现代人将自己视为自由而平等的个体，政治权威必须解释其统治的根本依据。 </p>
<p>为了解释政府的存在，霍布斯、卢梭、洛克等人提出了不同版本的“社会契约论”，它们都具有两个共同特征： </p>
<ul>
<li>先存在自然状态，然后才有的政府，即政府不是天然的。 </li>
<li>政治权威的统治合法性来自被统治者的同意，是自下而上的。</li>
</ul>
<p>20世纪有着许多残酷的灾难： 两次世界大战、纳粹大屠杀、冷战、经济危机，但是20世纪也是人类文明取得长足进步的一个实际，而这些灾难是： </p>
<blockquote>
<p>文明时代的野蛮，理性时代的疯狂。 </p>
</blockquote>
<h4 id="齐格-cdot-鲍曼-1925-2017"><a href="#齐格-cdot-鲍曼-1925-2017" class="headerlink" title="齐格$\cdot$鲍曼(1925-2017)"></a>齐格$\cdot$鲍曼(1925-2017)</h4><p>对于如何理解大屠杀，思想界有两种理论最为流行： </p>
<ul>
<li>将大屠杀看作是<strong>反常的偶然现象</strong>,即德国出现了一群丧心病狂的变态疯子，犯下了骇人听闻的暴行，将灾难例外化，看作是一种反常的偶然现象。 </li>
<li>仇恨论，认为大屠杀之所以发生，是因为德国人与犹太人之间有一种特殊而沉重的仇恨。 </li>
</ul>
<p>但在鲍曼看来，这两种理论都站不住脚，都只是将大屠杀看作现代文明的反常例外，逃避了最需要反思的问题，在鲍曼看来： </p>
<blockquote>
<p>现代性内部的一些本质因素，才使得大屠杀成为现实，而其中关键的一点，就是理性和理性化。 </p>
</blockquote>
<p>鲍曼之所以提出这个论断，主要基于以下几点： </p>
<ul>
<li>机器般理性的官僚制，实现了大屠杀这样一个非理性的暴徒。在鲍曼看来，官僚制不仅会损坏个人自由，还会导致道德冷漠、逃避责任。 </li>
<li>现代科学主义为大屠杀提供了某种理念支持，鲍曼把这种理念称为“园艺文化”，需要净化社会中的杂志-犹太人。</li>
</ul>
<h4 id="波普尔-1902-1994"><a href="#波普尔-1902-1994" class="headerlink" title="波普尔(1902-1994)"></a>波普尔(1902-1994)</h4><h5 id="证伪主义"><a href="#证伪主义" class="headerlink" title="证伪主义"></a>证伪主义</h5><p>证伪主义可以被概括为一句话： </p>
<blockquote>
<p>一个理论算不算科学理论，首先不是看他的对错，而是要看它是否能接受事实的检测，是否具有“可证伪性”。 </p>
</blockquote>
<p>这其实是对归纳法提出了挑战，证实和证伪是不对称的，一个理论被证实成千上万次，也不能证明其彻底正确，但只要被证伪了一次，它就被推翻了。</p>
<h5 id="批判理性主义"><a href="#批判理性主义" class="headerlink" title="批判理性主义"></a>批判理性主义</h5><p>在科学领域，波普尔认识到，理性所能达到的“正确”也不过是一种“不彻底的正确”，当波普尔将这个思想转向社会政治领域，就形成了他的基本思想-批判理性主义，概括起来就是： </p>
<blockquote>
<p>人类有理性，理性有局限 </p>
</blockquote>
<p>在社会政治领域，批判理性主义所要拒绝的就是“乌托邦社会工程”的概念，反对“历史决定论”。波普尔自身所支持的是渐近社会工程，与他反对的乌托邦社会工程有以下不同： </p>
<ul>
<li>前者着眼于要克服最紧迫的恶，而后者是要追求最终极的善。 </li>
<li>前者寻求改善人们命运的合理方法，而后者也许有着及其善良崇高的愿景，但在实践中却可能加重了现实的苦难。</li>
<li>从历史上看，渐进式的改良基本能够成功，而试图整体性地创造乌托邦的规划，基本上都会引发悲剧。 </li>
</ul>
<blockquote>
<p>缔造人间天堂的企图，结果总是造就了人间地狱。 </p>
</blockquote>
<h4 id="哈耶克-1899-1992"><a href="#哈耶克-1899-1992" class="headerlink" title="哈耶克(1899-1992)"></a>哈耶克(1899-1992)</h4><h5 id="自发秩序"><a href="#自发秩序" class="headerlink" title="自发秩序"></a>自发秩序</h5><p>哈耶克认为，除了人为设计出的秩序之外，还存在自然生成的规则、自发演化出的秩序。</p>
<p>几个自发秩序的例子： </p>
<ul>
<li>乡间小路</li>
<li>语言</li>
<li>法律</li>
</ul>
<h5 id="危险的理性"><a href="#危险的理性" class="headerlink" title="危险的理性"></a>危险的理性</h5><p>哈耶克提出了“理性的自负”这一概念，即对人类的理性能力抱有过度的信心， 相信理性能够获得几乎完美的知识，从而构建出完美的社会规划，实现理想的人类生活。<br>哈耶克曾说过，那些统治者“自觉地根据一些崇高的理想来缔造我们的未来，实际上却不知不觉地创造出一种和他们想要奋斗的东西截然相反的结果，人们还能想象出比这更大的悲剧么？”</p>
<blockquote>
<p>通向地狱之路，是用善良的愿望铺成的。 </p>
</blockquote>
<h5 id="人类的必然无知"><a href="#人类的必然无知" class="headerlink" title="人类的必然无知"></a>人类的必然无知</h5><p>在认识到理性的危险性之后，哈耶克告诫我们，必须始终清醒地意识到“人类的必然无知”，强调人类的知识总是有局限的，必然包含着无知的一面。<br>在哈耶克看来，理性有两个作用： </p>
<ul>
<li>追求知识</li>
<li>认识到理性知识本身的局限性，对此保持审慎与怀疑 </li>
</ul>
<p>因此在社会生活领域，哈耶克非常推崇“自然秩序”。</p>
<blockquote>
<p>人类真正的成熟，是在勇敢运用理性的同时，直面自己永远不可能完全摆脱的无知，勇敢地与不确定性共存。 </p>
</blockquote>
<h4 id="柏林-1909-1997"><a href="#柏林-1909-1997" class="headerlink" title="柏林(1909-1997)"></a>柏林(1909-1997)</h4><p>伯林的三重身份-俄国人、犹太人、英国人。 </p>
<h5 id="反对“价值一元论”"><a href="#反对“价值一元论”" class="headerlink" title="反对“价值一元论”"></a>反对“价值一元论”</h5><p>伯林认为，一元价值只是一种幻觉，多元价值之间的冲突是不可能消除的。</p>
<blockquote>
<p>多价值的不可公度性： 找不到一把通用的尺子</p>
</blockquote>
<h5 id="自由"><a href="#自由" class="headerlink" title="自由"></a>自由</h5><p>区分两种自由： </p>
<ul>
<li>消极自由： 我不想要什么，就可以不要什么</li>
<li>积极自由： 我想做什么，就可以去做 </li>
</ul>
<p>伯林认为，积极自由的扭曲和滥用更具有欺骗性，更加需要保持警惕。 </p>
<h4 id="马尔库塞-1898-1979"><a href="#马尔库塞-1898-1979" class="headerlink" title="马尔库塞(1898-1979)"></a>马尔库塞(1898-1979)</h4><p>马尔库塞认为，像美国这样的发达工业社会是一种“新型的极权主义”，它不是用恐怖的手段控制大众，而是用无尽的消费和享受来贿赂大众，让人们陷入“舒舒服服的不自由”之中。 </p>
<p>在黑格尔那里，异化这个词是主体在自身发展中，分裂出了一个反对自己的对立面，成为一种外在的异己力量。马克思借用了这个概念，提出了“劳动异化”，即人在劳动中不是肯定自己，而是否定自己。</p>
<p>从这个角度出发，马尔库塞认为处在资本主义社会的人变成了“单面人”，变成了失去自由的人。</p>
<h3 id="自由主义及其批判者"><a href="#自由主义及其批判者" class="headerlink" title="自由主义及其批判者"></a>自由主义及其批判者</h3><p>自由主义的一个界限与两个维度： </p>
<blockquote>
<ul>
<li>一个界限： 自由主义倡导<strong>个人自由</strong>，重视保障人的个人权利。 </li>
<li>两个维度： 考察自由主义家族内部的差异 <ul>
<li>空间： 英美自由主义(消极自由)和欧洲大陆自由主义(积极自由) </li>
<li>时间： <ul>
<li>17世纪： 古典自由主义，强调个人自由与基本权利，主张国家最少干预 </li>
<li>19世纪： 现代自由主义，注重社会公正和平等的价值，转向强调政治民主 </li>
</ul>
</li>
</ul>
</li>
</ul>
</blockquote>
<h4 id="罗尔斯-1921-2002"><a href="#罗尔斯-1921-2002" class="headerlink" title="罗尔斯(1921-2002)"></a>罗尔斯(1921-2002)</h4><p>在《正义论》的开篇，罗尔斯这样写到： </p>
<blockquote>
<p>正义是社会制度的首要价值，正像真理是思想体系的首要价值一样。 </p>
</blockquote>
<p>罗尔斯假象了一个“无知之幕”的存在，每个人都对自己的特点一无所知，忘记了“自己是谁”，在这个位置上，大家处于绝对平等的地位，然后来用自己的理性来制订契约。罗尔斯认为，这契约包含两条关键原则： </p>
<blockquote>
<p>平等的自由： 每个人都平等地享有一系列基本的自由。<br>分配原则：默认的分配选项应当是完全平等分配，在两个限制下可以不公平分配： </p>
<ul>
<li>保障公平的机会平等</li>
<li>满足差异原则： 优势群体应当改善弱势群体的处境 </li>
</ul>
</blockquote>
<h4 id="诺奇克-1938-2002"><a href="#诺奇克-1938-2002" class="headerlink" title="诺奇克(1938-2002)"></a>诺奇克(1938-2002)</h4><p>诺奇克认为，罗尔斯在政治和文化上坚持自由主义，但在社会和经济问题上采用了平等主义的立场，只能够算是半个自由主义者。</p>
<p>诺奇克自己的自有理论则是一种完全彻底的自由主义理论，将个人权利放到首位: </p>
<ul>
<li>诺奇克论证的起点是个人权利的绝对优先，对个体权利作出任何限制，都要给出很强的正当理由。 </li>
<li>主张要在政治、经济和社会等领域全方位坚持自由原则，对自由市场资本主义作出了道德辩护——获取正义、转让正义、矫正正义。 </li>
</ul>
<p>在政治方面，诺奇克提出“最小国家理论”， 这个“最小国家”只需要具有保障个体公民基本自由和权利的基本功能就可以。</p>
<p>诺奇克反对任何“模式正义”的理论，认为“人是目的，而不只是手段”。 </p>
<h4 id="德沃金-1931-2013"><a href="#德沃金-1931-2013" class="headerlink" title="德沃金(1931-2013)"></a>德沃金(1931-2013)</h4><p>现代社会一个显著的发展趋势就是平等压力的不断上升，从公民权利的平等，再到社会经济领域的平等。</p>
<p>德沃金认为，我们追求平等的目的是为了一视同仁的对每个人好，在这个基础上，他提出了两个原则： </p>
<ul>
<li>平等的尊重： 平等地尊重每个人自己选择的生活方式和目标 </li>
<li>平等的关怀：  不是“平等的待遇”，而是将每个人“当作平等的人来对待”。区分了导致境况变差的原因。</li>
</ul>
<h4 id="桑德尔-1953"><a href="#桑德尔-1953" class="headerlink" title="桑德尔(1953-)"></a>桑德尔(1953-)</h4><p>桑德尔是著名的社群主义学者，他认为先有社群，然后再有个体，因此桑德尔的个人观是社群主义的个人观。 </p>
<p>桑德尔认为社群不只是工具，也不只是合作团体中的情感依赖，事实上，社群有一种“纽带关系”，从根本上定义了“你是谁”，它塑造了你的身份认同、生活理想、道德感和责任意识。在这个基础上，桑德尔认为个人就具有了一种特殊的义务，桑德尔称为“团结的义务”。 </p>
<blockquote>
<p>你生而带有一种历史，你的生活故事是更为宏大的社会故事的一部分，也蕴含于无数他人的故事之中，割断了这种联系，也就割断了你的存在。 </p>
</blockquote>
<h4 id="沃尔泽-1935"><a href="#沃尔泽-1935" class="headerlink" title="沃尔泽(1935-)"></a>沃尔泽(1935-)</h4><p>沃尔泽也是社群主义的代表人物，社群主义对自由主义的批判主要有两点： </p>
<ul>
<li>自由主义的理论是虚假的，现实中根本不存在原子化的个人。 </li>
<li>自由主义的实践是有害的，造成了自我中心、相互分裂的冷漠社会。 </li>
</ul>
<p>沃尔泽认为这两点批判之间存在逻辑裂痕，即不存在的人为何会造成损害，沃尔泽认为，“孤立的自我”确实存在，但这“孤立的自我”恰恰是社会所塑造的，诺奇克从地理、社会身份、婚姻关系、政治上的“流动性”来进行阐释。 </p>
<p>所以现代社会中的社群主要是“自愿的社群”，这样的社群可以随时自愿加入或者退出，每个人都是“后社会的自我”，在这个意义上，沃尔泽说“社群主义不可能战胜自由主义”。 </p>
<h4 id="泰勒"><a href="#泰勒" class="headerlink" title="泰勒"></a>泰勒</h4><p>社群主义的代表人物，在现代： </p>
<blockquote>
<p>个人自由带来的病症是真实的，但威权式的精英主义的解药可能是毒药。 </p>
</blockquote>
<p>泰勒认为，人应当在社群框架下坚持自己本真性，他认为：</p>
<blockquote>
<p>个人自主性的来源不可能是“唯我论”的独白，而只能来自关系性的对话。 </p>
</blockquote>
<p>本真性的理想，一方面让我们忠实自己的内心感受，一方面要求我们不要陷入唯我论的独白，积极地介入对话和反思，这是自我通向共同背景的通道，把我们和一个更加开阔的世界联系在一起。 </p>
<h4 id="哈贝马斯-1929"><a href="#哈贝马斯-1929" class="headerlink" title="哈贝马斯(1929-)"></a>哈贝马斯(1929-)</h4><h5 id="韦伯难题"><a href="#韦伯难题" class="headerlink" title="韦伯难题"></a>韦伯难题</h5><p>在现代，我们面临着工具理性的空前成就，也面临着价值理性的衰败，却无可奈克。</p>
<h5 id="在人间：主体间的交往行动"><a href="#在人间：主体间的交往行动" class="headerlink" title="在人间：主体间的交往行动"></a>在人间：主体间的交往行动</h5><p>哈贝马斯为韦伯难题开出的解药就是“交往理性”。</p>
<h3 id="后冷战时代"><a href="#后冷战时代" class="headerlink" title="后冷战时代"></a>后冷战时代</h3><h4 id="福山-历史终结论"><a href="#福山-历史终结论" class="headerlink" title="福山-历史终结论"></a>福山-历史终结论</h4><p>1992年，福山出版了《历史的终结与最后的人》，从历史哲学和政治科学两个角度论证了自己的观点。 </p>
<p>在历史哲学角度，福山也采取了类似“历史决定论”的主张，认为历史的终点是自由民主，福山认为历史的历史发展的根本动力在于“为承认而斗争”，而他认为自由民主制在原则上已经实现了这种平等的互相承认，所以他认为“历史终结了”。 </p>
<p>而在政治科学角度，福山则是从科技发展，到市场经济，再到民主政治。</p>
<h4 id="亨廷顿-文明的冲突"><a href="#亨廷顿-文明的冲突" class="headerlink" title="亨廷顿-文明的冲突"></a>亨廷顿-文明的冲突</h4><p>亨廷顿是福山的老师，在公共领域影响最大的则是他的著作《文明的冲突与世界秩序的重建》，他以文明的范式来刻画后冷战的世界，他认为，世界主要包含七个主要的文明圈： </p>
<blockquote>
<p>西方文明，拉丁美洲文明，东正教文明，印度文明，中华文明，日本文明和伊斯兰文明 </p>
</blockquote>
<p>总的来说，亨廷顿是一个政治现实主义者，他认为文明差异不可消除，冲突不可根除，只能管控，世界秩序只能建立在多种文明共存的基础之上。 </p>
]]></content>
      <categories>
        <category>读后感</category>
      </categories>
      <tags>
        <tag>阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>《正义论》读书笔记</title>
    <url>/2022/10/03/zheng-yi-lun-du-shu-bi-ji/</url>
    <content><![CDATA[<p>人生路走的愈远，愈发意识到个人的边界，愈发对社会现实有了更加清醒的认识。一切的矛盾说到根源也逃不出分配二字，什么样的分配制度是正义的呢？带着这样一个问题，我翻开了罗尔斯的《正义论》，期待罗尔斯能够给我一个答案。<span id="more"></span> </p>
<h4 id="译者前记"><a href="#译者前记" class="headerlink" title="译者前记"></a>译者前记</h4><p>首先需要明确罗尔斯《正义论》中正义的对象:</p>
<blockquote>
<p>在《正义论》中，正义的对象是社会的基本结构——即用来分配公民的基本权利和义务、划分由社会合作产生的利益和负担的主要制度。他认为，人们不同的生活前景受到政治体制和一般的经济、社会条件的限制和影响，<strong>也受到人们出生伊始所具有的不平等的社会地位和自然禀赋的深刻而持久的影响，然而这种不平等却是个人无法自由选择的。</strong> 正义原则要通过调节主要的社会制度，来从全社会的角度处理这种出发点方面的不平等，尽量排除社会历史和自然方面的偶然任意因素对于人们生活前景的影响。 </p>
</blockquote>
<p>罗尔斯还谈到正义原则与功利主义原则的区别:</p>
<ul>
<li>功利主义允许在产生最大利益总额的前提下允许对一部分人平等自由的严重侵犯。 </li>
<li>在正义原则下，各方将选择的原则处在一种“词典式序列”的原则中<ul>
<li>平等自由原则 </li>
<li>机会的公正平等原则和差别原则的结合 </li>
</ul>
</li>
</ul>
<p>罗尔斯的理论有一种“平等主义”倾向，他总是从<strong>最少受惠者</strong>的地位来看待和衡量任何一种不平等，他的理论反映了对最少受惠者的偏爱，一种尽力想通过某种补偿或者再分配使一个社会的所有成员处于一种平等地位的愿望。 </p>
<blockquote>
<p>思考: 社会发展目标 = 功利目标 + 正则项(分配，制度建构)  正则项的畸化 </p>
</blockquote>
<h4 id="序言"><a href="#序言" class="headerlink" title="序言"></a>序言</h4><p>我们常常看来不得不在功利主义和直觉主义之间进行选择，最后很可能停留在某种功利主义的变种上，这种变种在某些特殊方面又受到直觉主义的修正和限定。</p>
<h3 id="第一编-理论"><a href="#第一编-理论" class="headerlink" title="第一编 理论"></a>第一编 理论</h3><h4 id="第一章-作为公平的正义"><a href="#第一章-作为公平的正义" class="headerlink" title="第一章 作为公平的正义"></a>第一章 作为公平的正义</h4><h5 id="正义的作用"><a href="#正义的作用" class="headerlink" title="正义的作用"></a>正义的作用</h5><p><strong>社会是一种对于互相利益合作的冒险形式，它却不仅具有一种利益一致的典型特征，而且也具有一种利益冲突的典型特征</strong>。由于存在社会合作，存在着一种利益的一致，它使所有人都可能过一种比他们仅靠自己的努力独自生存所过的生活更好的生活；另一方面，由于这些人对于他们协力产生的较大利益怎样分配并不是无动于衷的，这样就产生了一种利益的冲突，就需要一系列的原则来指导在各种不同的分配制度进行选择， 达到一种有关恰当分配份额的契约。 这些所需的原则就是正义的原则。</p>
<h5 id="正义的主题"><a href="#正义的主题" class="headerlink" title="正义的主题"></a>正义的主题</h5><p>一个社会体系的正义，本质上依赖于如何分配基本的权利义务，依赖于在社会的不同阶层中存在着的经济机会和社会条件。</p>
]]></content>
      <categories>
        <category>灵魂雕琢</category>
      </categories>
      <tags>
        <tag>正义</tag>
      </tags>
  </entry>
  <entry>
    <title>《生之欲》观后感</title>
    <url>/2021/05/27/sheng-zhi-yu-guan-hou-gan/</url>
    <content><![CDATA[<p>今天以讨论座谈的形式观看了电影《生之欲》，借这个博客记录一下我觉得这部电影想要表达的内容。<br><span id="more"></span></p>
<ul>
<li><p><strong>对人生的反思</strong><br>该部电影的日语题名为“<strong>生きる</strong>”，直译过来的意思是“<strong>活着</strong>”。人活着究竟是为什么？ 这是一个永远不会过时的哲学命题，对于本部电影中的主人公渡边堪治而言，在妻子死后，他活着唯一让他感到有价值的事情就是将他的儿子抚养长大，而在得知自己时日无多之时，又了解到自己的儿子更看重的其实只是他的退休金，这让他万念俱灰，人生仿佛失去了方向，已然接近终点的人生再不见一丝光亮。在这种情况下，他经历了两周的灯红酒绿，经历了与部门离职小姑娘小田切美纪的相伴，似乎，这些都不能让他感觉到活着的意义，而在了解到小田切美纪认为自己现在的工作很有意义时，渡边开始反省自己的工作，认为自己也能改变一些东西，由此渡边找到了继续活下去的理由，开始“真正”地活着。 </p>
</li>
<li><p><strong>对于公共部门官僚主义的讽刺</strong><br>这应当是这部电影最直接表现的主题了，公共部门中的每个人似乎都很忙，但似乎又什么都没干，大家都浑浑噩噩，不求有功，但求无过。<br>当初公共部门的创立是为了更好地服务，然而随着时间的推进，整个机构仿佛就已经僵化了，人人都在自己的位置上如一个没有思想的木偶，机械地运转着，大家都已经忘记了公共部门本身存在的意义。 </p>
</li>
<li><p><strong>理想主义与现实主义的冲突</strong><br>当渡边决定将建儿童公园作为其人生的意义之时，理想主义与现实主义的冲突就展开了，建立一个对人民有利的公园是理想，而公共部门彼此之间的扯皮是现实，两者似乎很难达成一致。<br>从这个角度来说，渡边是幸运的，好像是所有人最终都被他“说服”了，公园最终如期建成，然而黑泽明也在片中隐晦地透露道，如果不是刚好赶上副市长和议员竞选，渡边将很难说服市里的领导批准建公园，这不由传递出了一丝悲哀，哪怕另一边是死亡在追逐自己，可能最终也并不能跑赢现实。<br>但是努力改变，学会真正地“活着”又是应当去追求的，儿童乐园、儿童玩具，剧中的这些细节无不在透露着，哪怕现实已经如此的糟糕，但因为这些孩子的存在，我们也应当心存期待。 </p>
</li>
</ul>
]]></content>
      <categories>
        <category>电影观后感</category>
      </categories>
      <tags>
        <tag>日本电影、黑泽明</tag>
      </tags>
  </entry>
  <entry>
    <title>《贫穷的本质》读书笔记</title>
    <url>/2022/10/05/pin-qiong-de-ben-zhi-du-hou-gan-sfconflict-2019310913-tsinghua.edu.cn-2022-10-15-10-49-22/</url>
    <content><![CDATA[<p>我今天收拾房间的时候发现了当初读这本书时记的笔记，读来感觉有些观点已经有些遗忘了，便赶快将手稿收起来，更新到博客上，也借此机会温习一下这本书。<span id="more"></span> </p>
<h4 id="Chapter1-2"><a href="#Chapter1-2" class="headerlink" title="Chapter1-2"></a>Chapter1-2</h4><p>作者首先给出了“<strong>贫困陷阱</strong>”这样一个概念，这意味着当人没有足够的卡路里支持进行劳动时，便无法获得报酬，进而进入恶性循环，步入“贫困陷阱”。 作者驳斥了这样一个观点，他认为穷人购买食物往往会选择价格低廉、口味好的非健康食品，同时在食物之外也会将钱花在别处，以让自己的生活少点乏味。</p>
<blockquote>
<p>他们不会迁怒于自己的命运，而是通过降低标准来增强自己的忍耐力，然而他们却并一定因此而专注必需品，也不一定会排斥奢侈品。 </p>
</blockquote>
<p>作者在这里给出了贫穷的第一个理由：</p>
<blockquote>
<p>穷人关注当前，尽可能让日子过的愉快 </p>
</blockquote>
<h4 id="Chapter3-提高全球居民健康水平"><a href="#Chapter3-提高全球居民健康水平" class="headerlink" title="Chapter3 提高全球居民健康水平"></a>Chapter3 提高全球居民健康水平</h4><p>作者首先介绍了“健康陷阱”： </p>
<blockquote>
<p>贫穷 -&gt; 不能有效预防疾病 -&gt; 疾病流行 -&gt; 贫穷 </p>
</blockquote>
<p>在作者看来，从这个角度来制订脱贫政策是“好摘的果子”，比如疫苗、蚊帐。<br>《贫穷的终结》的作者萨克斯认为：</p>
<blockquote>
<p>对于处于“健康陷阱”之中的人，用钱就可以将他们救出，穷人有些找不到梯子，有些则根本不想搭上梯子，<strong>穷人往往将钱花在昂贵的治疗上，而不是廉价的预防上</strong>。 </p>
</blockquote>
<p>在贫穷国家，由于这种短视，公共机构往往不能够得到有效运转，免费的东西往往起不到应有的作用：</p>
<blockquote>
<p>心理沉没成本：人们更有可能会利用他们为之支付很多钱的东西 </p>
</blockquote>
<p>在这一章节里，作者总结了穷人的困境与富裕的优势:</p>
<ul>
<li>穷人的困境： 缺乏信息、信念不坚定、拖延</li>
<li>富裕的优势： 无处不在的助推力 </li>
</ul>
<h4 id="Chapter4-全班最优"><a href="#Chapter4-全班最优" class="headerlink" title="Chapter4 全班最优"></a>Chapter4 全班最优</h4><p>在章节开篇就抛出了一个问题：</p>
<ul>
<li>为何发展中国家的学校对学生不具备吸引力？ </li>
</ul>
<p>对于教育，不同派别的人有不同的看法： </p>
<ul>
<li>教育干涉主义：受教育者学习、生活等各方面的行为需要进行严厉管束</li>
<li>自由教育主义：除非有明确需求，否则根本没必要提供教育</li>
<li>需求主义：教育不过是另一种形式的投资，人们投资于教育，就像投资于任何其他领域一样，目的是赚到更多的钱，增加未来的收入 </li>
<li>对家长来说，教育不仅仅是一种投资，而且是他们赠送给孩子的礼物 </li>
</ul>
<p>为了鼓励父母将孩子送去接受教育，可以进行<strong>有条件的现金转移</strong>，奖励那些将孩子送去学校的父母，现金转移可以使家长们摆脱极度贫困的状态，或许也可以拓宽他们的思想空间，让他们拥有更长远的人生观。 </p>
<p>作者最后回答了章节开头的那个问题：</p>
<blockquote>
<p>不现实的目标、不必要的悲观预期以及不恰当的教师鼓励机制，导致发展中国家的教育体系没能完成自身两大任务： </p>
<ul>
<li>给予每个人一套健全的基本技能</li>
<li>发掘人才 </li>
</ul>
</blockquote>
<h4 id="Chapter5-来自克苏达诺的大家庭"><a href="#Chapter5-来自克苏达诺的大家庭" class="headerlink" title="Chapter5 来自克苏达诺的大家庭"></a>Chapter5 来自克苏达诺的大家庭</h4><p>孩子“质”与“量”的取舍，穷人往往多生，来规避风险 </p>
<h4 id="Chapter7-贷款给穷人：不那么简单的经济学"><a href="#Chapter7-贷款给穷人：不那么简单的经济学" class="headerlink" title="Chapter7 贷款给穷人：不那么简单的经济学"></a>Chapter7 贷款给穷人：不那么简单的经济学</h4><p>对于正规机构来说，可贷款数量与借款人的资金现状挂钩，因此穷人借款只能通过放债人，穷人使用高利贷规避可能出现的灾病风险，几乎不可能的脱贫，因为高利贷的利息成本和穷人的违约率“一损俱损”。 </p>
<h4 id="Chapter8-节省一砖一瓦"><a href="#Chapter8-节省一砖一瓦" class="headerlink" title="Chapter8 节省一砖一瓦"></a>Chapter8 节省一砖一瓦</h4><p>穷人耐心不够，不会未雨绸缪</p>
<h4 id="Chapter9-不情愿的企业家们-穷人"><a href="#Chapter9-不情愿的企业家们-穷人" class="headerlink" title="Chapter9 不情愿的企业家们(穷人)"></a>Chapter9 不情愿的企业家们(穷人)</h4><p>穷人企业的特点：小本生意、利润低<br>穷人做生意往往是失败的经济模式的演绎，这是因为他们对稳定十分向往。</p>
<h4 id="Chapter10-政策、政治"><a href="#Chapter10-政策、政治" class="headerlink" title="Chapter10 政策、政治"></a>Chapter10 政策、政治</h4><p>政治制度的存在是为了防止领导者建立为自己谋私利的经济制度<br>民主能够给政府提供直接的反馈信息，约束政府履行其职责 </p>
<blockquote>
<p>自由不能从外部引入，否则就不会有真正的自由</p>
</blockquote>
<p>政策的制定者是政治精英们，他们往往有着复杂的动机，制定后将作用于普通大众，割裂。<br>三大问题：意识形态、无知、惯性 </p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul>
<li>穷人缺少信息来源</li>
<li>穷人肩负着生活中的诸多责任</li>
<li>一些服务于穷人的市场正在消失，得到补贴的市场受到严格监管</li>
<li>贫困的国家不会因为贫穷或者不堪回首的历史而注定失败 </li>
<li>改变人们的期望是不容易的，在启动一个良性循环时，人们不应害怕必要的付出</li>
<li>拒绝懒惰和公式化的思考模式 </li>
</ul>
]]></content>
      <categories>
        <category>灵魂雕琢</category>
      </categories>
      <tags>
        <tag>书籍阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>《贫穷的本质》读书笔记</title>
    <url>/2022/10/05/pin-qiong-de-ben-zhi-du-hou-gan/</url>
    <content><![CDATA[<p>我今天收拾房间的时候发现了当初读这本书时记的笔记，读来感觉有些观点已经有些遗忘了，便赶快将手稿收起来，更新到博客上，也借此机会温习一下这本书。<span id="more"></span> </p>
<h4 id="Chapter1-2"><a href="#Chapter1-2" class="headerlink" title="Chapter1-2"></a>Chapter1-2</h4><p>作者首先给出了“<strong>贫困陷阱</strong>”这样一个概念，这意味着当人没有足够的卡路里支持进行劳动时，便无法获得报酬，进而进入恶性循环，步入“贫困陷阱”。 作者驳斥了这样一个观点，他认为穷人购买食物往往会选择价格低廉、口味好的非健康食品，同时在食物之外也会将钱花在别处，以让自己的生活少点乏味。</p>
<blockquote>
<p>他们不会迁怒于自己的命运，而是通过降低标准来增强自己的忍耐力，然而他们却并一定因此而专注必需品，也不一定会排斥奢侈品。 </p>
</blockquote>
<p>作者在这里给出了贫穷的第一个理由：</p>
<blockquote>
<p>穷人关注当前，尽可能让日子过的愉快 </p>
</blockquote>
<h4 id="Chapter3-提高全球居民健康水平"><a href="#Chapter3-提高全球居民健康水平" class="headerlink" title="Chapter3 提高全球居民健康水平"></a>Chapter3 提高全球居民健康水平</h4><p>作者首先介绍了“健康陷阱”： </p>
<blockquote>
<p>贫穷 -&gt; 不能有效预防疾病 -&gt; 疾病流行 -&gt; 贫穷 </p>
</blockquote>
<p>在作者看来，从这个角度来制订脱贫政策是“好摘的果子”，比如疫苗、蚊帐。<br>《贫穷的终结》的作者萨克斯认为：</p>
<blockquote>
<p>对于处于“健康陷阱”之中的人，用钱就可以将他们救出，穷人有些找不到梯子，有些则根本不想搭上梯子，<strong>穷人往往将钱花在昂贵的治疗上，而不是廉价的预防上</strong>。 </p>
</blockquote>
<p>在贫穷国家，由于这种短视，公共机构往往不能够得到有效运转，免费的东西往往起不到应有的作用：</p>
<blockquote>
<p>心理沉没成本：人们更有可能会利用他们为之支付很多钱的东西 </p>
</blockquote>
<p>在这一章节里，作者总结了穷人的困境与富裕的优势:</p>
<ul>
<li>穷人的困境： 缺乏信息、信念不坚定、拖延</li>
<li>富裕的优势： 无处不在的助推力 </li>
</ul>
<h4 id="Chapter4-全班最优"><a href="#Chapter4-全班最优" class="headerlink" title="Chapter4 全班最优"></a>Chapter4 全班最优</h4><p>在章节开篇就抛出了一个问题：</p>
<ul>
<li>为何发展中国家的学校对学生不具备吸引力？ </li>
</ul>
<p>对于教育，不同派别的人有不同的看法： </p>
<ul>
<li>教育干涉主义：受教育者学习、生活等各方面的行为需要进行严厉管束</li>
<li>自由教育主义：除非有明确需求，否则根本没必要提供教育</li>
<li>需求主义：教育不过是另一种形式的投资，人们投资于教育，就像投资于任何其他领域一样，目的是赚到更多的钱，增加未来的收入 </li>
<li>对家长来说，教育不仅仅是一种投资，而且是他们赠送给孩子的礼物 </li>
</ul>
<p>为了鼓励父母将孩子送去接受教育，可以进行<strong>有条件的现金转移</strong>，奖励那些将孩子送去学校的父母，现金转移可以使家长们摆脱极度贫困的状态，或许也可以拓宽他们的思想空间，让他们拥有更长远的人生观。 </p>
<p>作者最后回答了章节开头的那个问题：</p>
<blockquote>
<p>不现实的目标、不必要的悲观预期以及不恰当的教师鼓励机制，导致发展中国家的教育体系没能完成自身两大任务： </p>
<ul>
<li>给予每个人一套健全的基本技能</li>
<li>发掘人才 </li>
</ul>
</blockquote>
<h4 id="Chapter5-来自克苏达诺的大家庭"><a href="#Chapter5-来自克苏达诺的大家庭" class="headerlink" title="Chapter5 来自克苏达诺的大家庭"></a>Chapter5 来自克苏达诺的大家庭</h4><p>孩子“质”与“量”的取舍，穷人往往多生，来规避风险 </p>
<h4 id="Chapter7-贷款给穷人：不那么简单的经济学"><a href="#Chapter7-贷款给穷人：不那么简单的经济学" class="headerlink" title="Chapter7 贷款给穷人：不那么简单的经济学"></a>Chapter7 贷款给穷人：不那么简单的经济学</h4><p>对于正规机构来说，可贷款数量与借款人的资金现状挂钩，因此穷人借款只能通过放债人，穷人使用高利贷规避可能出现的灾病风险，几乎不可能的脱贫，因为高利贷的利息成本和穷人的违约率“一损俱损”。 </p>
<h4 id="Chapter8-节省一砖一瓦"><a href="#Chapter8-节省一砖一瓦" class="headerlink" title="Chapter8 节省一砖一瓦"></a>Chapter8 节省一砖一瓦</h4><p>穷人耐心不够，不会未雨绸缪</p>
<h4 id="Chapter9-不情愿的企业家们-穷人"><a href="#Chapter9-不情愿的企业家们-穷人" class="headerlink" title="Chapter9 不情愿的企业家们(穷人)"></a>Chapter9 不情愿的企业家们(穷人)</h4><p>穷人企业的特点：小本生意、利润低<br>穷人做生意往往是失败的经济模式的演绎，这是因为他们对稳定十分向往。</p>
<h4 id="Chapter10-政策、政治"><a href="#Chapter10-政策、政治" class="headerlink" title="Chapter10 政策、政治"></a>Chapter10 政策、政治</h4><p>政治制度的存在是为了防止领导者建立为自己谋私利的经济制度<br>民主能够给政府提供直接的反馈信息，约束政府履行其职责 </p>
<blockquote>
<p>自由不能从外部引入，否则就不会有真正的自由</p>
</blockquote>
<p>政策的制定者是政治精英们，他们往往有着复杂的动机，制定后将作用于普通大众，割裂。<br>三大问题：意识形态、无知、惯性 </p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul>
<li>穷人缺少信息来源</li>
<li>穷人肩负着生活中的诸多责任</li>
<li>一些服务于穷人的市场正在消失，得到补贴的市场受到严格监管</li>
<li>贫困的国家不会因为贫穷或者不堪回首的历史而注定失败 </li>
<li>改变人们的期望是不容易的，在启动一个良性循环时，人们不应害怕必要的付出</li>
<li>拒绝懒惰和公式化的思考模式 </li>
</ul>
]]></content>
      <categories>
        <category>灵魂雕琢</category>
      </categories>
      <tags>
        <tag>书籍阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>人像摄影-光线与构图</title>
    <url>/2020/11/02/ren-xiang-she-ying/</url>
    <content><![CDATA[<p>这一部分介绍一下在进行人像摄影时的一些理论知识，该部分目录如下:<br><!-- TOC --></p>
<ul>
<li><a href="#光线">光线</a><ul>
<li><a href="#光位">光位</a></li>
<li><a href="#光质">光质</a><ul>
<li><a href="#时刻">时刻</a></li>
<li><a href="#天气">天气</a></li>
<li><a href="#环境光">环境光</a></li>
<li><a href="#立体感塑造">立体感塑造</a></li>
<li><a href="#少光环境">少光环境</a></li>
</ul>
</li>
<li><a href="#曝光技巧">曝光技巧</a><ul>
<li><a href="#曝光-cdot-寻找光斑">曝光 $\cdot$ 寻找光斑</a><ul>
<li><a href="#曝光-cdot-设置">曝光 $\cdot$ 设置</a></li>
</ul>
</li>
<li><a href="#曝光-cdot-大光比">曝光 $\cdot$ 大光比</a></li>
<li><a href="#曝光-cdot-剪影">曝光 $\cdot$ 剪影</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#构图">构图</a></li>
</ul>
<!-- /TOC -->
<span id="more"></span>
<h3 id="光线"><a href="#光线" class="headerlink" title="光线"></a>光线</h3><h4 id="光位"><a href="#光位" class="headerlink" title="光位"></a>光位</h4><p>首先在进行人像拍摄时，我们一定要明确主光源的位置，主光源与人像主体位置对于最终拍摄效果影响很大，如下图所示:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%85%89%E4%BD%8D.jpeg" alt="光位"><br>光位大概分几个:</p>
<ul>
<li>顺光：光线从人像前方照过来  </li>
<li>逆光：光线从人像后方照过来 </li>
<li>前侧光: 光线投射的方向与景物、照相机呈45度左右夹角</li>
<li>后侧光: 光线投射过来的方向与景物、照相机呈135度左右夹角<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%85%89%E4%BD%8D1.jpeg" alt="常用光位"></li>
</ul>
<p>下面大概地讲一讲不同光位进行拍摄所带来的效果:</p>
<ul>
<li>顺光: 还原颜色，立体感差，规避瑕疵，通透 </li>
<li>侧光: 脸部立体感凸显，阴阳脸控制<ul>
<li><strong>前侧光: 窄面光，也就是说此时脸部大部亮,可以使得脸颊比较消瘦</strong></li>
<li>后侧光: 宽面广，此时脸部大部较暗，会显得脸部比较宽</li>
<li>伦布朗光: 拍摄时，被摄者脸部阴影一侧对着相机，灯光照亮脸部的四分之三。以这种用光方法拍摄的人像酷似伦勃朗的人物肖像绘画，因而得名。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%AE%BD%E7%AA%84%E9%9D%A2%E5%85%89.jpg" alt="宽窄面光"></li>
</ul>
</li>
<li>逆光: 勾勒轮廓，发丝光，显瘦，对焦困难一些</li>
<li>顶/底光: 一般而言我们并不喜欢顶光和底光，但如果适当运用阴影遮挡，也可以达到较好效果，使用透明伞作为柔光设备，要适当注意反光造成的底光效果。   </li>
</ul>
<h4 id="光质"><a href="#光质" class="headerlink" title="光质"></a>光质</h4><p>首先给出光质的定义:</p>
<blockquote>
<p>光质是指拍摄所用光线的软硬性质。可分为硬质光和软质光。 </p>
</blockquote>
<p>下面给出硬质光和软质光的基本概念:</p>
<ul>
<li>硬质光即是强烈的直射光，如晴天的阳光，人工灯中的聚光灯、回光灯的灯光等。硬质光照射下的被摄体表面的物理特性表现为：<strong>受光面、背光面及投影非常鲜明，明暗反差较大，对比效果明显，有助于表现受光面的细节及质感，造成有力度、鲜活等视角艺术效果。</strong></li>
<li>软质光是一种漫散射性质的光，没有明确的方向性，在被照物上不留明显的阴影。如大雾中的阳光，泛光灯光源等。软质光的特点是<strong>光线柔和，强度均匀，光比较小，形成的影像反差不大，主体感和质感较弱。</strong></li>
</ul>
<h5 id="时刻"><a href="#时刻" class="headerlink" title="时刻"></a>时刻</h5><p>在进行拍摄时，合适的光质对于最终的出片质量影响非常巨大，但当我们出行的时间刚好是正午，此时光线非常强烈，我们可以通过以下几种方式来进行解决: </p>
<ul>
<li>选择合适的阴影场地 </li>
<li>通过一些柔光设备</li>
<li>合适的颜色搭配来突出主体,特别是进行雪地拍摄时 </li>
</ul>
<p>最适合进行拍照的时间一般是<strong>清晨/傍晚时分</strong>，此时:</p>
<ul>
<li>太阳高度不太高 </li>
<li>光线不是很强，软硬度合适</li>
<li>最终成像使得既能呈现脸部立体感，又不至于因光线太强而出现太多难以修复的影子</li>
</ul>
<p>最后给出风光摄影中常提的两个概念:</p>
<ul>
<li>蓝调时刻: 蓝调时刻指的是太阳落山之后（或者日出之前），天空从金色变成蓝色，但又没完全变黑的时候。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E8%93%9D%E8%B0%83%E6%97%B6%E5%88%BB.jpg" alt="蓝调时刻"></li>
<li>黄金时刻: 天气晴朗的清晨和黄昏，此时阳光（作为光源）广阔而柔和，选好角度，可以拍摄逆光、阳光铺洒的感觉，十分温暖、唯美。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E9%BB%84%E9%87%91%E6%97%B6%E5%88%BB.jpeg" alt="黄金时刻"></li>
</ul>
<h5 id="天气"><a href="#天气" class="headerlink" title="天气"></a>天气</h5><p>天气其实也就大致分: </p>
<blockquote>
<p>晴 $\cdot$ 云 $\cdot$ 雨 $\cdot$ 雪 $\cdot$ 霞 </p>
</blockquote>
<ul>
<li>晴天: 等云来，找阴影，柔光设备</li>
<li>雪: 颜色搭配，后期调色 </li>
<li>霞: 提前规划，搭建脚本 </li>
</ul>
<h5 id="环境光"><a href="#环境光" class="headerlink" title="环境光"></a>环境光</h5><p>需要注意环境中的反射光:</p>
<ul>
<li>光线打到草地上，又反射到脸上，可以通过反光板来削弱不想要的反射光</li>
<li>夕阳直射面部发黄 </li>
<li><strong>通过白墙、水泥地、书来进行光线反射以补光</strong></li>
</ul>
<h5 id="立体感塑造"><a href="#立体感塑造" class="headerlink" title="立体感塑造"></a>立体感塑造</h5><p>这一部分介绍如何应用光线来进行人物立体感塑造,主要有以下几点技巧: </p>
<ul>
<li>方向性光线，比如窄面光 </li>
<li>颜色对比，背景与人物颜色的反差更能够凸显主体</li>
<li>明暗对比，通过人物背景的明暗反差可以拉远主体背景之间的关系</li>
</ul>
<h5 id="少光环境"><a href="#少光环境" class="headerlink" title="少光环境"></a>少光环境</h5><p>当在光线比较少的情况霞，需要通过一些人造光源来达到补光的效果，人造光源可以大致分为两类:</p>
<ul>
<li>常亮光源: 比如灯笼，或者手持灯，一般而言光源离主体越近，光线越柔和</li>
<li>闪光灯: 可能需要试拍，调整闪光灯强度、时间，在下雨时，闪光灯快速闪一下，可以起到凝固水珠的效果<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E8%A1%A5%E5%85%89.png" alt="补光"><br>在星光环境下拍摄一定要补光，此时人像摄影师和风光摄影师的侧重点就完全不同，比如对于一颗彗星，左边第一幅图就是风光摄影师拍摄的，而右边几张则是人像摄影师，人像摄影师在这种昏暗环境下使用补光设备一定要注意不能让人物面部出现死光，因此补光设备的光线都会压的非常暗，要不然就会出现过曝现象。</li>
</ul>
<h4 id="曝光技巧"><a href="#曝光技巧" class="headerlink" title="曝光技巧"></a>曝光技巧</h4><h5 id="曝光-cdot-寻找光斑"><a href="#曝光-cdot-寻找光斑" class="headerlink" title="曝光 $\cdot$ 寻找光斑"></a>曝光 $\cdot$ 寻找光斑</h5><p>在进行人像拍摄时，我们往往期望获得一个较为梦幻的虚化效果，这就要求背景最好有光斑一类的东西，因此就需要找一些透光的树林。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%AF%BB%E6%89%BE%E5%85%89%E6%96%91.png" alt="寻找光斑"></p>
<h6 id="曝光-cdot-设置"><a href="#曝光-cdot-设置" class="headerlink" title="曝光 $\cdot$ 设置"></a>曝光 $\cdot$ 设置</h6><p>通过调整曝光补偿和白平衡来使相机直出的图像更加漂亮，如果保存为<code>raw</code>格式，在进行后期时时可以无损调整的。 </p>
<h5 id="曝光-cdot-大光比"><a href="#曝光-cdot-大光比" class="headerlink" title="曝光 $\cdot$ 大光比"></a>曝光 $\cdot$ 大光比</h5><ul>
<li>提高曝光宽容度<ul>
<li>我们在进行曝光时一定要<strong>尽量</strong>保证高光不死白-<strong>宁欠勿曝</strong></li>
<li>在保证亮部不过曝的情况下尽量向右曝光,拉亮暗部,保留更多信息-<strong>向右曝光</strong> </li>
</ul>
</li>
<li>拍摄时推荐使用M档，适当调整保证曝光补偿<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%A4%A7%E5%85%89%E6%AF%94.png" alt="光比"><h5 id="曝光-cdot-剪影"><a href="#曝光-cdot-剪影" class="headerlink" title="曝光 $\cdot$ 剪影"></a>曝光 $\cdot$ 剪影</h5>对焦、曝光分离，将焦点对在人物上，使人物部分一片死黑，拍摄时注意下鼻子。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%89%AA%E5%BD%B1.png" alt="剪影"></li>
</ul>
<h3 id="构图"><a href="#构图" class="headerlink" title="构图"></a>构图</h3><p>这里就简单介绍几种中心构图的思路:</p>
<ul>
<li>中心构图<br>有时可以通过水或者镜面来实现中心对称效果</li>
<li>倒影<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E4%B8%BB%E6%A5%BC%E5%89%8D%E6%B0%B4%E6%B1%A0.JPG" alt="水池"></li>
<li>三分构图<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E4%B8%89%E5%88%86%E6%9E%84%E5%9B%BE.jpg" alt="三分构图"><br>但需要注意主体应当放在哪一个点上。</li>
<li><p>构图 $\cdot$ 引导线<br>适当的引导线可以将观众引导到拍摄主体上去<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%BC%95%E5%AF%BC%E7%BA%BF.jpeg" alt></p>
</li>
<li><p>构图 $\cdot$ 对比<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%AF%B9%E6%AF%94.png" alt="对比"></p>
</li>
<li><p>构图 $\cdot$ 正常情况<br>在实际构图中，往往都是多种技巧结合，经过训练后其实都是后知后觉<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%AE%9E%E9%99%85%E6%9E%84%E5%9B%BE.png" alt="正常构图"></p>
</li>
<li>构图 $\cdot$ 景别<br>组图需要有层次有差别</li>
<li>构图 $\cdot$ 立体感打造<br>打造立体感主要有以下几种思路: 透视、压缩、前后景等等</li>
</ul>
<p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E7%A9%BA%E9%97%B4%E6%84%9F.png" alt="立体感"></p>
<ul>
<li><p>构图 $\cdot$ 俯仰<br>仰拍要注意下巴，俯拍要注意不要拍全身</p>
</li>
<li><p>构图 $\cdot$ 人像裁切示意图<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E4%BA%BA%E5%83%8F%E8%A3%81%E5%88%87.jpeg" alt="人像裁切"><br>基本原则就是关节部位不要切，脖子不要切</p>
</li>
<li><p>构图 $\cdot$ 雷区</p>
<ul>
<li>不要线穿头 </li>
<li>尽量不要倾斜，仰拍俯拍可以适当倾斜</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>点滴生活</category>
      </categories>
      <tags>
        <tag>人像摄影入门，光线构图</tag>
      </tags>
  </entry>
  <entry>
    <title>人像摄影全流程</title>
    <url>/2020/11/03/ren-xiang-she-ying-quan-liu-cheng/</url>
    <content><![CDATA[<p>上一篇文章<a href="https://soundofwind.top/2020/11/02/ren-xiang-she-ying/">人像摄影-曝光与构图</a>中讲解了人像构图中两个重要的技巧<strong>曝光</strong>和<strong>构图</strong>，这一部分则重点讲解下在进行人像摄影时全流程注意事项<br><span id="more"></span></p>
<h3 id="拍摄前准备"><a href="#拍摄前准备" class="headerlink" title="拍摄前准备"></a>拍摄前准备</h3><h4 id="模特来源"><a href="#模特来源" class="headerlink" title="模特来源"></a>模特来源</h4><p>拍摄对象一般有两种来源:</p>
<ul>
<li>朋友: 可能会缺乏拍摄经验，需要摄影师进行引导</li>
<li>线上寻找: 如果能够找到有经验的模特来进行拍摄， 那么摄影师可以将更多的关注点放在构图曝光后期等技术细节的磨练上，而不用将太多精力放在协助模特摆动作上面。</li>
</ul>
<h4 id="灵感来源"><a href="#灵感来源" class="headerlink" title="灵感来源"></a>灵感来源</h4><p>灵感来源可能有:</p>
<ul>
<li>假期: 比如放假去景区游玩 </li>
<li>特别的季节: 比如现在的秋天黄叶 </li>
<li>尝试写脚本，可以了解一下其他人在这里景点处拍摄了什么图像，踩点，拍摄空景</li>
</ul>
<h4 id="拍摄地点"><a href="#拍摄地点" class="headerlink" title="拍摄地点"></a>拍摄地点</h4><h5 id="地点-cdot-室内"><a href="#地点-cdot-室内" class="headerlink" title="地点 $\cdot$ 室内"></a>地点 $\cdot$ 室内</h5><p>在室内可能需要一个稍微广的镜头, 35mm焦段比较舒服，小广角。<br>有时在进行室内拍摄时需要人造光源。</p>
<h5 id="地点-cdot-室外"><a href="#地点-cdot-室外" class="headerlink" title="地点 $\cdot$ 室外"></a>地点 $\cdot$ 室外</h5><ul>
<li>在室外进行拍摄时需要特别注意光位，比如宽面光，窄面光，逆光，顶光，底光</li>
<li>在阴天和阴影区需要注意</li>
</ul>
<h4 id="拍摄时间"><a href="#拍摄时间" class="headerlink" title="拍摄时间"></a>拍摄时间</h4><p>在进行拍摄时一定要尽量避免正午，清晨和傍晚是比较适合拍照的，蓝调时刻和黄金时刻 </p>
<h4 id="颜色搭配"><a href="#颜色搭配" class="headerlink" title="颜色搭配"></a>颜色搭配</h4><p>颜色搭配有几种可选思路:</p>
<ul>
<li>单色搭配 </li>
<li>补色: 比如红配绿</li>
<li>分离补色: 如果场景里面有很多蓝、绿，而人物作为红/橙颜色出现，就比较和谐。 </li>
<li>分裂色 </li>
<li>四角色<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E8%89%B2%E5%BD%A9%E6%90%AD%E9%85%8D.png" alt="颜色搭配"><br>常用配色有青红配色、黄蓝配色(ins风)、橙色相邻色、青色相邻色<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E8%89%B2%E5%BD%A9%E6%A0%B7%E5%9B%BE.png" alt="样图"><h4 id="样片"><a href="#样片" class="headerlink" title="样片"></a>样片</h4>给一些可以找到样片的地方:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E6%A0%B7%E7%89%87%E5%9C%B0%E5%9D%80.png" alt="样片地址"></li>
</ul>
<h4 id="道具"><a href="#道具" class="headerlink" title="道具"></a>道具</h4><p>通过道具来缓解模特的紧张情绪，同时使组图更加丰富 </p>
<h4 id="拍摄前相机设置"><a href="#拍摄前相机设置" class="headerlink" title="拍摄前相机设置"></a>拍摄前相机设置</h4><h5 id="白平衡"><a href="#白平衡" class="headerlink" title="白平衡"></a>白平衡</h5><p>拍摄模式，适当调整曝光补偿；白平衡模式，自动设置，如果想直接出图还是要好好设置下 </p>
<ul>
<li>金浩森雪景蓝调: 白平衡偏低，降低饱和对比，白平衡偏移: 蓝&amp;品</li>
<li>微单: 电子快门关掉</li>
</ul>
<h5 id="光圈"><a href="#光圈" class="headerlink" title="光圈"></a>光圈</h5><p>小光圈可以产生星芒效果，大光圈背景虚化 </p>
<h5 id="对焦"><a href="#对焦" class="headerlink" title="对焦"></a>对焦</h5><p>对焦一般是对在人物眼睛上，剪影时要考虑对在边缘上；单点对焦</p>
<h5 id="光线-cdot-反光"><a href="#光线-cdot-反光" class="headerlink" title="光线 $\cdot$ 反光"></a>光线 $\cdot$ 反光</h5><p>前期做好，后期工作量大大减小</p>
<h5 id="摆姿"><a href="#摆姿" class="headerlink" title="摆姿"></a>摆姿</h5><p>蹲着、坐着、转身、躺着、不看镜头更加自然；三线不平行时会更有动感，模特重心不要在中心位置 </p>
<h3 id="照片分析"><a href="#照片分析" class="headerlink" title="照片分析"></a>照片分析</h3><p>分析思路主要从以下几个角度:</p>
<ul>
<li>首先分析光源，</li>
<li>透视关系 </li>
<li>曝光情况</li>
<li>构图</li>
</ul>
<h3 id="后期"><a href="#后期" class="headerlink" title="后期"></a>后期</h3><p>后期其实就包括三步: 磨皮、液化、调色 </p>
]]></content>
      <categories>
        <category>点滴生活</category>
      </categories>
      <tags>
        <tag>人像摄影入门，流程解析</tag>
      </tags>
  </entry>
  <entry>
    <title>再谈极大似然估计求解</title>
    <url>/2020/08/24/zai-tan-ji-da-si-ran-gu-ji-qiu-jie/</url>
    <content><![CDATA[<p>首先我们思考这样一个问题：</p>
<blockquote>
<p>当我们用最大似然估计进行概率模型参数估计时，为什么基本都是直接求导，一阶导数等于0的点就是我们待求的最优估计?</p>
</blockquote>
<p>问到这个地方的时候，可能有一部分人就不知该如何回答了，因为一阶导数为0显然不是函数最大值点的充要条件，但我相信肯定有的答案是:</p>
<blockquote>
<p>因为碰到的对数似然函数是一个凹函数形式，这样一阶导数为0的点就与函数最大值点互为充要条件了</p>
</blockquote>
<p>这个答案是正确的，但是不够严谨，我相信基本没人会在应用最大似然进行参数估计时首先进行对数似然函数的凸性判定，这篇文章主要就是想通过严谨的数学推导来说明一类概率密度函数的对数似然函数是凹函数，可以直接利用求导等于0这种简单直接的方法寻找最优估计，而若碰到不属于这一类的概率密度函数，则在使用最大似然估计时还是先判断对数似然函数凹凸性为妙，本篇文章按照以下结构组织:</p>
<ul>
<li>指数分布族</li>
<li>指数族函数举例</li>
<li>对数似然函数凹凸性证明</li>
<li>总结<span id="more"></span>
<h3 id="指数分布族"><a href="#指数分布族" class="headerlink" title="指数分布族"></a>指数分布族</h3>首先给出指数分布族的定义：<blockquote>
<p>指数分布族是一类概率分布的总称，这类分布的概率密度函数具有这样的形式：</p>
<script type="math/tex; mode=display">
  p_\theta(x) = h(x) \exp(\theta^T \phi(x) - A(\theta))</script><p>式中，$x$是密度函数自变量，$x \in \mathcal{X}$;$\phi(x)$是充分统计量，可以看做是原始变量的一个映射:</p>
<script type="math/tex; mode=display">
  \phi: \mathcal{X} \rightarrow R^d</script><p>$\theta$是模型参数向量，与充分统计量维度相同，$h(x)$是一个只与$x$有关的统计量，$A(\theta)$为配分函数，通过该函数来保证$p_\theta(x)$满足概率密度函数的定义：</p>
<script type="math/tex; mode=display">
   \int_{\mathcal{X}} p_{\theta}(x) dx = 1</script><p>由此约束条件，我们可以得到$A(\theta)$的解析表达式：</p>
<script type="math/tex; mode=display">
  A(\theta) = \log (\int h(x) \exp(\theta^T \phi(x))dx )</script></blockquote>
</li>
</ul>
<h3 id="指数分布族函数举例"><a href="#指数分布族函数举例" class="headerlink" title="指数分布族函数举例"></a>指数分布族函数举例</h3><p>首先给出结论，按照笔者调研，属于指数分布族的分布有：</p>
<ul>
<li>正态分布$N(\mu,\sigma^2)$</li>
<li>伯努利分布(两点分布)$B(1,\pi)$</li>
<li>二项分布$B(n,\pi)$</li>
<li>泊松分布$P(\lambda)$</li>
<li>伽马分布$G(\mu,v)$</li>
<li>……. </li>
</ul>
<p>下面就将其中几个分布化成指数分布族的标准形式</p>
<h4 id="伯努利分布"><a href="#伯努利分布" class="headerlink" title="伯努利分布"></a>伯努利分布</h4><p>对于伯努利分布，我们有$\mathcal{X} = { 0,1 }$,模型参数为$P(x = 1) = \pi,P(x = -1) = 1 - \pi$,因此我们有:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        P(X = x)  = \pi^x (1 - \pi)^{1-x} &= \exp(x \log \pi + (1-x) \log(1-\pi) )  \\
        &= \exp(x \log \frac{\pi}{1-\pi} + \log (1-\pi)) 
    \end{aligned}</script><p>因此令$\theta = \log \frac{\pi}{1 - \pi}$, 则$P(X = x)$可以写做:</p>
<script type="math/tex; mode=display">
    P(X = x) = \exp(x\theta - \log(1 + e^\theta))</script><p>因此对于伯努利分布$h(x) = 1,\phi(x) = x, \theta = log \frac{\pi}{1-\pi}, A(\theta) = log(1 + e^\theta)$ </p>
<h4 id="泊松分布"><a href="#泊松分布" class="headerlink" title="泊松分布"></a>泊松分布</h4><p>首先给出泊松分布的形式:</p>
<script type="math/tex; mode=display">
    P_\lambda(X = x) = \frac{\lambda^x}{x!} e^{- \lambda}</script><p>下面将其转化成指数分布族标准形式:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        P_\lambda(X = x) &= \frac{\lambda^x}{x!} e^{- \lambda} \\
        &= \frac{1}{x!} e^{x\log \lambda - \lambda}
    \end{aligned}</script><p>因此，对于泊松分布，$h(x) = \frac{1}{x!}, \theta = \log \lambda,\phi(x) = x,A(\theta) = e^\theta$   </p>
<h4 id="高斯分布"><a href="#高斯分布" class="headerlink" title="高斯分布"></a>高斯分布</h4><p>高斯分布的概率密度函数形式如下:</p>
<script type="math/tex; mode=display">
    p_{\mu,\sigma}(x) = \frac{1}{\sqrt{2 \pi} \sigma} \exp(- \frac{(x-\mu)^2}{2\sigma^2})</script><p>下面将其转化成指数分布族标准形式: </p>
<script type="math/tex; mode=display">
    \begin{aligned}
         p_{\mu,\sigma}(x) &= \frac{1}{\sqrt{2 \pi} \sigma} \exp(- \frac{(x-\mu)^2}{2\sigma^2})  \\
         &= \frac{1}{\sqrt{2 \pi} \sigma} \exp(\frac{-x^2}{2 \sigma^2} + \frac{x \mu}{\sigma^2} - \frac{\mu^2}{2\sigma^2}) \\
         &= \frac{1}{\sqrt{2 \pi} } \exp(\frac{-x^2}{2 \sigma^2} + \frac{x \mu}{\sigma^2} - \frac{\mu^2}{2\sigma^2} + \log \sigma)
    \end{aligned}</script><p>因此，对于高斯分布:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        h(x) &= \frac{1}{\sqrt{2 \pi} \sigma}  \\
        \phi(x) &= [\frac{x^2}{2}, x]^T \\
        \theta &= [-\frac{1}{\sigma^2}, \frac{\mu}{\sigma^2}]^T \\
        A(\theta) &= -\frac{1}{2} (log \theta^{(1)} + \theta^{(2)})
    \end{aligned}</script><h3 id="对数似然函数凹凸性证明"><a href="#对数似然函数凹凸性证明" class="headerlink" title="对数似然函数凹凸性证明"></a>对数似然函数凹凸性证明</h3><p>我们关心的是最终对数似然函数的凹凸性，因为最终的对数似然函数是各个样本的概率密度函数取对数后累加的形式，由保凸运算可知，若单个对数概率密度函数的凹凸性可以确定，那么最终对数似然函数的凹凸性也就确定了。对于指数族分布，单个样本的概率密度函数取对数如下:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \log p_{\theta}(x) &= \log h(x) \exp(\theta^T \phi(x) - A(\theta)) \\
        &= \log h(x) + \theta^T \phi(x) + \log(-A(\theta))
    \end{aligned}</script><p>第一项与$\theta$无关，第二项为$\theta$的线性组合，不影响函数的凹凸性，所以整个函数的凹凸性是由第三项来确定，对于外层函数是对数函数的对数函数$\log f(x)$而言:</p>
<script type="math/tex; mode=display">
    (\log f(x))^{''} = \frac{f(x) f^{''}(x) - f^{'}(x)^2}{f(x)^2}</script><p>由对数函数性质有$f(x) &gt; 0$,因此，若$f(x)$是凹函数,即$f^{‘’}(x) \leq 0$,则可推出$(\log f(x))^{‘’} \leq 0$,即$\log f(x)$为凹函数，若$f(x)$为凸函数则不能有直接的结论，因此我们的重点放在讨论$A(\theta)$的凹凸性上。</p>
<p>下面证明$A(\theta)$为凸函数,从定义出发证明，记$\theta_{\lambda} = \lambda \theta_1 + (1 - \lambda) \theta_2$,其中$\theta_1,\theta_2 \in dom f, \lambda \in [0,1]$,由Hölder不等式，可知:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        A(\theta_\lambda) &= \log (\int h(x) \exp(\theta_{\lambda}^T \phi(x))dx ) \\ 
        &= \log (\int \exp(\theta_{\lambda}^T \phi(x))d\mu(x)\\
        &= \log (\int \exp[ (\lambda \theta_1 \phi(x) + (1-\lambda)\theta_2)\phi(x)]d\mu(x) ) \\
        &= \log (\int \exp(\theta_1 \phi(x)^{\lambda}) \exp (\theta_2 \phi(x))^{1-\lambda} d \mu(x)) \\
        &\leq \log (\int \exp(\theta_1 \phi(x))^{\frac{\lambda}{\lambda}} d\mu(x) )^\lambda (\int \exp(\theta_2 \phi(x))^{\frac{1-\lambda}{1- \lambda}}d\mu(x))^{1-\lambda}  (Hölder不等式) \\
        &= \lambda \log (\int \exp(\theta_1 \phi(x)) d\mu(x) ) + (1-\lambda)
        \log (\int \exp(\theta_2 \phi(x)) d\mu(x) ) \\
        &= \lambda A(\theta_1) + (1-\lambda) A(\theta_2)
    \end{aligned}</script><p>从凸函数定义可知,$A(\theta)$为凸函数，至此我们便得到了对数似然函数的凹凸性:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &A(\theta) 凸 \rightarrow -A(\theta) 凹 \rightarrow \log(-A(\theta)) 凹 \\
        & log(p_\theta(x)) 凹  \rightarrow 对数似然函数 凹
    \end{aligned}</script><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>从前面列出的指数分布族所包含的分布来看，我们日常所碰到的绝大多数概率分布都属于指数族分布，是可以直接通过求导等于0这种方法来得到参数估计，而对于不属于指数分布族的分布，则是有必要对对数似然函数进行分析，而不能直接通过求导来解最优参数估计值。</p>
<h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p>本文内容主要参考以下链接：<br>[1] <a href="https://www.zhihu.com/question/263423642/answer/269353169">为什么极大似然估计求导为 0 就是要求的值呢？</a><br>[2] <a href="https://web.stanford.edu/class/stats311/Lectures/lec-07.pdf">指数分布族函数</a></p>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>统计学习，凸优化</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树模型</title>
    <url>/2020/08/30/jue-ce-shu-mo-xing/</url>
    <content><![CDATA[<p>这一部分介绍下决策树算法，决策树是一种基本的分类与回归表示方法，决策树模型呈树形结构，在分类问题中，可以表示为基于特征对实例进行分类的过程。决策树可以认为是”if-then”规则的集合，也可以认为是定义在特征空间与类空间上的概率分分布。本文按照以下四部分进行组织:</p>
<ul>
<li>决策树模型与学习</li>
<li>特征选择</li>
<li>决策树生成算法</li>
<li>决策树剪枝算法</li>
</ul>
<span id="more"></span>
<h3 id="决策树模型与学习"><a href="#决策树模型与学习" class="headerlink" title="决策树模型与学习"></a>决策树模型与学习</h3><h4 id="决策树模型定义"><a href="#决策树模型定义" class="headerlink" title="决策树模型定义"></a>决策树模型定义</h4><p>首先给出决策树的定义:</p>
<blockquote>
<p><strong>决策树：</strong> 分类决策树模型是一种描述对实例进行分类的树形结构。决策树由节点和有向边组成，节点由两种类型：内部节点和叶节点。内部节点表示一个特征或属性，叶节点表示一个类。</p>
</blockquote>
<p>一个决策树模型如下图所示：<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/Decision_tree.png" alt="决策树"><br>决策树的逻辑其实与人思考的逻辑非常贴合,都是通过一连串的”if-then”语句来进行判断，这也是决策树算法具有较好可解释性的原因。</p>
<h4 id="决策树与”if-then”规则"><a href="#决策树与”if-then”规则" class="headerlink" title="决策树与”if-then”规则"></a>决策树与”if-then”规则</h4><p>一个决策树可以转换成一组”if-then”规则,将决策树转换成”if-then”规则集合的步骤如下:由决策树的根节点到叶节点的每一条路径构建一条规则：路径上内部节点的特征对应着规则的条件，而叶节点的类则对应着规则的结论。<br>决策树对应的”if-then”规则集合具有一个重要的性质：互斥并且完备，即每一个实例都被一条路径或一条规则所覆盖，而且只被一条规则或一条规则所覆盖。</p>
<h4 id="决策树与条件概率分布"><a href="#决策树与条件概率分布" class="headerlink" title="决策树与条件概率分布"></a>决策树与条件概率分布</h4><p>决策树还表示给定特征条件下类的条件概率分布。这一条件概率分布定义在特征空间的一个划分上。将特征空间划分为互不相交的单元或区域，并在每个单元定义一个类的概率分布就构成了一个条件概率分布。决策树的一条路径对应于划分中的一个单元，决策树所表示的条件概率分布由各个单元给定条件下类的条件概率分布组成。<br>假设$X$为表示特征的随机变量，$Y$为表示类别的随机变量，那么这个条件概率分布可以表示为$P(Y|X)$,$X$取值于给定划分下单元的集合，$Y$取值于类的集合。</p>
<h4 id="决策树学习"><a href="#决策树学习" class="headerlink" title="决策树学习"></a>决策树学习</h4><p>假设给定训练数据集:</p>
<script type="math/tex; mode=display">
    D = \{ (x_1,y_1),(x_2,y_2), \dots, (x_N,y_N)\}</script><p>其中$x_i \in R^n$为特征向量,$n$为特征个数，$y_i \in {1,2, \dots, K}$为类标记，$N$为样本容量。<br><strong>决策树学习的目标是根据给定的训练数据集构建一个决策树模型，使它能够对实例进行正确的分类。</strong></p>
<p>决策树学习本质上是从训练数据集中归纳出一组分类规则，这点与前面章节介绍过的规则学习非常类似，不过决策树所针对的问题更加具体。与训练数据集不相矛盾的决策树可能有多个，也可能一个也没有。我们需要的是一个与训练数据矛盾较小的决策树，同时具有很好的泛化能力。从条件概率分布的角度来看，决策树学习是由训练数据集估计条件概率模型，基于特征空间划分的类的条件概率模型有无穷多个，我们选择的条件概率模型应该不仅对训练数据有很好的拟合，同时也应当对未知的数据有较好的预测。<br>从所有可能的决策树中选取最优决策树是NP完全问题，所以现实中决策树学习算法通常采用启发式方法，近似求解这一最优问题，这样得到的决策树是次最优的。<br>决策树学习算法通常是一个递归地选取最优特征，并根据该特征对训练数据进行分割，使得各数据集有一个最好的分类的过程。这一过程对应着特征空间的划分，也对应着决策树的构建。构建流程如下:</p>
<ul>
<li>构建根节点，将所有训练数据都放在跟节点</li>
<li>选择一个最优特征，按照这一特征将训练数据集分割成子集，使得各个子集有一个在当前条件下最好的分类。</li>
<li>判断子集中的实例是否都被正确分类，若都已经被正确分类，则构建叶节点</li>
<li>若子集不能被正确分类，则返回第二步，选取最优特征并划分子集。</li>
</ul>
<p>通过上述流程所构建的决策树往往对训练数据有着良好的分类能力，但对未知的测试数据却未必有很好的分类能力，即可能发生过拟合现象，因此往往需要的生成的决策树自下而上进行剪枝。</p>
<h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p>特征选择的目的在于选取具有分类能力的特征，决策树的每一次分叉都是进行特征选择的过程, 所以有一个亟需回答的问题就是：</p>
<blockquote>
<p><strong>应当以什么样的标准来评判一个特征的分类能力？</strong></p>
</blockquote>
<p>通常评价特征分类能力的指标是信息增益和信息增益比，在前面章节中我已经给出了熵和条件熵的定义：</p>
<blockquote>
<p><strong>熵：</strong> 在信息论与概率统计中，熵是表示<strong>随机变量不确定性</strong>的度量，设$X$是一个取有限个值的离散随机变量，其概率分布为:</p>
<script type="math/tex; mode=display">
    P(X = x_i) = p_i, \quad i =1,2,\dots,n</script><p>则随机变量$X$的熵定义为:</p>
<script type="math/tex; mode=display">
    H(X) = - \sum_{i=1}^n p_i \log p_i</script><p><strong>条件熵：</strong> 设有随机变量$(X,Y)$,其联合概率分布为：</p>
<script type="math/tex; mode=display">
    P(X = x_i,Y = y_i) = p_{ij}\quad i = 1,2,\dots,n;\quad j = 1,2,\dots,m</script><p>条件熵$H(Y|X)$表示在已知随机变量$X$条件下随机变量$Y$的不确定性。随机变量$X$给定的条件下随机变量$Y$的条件熵$H(Y|X)$,定义为$X$给定条件下$Y$的条件概率分布的熵对$X$的数学期望：</p>
<script type="math/tex; mode=display">
    H(Y|X) = \sum_{i=1}^n p_i H(Y|X = x_i)</script><p>当熵和条件熵中的概率由数据估计得到时，所对应的熵与条件熵分别称为经验熵和经验条件熵</p>
</blockquote>
<h4 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h4><p>下面给出信息增益的定义：</p>
<blockquote>
<p><strong>信息增益：</strong> 特征$A$对训练集$D$的信息增益$g(D,A)$,定义为集合$D$的经验熵$H(D)$与特征$A$给定条件下$D$的经验条件熵$H(D|A)$之差，即：</p>
<script type="math/tex; mode=display">
    g(D,A) = H(D) - H(D|A)</script></blockquote>
<p>给定数据集$D$和特征$A$,经验熵$H(D)$表示对数据集$D$进行分类的不确定性，而经验条件熵$H(D|A)$则表示在特征$A$给定条件下对数据集$D$进行分类的不确定性。而它们之间的差则表示由于特征$A$而使得对数据集$D$的分类的不确定性减少的程度。由此便可得通过信息增益来选择特征的算法如下:</p>
<blockquote>
<p><strong>信息增益算法</strong><br><strong>输入：</strong> 训练数据集$D$及特征$A$<br><strong>输出：</strong> 特征$A$对训练数据集$D$的信息增益$g(D,A)$</p>
<ul>
<li>Step1: 计算数据集$D$的经验熵：<script type="math/tex; mode=display">
  H(D) = -\sum_{k=1}^K \frac{|C_k|}{|D|} \log_2 \frac{|C_k|}{|D|}</script></li>
<li>Step2: 计算特征$A$对数据集$D$的经验条件熵$H(D|A)$<script type="math/tex; mode=display">
  H(D|A) = \sum_{i=1}^n \frac{|D_i|}{|D|} H(D_i) = -\sum_{i=1}^n \frac{|D_i|}{|D|} \sum_{k=1}^K \frac{|D_{ik}|}{|D_i|} \log_2 \frac{|D_{ik}|}{|D_i|}</script></li>
<li>Step3: 计算信息增益<script type="math/tex; mode=display">
  g(D,A) = H(D) - H(D|A)</script></li>
</ul>
</blockquote>
<h4 id="信息增益比"><a href="#信息增益比" class="headerlink" title="信息增益比"></a>信息增益比</h4><p>以信息增益作为划分训练数据集的特征，存在偏向于选择取值较多的特征的问题。使用信息增益比则可以对这一问题进行校正，下面给出信息增益比的定义:</p>
<blockquote>
<p><strong>信息增益比：</strong> 特征$A$对训练数据集$D$的信息增益比$g_R(D,A)$定义为其信息增益$g(D,A)$与训练数据集$D$关于特征$A$的值的熵$H_A(D)$之比，即：</p>
<script type="math/tex; mode=display">
    g_R(D,A) = \frac{g(D,A)}{H_A(D)}</script><p>其中$H<em>A(D) = -\sum</em>{i=1}^n \frac{|D_i|}{|D|} \log_2 \frac{|D_i|}{|D|}$,$n$是特征$A$取值的个数</p>
</blockquote>
<h4 id="基尼指数-基尼不纯度"><a href="#基尼指数-基尼不纯度" class="headerlink" title="基尼指数(基尼不纯度)"></a>基尼指数(基尼不纯度)</h4><p>首先给出基尼指数的定义:</p>
<blockquote>
<p><strong>基尼指数：</strong> 分类问题中，假设有$K$个类，样本属于第$k$类的概率为$p_k$，则概率分布的基尼指数定义为:</p>
<script type="math/tex; mode=display">
    Gini(p) = \sum_{k=1}^K p_k(1 - p_k) = 1 - \sum_{k=1}^K p_k^2</script><p>对于二分类问题，若样本点属于第一个类的概率是$p$,则概率分布的基尼指数为:</p>
<script type="math/tex; mode=display">
    Gini(p) = 2p(1-p)</script><p>对于给定的样本集合$D$，其基尼指数为:</p>
<script type="math/tex; mode=display">
    Gini(D) = 1 - \sum_{k=1}^K (\frac{|D_k|}{|D|})^2</script><p>在特征$a_i$下将特征空间划分成$n$块，各块的样本数为$D_i$,条件Gini指数可以写做:</p>
<script type="math/tex; mode=display">
    Gini(D|a_i) = \sum_{i=1}^n \frac{|D_i|}{|D|} Gini(D_i)</script><p>引入特征$a_i$后，集合$D$不确定性降低了:</p>
<script type="math/tex; mode=display">
    Gini(D) - Gini(D|a_i)</script><h3 id="决策树的生成"><a href="#决策树的生成" class="headerlink" title="决策树的生成"></a>决策树的生成</h3><p>决策树生成流程在前面已经介绍过，不同算法的区别主要在于特征选择标准上的差别，该部分主要介绍两种决策树生成算法：</p>
<ul>
<li>ID3算法 </li>
<li>C4.5算法</li>
</ul>
</blockquote>
<h4 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h4><p>ID3算法相当于用极大似然法进行概率模型的选择,下面给出ID3算法的流程:</p>
<blockquote>
<p><strong>ID3算法</strong><br><strong>输入：</strong> 训练数据集$D$, 特征集$A$阈值$\epsilon$<br><strong>输出：</strong> 决策树$T$ </p>
<ul>
<li>若$D$中所有实例属于同一类$C_k$,则$T$为单节点树，并将$C_k$作为该节点的类标记，返回$T$</li>
<li>若$A = \varnothing$,则$T$为单节点树，并将$D$中实例数最大的类$C_k$作为该节点的类标记，返回$T$</li>
<li>否则，计算$A$中各特征对$D$的信息增益，选择信息最大的特征$A_g$</li>
<li>如果$A_g$的信息增益小于阈值$\epsilon$，则置$T$为单节点树，并将$D$中最大实例数类$C_k$作为类别，返回$T-</li>
<li>否则，按照$A_g$的每一特征值将特征空间划分成若干子集，将$D_i$中实例最大的类作为标记，构建子节点，由节点及其子节点构成树$T$，返回$T$</li>
<li>对第$i$个子节点，以$D_i$为训练集，以$A - {A_g}$为特征集，递归地调用前述步骤，得到子树$T_i$,返回子树</li>
</ul>
</blockquote>
<h4 id="C4-5算法"><a href="#C4-5算法" class="headerlink" title="C4.5算法"></a>C4.5算法</h4><p>C4.5算法选用信息增益比作为特征选择标准，其流程如下：</p>
<blockquote>
<p><strong>C4.5算法</strong><br><strong>输入：</strong> 训练数据集$D$, 特征集$A$阈值$\epsilon$<br><strong>输出：</strong> 决策树$T$ </p>
<ul>
<li>若$D$中所有实例属于同一类$C_k$,则$T$为单节点树，并将$C_k$作为该节点的类标记，返回$T$</li>
<li>若$A = \varnothing$,则$T$为单节点树，并将$D$中实例数最大的类$C_k$作为该节点的类标记，返回$T$</li>
<li>否则，计算$A$中各特征对$D$的信息增益比，选择信息最大的特征$A_g$</li>
<li>如果$A_g$的信息增益小于阈值$\epsilon$，则置$T$为单节点树，并将$D$中最大实例数类$C_k$作为类别，返回$T-</li>
<li>否则，按照$A_g$的每一特征值将特征空间划分成若干子集，将$D_i$中实例最大的类作为标记，构建子节点，由节点及其子节点构成树$T$，返回$T$</li>
<li>对第$i$个子节点，以$D_i$为训练集，以$A - {A_g}$为特征集，递归地调用前述步骤，得到子树$T_i$,返回子树</li>
</ul>
</blockquote>
<h3 id="决策树的剪枝"><a href="#决策树的剪枝" class="headerlink" title="决策树的剪枝"></a>决策树的剪枝</h3><p>决策树算法非常容易产生过拟合问题，过拟合的原因在于决策树在学习时过多地考虑了如何提高对训练数据分类准确率，从而构建除了过于复杂的决策树，而剪枝就是为了减轻决策树过拟合的一种操作。剪枝操作按照进行的时间段可以分为前剪枝与后剪枝两种：</p>
<ul>
<li>预剪枝：预剪枝操作是在决策树的构建过程中, 即通过对信息增益/信息增益比/Gini指数设定阈值，当分裂前后相应标准小于该阈值时，决策树便不进行分裂操作，又或者是先验地限制决策树的深度或者节点个数。预剪枝得到的决策树尽管更加简单，泛化能力得到了提升，但这样的剪枝操作是盲目的、缺乏指导的，实际应用中很容易导致决策树训练不充分的问题。</li>
<li>后剪枝：后剪枝顾名思义，是在一棵完整的决策树构建完成之后进行剪枝，常用的后剪枝操作有两种:<ul>
<li>基于带正则项的损失函数进行剪枝</li>
<li>基于验证集错误率进行后剪枝 </li>
</ul>
</li>
</ul>
<p>预剪枝的思想非常简单，这里便不做过多介绍，下面以带正则化的损失函数为例介绍下后剪枝的流程</p>
<h4 id="基于正则项的损失函数"><a href="#基于正则项的损失函数" class="headerlink" title="基于正则项的损失函数"></a>基于正则项的损失函数</h4><p>首先考虑下对于一棵决策树，其似然函数应当怎么写，假设一棵决策树有$|T|$个叶节点，$t$是树$T$的叶节点，该叶节点上有$N<em>t$个样本点，其中$k$类的样本点有$N</em>{tk}$个，$k=1,2,\dots,K$。可以这么考虑，这$|T|$个叶节点将整个特征空间分成了$|T|$部分，其中$t$节点上一个属于$K$类的样本出现的概率(最大似然估计得到)为$\frac{N<em>{tk}}{N_t}$,而又假设样本之间是彼此独立的，该节点上有$N</em>{tk}$个该类样本，据此可以写出节点$t$上样本出现的概率:</p>
<script type="math/tex; mode=display">
     \prod_{k=1}^K (\frac{N_{tk}}{N_t})^{N_{tk}}</script><p>而一共有$|T|$个叶节点，故整个树上的样本出现的概率(似然函数)为：</p>
<script type="math/tex; mode=display">
    \prod_{t=1}^{|T|} \prod_{k=1}^K (\frac{N_{tk}}{N_t})^{N_{tk}}</script><p>至此便可以写出对数似然函数:</p>
<script type="math/tex; mode=display">
    L(T) = \sum_{t=1}^{|T|} \sum_{k=1}^K N_{tk} \log \frac{N_{tk}}{N_t}</script><p>我们想要似然函数最大，其实也就是负的对数似然函数最小，由此可得损失函数$C(T)$:</p>
<script type="math/tex; mode=display">
    C(T) = - L(T) = -\sum_{t=1}^{|T|} \sum_{k=1}^K N_{tk} \log \frac{N_{tk}}{N_t}</script><p>而我们不仅仅希望决策树$T$在训练集上表现良好，同时希望决策树具有良好的泛化性能，因此需要在上面损失函数的基础上添加正则项，正则项需要与决策树的复杂程度有关，这里选用叶节点个数$|T|$作为损失函数,由此可得正则化的损失函数如下:</p>
<script type="math/tex; mode=display">
    C_{\alpha}(T) = C(T) + \alpha |T|</script><p>其中$\alpha$是权重因子，用来平衡模型复杂度与训练数据拟合效果。将叶节点上的经验熵代入损失函数，可以得到损失函数的另一种表达形式:</p>
<script type="math/tex; mode=display">
    C_\alpha(T) = -\sum_{i=1}^{|T|} N_t H_t(T) + \alpha_t</script><p>其中$H_t(T)$为叶节点上的经验熵，至此我们便可以写出该后剪枝算法流程:</p>
<blockquote>
<p><strong>基于正则损失函数的后剪枝算法</strong><br><strong>输入：</strong> 生成算法产生的整个树$T$,$\alpha$<br><strong>输出：</strong> 修建后的子树$T_\alpha$</p>
<ul>
<li>计算当前树各个叶节点上的经验熵</li>
<li>递归地从树的叶节点向上回缩，设一组叶节点回缩到其父节点之前与之后的整体树分别为$T<em>B$与$T_A$,其对应的损失函数分别是$C</em>\alpha(T<em>B)$ 与 $C</em>\alpha(T_A)$,若：<script type="math/tex; mode=display">
  C_\alpha(T_A) \leq C_\alpha(T_B)</script>则进行剪枝，将父节点变为新的叶节点</li>
<li>返回第2步，直到不能继续为止，得到损失函数最小的子树$T_\alpha$</li>
</ul>
</blockquote>
<h4 id="基于验证集分类错误率进行后剪枝"><a href="#基于验证集分类错误率进行后剪枝" class="headerlink" title="基于验证集分类错误率进行后剪枝"></a>基于验证集分类错误率进行后剪枝</h4><p>在基于正则损失函数的后剪枝中，所有的数据集都被拿来训练，而在基于验证集分类错误率方法中，首先会将数据集分为训练集和验证集，该方法的大致流程如下:</p>
<ul>
<li>首先利用训练集得到一棵完全生长的决策树</li>
<li>然后测试该决策树在验证集上的错误率$E_1$，同时将某个叶节点向上回缩，即让某个父节点成为新的叶节点，验证新的树在验证集上的错误率$E_2$,若$E_2 \leq E_1$，则考虑将父节点成为新的叶节点</li>
<li>重复第二步，直到剪枝不能提升在验证集上的错误率</li>
</ul>
<p>这种剪枝思路的优点在于是有指导有方向的剪枝，理论上讲在验证集上决策树的性能获得提升，也能够在测试集上获得提升，缺点可能就是有可能会导致模型一定程度上对验证集的过拟合。</p>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>树模型,categorical变量</tag>
      </tags>
  </entry>
  <entry>
    <title>初识Docker</title>
    <url>/2020/10/28/chu-shi-docker/</url>
    <content><![CDATA[<p>近期因为在外出差，没咋看论文，为了让时间得到充分利用，自己打算学习一些开发相关的知识，毕竟技多不压身。 这部分就参考<a href="https://docs.docker.com/get-started/">Docker官方文档</a>来进行Docker基本知识的学习。<br>该部分分为以下三个章节进行组织:</p>
<ul>
<li>概念与设置 </li>
<li>构建并运行镜像</li>
<li>在Docker Hub 上共享镜像 <span id="more"></span>
<h3 id="概念与设置"><a href="#概念与设置" class="headerlink" title="概念与设置"></a>概念与设置</h3><h4 id="Docker概念"><a href="#Docker概念" class="headerlink" title="Docker概念"></a>Docker概念</h4>Docker是供开发人员和系统管理员 使用容器构建，运行和共享应用程序的平台。使用容器部署应用程序称为容器化。容器不是新的，但用于轻松部署应用程序的容器却是新的。<br>容器化越来越受欢迎，这是因为容器具有如下几点优点: </li>
<li>灵活：即使最复杂的应用程序也可以容器化。</li>
<li>轻量级：容器利用并共享主机内核，在系统资源方面比虚拟机更有效。 </li>
<li>可移植：您可以在本地构建，部署到云并在任何地方运行。</li>
<li>松散耦合：容器是高度自给自足并封装的，可让您在不破坏其他容器的情况下更换或升级它们。</li>
<li>可扩展：您可以在数据中心内增加并自动分布容器副本。</li>
<li>安全：容器将积极的约束和隔离应用于流程，而用户无需进行任何配置。 </li>
</ul>
<h4 id="镜像与容器"><a href="#镜像与容器" class="headerlink" title="镜像与容器"></a>镜像与容器</h4><p>从根本上说，一个容器不过是一个<strong>正在运行的进程</strong>，并对其应用了一些附加的封装功能，以使其与主机和其他容器隔离。容器隔离的最重要方面之一是每个容器都与自己的专用文件系统进行交互。该文件系统由<strong>Docker映像</strong>提供。映像包括运行应用程序所需的所有内容-代码或二进制文件，运行时，依赖关系以及所需的任何其他文件系统对象。</p>
<h4 id="容器和虚拟机"><a href="#容器和虚拟机" class="headerlink" title="容器和虚拟机"></a>容器和虚拟机</h4><p>一个容器本地运行于Linux系统上，并与其他容器共享主机内核。一个容器运行一个离散进程，占用的内存不超过其他任何可执行文件，因此其比较轻量。<br>相比之下，虚拟机（VM）运行一个全面的“来宾”操作系统，通过hypervisor对主机资源进行虚拟访问。一般来说，除了应用程序逻辑所消耗的外，vm会产生很多开销。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/Container.png" alt="容器与虚拟机"></p>
<h4 id="Docker环境设置"><a href="#Docker环境设置" class="headerlink" title="Docker环境设置"></a>Docker环境设置</h4><p>参考<a href="https://docs.docker.com/get-started/">docker桌面版安装及测试</a>来进行安装，运行:</p>
<pre class="line-numbers language-lang-bash"><code class="language-lang-bash">docker run hello-world
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>如果返回:</p>
<pre class="line-numbers language-lang-bash"><code class="language-lang-bash">Hello from Docker!
This message shows that your installation appears to be working correctly.

To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
    (amd64)
 3. The Docker daemon created a new container from that image which runs the
    executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it
    to your terminal.

To try something more ambitious, you can run an Ubuntu container with:
 $ docker run -it ubuntu bash

Share images, automate workflows, and more with a free Docker ID:
 https://hub.docker.com/

For more examples and ideas, visit:
 https://docs.docker.com/get-started/
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>则说明已经在机器上成功安装docker desktop 并进行了快速测试，成功运行了第一个容器化应用<code>hello-world</code>. </p>
<h3 id="构建并运行镜像"><a href="#构建并运行镜像" class="headerlink" title="构建并运行镜像"></a>构建并运行镜像</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>通过上面的测试，我们已经设置好了开发环境，接下来我们便可以开发容器化的应用程序，通常，开发流程如下: </p>
<ul>
<li>首先创建Docker映像，为应用程序的每个组件创建和测试单独的容器。</li>
<li>将您的容器和支持基础结构组装成一个完整的应用程序。</li>
<li>测试，共享和部署完整的容器化应用程序。 </li>
</ul>
<p>在本章节中，我们将工作重心放在第一个步骤，创建容器将基于的镜像。请记住，Docker映像捕获了将在其中运行容器化进程的私有文件系统；您需要创建一个图像，其中包含您的应用程序需要运行的内容。</p>
<h4 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h4><p>首先下载<code>node-bulletin-board</code>项目，这是一个用Node.js编写的简单公告版应用程序,首先通过<code>git</code>下clone该项目:</p>
<pre class="line-numbers language-lang-bash"><code class="language-lang-bash">git clone https://github.com/dockersamples/node-bulletin-board
cd node-bulletin-board/bulletin-board-app
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h4 id="使用dockerfile定义一个容器"><a href="#使用dockerfile定义一个容器" class="headerlink" title="使用dockerfile定义一个容器"></a>使用dockerfile定义一个容器</h4><p>在下载整个项目后，使用找到<code>bulletin board</code>应用中的<code>dockerfile</code>文件，<code>dockerfile</code>描述了如何为容器组装私有文件系统，并且还包含一些元数据来描述如何基于该映像运行容器。<br>下面给出该示例项目的<code>dockerfile</code>的注释文件: </p>
<pre class="line-numbers language-lang-bash"><code class="language-lang-bash"># Use the official image as a parent image.
FROM node:current-slim

# Set the working directory.
WORKDIR /usr/src/app

# Copy the file from your host to your current location.
COPY package.json .

# Run the command inside your image filesystem.
RUN npm install

# Add metadata to the image to describe which port the container is listening on at runtime.
EXPOSE 8080

# Run the specified command within the container.
CMD [ "npm", "start" ]

# Copy the rest of your app's source code from your host to your image filesystem.
COPY . .
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>下面给出该<code>dockerfile</code>命令逻辑解释: </p>
<ul>
<li>通过<code>FROM</code>指定一个基础映像-<code>node:current-slim</code>。这是由<code>node.js</code>公司构建的官方镜像并且已由<code>Docker</code>验证为包含<code>Node.js</code>长期支持解释器和基本依赖项的高质量镜像。</li>
<li>使用<code>WORKDIR</code>指定所有后续操作都应该从映像文件系统中的<code>/usr/src/app</code>目录（而不是主机的文件系统）执行。</li>
<li>使用<code>COPY</code>将<code>package.json</code>文件从主机复制到当前目录<code>(.)</code>,在本例子中，该当前目录是<code>/usr/src/app/package.json</code></li>
<li>使用<code>RUN</code>命令在你的镜像文件系统中运行<code>npm install</code>命令，它将读取<code>package.json</code>确定应用程序的节点依赖项并安装它们。</li>
<li>使用<code>COPY</code>将应用的剩余资源代码从主机复制到你的镜像文件系统。</li>
</ul>
<p>上面的步骤构建了我们的映像文件系统，但同时还包含一些其它命令:</p>
<ul>
<li>使用<code>CMD</code>命令来指定了如何基于该映像运行容器，该命令意味着该镜像要支持的容器化进程是<code>npm start</code> </li>
<li><code>EXPOSURE 8080</code>则是通知<code>Docker</code>容器会实时监听端口<code>8080</code> </li>
</ul>
<h4 id="构建并测试镜像"><a href="#构建并测试镜像" class="headerlink" title="构建并测试镜像"></a>构建并测试镜像</h4><p>运行以下命令来构建公告板映像:</p>
<pre class="line-numbers language-lang-bash"><code class="language-lang-bash">docker build --tag bulletinboard:1.0 .
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>运行成功后会显示： </p>
<pre class="line-numbers language-lang-bash"><code class="language-lang-bash">Successfully tagged bulletinboard:1.0
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h4 id="将镜像作为容器运行"><a href="#将镜像作为容器运行" class="headerlink" title="将镜像作为容器运行"></a>将镜像作为容器运行</h4><ol>
<li>运行以下命令以基于新映像启动容器 <pre class="line-numbers language-lang-bash"><code class="language-lang-bash">docker run --publish 8000:8080 --detach --name bb bulletinboard:1.0
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
这里有几个常见的标志: </li>
</ol>
<ul>
<li><code>--publish</code>要求Docker将主机端口8000上传入的流量转发到容器的端口8080。容器具有自己的专用端口集，因此，如果要从网络访问某个端口，则必须以这种方式将流量转发到该端口。否则，作为默认的安全状态，防火墙规则将阻止所有网络流量到达您的容器。 </li>
<li><code>--detach</code>要求docker在后台运行此程序 </li>
<li><code>--name</code>指定一个名称，在后续命令中，可以使用该名称引用容器，本命令中指定为<code>bb</code></li>
</ul>
<ol>
<li>在浏览器中访问应用程序<code>localhost:8000</code>,可以看到公告版应用程序已启动并且正在运行，在这一步，您通常会尽一切可能确保容器按预期方式工作。例如，现在是运行单元测试的时候了。</li>
<li>对公告板容器正常工作感到满意后可以将其删除：<pre class="line-numbers language-lang-bash"><code class="language-lang-bash">docker rm --force bb
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
该<code>--force</code>选项停止一个正在运行中的容器，也可以采用<code>docker stop bb</code>来停止一个容器，这样就不需要使用<code>--force</code>选项来<code>rm</code>容器。</li>
</ol>
<h3 id="在Docker-Hub-中分享镜像"><a href="#在Docker-Hub-中分享镜像" class="headerlink" title="在Docker Hub 中分享镜像"></a>在Docker Hub 中分享镜像</h3><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>开发容器化程序的最后一步是在<a href="https://hub.docker.com/">docker hub</a>之类的注册标上共享镜像，以便可以轻松下载他们，并在任何目标计算机上运行他们。 </p>
<h4 id="创建一个Docker-hub-存储库"><a href="#创建一个Docker-hub-存储库" class="headerlink" title="创建一个Docker hub 存储库"></a>创建一个Docker hub 存储库</h4><p>在创建完docker id之后，可以创建一个docker镜像仓库</p>
]]></content>
      <categories>
        <category>开发知识</category>
      </categories>
      <tags>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title>pytorch学习</title>
    <url>/2020/09/06/chu-shi-pytorch/</url>
    <content><![CDATA[<p>在前面介绍深度学习的理论知识时，相信大家可以感受到，神经网络的实现主要有以下两个难题：</p>
<ul>
<li>当网络结构复杂起来时，手写一个神经网络是非常困难(尤其是进行反向误差传播时)，也是十分费时的。</li>
<li>一个神经网络有着大量的参数，对计算机的计算能力要求非常高，而GPU是计算机中有着大量计算资源的部分，如何将这部分计算资源调动起来完成一个深度神经网络的训练是另一个难题。<span id="more"></span>
</li>
</ul>
<p>为了解决上述两个问题，深度学习框架便诞生了，目前主流的深度学习框架主要下图所示的这些:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/framework.jpeg" alt="主流框架"><br>这些框架比较如下图所示:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/framework1.png" alt="深度学习框架"><br>目前在科研机构中应用较多的是Tensorflow和pytorch,本文便以pytorch为例来进行讲解，本文内容主要参考官方教程：<a href="https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py">pytorch官方教程</a>。建议英文阅读能力较强的人还是去阅读原版教程，如果对于算法的理论理解已经到位的话，整个教程还是非常简洁明了的。本文按照以下结构组织:</p>
<ul>
<li>pytorch简介</li>
<li>张量和计算图 </li>
<li>低级API和高级API</li>
</ul>
<h3 id="pytorch简介"><a href="#pytorch简介" class="headerlink" title="pytorch简介"></a>pytorch简介</h3><p>pytorch 是一个开源的python 机器学习库，基于Torch，底层由C++实现，应用于人工智能领域，如自然语言处理(nlp)。它最初由Facebook的人工智能研究团队开发，并且被用于Uber的概率编程软件Pyro.<br>Pytorch 具有以下两大特征:</p>
<blockquote>
<ul>
<li>提供类似于Numpy的张量计算，可使用gpu加速</li>
<li>基于自动微分系统的深度神经网络</li>
</ul>
</blockquote>
<h3 id="张量和计算图"><a href="#张量和计算图" class="headerlink" title="张量和计算图"></a>张量和计算图</h3><p>从caffee以来，基本上所有的深度学习框架都包含这两个概念，其实这两个关键概念也正是针对本文一开始提出的两个问题。 </p>
<h4 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h4><blockquote>
<p><strong>张量：</strong> 张量可以看作gpu下 numpy的替代品，在应用传统机器学习算法时，和我们打交道最多python库就是numpy，但遗憾的是numpy并不能够在gpu下进行运算。</p>
</blockquote>
<p>输入:</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">torch.randn(2,3)
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>输出:</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">tensor([[ 1.9335,  0.8795, -0.6964],
        [ 0.1573,  1.5692, -0.2320]])
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>tensor的大部分操作与numpy是差不多的，具体属性和方法参考<a href="https://pytorch.org/docs/stable/tensors.html?highlight=torch%20tensor#torch.Tensor">torch.Tensor</a></p>
<h4 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h4><p>现代的神经网络架构可以拥有上百万个参数，从计算的角度看，训练神经网络包含两个阶段:</p>
<ul>
<li>用于计算损失函数值的正向传递</li>
<li>向后传递以计算可学习参数的梯度</li>
</ul>
<p>正向传递计算是非常简单的，前一层神经网络的输出是下一层神经网络的输入。后向传递有些复杂，因为这要求我们应用求导的链式法则来计算损失函数的梯度。</p>
<p>当一个神经网络的规模比较小(层数,各层神经元数)时，手算损失函数对各个参数的梯度是可行的，但随着神经网络规模的扩大，梯度的计算变得越来越困难，出于深度学习的这种现实需要，计算图便诞生了：<br>计算图属于有向无环图，计算图中的节点有两种，一种是基本数学运算符，另一种则是我们所定义的变量。比如下图就可以表示一个简单的神经网络:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        b &= w_1 * a \\
        c &= w_2 * a \\
        d &= w_3 * b  + w_4 * c \\
        L & = 10 - d
    \end{aligned}</script><p>在图中，变量$b,c$和$d$都是数学运算的结果，而变量$a ,w_1,w_2,w_3,w_4$ 由用户自己初始化，由于它们不是由任何数学运算符创建的，因此与其创建相对应的节点由其名称本身表示。</p>
<p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/computation_graph.png" alt="计算图"></p>
<p>下面来介绍如何使用计算图来进行梯度计算，首先我们计算在图中相连接的节点之间的梯度,将对应的梯度值写到边上，如下图所示:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/full_graph.png" alt="梯度计算图"><br>要计算损失$L$到某个变量$w$的梯度只需要按照以下步骤:</p>
<ol>
<li>找到从$L$到$w$所有可能的路径</li>
<li>对于各个路径，将沿路径所有边相乘 </li>
<li>将各个路径计算结果相加</li>
</ol>
<h3 id="低阶API和高阶API"><a href="#低阶API和高阶API" class="headerlink" title="低阶API和高阶API"></a>低阶API和高阶API</h3><p>我们在使用pytorch时主要接触到的pytorch的包的架构如下图所示:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/Pytorch-package-hierarchy.jpg" alt="pytorch主要包"><br>对于一个三层的全连结网络，我们可以仅仅使用tensor来实现，不过这种情况下需要手写梯度，下面我就一步步介绍如何用api来使你的代码变得简洁高效:</p>
<h4 id="tensor"><a href="#tensor" class="headerlink" title="tensor"></a>tensor</h4><pre class="line-numbers language-lang-python"><code class="language-lang-python"># -*- coding: utf-8 -*-

import torch


dtype = torch.float
device = torch.device("cpu")
# device = torch.device("cuda:0") # Uncomment this to run on GPU

# N is batch size; D_in is input dimension;
# H is hidden dimension; D_out is output dimension.
N, D_in, H, D_out = 64, 1000, 100, 10

# Create random input and output data
x = torch.randn(N, D_in, device=device, dtype=dtype)
y = torch.randn(N, D_out, device=device, dtype=dtype)

# Randomly initialize weights
w1 = torch.randn(D_in, H, device=device, dtype=dtype)
w2 = torch.randn(H, D_out, device=device, dtype=dtype)

learning_rate = 1e-6
for t in range(500):
    # Forward pass: compute predicted y
    h = x.mm(w1)
    h_relu = h.clamp(min=0)
    y_pred = h_relu.mm(w2)

    # Compute and print loss
    loss = (y_pred - y).pow(2).sum().item()
    if t % 100 == 99:
        print(t, loss)

    # Backprop to compute gradients of w1 and w2 with respect to loss
    grad_y_pred = 2.0 * (y_pred - y)
    grad_w2 = h_relu.t().mm(grad_y_pred)
    grad_h_relu = grad_y_pred.mm(w2.t())
    grad_h = grad_h_relu.clone()
    grad_h[h < 0] = 0
    grad_w1 = x.t().mm(grad_h)

    # Update weights using gradient descent
    w1 -= learning_rate * grad_w1
    w2 -= learning_rate * grad_w2
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="autograd"><a href="#autograd" class="headerlink" title="autograd"></a>autograd</h4><p>这种情况下其实是没有显示的模型的概念的，只有自己定义的一个个参数。但当神经网络复杂之后，手算梯度变得不再现实，pytorch为解决这个问题提供了<code>autograd</code>这样一个好用的工具，如果我们将需要计算梯度的参数设置为<code>requires_grad = True</code>,那么在进行前向计算过程中，会定义一个计算图，同时会保存对应参数的梯度信息，也就是前面介绍的计算图中边上的梯度信息，通过<code>loss.backward()</code>操作，可以将损失对各个参数的梯度计算出来，由此可以重写上面的代码如下:</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python"># -*- coding: utf-8 -*-
# -*- coding: utf-8 -*-
import torch

dtype = torch.float
device = torch.device("cpu")
# device = torch.device("cuda:0") # Uncomment this to run on GPU

# N is batch size; D_in is input dimension;
# H is hidden dimension; D_out is output dimension.
N, D_in, H, D_out = 64, 1000, 100, 10

# Create random Tensors to hold input and outputs.
# Setting requires_grad=False indicates that we do not need to compute gradients
# with respect to these Tensors during the backward pass.
x = torch.randn(N, D_in, device=device, dtype=dtype)
y = torch.randn(N, D_out, device=device, dtype=dtype)

# Create random Tensors for weights.
# Setting requires_grad=True indicates that we want to compute gradients with
# respect to these Tensors during the backward pass.
w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)
w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)

learning_rate = 1e-6
for t in range(500):
    # Forward pass: compute predicted y using operations on Tensors; these
    # are exactly the same operations we used to compute the forward pass using
    # Tensors, but we do not need to keep references to intermediate values since
    # we are not implementing the backward pass by hand.
    y_pred = x.mm(w1).clamp(min=0).mm(w2)

    # Compute and print loss using operations on Tensors.
    # Now loss is a Tensor of shape (1,)
    # loss.item() gets the scalar value held in the loss.
    loss = (y_pred - y).pow(2).sum()
    if t % 100 == 99:
        print(t, loss.item())

    # Use autograd to compute the backward pass. This call will compute the
    # gradient of loss with respect to all Tensors with requires_grad=True.
    # After this call w1.grad and w2.grad will be Tensors holding the gradient
    # of the loss with respect to w1 and w2 respectively.
    loss.backward()

    # Manually update weights using gradient descent. Wrap in torch.no_grad()
    # because weights have requires_grad=True, but we don't need to track this
    # in autograd.
    # An alternative way is to operate on weight.data and weight.grad.data.
    # Recall that tensor.data gives a tensor that shares the storage with
    # tensor, but doesn't track history.
    # You can also use torch.optim.SGD to achieve this.
    with torch.no_grad():
        w1 -= learning_rate * w1.grad
        w2 -= learning_rate * w2.grad

        # Manually zero the gradients after updating weights
        w1.grad.zero_()
        w2.grad.zero_()
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="Extend-autograd-function"><a href="#Extend-autograd-function" class="headerlink" title="Extend autograd function"></a>Extend autograd function</h4><p>可以看到，有了<code>autograd</code>这个工具后，复杂网络的反向梯度计算也很容易解决。虽然<code>autograd.Function</code>中已经基本包含了我们所经常用到的运算函数(自动微分算子)，但若我们希望将一个其中没有的函数也加入到计算图中，则需要对<code>autograd.Function</code>进行扩展，比如我们可以重写<code>ReLu</code>函数，然后将其纳入自动微分:</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python"># -*- coding: utf-8 -*-
import torch


class MyReLU(torch.autograd.Function):
    """
    We can implement our own custom autograd Functions by subclassing
    torch.autograd.Function and implementing the forward and backward passes
    which operate on Tensors.
    """

    @staticmethod
    def forward(ctx, input):
        """
        In the forward pass we receive a Tensor containing the input and return
        a Tensor containing the output. ctx is a context object that can be used
        to stash information for backward computation. You can cache arbitrary
        objects for use in the backward pass using the ctx.save_for_backward method.
        """
        ctx.save_for_backward(input)
        return input.clamp(min=0)

    @staticmethod
    def backward(ctx, grad_output):
        """
        In the backward pass we receive a Tensor containing the gradient of the loss
        with respect to the output, and we need to compute the gradient of the loss
        with respect to the input.
        """
        input, = ctx.saved_tensors
        grad_input = grad_output.clone()
        grad_input[input < 0] = 0
        return grad_input


dtype = torch.float
device = torch.device("cpu")
# device = torch.device("cuda:0") # Uncomment this to run on GPU

# N is batch size; D_in is input dimension;
# H is hidden dimension; D_out is output dimension.
N, D_in, H, D_out = 64, 1000, 100, 10

# Create random Tensors to hold input and outputs.
x = torch.randn(N, D_in, device=device, dtype=dtype)
y = torch.randn(N, D_out, device=device, dtype=dtype)

# Create random Tensors for weights.
w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)
w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)

learning_rate = 1e-6
for t in range(500):
    # To apply our Function, we use Function.apply method. We alias this as 'relu'.
    relu = MyReLU.apply

    # Forward pass: compute predicted y using operations; we compute
    # ReLU using our custom autograd operation.
    y_pred = relu(x.mm(w1)).mm(w2)

    # Compute and print loss
    loss = (y_pred - y).pow(2).sum()
    if t % 100 == 99:
        print(t, loss.item())

    # Use autograd to compute the backward pass.
    loss.backward()

    # Update weights using gradient descent
    with torch.no_grad():
        w1 -= learning_rate * w1.grad
        w2 -= learning_rate * w2.grad

        # Manually zero the gradients after updating weights
        w1.grad.zero_()
        w2.grad.zero_()
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="nn-Module"><a href="#nn-Module" class="headerlink" title="nn.Module"></a>nn.Module</h4><p>如果我们要构建一个深层神经网络，固然可以用这些基本的自动微分算子来构建，但这样做显得有些<code>low-level</code>，因为神经网络在进行理论推导时实际上就是<code>层的堆砌</code>，那么在进行编程实现时，可否沿用这个思想，将一些微分算子封装成神经网络层的形式，pytorch中实现这个功能是通过包<code>nn</code>，<code>nn</code>中除了定义了一系列模块<code>Modules</code>，同时还有大量的损失函数，下面我们就用<code>torch.nn.Sequential</code>来重新实现这样一个三层神经网络:</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">import torch

# N is batch size; D_in is input dimension;
# H is hidden dimension; D_out is output dimension.
N, D_in, H, D_out = 64, 1000, 100, 10

# Create random Tensors to hold inputs and outputs
x = torch.randn(N, D_in)
y = torch.randn(N, D_out)

# Use the nn package to define our model as a sequence of layers. nn.Sequential
# is a Module which contains other Modules, and applies them in sequence to
# produce its output. Each Linear Module computes output from input using a
# linear function, and holds internal Tensors for its weight and bias.
model = torch.nn.Sequential(
    torch.nn.Linear(D_in, H),
    torch.nn.ReLU(),
    torch.nn.Linear(H, D_out),
)

# The nn package also contains definitions of popular loss functions; in this
# case we will use Mean Squared Error (MSE) as our loss function.
loss_fn = torch.nn.MSELoss(reduction='sum')

learning_rate = 1e-4
for t in range(500):
    # Forward pass: compute predicted y by passing x to the model. Module objects
    # override the __call__ operator so you can call them like functions. When
    # doing so you pass a Tensor of input data to the Module and it produces
    # a Tensor of output data.
    y_pred = model(x)

    # Compute and print loss. We pass Tensors containing the predicted and true
    # values of y, and the loss function returns a Tensor containing the
    # loss.
    loss = loss_fn(y_pred, y)
    if t % 100 == 99:
        print(t, loss.item())

    # Zero the gradients before running the backward pass.
    model.zero_grad()

    # Backward pass: compute gradient of the loss with respect to all the learnable
    # parameters of the model. Internally, the parameters of each Module are stored
    # in Tensors with requires_grad=True, so this call will compute gradients for
    # all learnable parameters in the model.
    loss.backward()

    # Update the weights using gradient descent. Each parameter is a Tensor, so
    # we can access its gradients like we did before.
    with torch.no_grad():
        for param in model.parameters():
            param -= learning_rate * param.grad
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以看到，与不使用<code>nn</code>包相比，上面的代码实现一方面利用<code>nn.Module.Sequential</code>实现了对神经网络层的封装，另一方面应用<code>nn.MSELoss</code>来替代原始的手写损失函数，使得代码的可读性和简洁性进一步提升。同时需要注意的是，在进行反向传播之前通过<code>model.zero_grad()</code>将存储的梯度归0，在进行参数更新时必须要使用<code>with torch.no_grad()</code>上下文管理语句来避免在进行参数更新时仍记录梯度，提高计算速度。</p>
<h4 id="optim"><a href="#optim" class="headerlink" title="optim"></a>optim</h4><p>在实际进行优化时，我们不仅会用到<code>SGD</code>这种常规的优化算法，同时也会用到一些复杂的优化算法如<code>AdaGrad</code>,<code>RMSprop</code>, <code>Adam</code>等，<code>torch.optim</code>提供了大部分常用的优化算法，同时应用优化器后也不需要再使用<code>with torch.no_grad()</code>语句，可以直接使用<code>optimizer.step()</code>来实现参数更新，重写这个三层神经网络:</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python"># -*- coding: utf-8 -*-
import torch

# N is batch size; D_in is input dimension;
# H is hidden dimension; D_out is output dimension.
N, D_in, H, D_out = 64, 1000, 100, 10

# Create random Tensors to hold inputs and outputs
x = torch.randn(N, D_in)
y = torch.randn(N, D_out)

# Use the nn package to define our model and loss function.
model = torch.nn.Sequential(
    torch.nn.Linear(D_in, H),
    torch.nn.ReLU(),
    torch.nn.Linear(H, D_out),
)
loss_fn = torch.nn.MSELoss(reduction='sum')

# Use the optim package to define an Optimizer that will update the weights of
# the model for us. Here we will use Adam; the optim package contains many other
# optimization algorithms. The first argument to the Adam constructor tells the
# optimizer which Tensors it should update.
learning_rate = 1e-4
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
for t in range(500):
    # Forward pass: compute predicted y by passing x to the model.
    y_pred = model(x)

    # Compute and print loss.
    loss = loss_fn(y_pred, y)
    if t % 100 == 99:
        print(t, loss.item())

    # Before the backward pass, use the optimizer object to zero all of the
    # gradients for the variables it will update (which are the learnable
    # weights of the model). This is because by default, gradients are
    # accumulated in buffers( i.e, not overwritten) whenever .backward()
    # is called. Checkout docs of torch.autograd.backward for more details.
    optimizer.zero_grad()

    # Backward pass: compute gradient of the loss with respect to model
    # parameters
    loss.backward()

    # Calling the step function on an Optimizer makes an update to its
    # parameters
    optimizer.step()
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="Custom-nn-Modules"><a href="#Custom-nn-Modules" class="headerlink" title="Custom nn Modules"></a>Custom nn Modules</h4><p>在前面定义这个神经网络是通过<code>torch.nn.Sequential</code>将各层函数封装成一个模型，有时可能需要定义一个更加复杂的模型，而这个模型中的有些模块需要自己手动实现，此时可以通过定义一个继承<code>torch.nn.Module</code>的子类来实现这个功能：</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python"># -*- coding: utf-8 -*-
import torch


class TwoLayerNet(torch.nn.Module):
    def __init__(self, D_in, H, D_out):
        """
        In the constructor we instantiate two nn.Linear modules and assign them as
        member variables.
        """
        super(TwoLayerNet, self).__init__()
        self.linear1 = torch.nn.Linear(D_in, H)
        self.linear2 = torch.nn.Linear(H, D_out)

    def forward(self, x):
        """
        In the forward function we accept a Tensor of input data and we must return
        a Tensor of output data. We can use Modules defined in the constructor as
        well as arbitrary operators on Tensors.
        """
        h_relu = self.linear1(x).clamp(min=0)
        y_pred = self.linear2(h_relu)
        return y_pred


# N is batch size; D_in is input dimension;
# H is hidden dimension; D_out is output dimension.
N, D_in, H, D_out = 64, 1000, 100, 10

# Create random Tensors to hold inputs and outputs
x = torch.randn(N, D_in)
y = torch.randn(N, D_out)

# Construct our model by instantiating the class defined above
model = TwoLayerNet(D_in, H, D_out)

# Construct our loss function and an Optimizer. The call to model.parameters()
# in the SGD constructor will contain the learnable parameters of the two
# nn.Linear modules which are members of the model.
criterion = torch.nn.MSELoss(reduction='sum')
optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)
for t in range(500):
    # Forward pass: Compute predicted y by passing x to the model
    y_pred = model(x)

    # Compute and print loss
    loss = criterion(y_pred, y)
    if t % 100 == 99:
        print(t, loss.item())

    # Zero gradients, perform a backward pass, and update the weights.
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以看到，这样做其实与直接使用<code>torch.nn.Sequential</code>来定义模型在有些情况下是差不多的，但通过继承<code>nn.Module</code>一方面可以使得自己的模型更具扩展性，同时代码的可读性也进一步加强，因为你自己的神经网络模型是以一个类的形式存在的。</p>
<h4 id="TensorDataset"><a href="#TensorDataset" class="headerlink" title="TensorDataset"></a>TensorDataset</h4><p>在进行数据处理时，我们的数据基本都是<code>x_train,y_train,x_test,y_test</code>的形式，在进行迭代时可能必须要通过下标来进行迭代，而为了让迭代操作更加方便，<code>pytorch</code>引入了<code>torch.utils.data</code>来辅助进行数据处理，而其中<code>TensorDataset()</code>方法相当于是对<code>x,y</code>做了一个<code>wrap</code>操作，在进行迭代时可以一起迭代而不需要分别迭代：</p>
<blockquote>
<p>应用<code>TensorDataset()</code>方法:</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">train_ds = TensorDataset(x_train, y_train)
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>  应用前迭代：</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">xb = x_train[start_i:end_i]
yb = y_train[start_i:end_i]
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>应用后迭代：</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">xb,yb = train_ds[i*bs : i*bs+bs]
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</blockquote>
<h4 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h4><p>虽然使用<code>TensorDataset</code>使得迭代运算变得简单，但我们还是按照<code>batch_size</code>的大小来对迭代下标进行维护，为了能够更方便地应用数据集进行训练，<code>torch.utils.data</code>又为我们提供了另一个好用的工具<code>DataLoader</code>,它可以将<code>warp</code>之后的数据集按照<code>batch_size</code>大小进行分割，然后在迭代时每次取一个<code>batch</code>的数据。</p>
<blockquote>
<p>应用<code>DataLoader</code>对数据集进行处理：</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">train_ds = TensorDataset(x_train, y_train)
train_dl = DataLoader(train_ds, batch_size=bs)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>对处理后的数据进行迭代：</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">for xb,yb in train_dl:
   pred = model(xb)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</blockquote>
<h4 id="MNIST数据集CNN代码"><a href="#MNIST数据集CNN代码" class="headerlink" title="MNIST数据集CNN代码"></a>MNIST数据集CNN代码</h4><p>有了应用上面的那些封装好的api，在MNIST数据集上实现一个CNN代码便不再困难，下面给出代码：</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">from pathlib import Path
from matplotlib import pyplot as plt
from IPython.core.debugger import set_trace
from torch import nn
from torch import optim
from torch.utils.data import TensorDataset
from torch.utils.data import DataLoader
import torch.nn.functional as F
import numpy as np
import requests
import math
import pickle
import gzip
import torch

'''
class Mnist_logistic(nn.Module):
    def __init__(self):
        super().__init__()
        self.weights = nn.Parameter(torch.randn(784,10)/math.sqrt(784))
        self.bias = nn.Parameter(torch.zeros(10))
    def forward(self, xb):
        return xb @ self.weights + self.bias
'''
'''
class Mnist_logistic(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(784,10)
    def forward(self, x):
        return self.linear(x)
'''
def get_model():
    model = Mnist_CNN().to(device)
    opt = optim.SGD(model.parameters(), lr = 0.5)
    return model, opt
def preprocess(x, y):
    return x.view(-1,1,28,28).to(device), y.to(device)
class WrappedDataLoader:
    def __init__(self, d1, func, batch_size):
        self.d1 = d1
        self.func = func 
        self.batch_size = 64
    def __len__(self):
        return len(self.d1)
    def __iter__(self):
        batches = iter(self.d1)
        for b in batches:
            yield (self.func(*b))
class Mnist_CNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)
        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)
        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)
        self.relu = nn.ReLU()
        self.pooling = nn.AdaptiveAvgPool2d(1)
    def forward(self, xb):
        xb = self.relu(self.conv1(xb))
        xb = self.relu(self.conv2(xb))
        xb = self.relu(self.conv3(xb))
        xb = self.pooling(xb)
        return xb.view(-1,xb.size(1))
def loss_batch(moedl, loss_func, xb, yb, opt = None):
    loss = loss_func(model(xb), yb)
    if opt is not None:
        loss.backward()
        opt.step()
        opt.zero_grad()
    return loss.item(), len(xb)

def fit(epoches, model, loss_func, opt, train_dl, valid_dl):
    for epoch in range(epoches):
        model.train()
        for xb, yb in train_dl:
            loss_batch(model, loss_func, xb, yb, opt)
        model.eval()
        with torch.no_grad():
            losses, nums = zip(*[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl])
            val_loss = np.sum(np.multiply(losses, nums)/np.sum(nums))
            if epoch % 10 == 0:
                train_aur, valid_aur = cal_acur(model, train_dl, valid_dl)    
                print('epoch:',epoch,'验证集损失:',np.str(val_loss),'训练集准确率:',np.str(train_aur),'验证集准确率:',np.str(valid_aur))

def get_data(train_ds, valid_ds, bs):
    train_dl = DataLoader(train_ds, batch_size = bs, shuffle = True)
    valid_dl = DataLoader(valid_ds, batch_size = bs, shuffle = True)
    return train_dl, valid_dl
def batch_acu(y_pred, y):
    batch_pred = torch.argmax(y_pred, dim = 1)
    return (batch_pred == y).sum()

def cal_acur(model, train_dl, valid_dl):
    train_pred_right = 0
    valid_pred_right = 0
    for xb, yb in train_dl:
        y_pred = model(xb) 
        train_pred_right += batch_acu(y_pred, yb)
    for xb, yb in valid_dl:
        y_pred = model(xb)
        valid_pred_right += batch_acu(y_pred, yb)
    train_acur = train_pred_right.float()/(len(train_dl)*train_dl.batch_size) 
    valid_acur = valid_pred_right.float()/(len(valid_dl)*valid_dl.batch_size)
    return train_acur.item(), valid_acur.item()




if __name__ == '__main__':
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    batch_size = 64
    FILENAME = "data/mnist/mnist.pkl.gz"
    with gzip.open(FILENAME, "rb") as f:
        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding="latin-1")
    x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train, y_train, x_valid, y_valid))
    print(torch.cuda.get_device_name(0))
    train_ds = TensorDataset(x_train, y_train)
    valid_ds = TensorDataset(x_valid, y_valid)
    loss_func = F.cross_entropy
    epoches = 100
    # train and valid
    train_dl, valid_dl = get_data(train_ds, valid_ds, batch_size)
    train_dl = WrappedDataLoader(train_dl, preprocess, batch_size)
    valid_dl = WrappedDataLoader(valid_dl, preprocess, batch_size)
    model, opt = get_model()
    fit(epoches, model, loss_func, opt, train_dl, valid_dl)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>最后总结一下<code>pytorch</code>中常用的包：</p>
<ul>
<li><code>torch.nn:</code>包含搭建神经网络层的模块(Modules)和一系列<code>loss</code>函数</li>
<li><code>torch.nn.functional:</code>提供常用的激活函数，这算是一个比较低级的api，大部分激活函数在<code>nn</code>下都有封装</li>
<li><code>torch.autograd:</code> 提供所有张量操作的自动求导方法</li>
<li><code>torch.optim:</code> 提供各种参数优化方法，如<code>SGD</code>、<code>Adam</code>、<code>AdaGrad</code>等</li>
<li><code>torch.utils.data:</code> 用于加载数据，比如上面介绍的<code>TensorDataset()</code>和<code>DataLoader()</code>方法</li>
<li><code>torchvision.datasets:</code>加载图像处理领域常用数据集，如<code>MNIST</code>、<code>coco</code>、<code>CIFAR10</code>、<code>Imagenet</code>等</li>
<li><code>torchvision.modules:</code> 图像处理领域常用模型，如<code>AlexNet</code>、<code>VGG</code>、<code>ResNet</code>、<code>DenseNet</code>等</li>
<li><code>torchvision.transforms:</code> 图片相关处理操作，如裁剪、尺寸缩放、归一化等</li>
</ul>
<p><code>pytorch</code>的学习其实并不是孤立的，其实是与其他知识相耦合的:</p>
<ul>
<li><code>python</code>语法知识</li>
<li>算法理论知识</li>
</ul>
<p>如果你本身<code>python</code>用的非常熟练，同时算法的理论基础也比较扎实，那么<code>pytorch</code>对你来说可能就是一个非常容易上手的工具，但如果本身这两方面的知识不够牢固，在学习<code>pytorch</code>的过程中，这两方面的能力也能得到很大的提高。</p>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>pytorch，深度学习框架</tag>
      </tags>
  </entry>
  <entry>
    <title>司马相如与卓文君</title>
    <url>/2020/09/20/si-ma-xiang-ru-yu-zhuo-wen-jun/</url>
    <content><![CDATA[<p>是夜，余观《王立群读史记》毕，感于司马相如与卓文君之逸事，为此文，记<strong>后世文学之演绎</strong>。</p>
<blockquote>
<p><strong>白头吟(卓文君)</strong><br>皑如山上雪， 皎如云间月。<br>闻君有两意， 故来相决绝。<br>今日斗酒会， 明旦沟水头。<br>躞蹀御沟上， 沟水东西流。<br>凄凄复凄凄， 嫁娶不须啼。<br>愿得一人心， 白首不相离。<br>竹竿何袅袅， 鱼尾何簁簁！<br>男儿重意气， 何用钱刀为！<br><span id="more"></span><br><strong>两地书(司马相如)</strong><br>一二三四五六七八九十百千万</p>
<p><strong>怨郎诗(卓文君)</strong><br>一朝别后， 二地相悬。<br>只说是三四月， 又谁知五六年？<br>七弦琴无心谈， 八行书无可传。<br>九连环从中折断， 十里长亭望眼欲穿。<br>百思想， 千系念， 万般无奈把郎怨。<br>万语千言说不完， 百无聊赖， 十倚栏杆。<br>九重九登高看孤雁， 八月仲秋月圆人不圆。<br>七月半， 秉烛烧香问苍天，<br>六月三伏天， 人人摇扇我心寒。<br>五月石榴红似火， 偏遇阵阵冷雨浇花端。<br>四月枇杷未黄，我欲对镜心亦乱。<br>忽匆匆， 三月桃花随水转。<br>飘零零， 二月风筝线儿断。<br>噫， 郎呀郎，<br>巴不得下一世， 你为女来我做男。</p>
</blockquote>
]]></content>
      <categories>
        <category>闲谈</category>
      </categories>
      <tags>
        <tag>历史逸事</tag>
      </tags>
  </entry>
  <entry>
    <title>安全外壳协议-ssh</title>
    <url>/2022/10/24/an-quan-wai-ke-xie-yi-ssh/</url>
    <content><![CDATA[<h4 id="简介-from-wiki"><a href="#简介-from-wiki" class="headerlink" title="简介(from wiki)"></a>简介(from wiki)</h4><p>安全外壳协议(Secure Shell Protocol,简称ssh)是一种加密的网络传输协议，可在不安全的网络中为网络服务提供安全的传输环境。SSH通过在网络中创建安全隧道来实现SSH客户端与服务器之间的连接;SSH最常见的用途是远程登录系统，人们通常利用SSH来传输命令行界面和远程执行命令。<br><span id="more"></span></p>
<h4 id="相关文件"><a href="#相关文件" class="headerlink" title="相关文件"></a>相关文件</h4><p>SSH服务会在系统的用户目录下生成一个<code>.ssh</code>文件夹，文件夹下一般会有如下文件: </p>
<ul>
<li><code>config</code>: 配置文件，可以为远程主机配置host、登录端口、默认登录用户等，方便用户使用； </li>
<li><code>known_hosts</code>: 记录本机访问过的服务端所提供的host key，下次访问相同主机时会核对host key，如不匹配会发出警告； </li>
<li><code>id_rsa</code>: 保存本机的私钥 </li>
<li><code>id_rsa.pub</code>: 保存本机的公钥 </li>
<li><code>authorized_keys</code>: 本机作为服务端所保存的已授权客户端的公钥</li>
</ul>
<h4 id="非对称加密"><a href="#非对称加密" class="headerlink" title="非对称加密"></a>非对称加密</h4><p>SSH有密码登录和证书登录两种认证方式，都是以非对称加密实现身份验证。不同于对称加密的加密解密使用同一套密钥的方式，非对称加密拥有公钥和私钥两套密钥，其中 公钥负责加密，私钥负责解密 ，<strong>公钥加密后的密文只能通过对应的私钥进行解密，而通过公钥几乎不可能推算出私钥</strong>。另外提一下，数字签名一类是使用私钥编码、公钥解码的，但是这种方式只能称为编解码而不能称作加密解密，因为公钥是公开的，拥有公钥者都可以通过密文解码出明文，加密的意义就不存在。</p>
<h4 id="密码登陆的验证过程"><a href="#密码登陆的验证过程" class="headerlink" title="密码登陆的验证过程"></a>密码登陆的验证过程</h4><ol>
<li>客户端向远程服务端发出登录请求，服务端把自己的公钥发给客户端；</li>
<li>客户端本机使用服务端提供的公钥对密码进行加密，并把密文发送至服务端；</li>
<li>服务端接收密文并使用私钥把密文解密出密码；</li>
<li>服务端通过密码验证用户身份并返回登录结果；</li>
</ol>
<h4 id="证书登陆的验证过程"><a href="#证书登陆的验证过程" class="headerlink" title="证书登陆的验证过程"></a>证书登陆的验证过程</h4><ol>
<li>客户端事先生成本机的公钥和私钥，并把公钥追加到服务端主机的authorized_keys文件中；</li>
<li>客户端发出登录请求，服务端在authorized_keys中匹配该客户端对应的公钥；</li>
<li>服务端生成随机数，并使用客户端的公钥进行加密，然后把密文发送给客户端；</li>
<li>客户端通过本机私钥解密密文获得随机数；</li>
<li>客户端利用随机数和会话密钥session key通过MD5生成摘要Digest，并发送给服务端；</li>
<li>服务端使用同样的算法生成另一份Digest；</li>
<li>服务端对比生成的Digest和客户端发送过来的Digest，返回登录结果；</li>
</ol>
]]></content>
      <categories>
        <category>技术学习</category>
      </categories>
      <tags>
        <tag>安全性协议</tag>
      </tags>
  </entry>
  <entry>
    <title>少有人走的路-读后感</title>
    <url>/2021/01/09/shao-you-ren-zou-de-lu-du-hou-gan/</url>
    <content><![CDATA[<p>自己前一段时间收了几本旧书，偶然注意到了其中一本名叫《少有人走的路-心智成熟的旅程》的书，刚好那时《中国哲学简史》刚刚读完，我便开始着手读这本书。刚开始其实我是抱着读鸡汤文的想法读一读的，但在读的过程中发现从心理学的角度来看待心智成熟也是蛮有意思的一件事。<br>跳出此书，单纯从“心智成熟”这四个字出发，其实我更觉得这是一个属于哲学范畴的命题，所谓“心智成熟”，在我看来主要体现于以下几个方面<span id="more"></span>: </p>
<ul>
<li>明确个体在世界中的位置，在一个庞大的坐标系中找到自己所处的位置。 </li>
<li>不断地反思是与非的界限，并清晰地认识到自己认知的局限。 </li>
<li>敢于面对想法与现实之间的gap并可以为消除gap不断努力。 </li>
</ul>
<p>其实这三个方面其实就是讨论了人与世界、事物(事件)、自身的关系，这三个方面其实只是一个大框架，针对具体的个人答案可能会全然不同，但是如果是一个认真反省过这三件事的人，那么想必他/她的生活中会少一些迷茫，多一些坚定。<br>本文后面内容就按照原书的四个章节划分进行组织。 </p>
<h4 id="第一部分-自律"><a href="#第一部分-自律" class="headerlink" title="第一部分 自律"></a>第一部分 自律</h4><blockquote>
<p>自律是解决人生问题最主要的工具，也是消除人生痛苦最重要的方法。</p>
</blockquote>
<p>人生苦难重重，而也正是因为这些苦难，我们才能够不断成长，但苦难可以让一个人成长，也可以让一个人毁灭，其根源区别就在于<strong>个人是否自律</strong>，何为自律? </p>
<blockquote>
<p>自律就是主动要求自己以积极的态度去承受痛苦，解决问题。 </p>
</blockquote>
<p>在作者看来，自律有四个原则: </p>
<ul>
<li>推迟满足感</li>
<li>承担责任 </li>
<li>忠于事实 </li>
<li>保持平衡 </li>
</ul>
<p>这四个道理其实很简单，然而这却会与人的本性相违背，因此个体总会或多或少落入四个原则的对立面，这就要求我们在日常生活中不断自省，及时修正自己的想法和行为。<br>关于承担责任，对应于心理学领域的两种疾病: </p>
<ul>
<li>神经官能症: 患者总是为自己强加责任，导致个体焦虑。 </li>
<li>人格失调症: 患者总是不愿承担原本属于自己的责任，总认为错在他人。 </li>
</ul>
<blockquote>
<p>作为成年人，我们一生都充满选择和决定的机会，接受这一事实，就会变成自由的人；无法接受这种事实，就会永远觉得自己是牺牲品。</p>
</blockquote>
<p>忠于事实，意味着我们要用一生的时间不间断地进行自我反省，意味着我们要敢于接受外界的质疑与挑战。对于自律其是，总结来说: </p>
<blockquote>
<p>自律是一项艰苦而复杂的任务，需要足够的勇气和判断力。你要以追求诚实为己任，也需要隐瞒部分事实和真相。你既要承担责任，也要拒绝不该承担的责任。你既要学会推迟满足感，先苦后甜，把眼光放远，同时又要尽可能过好当前的生活，让人生的快乐多于痛苦，这就要求我们拥有保持平衡的艺术。</p>
</blockquote>
<p>在本章的最后，作者谈论了“放弃与新生”，有点佛教理论的味道了，死亡与新生正如一枚硬币的正反面，两者所带来的痛苦并无不同: </p>
<blockquote>
<p>如同死亡，新的诞生也带给我们痛苦。 </p>
</blockquote>
<h4 id="第二部分-爱"><a href="#第二部分-爱" class="headerlink" title="第二部分-爱"></a>第二部分-爱</h4><blockquote>
<p>爱，是为了促进自己和他人心智成熟，而不断拓展自我界限，实现自我完善的一种意愿。      </p>
</blockquote>
<p>在谈论完自律之后，作者分析了自律背后的深层次原因-爱，这一部分内容则主要来自于作者的主观总结，在作者看来，真正的“爱”具有以下几点特征：</p>
<ul>
<li>爱与非爱最显著的区别之一，就在于当事人意识和潜意识中的目标是否一致，如果不一致，就不是真正的爱。(ps. 潜意识中的目标似乎很难确定) </li>
<li>爱是一个长期、渐进的过程。 </li>
<li>真正意义上的爱，既是爱自己，也是爱他人。 </li>
<li>爱是一种意愿，需要付出努力。 </li>
</ul>
<p>就具体表现而言，“爱”的结果是导致自我界限的扩展还是自我界限的崩溃是区分成熟的爱与原始冲动的重要指标。</p>
<blockquote>
<p>真正的爱是一种扩展自我界限的体验，既是扩展自己的，也要扩展被爱对象。</p>
</blockquote>
<p>简单的“坠入情网”并非是爱，“依赖性”也并不是爱(消极性依赖人格失调症)，“一味的给予，纯粹的自我牺牲”也并不是爱。</p>
<blockquote>
<p>真正的爱不是忘乎所以，而是深思熟虑，是奉献全部身心的重大决定。  </p>
</blockquote>
<p>当“爱”落实到具体的小事之时，则需要一些技巧：</p>
<ul>
<li>学会聆听他人。 </li>
<li>在指导他人之时，既要尊重对方的独立性，又要给出有价值的指导。</li>
</ul>
<blockquote>
<p>真正以爱为出发点的人，总是致力于自我完善，让自己具备起码的道德与智慧，然后才会行使批评权。</p>
</blockquote>
<p>与之相对的是自恋的人: </p>
<blockquote>
<p>自恋的人无视别人的存在，只把别人当成自我的延伸(缺乏共情心)。 </p>
</blockquote>
<p>婚姻可以看作是“爱”的契约: </p>
<blockquote>
<p>理想婚姻的基本目标，是让双方同时得到滋养，推动两颗心灵的共同成长。</p>
</blockquote>
<p>纪伯伦在《论婚姻》中这样谈到:</p>
<blockquote>
<p>你们一块出生<br>也将永远相依<br>当死神的白色羽翼驱散你们的日子，你们也应在一起<br>的确，你们始终相守，即使在上帝的记忆中</p>
<p>但在聚守中你们要保留空间<br>让来自天堂的风在你们的空隙之间舞动 </p>
<p>彼此相爱，但不要让爱成为束缚<br>让爱成为奔流于你们灵魂海岸间的海洋<br>盛满彼此的杯盏，但不要只从一只杯盏中取饮<br>彼此互赠面包，但不要只向一块面包取食 </p>
<p>一起欢歌曼舞<br>但要保持各自的独立<br>鲁特琴的琴弦也彼此分开<br>即使它们为同一首乐曲震颤 </p>
<p>一定要把心扉向对方敞开<br>但并不是交给对方来保管<br>因为唯有生命之手才能接纳你们的心 </p>
<p>站在一起，但不要靠的太近<br>因为殿宇的支柱总是彼此分立的<br>橡树和松柏也不在彼此的阴影下生长 </p>
</blockquote>
<h4 id="第三部分-成长与信仰"><a href="#第三部分-成长与信仰" class="headerlink" title="第三部分-成长与信仰"></a>第三部分-成长与信仰</h4><blockquote>
<p>人人都有自己的信仰，对人生的认识和了解就属于信仰的范畴。</p>
</blockquote>
<p>首先来谈一下什么是世界观: </p>
<blockquote>
<p>世界观其实就是一个人所感受到的世界的模样(规律和本质)。</p>
</blockquote>
<p>在作者看来，我们对于一种信仰并不应当是深信不疑，而是： </p>
<blockquote>
<p>我们应当过去的信仰提出疑问，主动探索陌生领域，挑战某些久被视为真理的结论。只有怀疑和挑战，才能使我们走上神圣的自由之路。 </p>
</blockquote>
<p>我们生活中很多的知识都是二手的资料，像自然科学的各种定理，但我们可以在日常中进行验证，因此这些知识尽管“二手”，但仍“充满活力”。 </p>
<blockquote>
<p>但是，有关人类生存的意义、目的与死亡的问题，一切二手材料我都无法接受。 </p>
</blockquote>
<p>或许，在我看: </p>
<blockquote>
<p><strong>敢于摆脱既往的经验，敢于迎接未知的挑战，敢于质疑所谓的权威，这本身也是一种信仰，一种更具神性的信仰。</strong></p>
</blockquote>
<p>最后谈一下宗教,许多心理学家往往视宗教为心理成熟的重大障碍： </p>
<blockquote>
<p>宗教本身就是一种神经官能症——一种禁锢心灵的非理性观念。 </p>
</blockquote>
<p>就我个人对宗教浅薄的理解来说: </p>
<blockquote>
<p>宗教既可以是毒药，也可以是解药，它的效用取决于作用于什么样的人身上。</p>
</blockquote>
<h4 id="第四部分-恩典"><a href="#第四部分-恩典" class="headerlink" title="第四部分-恩典"></a>第四部分-恩典</h4><blockquote>
<p>我们之所以具备爱的能力和成长的意愿，不仅取决于童年时父母爱的滋养，也取决于我们一生中对恩典的接纳。 </p>
</blockquote>
<p>这个世界每天都会发生一些我们无法解释的事件，纯粹的数理学派可以将它们简单归类于“小概率时间”，而斯科特$\cdot$派克则就这些事件从心理学角度展开了思考，将它们看作是<strong>恩典</strong>。</p>
<p>作者主要从梦境、潜意识出发来试图对这些<strong>恩典</strong>进行说明，荣格的“集体潜意识”理论暗示，我们的智慧来自于对全人类智慧的继承。<br>画<br>下面给出恩典的定义: </p>
<blockquote>
<ul>
<li>它们具有滋养生命、促进心智成熟的作用。</li>
<li>它们的具体作用机制仍然无法用科学解释。 </li>
<li>它们是人类世界中的普遍现象，在不同的人身上均会反复发生。</li>
<li>尽管它们可能或多或少受意识影响，但它们的根源位于意识和主观思维之外。</li>
</ul>
</blockquote>
<p>然后作者还从熵的角度来进行理解，熵会让一个物体走向无序，走向发散，但人类的进化以及心智的成熟其实是逆熵增的，这从某个角度来说也可以说是<strong>恩典</strong>。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>斯科特$\cdot$派克本人是一名出色的心理医生，因此斯科特在叙述一套理论时，往往都会附上一些具体的心理学案例加以辅助说明，这使得本书没有落入过分理论的窠臼之中。然后从内容角度来说，因为我们都是“人”的具体化，因此对于书中总结的一些规律，我们往往会有感同深受之感，若是一个心智成熟的人阅读这本书，那么可能更多的是为自己的行为找到了一些理论支撑，同时也可以以一套更加成熟的框架(成熟的语言体系)来分析其他人的行为。本书分为四部分——自律、爱、成长与信仰、恩典，就我看来，第一、三部分是较为可信的，而二、四部分属于见仁见智的部分，毕竟有点“形上学”了，这也是渴望将具体问题纳入一个更加宏大的框架来进行描述必然面临的问题，也不失为斯科特$\cdot$派克作为心理学家的一种尝试吧。 </p>
]]></content>
      <categories>
        <category>灵魂雕琢</category>
      </categories>
      <tags>
        <tag>心智成熟，心理学</tag>
      </tags>
  </entry>
  <entry>
    <title>常用Linux命令整理</title>
    <url>/2022/10/18/chang-yong-linux-ming-ling-zheng-li/</url>
    <content><![CDATA[<p>在服务器上训练深度学习模型时不可避免地需要进行大量的命令行操作，熟练使用命令行已经成为了一项程序员必备的技能，本文对常用的linux命令进行整理，以加深印象和方便后续查询。<br><span id="more"></span> </p>
<h4 id="文件管理"><a href="#文件管理" class="headerlink" title="文件管理"></a>文件管理</h4><ul>
<li><code>cat</code>: 用于连接文件并打印到标准输出设备上 <ul>
<li>使用权限: 所有使用者 </li>
<li>语法格式: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">cat [-AbeEnstTuv] [--help] [--version] fileName
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
<li>参数说明: <ul>
<li>-n/—number: 由1开始对所有输出的行号编号 </li>
<li>-b: 与-n类似，只是对空白行不编号 <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">cat file1 > file2 #将file1的内容拷贝到file2中(覆盖)
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
</ul>
</li>
</ul>
</li>
<li><code>chmod</code>: 控制用户对文件的权限 <ul>
<li>使用权限: 只有文件所有者和超级用户可以修改文件或者目录的权限 </li>
<li>说明: Linux/unix的文件调用权限分为三级: 文件所有者、用户组、其他用户<br>用户创建一个新文件时，默认权限是<code>-rw-r--r--</code><br><img src="/.io//%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90.png" alt><br>可以通过使用绝对模式(八进制数字模式)指定文件的权限<br><img src="/.io//%E7%94%A8%E6%88%B7%E7%BB%84.png" alt></li>
<li>语法: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">chmod [-cfvR] [--help] [--version] mode file...
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
<li>参数说明: <ul>
<li>mode: 权限设定字串<pre class="line-numbers language-lang-shell"><code class="language-lang-shell">  符号模式: [ugoa...][[+-=][rwxX]...][,...]
  八进制模式: 777
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</li>
</ul>
</li>
<li>使用示例: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">chmod a+rwx file #符号模式向三类用户开放读写执行权限
chmod 777 file   #八进制数字模式，功能与上面等价
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</li>
</ul>
</li>
<li><code>chown</code>: change owner, 将文件的拥有者改为指定的用户或组<ul>
<li>使用权限: 超级用户 </li>
<li>语法: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">chown [-cfhvR] [--help] [--version] user[:group] file...
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
<li>参数说明: <ul>
<li>user: 新的文件拥有者或用户id </li>
<li>group: 新的文件拥有者的使用者组 </li>
<li>-c: 显示更改的部分的信息 </li>
<li>-R: 处理指定目录以及其子目录下的所有文件 </li>
</ul>
</li>
<li>使用示例: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">chown -R root dir #将文件夹dir及其子目录的所有者设定为root
chown -R xuejianye dir #将文件夹dir及其子目录的所有者设定为xuejianye
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</li>
</ul>
</li>
<li><code>diff</code>: 比较文本文件的异同，若相同则没有输出，有差异则会输出差异位置及内容<pre class="line-numbers language-lang-shell"><code class="language-lang-shell">  diff file1 file2
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
<li><code>find</code>: 在指定目录下查找文件<ul>
<li>语法: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">  find   path   -option   [   -print ]   [ -exec   -ok   command ]   &#123;&#125; \;
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
<li>使用示例: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">  find . -name "*.txt" #在当前目录下找到所有txt文件
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
</ul>
</li>
<li><code>mv</code>: 将文件或目录移入其他位置/修改文件或目录的名称 <ul>
<li>语法: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">mv [options] source dest
mv [options] source... directory
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</li>
<li>参数: <ul>
<li>-b: 当目标文件或目录存在时，在执行覆盖前，会为其创建一个备份 </li>
<li>-i: 如果指定移动的源目录或文件与目标的目录或文件同名，则会先询问是否覆盖旧文件，输入 y 表示直接覆盖，输入 n 表示取消该操作。</li>
<li>-f: 如果指定移动的源目录或文件与目标的目录或文件同名，不会询问，直接覆盖旧文件。</li>
<li>-n: 不要覆盖任何已存在的文件或目录。 </li>
</ul>
</li>
<li>使用示例: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">mv source_file(文件) dest_file(文件) #将源文件名 source_file 改为目标文件名 dest_file
mv source_file(文件) dest_directory(目录) #将文件 source_file 移动到目标目录 dest_directory 中
mv source_directory(目录) dest_directory(目录) #目录名 dest_directory 已存在，将 source_directory 移动到目录名 dest_directory 中；目录名 dest_directory 不存在则 source_directory 改名为目录名 dest_directory
mv aaa bbb #将文件aaa改名为bbb
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
</li>
</ul>
</li>
<li><code>paste</code>: 合并文件的列<pre class="line-numbers language-lang-shell"><code class="language-lang-shell">  icarus@DESKTOP-7Q4C11S  ~  cat test.txt copy.txt
  123
  456
  123
  456
  icarus@DESKTOP-7Q4C11S  ~  cat test.txt copy.txt > new.txt
  icarus@DESKTOP-7Q4C11S  ~  cat new.txt
  123
  456
  123
  456
  icarus@DESKTOP-7Q4C11S  ~  paste test.txt copy.txt
  123     123
  456     456
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><code>rm</code>: 用于删除一个文件或目录 <ul>
<li>语法<pre class="line-numbers language-lang-shell"><code class="language-lang-shell">rm [options] name...
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
<li>参数 -r: 递归删除目录内所有文件 </li>
</ul>
</li>
<li><code>touch</code>: 修改文件或者目录的时间属性，若文件不存在则会创建一个新文件<br>  -语法: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">  touch [-acfm][-d<日期时间>][-r<参考文件或目录>] [-t<日期时间>][--help][--version][文件或目录…]
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
  -使用示例: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">  touch file #若文件不存在则创建文件，文件存在则修改文件的事件属性
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
<li><p><code>which</code>: 查找文件，会在环境变量$PATH设置的目录里查找符合条件的文件</p>
<pre class="line-numbers language-lang-shell"><code class="language-lang-shell">  which conda
  which pip
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</li>
<li><p><code>cp</code>: 用于复制文件或者目录</p>
<ul>
<li>语法:<pre class="line-numbers language-lang-shell"><code class="language-lang-shell">cp [options] source dest
cp [options] source... directory
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</li>
<li>参数说明: <ul>
<li>-r: 若给出的源文件是一个目录文件，此时将复制该目录下所有的子目录和文件。</li>
</ul>
</li>
<li>使用示例<pre class="line-numbers language-lang-shell"><code class="language-lang-shell">cp –r test/ newtest   #用户使用该指令复制目录时，必须使用参数 -r 或者 -R
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
</ul>
</li>
<li><code>scp</code>:  是 secure copy 的缩写, scp 是 linux 系统下基于 ssh 登陆进行安全的远程文件拷贝命令 <ul>
<li>语法: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">scp [可选参数] file_source file_target
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
<li>使用示例: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">#从本机复制到远程 
scp local_file remote_username@remote_ip:remote_folder 
或者 
scp local_file remote_username@remote_ip:remote_file 
或者 
scp local_file remote_ip:remote_folder 
或者 
scp local_file remote_ip:remote_file 
#从远程复制到本地
scp root@www.runoob.com:/home/root/others/music /home/space/music/1.mp3 
scp -r www.runoob.com:/home/root/others/ /home/space/music/
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
</ul>
</li>
</ul>
<h4 id="文档编辑"><a href="#文档编辑" class="headerlink" title="文档编辑"></a>文档编辑</h4><ul>
<li><code>grep</code>: 用于查找文件里符合条件的字符串 <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">  grep "被查找的字符串" 文件名
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
</ul>
<h4 id="文件传输"><a href="#文件传输" class="headerlink" title="文件传输"></a>文件传输</h4><h4 id="磁盘管理"><a href="#磁盘管理" class="headerlink" title="磁盘管理"></a>磁盘管理</h4><ul>
<li><code>cd</code>: 切换当前工作目录 </li>
<li><code>df</code>: 显示目前在linux系统上的文件系统磁盘使用情况统计 <ul>
<li>语法: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">df [选项]... [FILE]...
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
<li>使用示例: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">icarus@DESKTOP-7Q4C11S  /home  df icarus
Filesystem     1K-blocks     Used Available Use% Mounted on
/dev/sdc       263174212 35268580 214467476  15% /
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
</li>
</ul>
</li>
<li><code>du</code>: 用于显示目录或文件的大小 <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">  du -s icarus/ #显示该文件夹中所有文件所占的内存和 
  du -a icarus/ #显示目录中个别文件的大小
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</li>
<li><code>mkdir</code>: 用于创建目录 <ul>
<li>参数说明: -p 确保目录名称存在，不存在就新建一个  </li>
<li>使用示例: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">mkdir -p /home/projects
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
</ul>
</li>
<li><p><code>tree</code>: 以树状图列出目录的内容 </p>
</li>
<li><p><code>ls</code>: 显示指定工作目录下的内容 </p>
<ul>
<li>参数 <ul>
<li>-a: 显示所有文件及目录 </li>
<li>-l: 除文件名称外，亦将文件型态、权限、拥有者、文件大小等资讯详细列出 </li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="磁盘维护"><a href="#磁盘维护" class="headerlink" title="磁盘维护"></a>磁盘维护</h4><h4 id="网络通讯"><a href="#网络通讯" class="headerlink" title="网络通讯"></a>网络通讯</h4><ul>
<li><code>ifconfig</code>: 用于显示或设置网络设备,查看ip/mac地址 </li>
<li><code>ping</code>: 用于检测主机，</li>
</ul>
<h4 id="系统管理"><a href="#系统管理" class="headerlink" title="系统管理"></a>系统管理</h4><ul>
<li><code>kill</code>: 用于删除执行中的程序或工作<ul>
<li>语法: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">kill [-s <信息名称或编号>][程序]　或　kill [-l <信息编号>]
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
<li>常用参数: <ul>
<li>-HUP: 重新加载进程 </li>
<li>-KILL: 杀死一个进程 </li>
<li>-TERM: 正常停止一个进程</li>
</ul>
</li>
<li>使用示例: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">kill 12345
kill -KILL 123456 #强制杀死进程
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</li>
</ul>
</li>
<li><code>ps</code>: 显示当前进程的状态，类似于windows的任务管理器 <ul>
<li>语法: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">ps [options] [--help]
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
<li>参数 <ul>
<li>-a: 列出所有的进程 </li>
</ul>
</li>
<li>使用示例: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">ps -ef | grep 进程关键字
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
</ul>
</li>
</ul>
<h4 id="系统设置"><a href="#系统设置" class="headerlink" title="系统设置"></a>系统设置</h4><ul>
<li><code>clear</code>: 用于清除屏幕 </li>
<li><code>export</code>: 用于设置或者显示环境变量,效力仅限于该次登陆操作 <ul>
<li>语法: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">export [-fnp][变量名称]=[变量设置值]
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
<li>参数名称<ul>
<li>-n: 删除指定的变量 </li>
<li>-p: 列出所有的shell赋予程序的环境变量 </li>
</ul>
</li>
<li>使用示例: <pre class="line-numbers language-lang-shell"><code class="language-lang-shell">export CUDA_VISIBLE_DEVICES=0,3
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</li>
</ul>
</li>
</ul>
<h4 id="备份压缩"><a href="#备份压缩" class="headerlink" title="备份压缩"></a>备份压缩</h4><h4 id="设备管理"><a href="#设备管理" class="headerlink" title="设备管理"></a>设备管理</h4>]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>命令行</tag>
      </tags>
  </entry>
  <entry>
    <title>强化学习</title>
    <url>/2020/10/06/qiang-hua-xue-xi/</url>
    <content><![CDATA[<p>这部分将根据周志华老师的西瓜书对强化学习部分做一个简单介绍，该部分按照以下章节进行组织:</p>
<ul>
<li>思想介绍——任务与奖赏 </li>
<li>K-摇臂赌博机 </li>
<li>有模型学习 </li>
<li>免模型学习 </li>
<li>值函数近似 </li>
<li>模仿学习 <span id="more"></span>
</li>
</ul>
<h3 id="思想介绍-任务与奖赏"><a href="#思想介绍-任务与奖赏" class="headerlink" title="思想介绍-任务与奖赏"></a>思想介绍-任务与奖赏</h3><p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/reinforce.png" alt="强化学习"><br>考虑这样病人看病的场景，假设我们是看病的医生，在我们与病人的交互过程中，大概是这么一个交互顺序:</p>
<ul>
<li>病人本身有一个状态，记做$S$，表示病人目前的身体状况。</li>
<li>在看病的过程中，我认为病人处于某个状态$S’$，然后对病人施加了一个动作A，比如给病人吃了一些药，或者打了针。</li>
<li>在病人接受了治疗之后，其本身状态发生了一个变化，该状态的转移我们用概率矩$P$来表示，表示病人状态发生了一个变化，比如痊愈了或者病情更加严重了。 </li>
<li>在病人的状态发生了变化之后，会给作为医生的我们一个反馈，记做$R$,如果病人痊愈了，那我们得到的反馈可能会是一面锦旗和很多钱，如果病情更加严重了，我们得到的反馈可能就是埋怨。 </li>
</ul>
<p>上面我所描述的场景其实就构成了一轮强化学习的过程，强化学习任务常用马尔可夫决策过程来描述，这意味着环境下一时刻的状态仅仅与当前时刻状态有关而与之前状态无关:</p>
<script type="math/tex; mode=display">
    P(s_{t+1}| s_t,\dots, s_1) = P(s_{t+1}|s_{t})</script><p>综合起来，强化学习对应了四元组$E = <S,A,P,R>$,其中:</S,A,P,R></p>
<script type="math/tex; mode=display">
    P: X \times A \times X \rightarrow \mathbb{R}</script><p>而:</p>
<script type="math/tex; mode=display">
    R: X \times A \times X \rightarrow \mathbb{R}</script><p>指定了奖赏，在有的应用中，状态可能仅与状态转移有关，即$R: X \times X \rightarrow \mathbb{R}$, 下面给出一个种瓜的马尔可夫决策过程的栗子。<br><img src="https://github.com/xuejy19/xuejy19.github.io/blob/source/Img/Markov_decision.png" alt="马尔可夫决策过程"><br>在该过程中只有四个状态:健康、缺水、溢水和凋亡和两个动作:浇水和不浇水。在每一步转移后，若状态是保持瓜苗健康则获得奖励1，瓜苗缺水或者溢水奖赏为-1，这时通过浇水或者不浇水可以让瓜苗恢复健康状态，当瓜苗凋零时奖赏是最小值-100且无法恢复。图中箭头表示状态转移，$a、p、r$分别表示导致状态转移的动作、转移概率以及返回的奖赏。容易看出，最优策略是在“健康”和“缺少”状态下选择浇水，而在“溢水”状态下选择不浇水。</p>
<p>需要注意区分“机器”和“环境”的界限，在下棋中，棋盘是环境与对手；在机器人控制中，环境是机器人的躯体与物理世界。总之，在环境中状态的转移以及奖赏的返回是不受机器控制的，机器只能通过选择要执行的动作来影响环境，也只能通过观察转移后的状态和返回的奖赏来感知世界。</p>
<p>机器要做的是学习到一个策略$\pi$，根据这个策略，在状态$x$下就能得知想要执行的动作$a = \pi(x)$, 例如看到瓜苗状态为缺水时，能返回动作“浇水”。策略有两种表示:</p>
<ul>
<li>一种是将策略表示为函数$\pi: X \rightarrow A$,确定性策略通常用这种表示。 </li>
<li>一种是概率表示$\pi: X \times A \rightarrow R$ ,随机性概率通常用这种表示，$\pi(x,a)$为状态$x$下选择动作$a$的概率，这里必须有$\sum_a \pi(x,a) = 1$</li>
</ul>
<p>策略的优劣取决于长期执行这一策略后得到的累计奖赏，例如某个策略使得瓜苗枯死，那么它的累积奖赏会很小，另一个策略种出了好瓜，它的累积奖赏会很大。在强化学习中，学习的目的就是要找到能使长期累积奖赏最大化的策略。长期累积奖赏有多种计算方式，常用的有两种:</p>
<ul>
<li>T步累积奖赏$E[\frac{1}{T} \sum_{t=1}^T r_t]$</li>
<li>$\gamma$折扣累积奖赏: $E[\sum<em>{t=0}^\infty] \gamma^t r</em>{t+1}$, 其中$\gamma$表示贴现系数。 </li>
</ul>
<p>最后讨论下强化学习与监督学习的关系:</p>
<ul>
<li>强化学习中的“状态”对应于监督学习中的“示例”。</li>
<li>强化学习中的“动作”对应于监督学习中的“标记” </li>
<li>强化学习中的“策略”实际上就相当于监督学习中的“分类器”或“回归性” </li>
</ul>
<p>但是在强化学习中，并没有监督学习中的有标记样本，换言之，没有人直接告诉机器在什么状态下应该做什么动作，只有等到最终结果揭晓，才能通过“反思”之前的动作是否正确来进行学习，因此，强化学习在某种意义上可以看作具有“延迟标记信息”的监督学习问题。 </p>
<h3 id="K-摇臂赌博机"><a href="#K-摇臂赌博机" class="headerlink" title="K 摇臂赌博机"></a>K 摇臂赌博机</h3><h4 id="概念介绍"><a href="#概念介绍" class="headerlink" title="概念介绍"></a>概念介绍</h4><p>与一般监督学习不同，强化学习最终奖赏需要在多步动作后才能够观察到，这里我们首先考虑最简单的情形:最大化单步奖赏。<br>欲最大化单步奖赏需要考虑两个方面:一是需要知道每个动作带来的奖赏，二是要执行奖赏最大的动作。若每个动作对应的奖赏是确定值，那么尝试一遍所有动作便可以找到奖赏最大的动作。但更一般的情形是，一个动作的奖赏值是来自一个概率分布，仅通过一次尝试并不能确切地获得平均奖赏值。<br>实际上，单步强化学习任务对应了一个理论模型-“K-摇臂赌博机”，K摇臂赌博机有K个摇臂，赌徒在投入硬币后可选择按下其中一个摇臂，每个摇臂以一定的概率吐出硬币，但这个概率赌徒并不知道，赌徒的目标是通过一定的策略最大化自己的奖赏，即获得最多的硬币。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/K-armed.jpeg" alt="K摇臂赌博机"><br>若仅为获知每个摇臂的期望奖赏，则可以采用“仅搜索法”:将所有尝试机会平均分配给每个摇臂，最后以每个摇臂各自平均的吐币概率作为其奖赏期望的近似估计。若仅为执行奖赏最大的动作，则可采用“仅利用”法: 按下目前最优的摇臂。显然，“仅探索”法能够很好地估计每个摇臂的奖赏，却会失去很多选择最优摇臂的机会；仅利用法则相反，它没有很好地估计摇臂期望奖赏，很可能经常选不到最优摇臂。因此，这两种方法都难以使得最终累积奖赏最大化。<br>事实上，“探索”和“利用”这两者是矛盾的，因为尝试次数有限，加强了一方则自然就会削弱另一方，这就是强化学习所面临的“探索-利用”窘境。显然，如欲累积奖赏最大，则必须在探索与利用之间达成较好的折衷。</p>
<h4 id="epsilon-贪心"><a href="#epsilon-贪心" class="headerlink" title="$\epsilon-$贪心"></a>$\epsilon-$贪心</h4><p>$\epsilon-$贪心基于一个概率$\epsilon$来对探索和利用进行折中: 每次尝试时，以$\epsilon$概率进行探索，即以均匀概率随机选取一个摇臂；以$1- \epsilon$概率进行利用，即选择当前平均奖赏最高的摇臂。<br>令$Q(k)$记录摇臂$k$的平均奖赏，若摇臂$k$被尝试了$n$次，得到的奖赏为$v_1,v_2,\dots, v_n$,则平均奖赏为:</p>
<script type="math/tex; mode=display">
    Q(k) = \frac{1}{n} \sum_{i=1}^n v_i</script><p>更高效的方法是进行增量式计算，即每一次尝试后就立刻更新$Q(k)$，不妨用下标来表示尝试的次数，初始时$Q<em>0(k) = 0$。对于任意的$n \geq 1$,若第$n-1$次尝试后的平均奖赏为$Q</em>{n-1}(k)$,则在经过第$n$次尝试获得奖赏$v_n$后，平均奖赏应更新为:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        Q_n(k) &= \frac{1}{n} ((n-1) \times Q_{n-1}(k) + v_n) \\
               &= Q_{n-1}(k) + \frac{1}{n} (v_n - Q_{n-1}(k))        
    \end{aligned}</script><p>若摇臂奖赏的不确定性较大， 例如概率分布较宽时，则需要更多的探索，此时需要较大的$\epsilon$值；若摇臂的不确定性较小，例如概率分布较集中时，此时只需要少量的探索即可，将$\epsilon$设置值较小即可。随着尝试次数的增多，在一段时间后，摇臂的奖赏都能够较好地近似出来，不再需要探索，这种情况下可以让$\epsilon$随着尝试次数的增加而逐步减小，例如取$\epsilon = \frac{1}{\sqrt{t}}$ </p>
<h4 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h4><p>Softmax 算法中摇臂概率的分配是基于Boltzmann分布:</p>
<script type="math/tex; mode=display">
    P(k) = \frac{e^{\frac{Q(k)}{\tau}}}{\sum_{i=1}^K e^{\frac{Q(k)}{\tau}}}</script><p>其中$q(i)$记录当前摇臂的平均奖赏，$\tau &gt;0$称为温度，$\tau$越小则平均奖赏高的摇臂被选取的概率越高，$\tau$趋于0时Softmax将趋于“仅利用”，$\tau$趋于无穷大时Softmax将趋于“仅搜索”。 </p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>前面通过K摇臂赌博机给出了单步强化学习的概念，同时介绍了单步强化学习实现的两种算法:$\epsilon$-贪心算法和Softmax算法，这两种算法并无绝对优劣差距，在进行应用中需要具体问题具体分析。<br>对于离散状态空间、离散动作空间上的多步强化学习任务，一种直接的办法是将每个状态上动作的选择看作是一个K摇臂赌博机问题，用强化学习任务的累积奖赏来代替K摇臂赌博机算法中的奖赏函数，即可将赌博机算法应用于每个状态: 对每个状态分别记录各动作的尝试次数、当前平均累积奖赏等信息，基于赌博机算法选择想要尝试的动作。<strong>然而这样做有很多局限，因为它没有考虑强化学习任务马尔可夫决策过程的结构。</strong> </p>
<h3 id="有模型学习"><a href="#有模型学习" class="headerlink" title="有模型学习"></a>有模型学习</h3><p>考虑一个多步强化学习任务，我们假设任务对应的马尔可夫决策过程四元组$E  =<X, a,p,r>$均为已知，这样的情形称为<strong>模型已知</strong>,即机器已经对环境进行了建模。在已知模型的环境中学习称为“有模型学习”。此时，对于任意状态$x,x’$和动作$a$，在$x$状态下执行动作$a$转移到状态$x’$的概率$P<em>{x \rightarrow x’}^a$ 是已知的，该转移所带来的奖赏$R</em>{x \rightarrow x’}^a$也是已知的。为便于讨论，不妨假设状态空间和动作空间均有限。 </X,></p>
<h4 id="策略评估"><a href="#策略评估" class="headerlink" title="策略评估"></a>策略评估</h4><p>在模型已知时，对任意策略能估计出该策略带来的期望累积奖赏，令函数$V^\pi(x)$表示从状态$x$出发，使用策略$\pi$所带来的累积奖赏。函数$Q^{\pi}(x,a)$ 表示从状态$x$出发，执行动作$a$后再使用策略$\pi$所带来的累积奖赏，这里:</p>
<ul>
<li>$V(\cdot)$ 称为“状态值”函数，表示指定“状态”上的累积奖赏</li>
<li>$Q(\cdot)$ 称为“状态-动作值”函数，表示指定“状态-动作”上的累积奖赏。 </li>
</ul>
<p>由累积奖赏的定义，有状态值函数: </p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
V_{T}^{\pi}(x)=\mathbb{E}_{\pi}\left[\frac{1}{T} \sum_{t=1}^{T} r_{t} \mid x_{0}=x\right], \quad T \text { 步累积奖赏 } \\
V_{\gamma}^{\pi}(x)=\mathbb{E}_{\pi}\left[\sum_{t=0}^{+\infty} \gamma^{t} r_{t+1} \mid x_{0}=x\right], \quad \gamma \text { 折扣累积奖赏. }
\end{array}\right.</script><p>令$x_0$表示起始状态，$a_0$表示起始状态上采取的第一个动作；对于$T$步累积奖赏，用下标$t$表示后续执行的步数，我们有状态动作值函数: </p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
Q_{T}^{\pi}(x,a)=\mathbb{E}_{\pi}\left[\frac{1}{T} \sum_{t=1}^{T} r_{t} \mid x_{0}=x, a_0 = a\right], \quad T \text { 步累积奖赏 } \\
Q_{\gamma}^{\pi}(x,a)=\mathbb{E}_{\pi}\left[\sum_{t=0}^{+\infty} \gamma^{t} r_{t+1} \mid x_{0}=x, a_0 = a\right], \quad \gamma \text { 折扣累积奖赏. }
\end{array}\right.</script><p>根据马尔可夫决策过程的马尔可夫性，值函数可以有更加简单的递推形式，对于$T$步累积奖赏有:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        V_T^\pi (x) &= E_{\pi} [\frac{1}{T} \sum_{t=1}^T r_t| x =x_0] \\
        &= E_{\pi} [\frac{1}{T} r_1 + \frac{T-1}{T} \frac{1}{T-1} \sum_{t=2}^T r_t | x_0 = x] \\ 
        &= \sum_{a \in A} \pi(x,a) \sum_{x' \in X}  P_{x \rightarrow x'}^a (\frac{1}{T} R_{x \rightarrow x'}^a  + \frac{T-1}{T} E_{\pi} [\frac{1}{T-1} \sum_{t=1}^{T-1} r_t|x_0 = x'])  \\
        &= \sum_{a \in x} \pi(x,a) \sum_{x' \in X}  P_{x \rightarrow x'} (\frac{1}{T} R_{x \rightarrow x'}^a + \frac{T-1}{T} V_{T-1}^\pi (x')) 
    \end{aligned}</script><p>类似的，对于$\gamma$折扣累积奖赏有: </p>
<script type="math/tex; mode=display">
V_{\gamma}^{\pi}(x)=\sum_{a \in A} \pi(x, a) \sum_{x^{\prime} \in X} P_{x \rightarrow x^{\prime}}^{a}\left(R_{x \rightarrow x^{\prime}}^{a}+\gamma V_{\gamma}^{\pi}\left(x^{\prime}\right)\right)</script><p>值函数的递推方程也被称作<strong>Bellman方程</strong>。<br>用这种递归等式来计算值函数，实际上就是一种动态规划算法。换言之，从值函数的初始值$V_0(\pi)$出发，通过每一次迭代能够计算出每个状态的单步奖赏$V_1^\pi$,进而从单步奖赏出发，通过一次迭代计算出两步累积奖赏$V_2^\pi$,对于$T$步累积奖赏，只需要迭代$T$轮就能精确地求解出值函数。<br>可以总结基于$T$步累积奖赏的策略评估办法:</p>
<blockquote>
<p><strong>输入:</strong> MDP四元组$E = <X,A,P,R>$; 被评估的策略$\pi$; 累积奖赏参数$T$<br><strong>算法流程:</strong> </X,A,P,R></p>
<ul>
<li>初始化$V(x) = 0$</li>
<li>递推计算$V_1^\pi, V_2^\pi, \dots, V_t^\pi, \dots$ </li>
<li>递推直到$V_t^\pi = V_T^\pi$</li>
</ul>
<p><strong>输出:</strong> 状态值函数$V$ </p>
</blockquote>
<p>对于$\gamma$折扣累积奖赏算法，与普通$T$步累积累积奖赏递推类似，同时考虑到当$t$很大时，$\gamma^t$ 会趋于0，因此算法计算终止常通过阈值来进行确定:</p>
<script type="math/tex; mode=display">
    \max_{x \in X} |V(x) - V'(x)| < 0</script><p>有了状态值函数，就能直接计算出状态-动作值函数:</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
Q_{T}^{\pi}(x, a)=\sum_{x^{\prime} \in X} P_{x \rightarrow x^{\prime}}^{a}\left(\frac{1}{T} R_{x \rightarrow x^{\prime}}^{a}+\frac{T-1}{T} V_{T-1}^{\pi}\left(x^{\prime}\right)\right) \\
Q_{\gamma}^{\pi}(x, a)=\sum_{x^{\prime} \in X} P_{x \rightarrow x^{\prime}}^{a}\left(R_{x \rightarrow x^{\prime}}^{a}+\gamma V_{\gamma}^{\pi}\left(x^{\prime}\right)\right)
\end{array}\right.</script><h4 id="策略改进"><a href="#策略改进" class="headerlink" title="策略改进"></a>策略改进</h4><p>对某个策略的累积奖赏进行评估后，若发现某个策略并非最优策略，则自然期望改变策略以使累积奖赏最大：</p>
<script type="math/tex; mode=display">
    \pi^\ast = \argmax_{\pi} \sum_{x \in X} V^{\pi}(x)</script><p>一个强化学习任务可能有多个最优策略，最优策略所对应的值函数$V^\ast$称为最优值函数，即:</p>
<script type="math/tex; mode=display">
    \forall x \in X: V^{\ast} (x) = V^{\pi^\ast} (x)</script><p>注意，当策略空间无约束时$V^\ast$才是最优策略所对应的值函数，对于离散状态空间与离散动作空间，策略空间是状态上所有动作的组合，共有$|A|^|X|$种不同的策略，若策略空间有约束，则违背约束的策略是“不合法”的，即便其值函数所取得的累积奖赏最大，也不能作为最优值函数。<br>对于前面值函数的递推方程<strong>Bellman</strong>方程稍加改动便可得到最优值函数的递推公式: </p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
V_{T}^{*}(x)=\max _{a \in A} \sum_{x^{\prime} \in X} P_{x \rightarrow x^{\prime}}^{a}\left(\frac{1}{T} R_{x \rightarrow x^{\prime}}^{a}+\frac{T-1}{T} V_{T-1}^{*}\left(x^{\prime}\right)\right) \\
V_{\gamma}^{*}(x)=\max _{a \in A} \sum_{x^{\prime} \in X} P_{x \rightarrow x^{\prime}}^{a}\left(R_{x \rightarrow x^{\prime}}^{a}+\gamma V_{\gamma}^{*}\left(x^{\prime}\right)\right)
\end{array}\right.</script><p>换言之:</p>
<script type="math/tex; mode=display">
    V^{*}(x)=\max _{a \in A} Q^{\pi^{*}}(x, a)</script><p>将该式代入状态-动作值函数刻度可得最优状态-动作值函数: </p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
Q_{T}^{*}(x, a)=\sum_{x^{\prime} \in X} P_{x \rightarrow x^{\prime}}^{a}\left(\frac{1}{T} R_{x \rightarrow x^{\prime}}^{a}+\frac{T-1}{T} \max _{a^{\prime} \in A} Q_{T-1}^{*}\left(x^{\prime}, a^{\prime}\right)\right) \\
Q_{\gamma}^{*}(x, a)=\sum_{x^{\prime} \in X} P_{x \rightarrow x^{\prime}}^{a}\left(R_{x \rightarrow x^{\prime}}^{a}+\gamma \max _{a^{\prime} \in A} Q_{\gamma}^{*}\left(x^{\prime}, a^{\prime}\right)\right)
\end{array}\right.</script><p>上述关于最优值函数的等式，称为最优Bellman等式，其唯一解是最优值函数。<br>最优Bellman等式揭示了非最优策略的改进方式: 将策略选择的动作改编为当前最优的动作。显然，这样的改变能使策略更好，不妨记动作改变后对应的策略为$\pi’$,改变动作的条件为$Q^\pi (x, \pi^i(x)) \geq V^\pi(x)$, 以$\gamma$折扣累积奖赏为例，由式可计算递推不等式: </p>
<script type="math/tex; mode=display">
    \begin{aligned}
        V^{\pi}(x) &\leq Q^{\pi}(x, \pi'(x)) \\ 
                   &= \sum_{x' \in X} P_{x \rightarrow x'}^{\pi'(x)} (R_{x \rightarrow x'}^{\pi'(x)} + \gamma V^\pi(x')) \\ 
                   &\leq \sum_{x' \in X} P_{x \rightarrow x'}^{\pi'(x)} (R_{x \rightarrow x'}^{\pi'(x)} + \gamma Q^{\pi}(x', \pi'(x'))) \\
                   &= .... \\
                   &= V^{\pi'}(x)
    \end{aligned}</script><p>值函数每一次对于策略的改进都是递增的，因此对于当前的策略$\pi$，可以放心地将其改进为:</p>
<script type="math/tex; mode=display">
    \pi'(x) = \argmax_{a \in A} Q^{\pi}(x, a)</script><p>直到$\pi’$与$\pi$一致、不再发生变化，此时就满足了最优Bellman等式，即找到了最优策略。</p>
<h4 id="策略迭代与值迭代"><a href="#策略迭代与值迭代" class="headerlink" title="策略迭代与值迭代"></a>策略迭代与值迭代</h4><p>在前面介绍了两部分内容:</p>
<ul>
<li>如何评估一个策略的值函数 </li>
<li>在策略评估后如何改进以获得最优策略 </li>
</ul>
<p>将这两者结合起来即可得到求解最优解的方法: </p>
<blockquote>
<p>从一个初始策略(通常是随机策略)出发，先进性策略评估，然后改进策略，评估改进的策略，再进一步改进策略，……不断迭代进行策略评估和改进直到策略不再改变为止，这样的做法称为“策略迭代”.</p>
</blockquote>
<p>下面给出基于$T$步累积奖赏的策略迭代算法:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E7%AD%96%E7%95%A5%E8%BF%AD%E4%BB%A3.png" alt="策略迭代算法"></p>
<p>策略迭代算法在每次改进策略后都需要进行策略评估，这通常比较耗时。但是实际上策略改进与值函数的改进是一致的，因此可讲策略改进视为值函数的改善:</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l}
V_{T}(x)=\max _{a \in A} \sum_{x^{\prime} \in X} P_{x \rightarrow x^{\prime}}^{a}\left(\frac{1}{T} R_{x \rightarrow x^{\prime}}^{a}+\frac{T-1}{T} V_{T-1}\left(x^{\prime}\right)\right) \\
V_{\gamma}(x)=\max _{a \in A} \sum_{x^{\prime} \in X} P_{x \rightarrow x^{\prime}}^{a}\left(R_{x \rightarrow x^{\prime}}^{a}+\gamma V_{\gamma}\left(x^{\prime}\right)\right)
\end{array}\right.</script><p>于是可以得到值迭代算法:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%80%BC%E8%BF%AD%E4%BB%A3.png" alt="值迭代算法"> </p>
<p>在模型已知时，强化学习任务能归结为基于动态规划的寻优问题。与监督学习不同，这里并未涉及泛化能力，仅仅是为每一个状态寻找的一个最佳动作。</p>
<h3 id="免模型学习"><a href="#免模型学习" class="headerlink" title="免模型学习"></a>免模型学习</h3><p>在现实的强化学习任务中，环境的转移概率、奖赏函数往往很难得知，甚至很难直到环境中有几个状态，若学习算法不依赖于环境建模，则称为<strong>“免模型学习”</strong>。 </p>
<h4 id="蒙特卡罗强化学习"><a href="#蒙特卡罗强化学习" class="headerlink" title="蒙特卡罗强化学习"></a>蒙特卡罗强化学习</h4><p>在免模型情况下，策略迭代算法首先碰到的问题便是策略无法评估，这是由于模型未知而导致无法做全概率展开。此时，只能通过在环境中执行选择的动作，来观察转移的状态和得到的奖赏。受K摇臂赌博机的启发，一种直接的策略评估方法是“多次采样”，然后求取平均累积奖赏作为期望累积奖赏的近似，这称为蒙特卡罗强化学习方法，由于采样必须为有限次数，因此该方法更适合于使用$T$步累积奖赏的强化学习任务。 </p>
<p>另一方面，策略迭代算法估计的是值函数，而在进行策略选择时依赖的是状态-动作值函数$Q$，当模型已知时，从$V$到$Q$有很简单的转化方法，而当模型未知时，这也会出现困难。于是我们将估计对象从$V$转变为$Q$,即估计每一对“状态-动作”的值函数。 </p>
<script type="math/tex; mode=display">
    \begin{aligned}
        az^{-1} u(k) &= au(k-1) \\
        a z^{-1} u(k)^2 &= au(k-1) u(k)
    \end{aligned}</script>]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>指数族分布与广义线性模型</title>
    <url>/2020/10/07/zhi-shu-zu-fen-bu-yu-guang-yi-xian-xing-mo-xing/</url>
    <content><![CDATA[<p>在<a href="https://soundofwind.top/2020/08/24/zai-tan-ji-da-si-ran-gu-ji-qiu-jie/">再谈极大似然估计</a>中已经讨论过指数分布族的概念，并且推导出了若概率分布是指数分布族分布，则最终的对数似然函数一定是一个凹函数，直接求偏导等于0便可得到参数估计。</p>
<p>在听了<a href="http://ml.cs.tsinghua.edu.cn/~jun/index.shtml">朱军老师</a>的关于指数分布族函数的讲解之后，发现可以从一个更加general的角度来对指数分布族函数来进行把握，而之前得到的凹性结论也不过是其中一小部分而已，该部分按照以下结构组织: </p>
<ul>
<li>简要回顾指数分布族 </li>
<li>配分函数$A(\theta)$的性质 </li>
<li>从指数分布族到广义线性模型 </li>
<li>广义线性模型性质 </li>
</ul>
<span id="more"></span> 
<h3 id="简要回顾指数分布族函数"><a href="#简要回顾指数分布族函数" class="headerlink" title="简要回顾指数分布族函数"></a>简要回顾指数分布族函数</h3><p>首先给出指数分布族的定义:</p>
<blockquote>
<p>指数分布族是一类概率分布的总称，这类分布的概率密度函数具有这样的形式：</p>
<script type="math/tex; mode=display">
    p_\theta(x) = h(x) \exp(\theta^T \phi(x) - A(\theta))</script><p>式中，$x$是密度函数自变量，$x \in \mathcal{X}$;$\phi(x)$是充分统计量，可以看做是原始变量的一个映射:</p>
<script type="math/tex; mode=display">
    \phi: \mathcal{X} \rightarrow R^d</script><p>$\theta$是模型参数向量，与充分统计量维度相同，$h(x)$是一个只与$x$有关的统计量，$A(\theta)$为配分函数，通过该函数来保证$p_\theta(x)$满足概率密度函数的定义：</p>
<script type="math/tex; mode=display">
     \int_{\mathcal{X}} p_{\theta}(x) dx = 1</script><p>由此约束条件，我们可以得到$A(\theta)$的解析表达式：</p>
<script type="math/tex; mode=display">
    A(\theta) = \log (\int h(x) \exp(\theta^T \phi(x))dx )</script></blockquote>
<p>同时概率密度函数我们也可以写成如下的形式:</p>
<script type="math/tex; mode=display">
    p_\theta(x) = \frac{1}{Z(\theta)}  h(x) exp(\theta^T \phi(x))</script><p>其中$Z(\theta) = exp(A(\theta))$,我们日常见到的很多分布都可以转化成指数分布族标准形式，比如: 伯努利分布，多项式分布，高斯分布，gamma分布等，一些变换的例子可以参考<a href="https://soundofwind.top/2020/08/24/zai-tan-ji-da-si-ran-gu-ji-qiu-jie/"><code>再谈极大似然估计</code></a></p>
<h3 id="配分函数-A-theta-的性质"><a href="#配分函数-A-theta-的性质" class="headerlink" title="配分函数$A(\theta)$的性质"></a>配分函数$A(\theta)$的性质</h3><h4 id="A-theta-性质"><a href="#A-theta-性质" class="headerlink" title="$A(\theta)$性质"></a>$A(\theta)$性质</h4><p>在之前证明$A(\theta)$的凸性性质时，所采用的方法是按照配分表达式直接证，通过赫尔德不等式可以从定义上证明其是凸函数，但其实$A(\theta)$具有更加一般的性质。 </p>
<p>$A(\theta)$其实是充分统计量$\phi(x)$的中心矩生成函数(moment generating function),这意味着:</p>
<script type="math/tex; mode=display">
  \begin{aligned}
      \nabla_{\theta} A(\theta) &= E_{p_{\theta}(x)}[\phi(x)] \\ 
      \nabla_{\theta}^2 A(\theta) &= Var[\phi(x)]  \\ 
      & ... \\
      \nabla_{\theta}^k A(\theta) &= E_{p_\theta(x)} [(\phi(x) - E[\phi(x)])^k]
  \end{aligned}</script><p>下面以一阶统计量为例做一下简单推导:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \nabla_{\theta}A(\theta) & = \nabla_{\theta} \log(Z(\theta)) \\
        &= \frac{1}{Z(\theta)} \nabla_{\theta} (\int_x h(x) \exp(\theta^T \phi(x)) dx) \\
        &= \frac{1}{Z(\theta)} \int_x h(x) \phi(x) \exp(\theta^T \phi(x))dx \\ 
        &= \int_x \frac{1}{Z(\theta)} h(x) \exp(\theta^T \phi(x)) \phi(x) dx \\ 
        &= \int_x p(x|\theta) \phi(x) dx \\
        &= E_{p_\theta(x)}[\phi(x)] 
    \end{aligned}</script><p>$A(\theta)$的上述性质可以导出一些非常好用的结论:</p>
<ul>
<li><p>如果记:</p>
<script type="math/tex; mode=display">
  \nabla_{\theta} A(\theta) = E_{p_{\theta}(x)} [\phi(x)] \overset{\triangle}{=} \mu</script><p>这里$\mu$一般被称作矩参数或者均值参数，对于不同的指数分布族函数，一般都可以找到一个双射函数$\psi$,使得:</p>
<script type="math/tex; mode=display">
  \theta \overset{\triangle}{=} \psi(\mu)</script><p>这就建立了均值参数与模型的自然参数之间的一一映射关系，在参数估计时如果得到了均值参数估计，同时直到映射关系$\psi$，那么便可以直接得到模型自然参数$\theta$的估计。</p>
</li>
<li><p>因为$\nabla_{\theta}^2 A(\theta) = Var[\phi(x)]$，而我们知道一个向量变量的协方差矩阵至少是半正定的，也就是说:</p>
<script type="math/tex; mode=display">
  \nabla_{\theta}^2  A(\theta)= Var[\phi(x)] \succeq 0</script><p>这也就直接证明了$A(\theta)$的二阶海塞矩阵半正定，即$A(\theta)$是关于$\theta$的凸函数。</p>
</li>
</ul>
<h4 id="iid-条件下样本集分布-p-D-theta"><a href="#iid-条件下样本集分布-p-D-theta" class="headerlink" title="$iid$条件下样本集分布$p(D|\theta)$"></a>$iid$条件下样本集分布$p(D|\theta)$</h4><p>在独立同分布假设下，我们通过采样得到样本集$D = { x_1, x_2, \dots, x_N }$, 在进行参数估计时我们往往需要计算整个样本集出现的概率:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        p(D|\theta) &= \prod_{i} h(x_i) \exp(\theta^T \phi(x_i) - A(\theta)) \\ 
        &= (\prod_i h(x_i)) \exp(\theta^T \sum_i \phi(x_i) - N A(\theta))
    \end{aligned}</script><p>从格式上来看，会发现样本集的分布仍然是指数族分布，只不过是充分统计量$\phi’(D)$变为了:</p>
<script type="math/tex; mode=display">
    \phi'(D) = \sum_i \phi(x_i)</script><p>这给我们一个启示，当我们要利用一组数据进行参数估计时，我们只需要将各个样本的充分统计量累加起来便可以得到整个样本集合的充分统计量，后面进行参数估计时只需要利用充分统计量即可，原始数据可以舍弃。</p>
<p>在进行极大似然估计时，我们往往会求解对数似然函数最大，下面写出指数分布的对数似然函数的一般形式:</p>
<script type="math/tex; mode=display">
    L(D;\theta) = \sum_{i} \log h(x_i) + \theta^T \sum_{i} \phi(x_i) - N A(\theta)</script><p>由于$A(\theta)$是凸函数，所以显然$L(D; \theta)$是凹函数，因此直接对$\theta$求偏导:</p>
<script type="math/tex; mode=display">
    \nabla_{\theta}(D; \theta) = \sum_{i} \phi(x_i) - N \nabla_{\theta} A(\theta) = 0</script><p>可以得到:</p>
<script type="math/tex; mode=display">
    \hat{\mu}_{MLE} = \nabla_{\theta} A(\theta) = \frac{1}{N} \sum_i \phi(x_i)</script><p>这说明充分统计量均值的极大似然估计就等于采样均值，又从前面我们得知均值参数$\mu$与模型的自然参数$\theta$通过函数$\psi$一一对应，因此可以通过充分统计量的均值估计得到模型参数的极大似然估计:</p>
<script type="math/tex; mode=display">
    \hat{\theta}_{MLE} = \psi(\hat{\mu}_{MLE})</script><h3 id="从指数分布族到广义线性模型"><a href="#从指数分布族到广义线性模型" class="headerlink" title="从指数分布族到广义线性模型"></a>从指数分布族到广义线性模型</h3><p>首先给出广义线性模型的定义:</p>
<blockquote>
<p><strong>广义线性模型:</strong><br>假设我们的数据是${ x<em>i, y_i}</em>{i=1}^n$，其中因变量$y_i$服从某一指数族分布，即:</p>
<script type="math/tex; mode=display">
    p(y_i;\theta) = h(y_i) \exp(\theta^T \phi(y_i) - A(\theta))</script><p>而对于观测量$x_i$，首先获得其线性组合:</p>
<script type="math/tex; mode=display">
    \xi_i = \eta^T x_i</script><p>然后$y_i$与 $x_i$具有这样的关系:</p>
<script type="math/tex; mode=display">
    E_{p(y;\theta)}[y] = \mu = f(\eta^T x)</script><p>$f$称作联系函数或者激活函数  </p>
</blockquote>
<p>广义线性模型的产生可以通过下图直观展示:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/glim.png" alt="广义线性模型"><br>在定义中的同路实际上是图中$\mu \rightarrow y$这条同路，但从图中可以看到，通过下面一条通路也是可以的，通过$\mu$和$\eta$之间的关系来构造指数分布。在进行广义线性模型选择时，我们有两个自由度:</p>
<ul>
<li>激活函数$f$的选择 </li>
<li>指数分布$p$的选择 </li>
</ul>
<p>指数分布$p$的选择更多与实际问题有关，比如如果是一个二分类问题，常选用伯努利分布，如果是一个多分类问题，常选用多项式分布，回归问题则常选用高斯分布，而激活函数的选择则是与分布对应的均值特性有关，比如对于伯努利分布，要求均值在$[0,1]$之间，所以在$logistic$回归中选择的是$Sigmoid$函数作为激活函数。对于多分类问题，则可以选用多项式分布作为指数分布，然后激活函数选用$softmax$函数，就可以导出扩展$logistic$到多分类问题中，得到$softmax$分类器。</p>
<p>如果取激活函数$f = \psi^{-1}$，那么模型的自然参数$\theta$:</p>
<script type="math/tex; mode=display">
    \theta = \eta^T x</script><p>此时该激活函数$f$被称作正则响应函数。</p>
<h3 id="广义线性模型性质"><a href="#广义线性模型性质" class="headerlink" title="广义线性模型性质"></a>广义线性模型性质</h3><p>当我们构造出广义线性模型后，我们需要进行参数$\eta$的学习，在没有参数先验知识的情况下，我们一般采用极大似然估计来进行参数估计，我们首先写出广义线性模型的对数似然函数形式:</p>
<script type="math/tex; mode=display">
    L(\eta, D) = \sum_{i} \log h(x_i) + \sum_i (\theta_i y_i - A(\theta_i))</script><p>其中$\theta_i = \psi(\mu_i)$,而$\mu_i = f(\eta^T x_i)$,这其实也可以简单地认为是用回归的结果来对$y_i$的值做概率预测。 对对数似然函数求偏导，可得:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \nabla_{\eta} L(\eta, D) &= \sum_i (y_i \nabla_{\eta} \theta_i  - \frac{d A(\theta_i)}{d \theta_i} \nabla_{\eta} \theta_i ) \\
        &= \sum_i (y_i - \mu_i)\nabla_{\eta} \theta_i 
    \end{aligned}</script><p>所以在进行迭代优化时，我们有:</p>
<script type="math/tex; mode=display">
    \theta_{t+1} = \theta_t + \rho (y_i - \mu_i^t) \nabla_{\eta} \theta_i</script>]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>指数分布族， 广义线性模型</tag>
      </tags>
  </entry>
  <entry>
    <title>提升算法总结</title>
    <url>/2020/09/01/ti-sheng-suan-fa-zong-jie/</url>
    <content><![CDATA[<p>对于一个特定机器学习问题，我们可能会建立很多模型，这些单个模型可能表现都不是非常好，由此便会引出一个问题:</p>
<blockquote>
<p><strong>问题1: 能否通过一个算法将这些模型组合起来(Ensemble)，产生一个效果更好的组合模型？</strong></p>
</blockquote>
<p>这个问题的答案是肯定的，历史上，Kearns 和 Valiant首先提出了“弱可学习”和“强可学习”的概念：</p>
<blockquote>
<p><strong>强可学习：</strong> 在概率近似正确(PAC)框架下，一个概念(类)，如果存在一个多项式的学习算法能够学习它，并且正确率很高，就称这个概念是强可学习的<br><strong>弱可学习：</strong> 一个概念，如果存在一个多项式的算法能够学习它，但学习的正确率仅仅比随机猜测好，则称该概念是弱可学习</p>
</blockquote>
<p>后来Schapire证明了一个重要结论:</p>
<blockquote>
<p><strong>一个概念是强可学习的  $\Leftrightarrow$ 一个概念是弱可学习的</strong></p>
</blockquote>
<p>这样一来，问题1就转换成了另一个问题:</p>
<blockquote>
<p><strong>问题2: 在学习中国，如果已经发现了“弱可学习算法”，那么能否将它提升为强可学习算法？</strong></p>
</blockquote>
<p>该部分介绍以下几类提升算法:</p>
<ul>
<li>Bagging</li>
<li><strong>AdaBoost</strong></li>
<li>随机森林 </li>
<li>提升算法解释</li>
<li>总结</li>
</ul>
<span id="more"></span>
<h3 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h3><p>对于一个训练数据集，如果我们将所有的训练集数据拿来训练，那么我们便只能得到一个模型，因此Bagging的思想非常简单：</p>
<blockquote>
<p>每次从训练数据集中取一部分数据来训练模型，通过这种方式得到多个模型，最后的决策结果则由这些模型投票表决</p>
</blockquote>
<p>算法流程如下:</p>
<blockquote>
<ul>
<li>Step1: 从包含$n$个样本的数据集中取$m$个样本作为新的训练集</li>
<li>Step2: 用挑选出的数据集来训练得到一个模型</li>
<li>Step3: 重复Step1 L次，得到L个模型</li>
<li>Step4: 最终决策结果由这$L$个模型多数投票得到</li>
</ul>
</blockquote>
<h3 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h3><h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4><p>Bagging的思想比较简单粗暴，所有样本都一视同仁，而另一种思路则是改变训练数据的概率分布(训练数据的权值分布)，针对不同的训练数据分布调用弱学习算法学习一系列弱分类器。这样，对于提升算法而言，有两个问题需要回答：</p>
<ul>
<li>在每一轮如何改变训练数据的权值或概率分布  </li>
<li>如何将这些弱分类器组合成一个强分类器</li>
</ul>
<p>AdaBoost针对这两个问题的的解决方案是:</p>
<ul>
<li>第1个问题: 提高那些被前一轮弱分类器错误分类样本的权值，而降低那些被正确分类的样本的权值。这样一来，那些没有得到正确分类的数据由于权值加大而受到后一轮弱分类器的更多关注。</li>
<li>第2个问题：AdaBoost采用加权表决的方法,加大分类误差率小的弱分类器的权值。</li>
</ul>
<p>AdaBoost算法流程如下:</p>
<blockquote>
<p><strong>AdaBoost算法</strong><br><strong>输入：</strong> 训练数据集$T = { (x_1,y_1), (x_2,y_2),\dots, (x_N,y_N)}$,其中$x_i \in R^n, y_i \in { -1, +1 }$,弱学习算法<br><strong>输出：</strong> 最终分类器$G(x)$ </p>
<ol>
<li>初始化训练数据的权值分布<script type="math/tex; mode=display">
 D_1 = (w_{11}, \dots, w_{1i}, \dots,w_{1N}), w_{1i} = \frac{1}{N}</script></li>
<li>对于$m = 1,2,\dots,M$ <ul>
<li>使用具有权值分布$D_m$的训练数据集学习，得到基本分类器<script type="math/tex; mode=display">
   G_m(x): \mathcal{X} \rightarrow \{ -1, +1 \}</script></li>
<li>计算$G_m(x)$ 在训练数据集上的分类误差率<script type="math/tex; mode=display">
   e_m = \sum_{i=1}^N P(G_m(x_i) \neq y_i) = \sum_{i=1}^N w_{mi} I(G_m(x_i) \neq y_i)</script></li>
<li>计算$G_m(x)$的系数:<script type="math/tex; mode=display">
   \alpha_m = \frac{1}{2} \log \frac{1 - e_m}{e_m}</script></li>
<li>更新训练数据集的权值分布<script type="math/tex; mode=display">
\begin{aligned}
   D_{m+1} &= (w_{m+1,1},\dots, w_{m+1,i}, \dots,w_{m+1,N}) \\
   w_{m+1,i} &= \frac{w_{m+1,i}}{Z_{m}} \exp(- \alpha_m y_i G_m(x_i)) \\
   Z_m &= \sum_{i=1}^N w_{mi} \exp(-\alpha_m y_i G_m(x_i))
\end{aligned}</script></li>
<li>构建基本分类器的线性组合:<script type="math/tex; mode=display">
    f(x) = \sum_{m=1}^M \alpha_m G_m(x)</script>得到最终分类器：<script type="math/tex; mode=display">
   G(x) = sign(f(x)) = sign(\sum_{m=1}^M \alpha_m G_m(x))</script></li>
</ul>
</li>
</ol>
</blockquote>
<p>下面对AdaBoost算法说明如下:</p>
<ul>
<li>在最开始假设训练数据具有均匀的权值分布，即每个训练样本在基本分类器中的作用相同，这一假设保证第一步能够在原始数据上学习基本分类器$G_1(x)$</li>
<li>AdaBoost反复学习基本分类器，在每一轮弱分类器训练中，首先使用当前分布$D_m$加权的训练数据集，学习基本分类器$G_m(x)$,使用加权数据进行训练，最终学得的分类器更加关注权重较高的数据，接下来计算该基本分类器$G_m(x)$在加权训练数据集上的分类误差率,然后通过该误差率计算分类器$G_m(x)$的权重，从权重计算公式可以看出，当$e_m \leq 0.5$(弱分类器前提假设)时，$\alpha_m \geq 0$,且随着$e_m$减小，$\alpha_m$会不断增大。 </li>
<li>接下来更新训练数据的权值，对于被分类器$G_m(x)$分类正确的样本，增加其权重，反之减少其权重。<strong>不改变所给的训练数据，而是不断改变训练数据权值的分布，使得训练数据在基本分类器的学习中起不同作用。</strong></li>
<li>最终的组合分类器是一个基本分类器的线性组合形式，$f(x)$的符号决定了实例$x$的类，而$f(x)$的绝对值则显示了分类结果的置信度。</li>
</ul>
<h4 id="算法理论说明"><a href="#算法理论说明" class="headerlink" title="算法理论说明"></a>算法理论说明</h4><p>上一部分从算法思想来对AdaBoost进行理解，这一部分将从理论推导方面证明AdaBoost中的一些关键公式是如何来的，比如：</p>
<ul>
<li>分类器权重$\alpha_m = \frac{1}{2} \log \frac{1-e_m}{e_m}$</li>
<li>样本点权重更新公式： <script type="math/tex; mode=display">
\begin{aligned}
  D_{m+1} &= (w_{m+1,1},\dots, w_{m+1,i}, \dots,w_{m+1,N}) \\
  w_{m+1,i} &= \frac{w_{m+1,i}}{Z_{m}} \exp(- \alpha_m y_i G_m(x_i)) \\
  Z_m &= \sum_{i=1}^N w_{mi} \exp(-\alpha_m y_i G_m(x_i))
\end{aligned}</script></li>
</ul>
<h5 id="AdaBoost算法训练误差界"><a href="#AdaBoost算法训练误差界" class="headerlink" title="AdaBoost算法训练误差界"></a>AdaBoost算法训练误差界</h5><p>首先来推导下AdaBoost的训练误差界，样本$x_i$ 在第$t$轮训练时的权重，由样本点权重递推公式可以得到：</p>
<script type="math/tex; mode=display">
    w_{t+1i} = w_{ti} \frac{e^{-\alpha_t y_i h_t(i)}}{Z_{t}} = \dots = w_{1i} \frac{e^{-y_i \sum_{j=1}^t \alpha_j h_j(i)}}{\prod_{i=1}^{t} Z_i}</script><p>其中$w_{1i} = \frac{1}{N}$,若记：</p>
<script type="math/tex; mode=display">
    \boldsymbol{\alpha} = [\alpha_1,\alpha_2,\dots, \alpha_t], \boldsymbol{h(x)} = [h_1(i),h_2(i),\dots, h_t(i)]</script><p>$w_{t+1i}$可以写成更加紧凑的形式:</p>
<script type="math/tex; mode=display">
    w_{t+1i} = \frac{e^{-y_i <\boldsymbol{\alpha}, \boldsymbol{h(x)}>}}{N \prod_{i=1}^t Z_i}</script><p>又因为有$\sum<em>{i=1}^N w</em>{t+1i} = 1$,对上式求和后可得：</p>
<script type="math/tex; mode=display">
    \prod_{i=1}^t Z_i = \frac{1}{N} \sum_{i=1}^N e^{-y_i <\boldsymbol{\alpha}, \boldsymbol{h(x)}>}</script><p>需要注意的是，$&lt;\boldsymbol{\alpha}, \boldsymbol{h(x)}&gt;$刚好是使用AdaBoost最终得到模型的预测结果(未取sign)，下面考虑两种情况：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &If \quad sign(<\boldsymbol{\alpha}, \boldsymbol{h(x_i)}>) = h(x_i) = y_i \Rightarrow <\boldsymbol{\alpha}, \boldsymbol{h(x)}> \cdot y_i = c \geq 0  , 0 \leq e^{-c}  \\
        &If \quad sign(<\boldsymbol{\alpha}, \boldsymbol{h(x_i)}>) = h(x_i) \neq y_i \Rightarrow <\boldsymbol{\alpha}, \boldsymbol{h(x)}> \cdot y_i = c \leq 0  , 1 \leq e^{-c} 
    \end{aligned}</script><p>而AdaBoost最终训练得到的模型的分类误差为:</p>
<script type="math/tex; mode=display">
    \epsilon  = \frac{1}{N}\sum_{i=1}^N \epsilon_i, \epsilon_i = \begin{cases}
        1 & h(x_i) \neq y_i \\
        0 & h(x_i) = y_i
    \end{cases}</script><p>从前面两种分类讨论可以得到:</p>
<script type="math/tex; mode=display">
    \epsilon_i \leq e^{-y_i <\boldsymbol{\alpha}, \boldsymbol{h(x_i)}>}</script><p>由此便可以得到AdaBoost分类器的<strong>分类错误率上界</strong>：</p>
<script type="math/tex; mode=display">
 \epsilon = \frac{1}{N}\sum_{i=1}^N \epsilon_i \leq \frac{1}{N} \sum_{i=1}^N e^{-y_i <\boldsymbol{\alpha}, \boldsymbol{h(x_i)}>}  = \prod_{i=1}^t Z_i</script><h5 id="alpha-t-ast-推导"><a href="#alpha-t-ast-推导" class="headerlink" title="$\alpha_t^\ast$ 推导"></a>$\alpha_t^\ast$ 推导</h5><p>需要注意的是，我们上面并未指定权重$\alpha$的表达式，那么现在我们考虑这样一个问题:</p>
<blockquote>
<p>$\alpha$取什么值时分类错误率的上界可以尽可能小</p>
</blockquote>
<p>因为$Z_i$的大小依赖于$\alpha_i$，而且它们都是迭代过程中的变量，因此可以考虑将上述问题转化为:</p>
<blockquote>
<p>如何在每一步迭代中选择合适的$\alpha_t$使得$Z_t$尽可能小 </p>
</blockquote>
<p>$Z_t$的表达式如下:</p>
<script type="math/tex; mode=display">
    Z_t = \sum_{i=1}^N w_{ti} e^{-\alpha_t y_i h_t(x_i)}</script><p>这是一个凸函数，因此可以直接求导令导数等于0：</p>
<script type="math/tex; mode=display">
    \frac{\partial Z_t}{\partial \alpha_t} = -\sum_{i=1}^N w_{ti} y_i h_t(x_i) e^{-\alpha_t y_i h_t(x_i)} = 0</script><p>下面考虑两个集合：</p>
<script type="math/tex; mode=display">
    A = y_i h_t(x_i) = 1, \bar{A} = y_i h_t(x_i) = -1</script><p>据此，上面的偏导可以写成:</p>
<script type="math/tex; mode=display">
    \frac{\partial Z_t}{\partial \alpha_t} = -\sum_{x_i \in A} w_{ti} e^{-\alpha_t} + \sum_{x_i \in \bar{A}} w_{ti} e^{\alpha} = 0</script><p>由此可得:</p>
<script type="math/tex; mode=display">
    e^{2\alpha_t} = \frac{\sum_{x_i \in A} w_{ti}}{\sum_{x_i \in \bar{A}} w_{ti}} = \frac{1 -\epsilon_t}{\epsilon_t}</script><p>求得$\alpha_t$的最优取值为:</p>
<script type="math/tex; mode=display">
    \alpha_t^\ast = \frac{1}{2} \log \frac{1 - \epsilon_t}{\epsilon_t}</script><p>至此我们便理解了每一步迭代$\alpha_t$表达式的来源，该表达式刚好可以保证最终得到的分类器错误率上界尽可能小(局部最小)。</p>
<h5 id="训练误差界-二分类问题"><a href="#训练误差界-二分类问题" class="headerlink" title="训练误差界(二分类问题)"></a>训练误差界(二分类问题)</h5><p>对于一个二分类问题，则可以将$Z_t$的表达式直接写出:</p>
<script type="math/tex; mode=display">
    Z_t = 2 \sqrt{e_t(1 - e_t)}</script><p>令$e_t = \frac{1}{2} - \gamma_t$,则可得：</p>
<script type="math/tex; mode=display">
    Z_t = \sqrt{1 - 4 \gamma_t^2} \leq e^{-2 \gamma_t^2}</script><p>由此便可得分类错误率上界为:</p>
<script type="math/tex; mode=display">
    \prod_{i=1}^t Z_i \leq e^{-2 \sum_{i=1}^t \gamma_t^2}</script><p>据此可以得到推论:</p>
<blockquote>
<p><strong>推论：</strong> 如果存在$\gamma &gt;0$,对所有$i$有，$\gamma_i \geq \gamma$,则有：</p>
<script type="math/tex; mode=display">
    \frac{1}{N} \sum_{i=1}^N I(h(x_i) \neq y_i) \leq \exp(-2N\gamma^2)</script><p>这说明对于二分类问题，AdaBoost的训练误差是指数速率下降的。</p>
</blockquote>
<p><strong>tips:</strong> </p>
<ul>
<li>对于无法接受带权样本的基学习算法，可以通过重采样法来处理，即在每一轮学习中，根据样本分布对训练集重新进行采样，变相实现带权样本，两种做法没有本质区别。</li>
<li>Boosting算法在训练的每一轮都需要检查当前生成的基学习器是否满足条件(比随机猜测要好)，若不满足，则抛弃该基学习器，学习过程停止，若采用”重采样法”，则可获得“重启动机会”，避免算法过早停止。</li>
</ul>
<h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><p>随机森林算法其实就是以决策树算法作为基学习算法，选用Bagging策略作为提升策略，最终得到的一个算法，可以这么理解:</p>
<script type="math/tex; mode=display">
    随机森林 = 决策树 + Bagging</script><p>随机森林算法简单、容易实现、计算开销小，令人惊奇的是，它在很多现实任务中展现了强大的性能，被誉为“代表集成学习技术水平的方法”。<br>不过传统的Bagging算法仅仅是在训练样本上引入随机性，而随机森林往往考虑在属性选择上引入随机性，具体做法是:原始的决策树算法是从该节点所有属性中选择一个最优属性进行节点分裂，而作为基学习器，为进一步引入随机性，一般会规定从当前节点所有属性中随机选$k$个，然后从这$k$个属性中选择一个最优的来分裂节点，若该节点有$d$个属性，常见的$k$的取值为$k = \log_2 d$</p>
<h3 id="提升算法解释"><a href="#提升算法解释" class="headerlink" title="提升算法解释"></a>提升算法解释</h3><p>学习器结合可能会从三个方面带来好处:</p>
<ul>
<li>从统计的方面来看，由于学习任务的假设空间往往非常大，此时若使用单学习器可能因误选而导致泛化性能不佳，结合多个学习器会减少这一风险。</li>
<li>从计算角度来看，学习算法往往会陷入局部极小，有的局部极小点所对应的泛化性能可能非常糟糕，而通过多次运行之后进行结合，可降低陷入糟糕极小点的风险。</li>
<li>从表示的方面来看，某些学习任务的真实假设可能不在当前学习算法s所考虑的假设空间中，此时若使用单学习器肯定无效，而通过结合多个学习器，由于相应的假设空间有所扩大，有可能学得更好的近似。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/Ensemble.png" alt="集成学习解释"></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>该部分主要总结下两个方面的内容，一个是结合策略的选择，另一个则是引入扰动的思路。</p>
<h4 id="结合策略"><a href="#结合策略" class="headerlink" title="结合策略"></a>结合策略</h4><p>结合策略主要有以下几种:</p>
<ul>
<li>平均法,包括简单平均法和加权平均法，一般而言，在个体学习器性能相差较大时，加权平均法表现较好，在个体学习器性能接近时采用简单平均法较好。</li>
<li>投票法,包括绝对多数投票法(设定得票率阈值)，相对多数投票法，加权投票法</li>
<li>学习法，即通过另一个学习器来结合这些基于学习器，该学习器被称为元学习器或者次级学习器，基学习器被称作初级学习器，初级学习器的输出作为次级学习器的输入。</li>
</ul>
<h4 id="引入扰动"><a href="#引入扰动" class="headerlink" title="引入扰动"></a>引入扰动</h4><p>常见的引入扰动的思路有如下几种:</p>
<ul>
<li>数据样本扰动</li>
<li>输入属性扰动</li>
<li>输出表示扰动</li>
<li>算法参数扰动</li>
</ul>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>Bagging, AdaBoost, 提升树模型</tag>
      </tags>
  </entry>
  <entry>
    <title>插件版本管理</title>
    <url>/2022/08/20/cha-jian-ban-ben-guan-li/</url>
    <content><![CDATA[<p>本博客用于对我更新的赛尔号插件进行版本管理。</p>
<p>不是每个人都应该像我这样去建造一座水晶大教堂，但是每个人都应该拥有自己的梦想，设计自己的梦想，追求自己的梦想，实现自己的梦想。梦想是生命的灵魂，是心灵的灯塔，是引导人走向成功的信仰。有了崇高的梦想，只要矢志不渝地追求，梦想就会成为现实，奋斗就会变成壮举，生命就会创造奇迹。——罗伯·舒乐 <span id="more"></span></p>
<ul>
<li><p>光螳螂第二关</p>
<ul>
<li>版本记录<ul>
<li>V1.0：初步完成 更新结束</li>
</ul>
</li>
</ul>
</li>
<li><p>光之惩戒英卡洛斯第三关点灯</p>
<ul>
<li>版本记录<ul>
<li>V1.3：更新了托管源 更新结束</li>
<li>V1.2：修复了明翼技能石技能bug </li>
<li>V1.1：判断明翼是否带技能石，没带则用150，优化了借火逻辑</li>
<li>V1.0：初步集成了光螳螂第三关多种打法</li>
</ul>
</li>
</ul>
</li>
<li><p>光螳螂前置-英卡洛斯一键日常版本</p>
<ul>
<li>版本记录<ul>
<li>V1.4：更新了托管源 更新结束 </li>
<li>V1.3：背包自动放入西游 </li>
<li>V1.2：优化了借火逻辑</li>
<li>V1.1：添加了背包自动复原功能</li>
<li>V1.0：一键完成前置英卡洛斯刷能量以及平衡能量</li>
</ul>
</li>
</ul>
</li>
<li><p>新手三主宠一键日常脚本</p>
<ul>
<li>版本记录<ul>
<li>V1.2：更新了版本托管源 更新结束</li>
<li>V1.1：优化借火逻辑，打完还原背包，优化赤炎金刚最后两个boss挑战逻辑 </li>
<li>V1.0：一键完成三主宠刷材料，只需艾欧</li>
</ul>
</li>
</ul>
</li>
<li><p>潘朵自定义强攻Most关卡</p>
<ul>
<li>版本记录<ul>
<li>V1.4：修复了圣雷三件套的挑战包bug 更新结束</li>
<li>V1.3：集成了星界祖皇作为传承强化精灵</li>
<li>V1.2：将幻影蝶技能替换成了暗尾刺（必中）和暗影自爆（攻击自爆）两个技能</li>
<li>V1.1：集成了表姐和混元天尊</li>
<li>V1.0：初步集成了关卡以及自定义接口</li>
</ul>
</li>
</ul>
</li>
<li><p>艾夏拉第四关综合稳定版 </p>
<ul>
<li>版本记录<ul>
<li>V1.3：更新了版本托管源 更新结束</li>
<li>V1.2：优化了借火逻辑和对战延迟 </li>
<li>V1.1：为威克斯更新了库贝萨隆打法</li>
<li>V1.0：初步集成第六关六个Boss打法</li>
</ul>
</li>
</ul>
</li>
<li><p>点灯关卡合集</p>
<ul>
<li><p>版本记录</p>
<ul>
<li>V1.0：初步集成了五个点灯关卡 更新结束</li>
</ul>
</li>
<li><p>下载源</p>
</li>
</ul>
</li>
<li><p>飞王点灯一键日常版本</p>
<ul>
<li>版本记录<ul>
<li>V1.5：修改了插件版本管理的托管网站，避免卡死 更新结束</li>
<li>V1.4：添加了哈迪斯补刀，拉取星皇和元神如果有如果有 </li>
<li>V1.3：修复了表姐玩家圣谱补刀优先级的问题</li>
<li>V1.2：自动拉取西游，克罗蒂朵默认时空补刀</li>
<li>V1.1：修复了材料数目判定错误的bug</li>
<li>V1.0：初步集成了收集材料和点灯</li>
</ul>
</li>
</ul>
</li>
<li><p>X战队密室</p>
<ul>
<li>版本记录<ul>
<li>V1.0：初步完成 更新结束</li>
</ul>
</li>
</ul>
</li>
<li><p>三件套合集</p>
<ul>
<li>版本记录<ul>
<li>V1.0：初步集成20个关卡 更新结束</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>游戏</category>
      </categories>
      <tags>
        <tag>插件管理</tag>
      </tags>
  </entry>
  <entry>
    <title>数据结构与算法</title>
    <url>/2022/09/29/shu-ju-jie-gou-yu-suan-fa/</url>
    <content><![CDATA[<p>数据结构与算法算是必考内容，如果能在笔试/面试的过程中快速找到算法题的解题思路，无疑会给面试官留下很好的印象，这类题目主要考察两个方面: </p>
<ul>
<li>数据结构的掌握程度，能否熟练掌握各类数据结构的特点及操作</li>
<li>常见算法，比如贪心算法、动态规划、BFS/DFS等 <span id="more"></span>
面试官的考察一般是循序渐进的：</li>
<li>一般首先会考察一些数据结构的知识来看被面试者的数据结构基础 </li>
<li>接下来会抛出一些常见算法，询问算法的实现细节、优缺点 </li>
<li>最后从一道具体的算法题目出发，考察被面试者分析问题，对算法举一反三的运用能力，一定要多注意思考有没有更好的解法</li>
<li>上机编程，考察被面试者的编程实现功底</li>
</ul>
<p>从上面的分析可以看出，前两项是后两项的理论基础，只有有了扎实的理论基础，后续在leetcode/牛客网刷题的时候才能事倍功半。 </p>
<h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><h4 id="编程语言"><a href="#编程语言" class="headerlink" title="编程语言"></a>编程语言</h4><p>从大的层面来看，编程语言分为两类: </p>
<ul>
<li>高级语言: 编译型语言、解释型语言 </li>
<li>低级语言: 机器语言、汇编语言 </li>
</ul>
<h5 id="编译型语言"><a href="#编译型语言" class="headerlink" title="编译型语言"></a>编译型语言</h5><blockquote>
<p><strong>编译型语言:</strong> C/C++、Pascal/Object Pascal、Golang<br><strong>定义:</strong> 程序在执行之前需要一个专门的编译过程，把程序编译成为机器语言的文件，运行时则不需要重新编译，直接运行编译后的结果就可以。</p>
<ul>
<li>优点: 程序执行效率高 </li>
<li>缺点: 依赖于编译器，跨平台性差 </li>
</ul>
</blockquote>
<h5 id="解释型语言"><a href="#解释型语言" class="headerlink" title="解释型语言"></a>解释型语言</h5><blockquote>
<p><strong>解释型语言:</strong> Python、Matlab、Javascript、Java、Ruby、C#、PHP等<br><strong>定义:</strong> 程序不需要编译，每次运行，都需要一边运行，一边翻译</p>
<ul>
<li>优点: 跨平台性能好 </li>
<li>缺点: 效率低 </li>
</ul>
</blockquote>
<h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><blockquote>
<p><strong>算法复杂度：</strong> 输入数据为$N$时，算法运行所需花费的时间 </p>
<ul>
<li>统计的是算法的<strong>计算操作数量</strong>，而不是算法的<strong>运行绝对时间</strong>，计算操作数量与算法运行绝对时间成正相关，但并不相等，还受到<strong>编程语言、计算机处理器速度、运行环境</strong>等多种因素的影响。 </li>
<li>体现的是计算操作随数据大小$N$变化时的变化情况，按照从小到大，常见的时间复杂度有: <script type="math/tex; mode=display">O(1) < O(logN) < O(N) < O(NlogN) < O(N^2) < O(2^N) < O(N!)</script></li>
</ul>
</blockquote>
<h4 id="空间复杂度"><a href="#空间复杂度" class="headerlink" title="空间复杂度"></a>空间复杂度</h4><p>空间复杂度涉及的空间类型有: </p>
<ul>
<li>输入空间: 存储输入数据所需的空间大小 </li>
<li>暂存空间: 算法运行过程中，存储所有中间变量和对象等数据所需的空间大小 </li>
<li>输出空间: 算法运行返回时，存储输出数据所需的空间 </li>
</ul>
<p>空间复杂度的计算一般只需要考虑 <strong>暂存空间</strong> + <strong>输出空间</strong><br>根据不同来源，算法使用的内存空间分为三类： </p>
<ul>
<li>指令空间: 编译后，程序指令所使用的内存空间 </li>
<li>数据空间: 算法中的各项变量使用的空间</li>
<li>栈帧空间: 一般在递归时会需要考虑 </li>
</ul>
<p>按照从小到大排列，常见的算法空间复杂度有: </p>
<script type="math/tex; mode=display">O(1) < O(logN) < O(N) < O(N^2) < O(2^N)</script><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p>在这一部分，我将回顾各种数据结构的概念以及优劣势</p>
<h4 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h4><p>数组一般用来存储相同类型的数据 </p>
<ul>
<li>特点<ul>
<li>长度固定，一般不可以动态扩展 </li>
<li>占据连续的内存空间 </li>
<li>数据的访问方式为随机访问 </li>
</ul>
</li>
<li>优点: 查改效率高，通过数组名和下标进行访问，¬$O(1)$复杂度 </li>
<li>缺点: 增删效率低，需要移动增删元素之后的所有元素 </li>
</ul>
<p><img src="/.io//%E6%95%B0%E7%BB%84.jpeg" alt="数组"></p>
<h4 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h4><p>链表相较于数组，除了数据域，还增加了指针域用于存储下一个节点的地址，链表中每一个元素都包含此节点的数据和指向下一节点地址的指针。</p>
<ul>
<li>特点<ul>
<li>长度可动态变化</li>
<li>非连续的内存空间</li>
<li>数据的访问方式为顺序访问 </li>
</ul>
</li>
<li>优点: 增删效率后，$O(1)$的时间复杂度 </li>
<li>缺点: 查改效率低，只能通过遍历节点依次查询，$O(N)$的时间复杂度  </li>
</ul>
<p><img src="/.io//%E9%93%BE%E8%A1%A8.jpeg" alt="链表"></p>
<h4 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h4><p>栈本身是一个线性表，但在这个表中只有一个口子允许数据的进出，其特点在于栈中元素的<strong>先进后出(FILO)</strong>，常用的操作有<code>push()、pop()、top()</code></p>
<p><img src="/.io//%E6%A0%88.gif" alt="栈"></p>
<h5 id="单调栈"><a href="#单调栈" class="headerlink" title="单调栈"></a>单调栈</h5><p>单调栈是一种特殊的栈，栈中的元素是单调递增/递减: </p>
<ul>
<li>单调递增栈: 可以找到元素向左遍历第一个比它小的元素 </li>
<li>单调递减栈: 可以找到元素向左遍历第一个比它大的元素 </li>
</ul>
<p>借助单调栈可以在线性时间内完成左侧第一个小于/大于元素的搜索，下面介绍几个典型题目 </p>
<ul>
<li>接雨水<br><img src="/.io//%E6%8E%A5%E9%9B%A8%E6%B0%B4.png" alt><ul>
<li><blockquote>
<p>题目描述: 给定一个列表表示高度图，计算下雨后能接多少雨水 </p>
</blockquote>
</li>
<li><blockquote>
<p>解题思路: 维护一个单调递减栈，一旦发现当前元素大于栈顶元素，当前元素便是右边界，栈顶元素出栈，此时单调栈的栈顶元素便成为了左侧边界，取两者最小值作为高度，乘以左右距离便得到了装水量。</p>
</blockquote>
</li>
</ul>
</li>
<li>求直方图中最大矩阵面积<br><img src="/.io//%E6%9C%80%E5%A4%A7%E7%9F%A9%E9%98%B5%E9%9D%A2%E7%A7%AF.png" alt><ul>
<li><blockquote>
<p>题目描述: 给定一个列表表示直方图，求该直方图中最大矩阵面积</p>
</blockquote>
</li>
<li><blockquote>
<p>解题思路: 维护一个单调递增栈，当遇到大的元素时直接进栈，一旦发现当前元素小于栈顶元素，则当前元素便是栈顶元素的右边界，而栈顶元素出栈后，下一个栈顶元素便是左边界，由此便可计算矩阵面积，遍历一次找到最大的矩阵面积即可。 </p>
</blockquote>
</li>
</ul>
</li>
<li>最大矩形<br><img src="/.io//%E6%9C%80%E5%A4%A7%E7%9F%A9%E5%BD%A2.png" alt><ul>
<li><blockquote>
<p>题目描述: 给定一个仅包含 0 和 1 、大小为 rows x cols 的二维二进制矩阵，找出只包含 1 的最大矩形，并返回其面积。</p>
</blockquote>
</li>
<li><blockquote>
<p>解题思路: 按行遍历，然后每次都堆叠列得到一个柱状图，然后通过单调栈算法，求最大矩形面积</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<p>单调栈算法总结: </p>
<blockquote>
<p>单调栈是一个原理简单，但不太好想到的一种思路，在leetcode往往是以hard题目形式出现，线性时间复杂度是该数据结构最大的优势，对于此类题目往往会先考虑暴力解法，如果需要寻找各个元素的左边界/右边界，则考虑能否应用单调栈降低时间复杂度。 </p>
</blockquote>
<h4 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h4><p>队列是一种线性数据结构，与栈的后进先出相对应，队列是<strong>先进先出(FIFO)</strong><br><img src="/.io//%E9%98%9F%E5%88%97.gif" alt="队列"></p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">import queue 
q = queue.Queue()
q.put(1)   #向队列中加入元素 
q.get()    #取出队列中最先进入的元素 
q.empty()  #判断队列是否为空 
q.qsize()  #获取队列长度
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="树"><a href="#树" class="headerlink" title="树"></a>树</h4><p>树作为一种树状的数据机构，其将有限个节点根据不同的层次关系进行排列，从而形成数据之间的父子关系，从某种角度来说，可以将树看作链表的高配版，对普通链表的指针域进行了扩展。<br>下面介绍一些常见的树的类型: </p>
<ul>
<li>完全二叉树: 除了最后一层节点，其他层的节点数都达到了最大值，同时最后一层的节点都是按照从左到右依次排布</li>
<li>满二叉树: 除了最后一层，其他层的节点都有两个子节点 </li>
<li>二叉排序树((二叉搜索树): 左子树上所有结点的值均小于根结点的值，右子树上所有结点的值均大于根结点，左右子树也分别时二叉排序树</li>
<li>平衡二叉树: 平衡二叉树又被称为AVL树，它是一个二叉排序树，且左右子树的高度差距不超过1，左右子树也都是二叉平衡树 <ul>
<li>优点: 平衡二叉树为了追求高度平衡，需要通过平衡处理使得左右子树的高度差必须小于等于1，高度平衡带来了更高的搜索效</li>
<li>缺点： 缺点则是对树中结点进行插入删除时需要经过多次旋转实现复衡，这导致AVL的插入和删除效率并不高。</li>
</ul>
</li>
<li>红黑树: <ul>
<li>每个结点要么是红的，要么是黑的</li>
<li>根结点是黑的 </li>
<li>每个叶结点(None)都是黑的 </li>
<li>如果一个结点是红的，那么它的两个儿子都是黑的</li>
<li>对于任意结点而言，其到叶结点树尾端None指针的每条路径都包含相同数目的黑结点<br><img src="/.io//%E7%BA%A2%E9%BB%91%E6%A0%91.jpeg" alt="红黑树"></li>
</ul>
</li>
<li>红黑树与平衡二叉树对比<br><img src="/.io//%E7%BA%A2%E9%BB%91vs%E5%B9%B3%E8%A1%A1.png" alt="AVLvs红黑树"></li>
</ul>
<p>树的遍历方式有四种: </p>
<ul>
<li>前序遍历: 按照 根结点-&gt;左子结点-&gt;右子结点的顺序进行遍历 </li>
<li>中序遍历: 按照 左子结点-&gt;根结点-&gt;右子结点的顺序进行遍历 </li>
<li>后序遍历: 按照 左子结点-&gt;右子结点-&gt;根结点的顺序进行遍历 </li>
<li>层次遍历: 从根结点开始，按结点所处层级进行遍历 <h4 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h4>堆通常可以看做一棵树的数组对象，堆的实现一般不通过指针域，而是通过构建一个一维数组与二叉树的父子结点进行对应，因此堆总是一棵完全二叉树。</li>
<li>对于任意一个父结点的序号$n$来说，它的子结点的序号一定是$2n+1, 2n+2$，因此可以直接用一个数组表示一个堆</li>
<li>堆中某个结点的值总是不大于或者不小于其父节点的值: 根结点最大的堆称为<strong>最大堆</strong>;根结点最小的堆称为<strong>最小堆</strong></li>
<li>堆常用来实现优先队列，比如堆排序、top$K$问题等 </li>
</ul>
<p><img src="/.io//%E5%A0%86.jpeg" alt></p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">import heapq  
pq = [] 
value = 1
heapq.heappush(pq, value)    #向小根堆中加入元素 
heapq.heapreplace(pq, value) #替换堆顶元素 
heapq.pop(pq)                #弹出堆顶元素
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h4><p>哈希表也叫散列表，是一种通过键值堆直接访问数据的结构，借助于哈希表可以实现$O(1)$的数据访问效率。<br><img src="/.io//%E5%93%88%E5%B8%8C%E8%A1%A8.jpeg" alt></p>
<p>哈希表实现的最关键就是哈希函数的定义和选择，一般常用的有以下几种： </p>
<ul>
<li>直接寻址法: 取关键字或者关键字的某个线性函数作为哈希地址 </li>
<li>数字分析法: 通过数据的特点，发现数据中冲突较少的部分，构造哈希地址。 </li>
<li>平方取中法:</li>
<li>取随机数法: 通常适用于关键字长度不同的场合</li>
<li>除留取余法: 取关键字被某个不大于散列表的表长$n$的数$m$除后所得的余数$p$作为散列地址，一般取素数或者直接用$n$。 </li>
</ul>
<p><strong>哈希冲突</strong>: 当不同的key值访问到同一个地址时，就发生了哈希冲突。<br>哈希冲突主要有以下解决方案： </p>
<ul>
<li>链地址法: 在冲突的地方再做一个链表</li>
<li>开放寻址法: 探测后续未被占用的地址 </li>
<li>再哈希: 使用关键字的其他部分继续计算地址，更换哈希函数 </li>
</ul>
<p><img src="/.io//%E9%93%BE%E5%9C%B0%E5%9D%80%E6%B3%95.jpeg" alt> </p>
<h4 id="图"><a href="#图" class="headerlink" title="图"></a>图</h4><p>图一般包含顶点和边，可粗略分为有向图和无向图。</p>
<ul>
<li>图的存储一般通过<strong>邻接矩阵</strong>实现<br><img src="/.io//%E9%82%BB%E6%8E%A5%E7%9F%A9%E9%98%B51.jpeg" alt></li>
<li>邻接矩阵往往是稀疏的，存储大量的0导致浪费了大量的空间，，一种只存储相连顶点关系的邻接表应运而生。<ul>
<li>在邻接表中，图的每一个顶点都是一个链表的头结点，其后连接着该节点能够到达的相邻节点。</li>
<li>邻接表只包含个个结点的出度信息</li>
</ul>
</li>
<li>逆邻接表: 包含结点的入度信息</li>
<li>十字链表 </li>
</ul>
<h3 id="常见算法"><a href="#常见算法" class="headerlink" title="常见算法"></a>常见算法</h3><h4 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h4><p>动态规划是算法与数据结构的重难点，其中包含了「分治思想」、「空间换时间」、「最优解」等多种算法思想，这部分将从以下三个方面对动态规划算法进行介绍: </p>
<ul>
<li>动态规划问题特点，<strong>动态规划</strong>和<strong>分治算法</strong>的联系与区别 </li>
<li>介绍<strong>重叠子问题</strong>与<strong>最优子结构</strong>分别是什么，以及动态规划是如何解决的 </li>
<li>动态规划的解题框架总结 </li>
</ul>
<h5 id="动态规划与分治"><a href="#动态规划与分治" class="headerlink" title="动态规划与分治"></a>动态规划与分治</h5><ol>
<li><strong>分治算法</strong>: 「分治」是算法中的一种基本思想，通过将<strong>原问题分解为子问题</strong>，不断递归地将子问题分解为更小的子问题，并通过<strong>组合子问题的解</strong>来得到原问题的解， e.g. 归并排序 </li>
<li><strong>动态规划</strong>: 与「分治」的相同点在于「动态规划」也是通过组合子问题的解来得到原问题的解，不同的是，能用「动态规划」解决的问题具有「<strong>重叠子问题</strong>」和「<strong>最优子结构</strong>」两大特性。</li>
</ol>
<h5 id="动态规划问题特性"><a href="#动态规划问题特性" class="headerlink" title="动态规划问题特性"></a>动态规划问题特性</h5><ul>
<li><strong>重叠子问题</strong>: 动态规划的子问题是有重叠的，即各个子问题中包含<strong>重复的更小子问题</strong>，若使用暴力法穷举，求解这些相同子问题会产生大量重复计算，效率低下。<br><img src="/.io//%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E6%95%B0%E5%88%97.png" alt><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 求第 n 个斐波那契数
def fibonacci(n):
  if n == 0: return 0       # 若求 f(0) 则直接返回 0
  a, b = 0, 1               # 初始化 f(0), f(1)
  for i in range(2, n + 1): # 状态转移求取 f(2), f(3), ..., f(n) 
      a, b = b, a + b
  return b                  # 返回 f(n)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><strong>最优子结构</strong>: 如果一个问题的最优解可以由其子问题的最优解组合而成，并且这些子问题可以独立求解，那么称此问题具有最优子结构。<br><img src="/.io//%E8%9B%8B%E7%B3%95%E6%9C%80%E9%AB%98%E5%94%AE%E4%BB%B7.png" alt><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 输入蛋糕价格列表 price_list ，求重量为 n 蛋糕的最高售价
def max_cake_price(n, price_list):
  if n <= 1: return price_list[n] # 蛋糕重量 <= 1 时直接返回
  dp = [0] * (n + 1)              # 初始化 dp 列表
  for j in range(1, n + 1):       # 按顺序计算 f(1), f(2), ..., f(n)
      for i in range(j):          # 从 j 种组合种选择最高售价的组合作为 f(j)
          dp[j] = max(dp[j], dp[i] + price_list[j - i])
  return dp[n]
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
</ul>
<h5 id="动态规划解题框架"><a href="#动态规划解题框架" class="headerlink" title="动态规划解题框架"></a>动态规划解题框架</h5><p>首先分析问题是否具有「<strong>重叠子问题</strong>」与「<strong>最优子结构</strong>」两个特性，若有则可以考虑用动态规划按照以下步骤进行求解: </p>
<ol>
<li><strong>状态定义</strong>: 构建问题最优解模型，包括问题<strong>问题最优解的定义</strong>、<strong>有哪些计算解的自变量</strong></li>
<li><strong>初始状态</strong>: 确定基础子问题的解，原问题和子问题的解都是以基础子问题的解为起始点，在迭代计算中得到 </li>
<li><strong>转移方程</strong>: 确定原问题与子问题之间的关系，以及使用何种选择规则从子问题最优解中组合出原问题的最优解 </li>
<li><strong>返回值</strong>: 确定应返回的问题的解是什么，即动态规划在何处停止迭代</li>
</ol>
<p><strong>示例: 斐波那契数列</strong></p>
<ul>
<li><strong>状态定义</strong>: 一维$dp$列表，设第$i$个斐波那契数为$dp[i]$ </li>
<li><strong>初始状态</strong>: 已知第$0,1$个斐波那契数为$dp[0] = 0, dp[1] = 1$</li>
<li><strong>转移方程</strong>: 后一个数字等于前两个数字之和<script type="math/tex; mode=display">dp[i] = dp[i-1] + dp[i-2]</script></li>
<li><strong>返回值</strong>: 第$n$个斐波那契数$dp[n]$</li>
</ul>
<h4 id="排序算法"><a href="#排序算法" class="headerlink" title="排序算法"></a>排序算法</h4><h5 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h5><p>排序算法用作实现列表的排序，列表元素可以是整数，也可以是浮点数、字符串等其他数据类型，生活中有许多需要用到排序算法的场景: </p>
<ul>
<li><strong>数字排序</strong>: 对于一个数组，我们希望将所有数字从小到大/从大到小排序 </li>
<li><strong>字符串排序</strong>: 对于一个字符串列表，我们希望将所有单词按照字符先后排序 </li>
<li><strong>自定义排序</strong>: 对于任意一个<strong>已定义比较规则</strong>的集合，我们希望将其按规则排序 </li>
</ul>
<p><img src="/.io//%E6%8E%92%E5%BA%8F%E6%A6%82%E8%BF%B0.png" alt></p>
<h5 id="常见排序算法"><a href="#常见排序算法" class="headerlink" title="常见排序算法"></a>常见排序算法</h5><p>常见排序算法包括「冒泡排序」、「插入排序」、「选择排序」、「快速排序」、「归并排序」、「堆排序」、「基数排序」、「桶排序」。如下图所示，为各排序算法的核心特性与时空复杂度总结<br><img src="/.io//%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%97%B6%E7%A9%BA%E5%A4%8D%E6%9D%82%E5%BA%A6.png" alt><br>如下图所示，为在 「随机乱序」、「接近有序」、「完全倒序」、「少数独特」四类输入数据下，各常见排序算法的排序过程。</p>
<p><img src="/.io//%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F%E5%8A%A8%E7%94%BB.gif" alt><br><img src="/.io//%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%E5%8A%A8%E7%94%BB.gif" alt><br><img src="/.io//%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F%E5%8A%A8%E7%94%BB.gif" alt><br><img src="/.io//%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E5%8A%A8%E7%94%BB.gif" alt><br><img src="/.io//%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E5%8A%A8%E7%94%BB.gif" alt><br><img src="/.io//%E5%A0%86%E6%8E%92%E5%BA%8F%E5%8A%A8%E7%94%BB.gif" alt></p>
<h5 id="排序算法主要可根据稳定性、就地性、自适应性分类，理想的排序算法具有以下特征"><a href="#排序算法主要可根据稳定性、就地性、自适应性分类，理想的排序算法具有以下特征" class="headerlink" title="排序算法主要可根据稳定性、就地性、自适应性分类，理想的排序算法具有以下特征:"></a>排序算法主要可根据<strong>稳定性、就地性、自适应性</strong>分类，理想的排序算法具有以下特征:</h5><ul>
<li><strong>稳定性</strong>: 相等元素的相对位置不变化 </li>
<li><strong>就地性</strong>: 不使用额外的辅助空间 </li>
<li><strong>自适应性</strong>: 时间复杂度受元素分布影响 </li>
</ul>
<p>按照稳定性来分类: </p>
<ul>
<li>稳定排序: 冒泡排序、插入排序、归并排序、基数排序、桶排序 </li>
<li>非稳定排序: 选择排序、快速排序、堆排序 </li>
</ul>
<p>按照就地性进行分类: </p>
<ul>
<li>原地排序: 不使用额外辅助数组，例如: 冒泡排序、插入排序、选择排序、快速排序、堆排序 </li>
<li>非原地排序: 使用额外辅助数组，例如: 基数排序、桶排序等 </li>
</ul>
<h5 id="时空复杂度"><a href="#时空复杂度" class="headerlink" title="时空复杂度"></a>时空复杂度</h5><p>常见排序算法时空复杂度见下图</p>
<p><img src="/.io//%E6%8E%92%E5%BA%8F%E5%A4%8D%E6%9D%82%E5%BA%A6.png" alt></p>
<ul>
<li>普通「冒泡排序」的最佳时间复杂度为$O(N^2)$，通过增加标志位实现提前返回 ，可以将最佳时间复杂度降低至$O(N)$</li>
<li>在输入列表完全倒序下，普通「快速排序」的空间复杂度劣化至$O(N)$通过代码优化 Tail Call Optimization 保持算法递归较短子数组，可以将最差递归深度降低至 $\log N$ </li>
<li>普通「快速排序」总以最左或最右元素为基准数，因此在输入列表有序或倒序下，时间复杂度劣化至$O(N^2)$; 通过随机选择基准数, 可极大减少此类最差情况发生, 尽可能地保持$O(NlogN)$的时间复杂度。</li>
<li>若输入列表是数组，则归并排序的空间复杂度为$O(N)$; 而若排序链表, 则「归并排序」不需要借助额外辅助空间，空间复杂度可以降低至$O(1)$</li>
</ul>
<h5 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h5><p>快速排序分为两步: </p>
<ul>
<li><strong>哨兵划分</strong>: 以数组某个元素为<strong>基准数</strong>，将所有小于基准数的元素移至其左边，大于基准数的元素移动至其右边</li>
<li><strong>递归</strong>: 对左子数组和右子数组分别执行<strong>哨兵划分</strong>，直至子数组长度为1终止递归 </li>
</ul>
<p><img src="/.io//%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F.png" alt></p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">def quick_sort(nums, l, r):
    # 子数组长度为 1 时终止递归
    if l >= r: return
    # 哨兵划分操作
    i = partition(nums, l, r)
    # 递归左（右）子数组执行哨兵划分
    quick_sort(nums, l, i - 1)
    quick_sort(nums, i + 1, r)

def partition(nums, l, r):
    # 以 nums[l] 作为基准数
    i, j = l, r
    while i < j:
        while i < j and nums[j] >= nums[l]: j -= 1
        while i < j and nums[i] <= nums[l]: i += 1
        nums[i], nums[j] = nums[j], nums[i]
    nums[l], nums[i] = nums[i], nums[l]
    return i

# 调用
nums = [3, 4, 1, 5, 2]
quick_sort(nums, 0, len(nums) - 1)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h5><p>归并排序体现了<strong>分治</strong>的算法思想，具体为: </p>
<ul>
<li><strong>分</strong>: 不断将数组从中点位置划分开，将原数组的排序问题转化为子数组的排序问题</li>
<li><strong>治</strong>: 划分到子数组长度为1时，开始向上合并，不断将<strong>左右两个较短排序数组</strong>合并为一个<strong>较长排序数组</strong>，直至合并至原数组完成排序</li>
</ul>
<p><img src="/.io//%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F.png" alt></p>
<p>代码实现</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">def merge_sort(nums, l, r):
    # 终止条件
    if l >= r: return
    # 递归划分数组
    m = (l + r) // 2
    merge_sort(nums, l, m)
    merge_sort(nums, m + 1, r)
    # 合并子数组
    tmp = nums[l:r + 1]       # 暂存需合并区间元素
    i, j = 0, m - l + 1       # 两指针分别指向左/右子数组的首个元素
    for k in range(l, r + 1): # 遍历合并左/右子数组
        if i == m - l + 1:
            nums[k] = tmp[j]
            j += 1
        elif j == r - l + 1 or tmp[i] <= tmp[j]:
            nums[k] = tmp[i]
            i += 1
        else:
            nums[k] = tmp[j]
            j += 1

# 调用
nums = [3, 4, 1, 5, 2, 1]
merge_sort(0, len(nums) - 1)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="搜索与回溯算法"><a href="#搜索与回溯算法" class="headerlink" title="搜索与回溯算法"></a>搜索与回溯算法</h4><h5 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h5><ul>
<li><strong>搜索</strong>是计算机解题中的常用算法，其本质是通过某种规则实现对解空间的遍历</li>
<li><strong>回溯</strong>搜索算法中的一种控制策略，它的基本思想是: 为了求得问题的解，先选择某一种可能的情况向前探索，在探索过程中，一旦发现上一步选择是错的，就退回一步重新选择，继续向前探索，直至得到解或者证明无解。 </li>
</ul>
<p>这类算法大致可以分为两类: </p>
<ul>
<li>暴力搜索(无信息搜索算法): 广度优先搜索(BFS)、广度优先搜索(DFS)</li>
<li>启发式搜索(有信息搜索算法): 贪心搜索、A*搜索 </li>
</ul>
<h5 id="广度优先搜索算法"><a href="#广度优先搜索算法" class="headerlink" title="广度优先搜索算法"></a>广度优先搜索算法</h5><p>BFS，类似地毯式搜索，以距离为层数逐层搜索，直到找到答案或者确认无解<br><img src="/.io//BFS.gif" alt><br>广度优先搜索一般通过队列实现: </p>
<ul>
<li>起始结点入队列</li>
<li>遍历与启示结点有连通的结点，入队列 </li>
<li>起始结点出队列</li>
<li>重复以上步骤，直至找到目标点或者队列为空(无解)</li>
</ul>
<h5 id="深度优先搜索算法"><a href="#深度优先搜索算法" class="headerlink" title="深度优先搜索算法"></a>深度优先搜索算法</h5><p>深度优先搜索(DFS)会从第一个指定的顶点开始遍历图，沿着这条路径直到最后一个顶点被访问了，再原路折回(回溯)探索下一条路径。<br><img src="/.io//DFS.gif" alt></p>
<p>深度优先搜索一般是通过递归回溯实现 </p>
<h5 id="贪心搜索"><a href="#贪心搜索" class="headerlink" title="贪心搜索"></a>贪心搜索</h5><p>当边上有权值时，BFS便不适用了，此时需要加入松弛变量来表示结点与顶点之间的距离，这就是dijkstra算法，对于无权图/树，dijkstra算法就退化成了BFS</p>
<p>动态规划是贪心的泛化，贪心是动态规划的特例(贪婪解也恰好是Bellman最优时)</p>
<h5 id="A-搜索"><a href="#A-搜索" class="headerlink" title="A*搜索"></a>A*搜索</h5><p>做到题目了再来补</p>
<h4 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h4><h5 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h5><p>程序中的所有数在计算机内存中都是以二进制的形式存储的，位运算就是直接对整数在内存中的二进制位进行运算，常见的运算操作符有: </p>
<ul>
<li>与(&amp;) </li>
<li>或(|) </li>
<li>异或(^) </li>
<li>取反(~) </li>
<li>左移(&lt;&lt;) </li>
<li>右移(&gt;&gt;) </li>
</ul>
<h5 id="与运算"><a href="#与运算" class="headerlink" title="与运算"></a>与运算</h5><p>两位同时为1，结果为1，否则为0<br>与运算的特殊用途: </p>
<ul>
<li>清零: 任何数字与0相与都是0 </li>
<li>取指定位: 与一个特定位为1，其他位为0的数字进行与运算即可取原数字中该特定位</li>
</ul>
<p><img src="/.io//%E4%B8%8E%E8%BF%90%E7%AE%97.png" alt></p>
<h5 id="或运算"><a href="#或运算" class="headerlink" title="或运算"></a>或运算</h5><p>二进制对应位两两进行或运算(有1则1，无1则0)<br>或运算的特殊用途: </p>
<ul>
<li>用来将数字的某些位置1 </li>
</ul>
<p><img src="/.io//%E6%88%96%E8%BF%90%E7%AE%97.png" alt></p>
<h5 id="异或运算"><a href="#异或运算" class="headerlink" title="异或运算"></a>异或运算</h5><p>二进制对应位两两进行异或运算(相同为1，不同为0)<br><img src="/.io//%E5%BC%82%E6%88%96%E8%BF%90%E7%AE%97.png" alt></p>
<p>异或运算的特殊用途: </p>
<ul>
<li>将低位1置0(n&amp;(n-1)将低位1置0) </li>
<li>使某些特定的位翻转(与指定位为1的数字进行异或运算) </li>
<li>判断两个值是否相等(相等则异或值为0)</li>
<li>实现两个值的交换(a = a^b, b = b^a, a = a^b) </li>
</ul>
<h5 id="按位取反"><a href="#按位取反" class="headerlink" title="按位取反"></a>按位取反</h5><p>二进制的0变成1，1变成0<br><img src="/.io//%E5%8F%96%E5%8F%8D%E8%BF%90%E7%AE%97.png" alt> </p>
<h5 id="移位运算符"><a href="#移位运算符" class="headerlink" title="移位运算符"></a>移位运算符</h5><ul>
<li>左移运算符$&lt;&lt;$: 左移后右侧补0 </li>
<li>右移运算符$&gt;&gt;$: 右移后左边补原左位值</li>
</ul>
<p>说明: </p>
<ul>
<li>左移一位相当于整个数乘以二 </li>
<li>右移一位相当于整数除以二</li>
</ul>
<p><img src="/.io//%E7%A7%BB%E4%BD%8D%E8%BF%90%E7%AE%97%E7%AC%A6.png" alt> </p>
<h5 id="位运算小技巧"><a href="#位运算小技巧" class="headerlink" title="位运算小技巧"></a>位运算小技巧</h5><ul>
<li>判断奇偶数<br>```python</li>
</ul>
<p>if(n &amp; 1 == 1){<br>// n 是个奇数。<br>} </p>
<pre><code>- 交换两个数
```python
a=a^b; #a=a^b
b=a^b; #b=(a^b)^b=a^0=a
a=a^b; #a=(a^b)^(a^b^b)=0^b=0
</code></pre><h5 id="经典问题"><a href="#经典问题" class="headerlink" title="经典问题"></a>经典问题</h5><ul>
<li>不用加减乘除做加法</li>
<li>二进制中1的个数</li>
<li>只出现一次的数字 </li>
</ul>
<p>….未完待续，后序刷题碰到未掌握的知识点后回来补充</p>
]]></content>
      <categories>
        <category>算法岗八股文</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>文城-读后感</title>
    <url>/2021/03/20/wen-cheng-du-hou-gan/</url>
    <content><![CDATA[<blockquote>
<p><strong>序:</strong> 3月12日晚，在王府井街道上的三联韬奋书店中，我轻抚着一本本书的封面，似乎试图透过封面上的零星字眼来寻找某种共鸣感，<strong>当我看到《文城》这本书时，腰封上的“人生就是自己的往事和他人的序章”蓦然间打动了我，于是我拿起了这本书，将与这本书的相遇纳入我的往事之中。</strong></p>
</blockquote>
<span id="more"></span>
<p>在读《文城》之前，我并没有读过余华的其他作品，但或许也正是因为这个原因，《文城》带给了我极大的惊喜感，不快不慢的文章节奏，入木三分的人物刻画，张弛有度的感情释放，引人入胜的情节设计…… 无不让我有眼前一亮之感。<br>读完《文城》后，我的脑中思绪万千，人物、情节、时代背景、个人命运…… 似乎从哪一个点切入都有着零碎的只言片语。然零星的只言片语只有经过文字的整理才能够成体系，本文就基于这样的目的简单地谈一谈自己对这本书的感受。 </p>
<h3 id="故事情节"><a href="#故事情节" class="headerlink" title="故事情节"></a>故事情节</h3><p>《文城》中的故事发生在清末民初的一个南方小镇中，其所述的故事兼具民间性与传奇性，小说由“文城”和“文城 补”构成，两部分，犹如两面镜子，彼此相互映照，但只有将两个镜中世界进行拼合，才能看到完整的故事。</p>
<blockquote>
<p><strong>文城</strong><br>阿强和小美在前往北京的过程中遇到了林祥福，阿强谎称他们来自“文城”，此后阿强独自离开，林祥福娶了留在家中的小美，小美在得知家中金条储藏位置后拿走少部分金条不辞而别；遭遇打击的林祥福为将被拿走的金条补上，开始四处拜师学艺，磨练自己的木匠活技巧；在林祥福生活再次归入平淡之际，小美归来了，但在为他诞下一女后又再次逃离；为寻找小美，林祥福决定将家产托付给管家，带着女儿踏上了去“文城”寻找小美之路，寻“文城”未果后林祥福在溪镇扎了根，叙述了林祥福父女与陈永良一家相伴生活的故事，然后在溪镇发生了遭遇龙卷风、霜冻自然灾害、遭遇北洋军阀的掠夺、遭遇土匪祸乱等事件，塑造了陈永良、顾益民、民团、匪帮等形象，最终林祥福在土匪祸乱中走向了他人生的句点。<br><strong>文城 补</strong><br>纪小美作为阿强家的童养媳从十岁开始便在阿强家长大，后因为接济家中弟弟被休回家。后来，阿强违逆父母心意，独自出逃去将纪小美从娘家带走，开启了一段冒险之旅，在山穷水尽之际，他们遇到了林祥福，小美在为林祥福诞下一女后与阿强返回溪镇，纪小美将对女儿的思念和对林祥福的歉意深埋心底，在溪镇与阿强开启了新的生活。当得知林祥福来到溪镇后，两人刻意躲避，在林祥福寻”文城”未果后，又于 雪冻之时返回了溪镇，时光在此交汇，阿强和纪小美冻死在了祭天之时，冻死于林祥福重新踏入溪镇准备开启新生活之时。 </p>
</blockquote>
<p><strong>如果说”文城”是江河表面的波澜壮阔，那么”文城 补”则是其下的暗流涌动，两者互为表里，综合起来便是林祥福、小美、阿强的完整人生。余华在”文城”篇也运用了倒叙和插叙的手法，让读者在阅读时始终带着悬念，当读完”文城 补”，一切谜底都揭晓之时，疑云消散，独留对命运的慨叹在心中回荡。</strong></p>
<h3 id="人物"><a href="#人物" class="headerlink" title="人物"></a>人物</h3><p>《文城》中人物刻画的突出特点就是人物内核的始终如一：</p>
<ul>
<li><strong>至纯至善的林祥福:</strong> 好心接纳阿强与小美留宿，原谅小美盗窃金条，携幼女南下寻找小美，在溪镇与陈永良一家组成组合家庭，面对匪帮时挺身而出。从出场到落幕，善始终是林祥福这个角色最浓重的一抹底色。 </li>
<li><strong>善良且富有母性的纪小美:</strong> 这个清秀温柔的南方女子，被命运裹挟着从溪镇来到了林祥福的家乡，后又回到了溪镇。这个简单的女子在与复杂的命运碰撞中，体验过幸福快乐，也经历过痛彻心扉。 </li>
<li><strong>沉稳且富有担当的顾益民:</strong> 雪冻之时组织祭拜苍天，沉着应对北洋军阀使溪镇化险为夷，组建溪镇民团，担任民团首领…… 这个沉稳严肃的黑瘦男子始终如溪镇的主心骨一般，在这个飘摇动荡的年代支撑起了溪镇，小说结尾，顾益民那“低头弓背，弱不禁风”的模样似乎预示了在这乱世中，溪镇将走向的结局。 </li>
<li>………</li>
</ul>
<p>故事中所有的人物大都是有着始终如一的底色，所以每一个人物都可以给读者留下深刻的印象，这在一定程度上削弱了故事的复杂性，但个性鲜明的人物加上精巧的剧情设计，使得整个故事的复杂度刚刚好，人物与情节耦合地纹丝合缝。<br>人物塑造的始终如一、人物与故事的相得益彰使得文中着墨描写的人物都十分鲜活，当我读完这本书之时，除了会慨叹命运之外，也会回味于走向结局之人的一生，也会构想那些未交代结局但在我脑海中鲜活着的人物的命运……这或许就是好小说的魅力所在吧，仿佛林祥福、纪小美、沈阿强、顾益民等角色真真正正地存在过，存在于那个久远的兵荒马乱的清末民初之时。<br><strong>或许某一天我会因《文城》中的某个人物而对现实中的某个人产生熟悉感，毕竟小说源于现实，而人性又总是相通的。</strong></p>
<h3 id="时代背景与个人命运"><a href="#时代背景与个人命运" class="headerlink" title="时代背景与个人命运"></a>时代背景与个人命运</h3><p>正如书的腰封中所说: </p>
<blockquote>
<p>这是一个蛮荒的时代，结束的尚未结束，开始的尚未开始。 </p>
</blockquote>
<p>在这样一个时代大背景下，个人命运被时代的洪流裹挟着前进，在那样一个乱的年代，各式各样的人性会随时代的奏乐喷涌而出，衍生出一个又一个的传奇故事，我想这也是余华老师选择清末民初作为小说背景的原因之一。<br>在这样的时代背景下讨论个人命运，我相信也是需要跳出我们的“现代人视角”来进行审视，林祥福、小美的命运显然是不够圆满的，他们的命运凸显着“裹挟”二字，他们被时代“裹挟”着相遇、分离、各自走向人生终点。但若回顾他们的一生，他们又都是幸运的，他们都短暂品尝到了人生中难得的温情，并不单调的度过了人生。 </p>
<blockquote>
<p><strong>最后我想引用林培源对这本书的书评中的一句话:</strong><br><strong>“任何故事经过转述，都面临被稀释的风险，《文城》感人至深、催人泪下的部分只有在阅读时才能被激活和唤醒。”</strong><br><strong>这或许也正是文字的魅力吧，完成了无法言传的情感的传递。</strong></p>
</blockquote>
]]></content>
      <categories>
        <category>灵魂雕琢</category>
      </categories>
      <tags>
        <tag>余华，清末民初</tag>
      </tags>
  </entry>
  <entry>
    <title>星轨拍摄与延时视频</title>
    <url>/2021/02/19/xing-kong-she-ying-yu-yan-shi-shi-pin/</url>
    <content><![CDATA[<p>在上学期马上要结束时，我动了换相机的邪念，这邪念最终导致我的钱包缩水，我的相机也由尼康家的D3500换成了佳能家Eosrp。鉴于我以前假期在家都是高强度娱乐，带回去的书往往就呆在行李箱睡大觉，这次我便将新购的相机和三脚架一并带回了家，<strong>万一自己在家想出去拍拍照呢？</strong></p>
<p>因为疫情原因，我也就在家周围拍了拍，就藉这篇文章简单地分享下自己拍的一些照片，然后介绍下星轨照片和延时视频制作的流程吧。 <span id="more"></span></p>
<h4 id="影像记录"><a href="#影像记录" class="headerlink" title="影像记录"></a>影像记录</h4><p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/落日-清音大桥.JPG" alt="落日-清音大桥"><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/夕阳-河流4.JPG" alt="落日-河流"><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/湖中村落.JPG" alt="湖中村落"><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/星空-堆栈-20MB.jpg" alt="星轨"></p>
<h4 id="延时视频"><a href="#延时视频" class="headerlink" title="延时视频"></a>延时视频</h4><ul>
<li><p>公园延时摄影</p>
<div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">
  <iframe src="//player.bilibili.com/player.html?aid=501747233&bvid=BV1BN411X7oM&cid=298163667&page=1&&high_quality=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="100%" height="520"> </iframe>
</div>
</li>
<li><p>星空延时摄影<br><div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">
  <iframe src="//player.bilibili.com/player.html?aid=586696451&bvid=BV1uz4y127zS&cid=298721215&page=1&&high_quality=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="100%" height="520"> </iframe>
</div></p>
<h5 id="简要介绍"><a href="#简要介绍" class="headerlink" title="简要介绍"></a>简要介绍</h5><p>哪怕大家对延时摄影这个概念非常模糊，但肯定见过与上面两个视频类似的视频，延时摄影当可以将斗转星移、日升日落、云彩飘动压缩到短短的十几秒视频中，所带来的视觉体验还是神奇的， 首先给出延时摄影的定义: </p>
<blockquote>
<p><strong>延时摄影:</strong> 延时摄影，又叫缩时摄影、缩时录影，是以一种将时间压缩的拍摄技术。其拍摄的通常是一组照片，后期通过将照片串联合成视频，把几分钟、几小时甚至是几天的过程压缩在一个较短的时间内以视频的方式播放。</p>
</blockquote>
</li>
</ul>
<h5 id="计算公式"><a href="#计算公式" class="headerlink" title="计算公式"></a>计算公式</h5><p>延时摄影可以为我们带来平日所接触不到的视觉体验，其原理也是非常简单的，只需要明确以下几点: </p>
<blockquote>
<ul>
<li><strong>视频:</strong> 视频其实就是一系列图片堆栈而成，若想让视频看起来流畅，则一秒钟至少需要有24帧图像。</li>
<li><strong>客观世界时长:</strong> 假设我们以高速快门间隔$t_p$s进行拍摄，最终拍摄时长为$ts$，则$t$就是客观世界所经历的时间，而所拍摄的照片张数为$a = \frac{t}{t_p}$。</li>
<li><strong>视频时长:</strong> 若视频帧数为24fps，那么若用相机拍摄的$a$张照片来制作延时视频，那么视频时长就是$t_v = \frac{a}{24}s$。 </li>
</ul>
</blockquote>
<p>由此，基于照片张数这样一个桥梁，我们就建立了如下一个等式: </p>
<script type="math/tex; mode=display">
    \frac{t}{t_p} = 24 \times t_v</script><p>比如我们想以固定间隔时间$t_p = 10s$， 想拍一个10$s$的视频，那么实际在进行间隔拍摄时就需要拍摄$t = 24<em>t_v</em>t_p = 2400s = 40 min$。这样就实现了将$40min$客观世界的变化压缩到了$10s$的视频内。但如果是慢门拍摄则在间隔时间里需要将曝光时间也算进去。 </p>
<h5 id="拍摄方法"><a href="#拍摄方法" class="headerlink" title="拍摄方法"></a>拍摄方法</h5><p>拍摄方法一般有三种: </p>
<ul>
<li>对于没有机内延时的相机，则需要借助快门线来实现间隔拍摄的功能。</li>
<li>间隔拍摄: 直接根据自己的需求来计算间隔时间和拍摄时间，然后将图片导出后导入PR来输出延时视频(教程很多)。 </li>
<li>延时视频: 现在很多相机都内置延时短片功能，设置拍摄间隔和拍摄张数，便可直出延时视频，省去了将图片堆栈成延时视频这一步。 </li>
</ul>
<h4 id="星轨拍摄"><a href="#星轨拍摄" class="headerlink" title="星轨拍摄"></a>星轨拍摄</h4><h5 id="简要介绍-1"><a href="#简要介绍-1" class="headerlink" title="简要介绍"></a>简要介绍</h5><blockquote>
<p><strong>星轨:</strong> 星轨其实是我们地球自身自转的反射，在拍摄过程中，我们的相机机位在地球上相对位置并未发生变化，但由于有地球自转存在，我们会观测到星星不断移动，形成一个圆形，而圆心就是我们自转的主轴所指向的无穷远处。 </p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E6%98%9F%E8%BD%A8.png" alt="星轨-from-500px"></p>
<h5 id="星轨拍摄-1"><a href="#星轨拍摄-1" class="headerlink" title="星轨拍摄"></a>星轨拍摄</h5><p>星轨拍摄需要慢门，但在实现上有两种思路: </p>
<blockquote>
<ul>
<li>直接采用B门定时拍摄，设置$10min$以上的曝光时间，然后拧动对焦环到无穷远处，最后调整曝光参数以保证最终图片恰当曝光，曝光参数可能需要多次尝试后确定，当拍摄环境并不够黑暗时，这种思路很难实现，因为长曝光会导致成片一片死白。 </li>
</ul>
</blockquote>
<p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/星轨3.JPG" alt="星轨-10min长曝光"></p>
<blockquote>
<ul>
<li>间隔拍摄，然后后期堆栈，比如我想拍30min时长所形成的星轨，那么我可以连续拍摄多个星空照片，然后后期进入PS，使用最大值堆栈进行星轨合成。 </li>
</ul>
</blockquote>
<p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/星空-堆栈-20MB.jpg" alt="星轨-后期堆栈"></p>
<blockquote>
<p><strong>tips:</strong> 记得关闭相机的长曝光降噪。 </p>
</blockquote>
<p>我比较推荐第二种方法，因为参数更容易设置，同时后期空间更大，试错成本更低。 </p>
]]></content>
      <categories>
        <category>点滴生活</category>
      </categories>
      <tags>
        <tag>星轨拍摄，延时视频</tag>
      </tags>
  </entry>
  <entry>
    <title>有感</title>
    <url>/2020/02/22/you-gan/</url>
    <content><![CDATA[<p>&emsp;    或许逃避是人的天性，整个博一上学期，似乎整天忙忙碌碌，在若干门课程中来回斡旋，<span id="more"></span>但当闲下来细细一想，似乎也有很多时间自己并没有好好利用，用那些时间在逃避、在咸鱼、在发呆。整个博一上学期自己也读了一些书，比如《历史的教训》、《贫穷的本质》、《禅与摩托车维修技术》、《变革中国》，相比于完整读下来的书，挖的坑自然是更多，《纯粹理性批判》、《世界文明史》、《资本论》……如果你要问我为什么选择这些书，我只能回答机缘巧合吧，这些书或是来源于上课时某位同学的推荐，或是来自于自己查询某些资料时的推荐，不一而足。其实我认为读这些书一方面是一种对自己空余时间的填充，对纯粹理工科学习的一种暂时逃避，也是一个不断寻找答案的过程，寻找一些理工科的书籍里缺乏的一些答案。其实我一直在思考一个问题，一个人的强大究竟是来源于其内心的强大，还是来源于其所凭外物，当你一无所有（指外物）之时，你还能剩下什么？是没有灵魂的一具空壳，还是一个拥有强大生命的种子。<br>&emsp;    读史教会我的第一点是作为历史当中普通人的世事无常，我们所接触的历史往往是王侯将相的历史，是英雄名士的历史，若人类发展的角度来看历史，一个人的历史观总会趋于无情，这种无情我们可以理解为作为现代人的傲慢/优越，如今我们去各地旅游，惊叹于种种历史古迹，惊叹于古人的智慧，但是孰又会在意这些历史古迹下面是当时多少奴隶的血泪。这些遗迹显示了当时高超的建造技术，为后人留下了宝贵遗产，我们或可以说这是历史的进步，然而那些建造他们的奴隶们则消逝于历史的阴影之中。若我们接受这样的历史进步性说法，由此会自然引出下一个结论——历史的发展是必然伴随着牺牲的，作为现代人，我们可以一方面斥责当时的暴政，另一方面又可以欣赏到这些暴政所留下的历史遗迹，每每想到这些，总觉如鲠在喉。或许从这些历史中我们可以得出这样的经验，某些我们认为错误的做法确实促进了当时历史的发展，但是历史发展途径许多，我们应当选择让人民整体更加幸福的发展道路，唉，不过聊以自慰耳。<br>&emsp;行路者需要背负东西，然而不能背负太多。我第一个放入背包的叫做责任，从诞生开始，我就开始与这个世界产生联系，父母、家庭、国家、人类，这些名词限定了我是我，梁启超在《最苦与最乐》中写道：“人生最苦，莫过于身上背负着一种未了的责任；人生最乐，莫过于尽责之时。“责任二字，说来轻巧，实则沉甸甸，也因责任二字，人生少了些凄清，多了些烟火；我第二个放入背包的叫做知识，在我看来，当曾经模糊看不清楚的东西在你眼前变得清晰之时，也是精神愉悦满足之时，文学史哲让你反求诸己，塑造清明的内心世界，理血工学让你更好地认识客观世界，改造客观世界，两种知识于我而言同样重要。吾之一生，有此两者，足矣。</p>
]]></content>
      <categories>
        <category>闲谈</category>
      </categories>
      <tags>
        <tag>无感而发</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习理论</title>
    <url>/2020/07/06/ji-qi-xue-xi-li-lun/</url>
    <content><![CDATA[<p>笔者近期想做一下<strong>机器学习</strong>相关理论总结<span id="more"></span>，计划划分为以下章节：</p>
<blockquote>
<ul>
<li>贝叶斯理论 </li>
<li>概率密度函数估计</li>
<li>EM算法</li>
<li>线性判别——感知器</li>
<li>支持向量机</li>
<li>近邻法 </li>
<li>特征提取与特征选择</li>
<li>神经网络</li>
<li>RNN</li>
<li>非监督学习</li>
<li>决策树</li>
<li>聚类</li>
</ul>
</blockquote>
<p>各章节主要包含两部分： </p>
<blockquote>
<ul>
<li>理论介绍</li>
<li>代码实战</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>条件随机场</title>
    <url>/2020/08/21/tiao-jian-sui-ji-chang/</url>
    <content><![CDATA[<p>另一种常用模型为条件随机场(CRF)模型,条件随机场是给定一组输入随机变量条件下另一组输出随机变量的条件概率分布模型，其特点是假设输出随机变量构成马尔可夫随机场。本章节按照以下几部分组织：</p>
<ul>
<li>概率无向图模型</li>
<li>条件随机场定义与形式</li>
<li>条件随机场概率计算</li>
<li>条件随机场学习算法</li>
<li>条件随机场预测算法<span id="more"></span>
</li>
</ul>
<h3 id="概率无向图模型"><a href="#概率无向图模型" class="headerlink" title="概率无向图模型"></a>概率无向图模型</h3><h4 id="概率无向图模型定义"><a href="#概率无向图模型定义" class="headerlink" title="概率无向图模型定义"></a>概率无向图模型定义</h4><p>图是由节点和及连接的边组成的集合，表示为$G = (V,E)$，若连接的边无方向，则称为无向图，反之则称为有向图。<br>概率图模型是由图表示的概率分布，图中的节点表示随机变量，节点之间的边表示变量之间的概率依赖关系。<br>给定一个联合概率分布$P(Y)$和表示它的无向图$G$,首先定义无向图表示的随机变量之间存在的成对马尔可夫性、局部马尔可夫性和全局马尔可夫性。</p>
<blockquote>
<ul>
<li>成对马尔可夫性：设$\mu$和$v$是无向图$G$中任意两个没有边连接的节点，两个节点分别对应随机变量$Y<em>{\mu},Y_v$。其他所有节点的集合记做$O$,对应随机变量组是$Y_O$。成对马尔可夫性是指给定随机变量组$Y_O$的条件下，随机变量$Y</em>{\mu}$和$Y_v$是条件独立的,即：<script type="math/tex; mode=display">
  P(Y_{\mu},Y_v|Y_O) = P(Y_{\mu}|Y_O)P(Y_{v}|Y_O)</script></li>
<li>局部马尔可夫性：设$v \in V$是无向图$G$中任意一个节点，$W$是与$v$有边连接的所有节点，$O$是$v$和$W$以外的其他所有节点。$v,W,O$对应的随机变量(组)记做$Y_v,Y_W,Y_O$,局部马尔可夫性是指在给定随机变量组$Y_W$条件下，随机变量$Y_v$与随机变量组$Y_O$是相互独立的:<script type="math/tex; mode=display">
  P(Y_{O},Y_v|Y_W) = P(Y_{v}|Y_W)P(Y_{O}|Y_W)</script>在$P(Y_O|Y_W)&gt;0$情况下，有：<script type="math/tex; mode=display">
  P(Y_v|Y_W) = P(Y_v|Y_W,Y_O)</script></li>
<li>全局马尔可夫性：设结点集合$A,B$是在无向图$G$中被节点集合$C$分开的任意节点集合，它们所对应的变量组记做$Y_A,Y_B,Y_C$。全局马尔可夫性是指给定随机变量组$Y_C$条件下随机变量组$Y_A，Y_B$是条件独立的，即：<script type="math/tex; mode=display">
  P(Y_A,Y_B|Y_C) = P(Y_A|Y_C)P(Y_B|Y_C)</script></li>
</ul>
</blockquote>
<p>下面定义概率无向图模型:</p>
<blockquote>
<p><strong>概率无向图模型:</strong> 设有联合概率分布$P(Y)$，由无向图$G = (V,E)$表示，在图$G$中，节点表示随机变量，边表示随机变量之间的概率依赖关系。若联合概率分布$P(Y)$满足<strong>成对、局部或全局马尔可夫性</strong>,就称此概率分布为概率无向图模型，或马尔可夫随机场。</p>
</blockquote>
<h4 id="概率无向图模型的因子分解"><a href="#概率无向图模型的因子分解" class="headerlink" title="概率无向图模型的因子分解"></a>概率无向图模型的因子分解</h4><p>能够使用图模型来对联合概率分布进行编码，主要出发点便是变量之间的马尔可夫性假设，这让我们可以以更加紧凑的形式来表示联合概率分布。<br>首先给出无向图中团与最大团的定义:</p>
<blockquote>
<p><strong>团与最大团</strong>:无向图中任何两个节点均有边连接的子集称为团(clique)。若$C$是无向图$G$的一个团，并且不能够再加入任何一个$G$的节点使其成为一个更大的团，则称此$C$为最大团。</p>
</blockquote>
<p>将概率无向图模型的联合概率分布表示为其最大团上的随机变量的函数的乘积的操作，称为概率无向图模型的因子分解。<br>给定概率图模型，设其无向图为$G$，$C$为$G$上的最大团，$Y_C$表示$C$对应的随机变量，那么联合概率分布$P(Y)$可以表示成图中所有最大团$C$上函数$\varPhi_C(Y_C)$的<strong>连乘形式</strong>:</p>
<script type="math/tex; mode=display">
    P(Y) = \frac{1}{Z} \prod_{C} \varPhi_C(Y_C)</script><p>公式中$Z$是一个归一化因子$Z = \sum<em>Y \prod</em>{C} \varPhi_C(Y_C)$。函数$\varPhi_C(Y_C)$称为势函数。势函数通常定义为指数函数:</p>
<script type="math/tex; mode=display">
    \varPhi_C(Y_C) = exp\{ -E(Y_C)\}</script><p>概率无向图的因子分解由Hammersley-Clifford定理保证:</p>
<blockquote>
<p>Hammersley-Clifford定理: 概率无向图模型的联合概率分布$P(Y)$可以表示为如下形式:</p>
<script type="math/tex; mode=display">
    P(Y) = \frac{1}{Z} \prod_C \varPhi_C(Y_C)</script><p>其中，$C$是无向图的最大团，$Y_C$是$C$的节点对应的随机变量，$\varPhi_C(Y_C)$是$C$上定义的严格正函数，乘积是在无向图所有的最大团上进行的，关于该定理的证明参考链接<a href="https://www.jianshu.com/p/dd27249b8c4a">Hammersley-Clifford定理证明</a></p>
</blockquote>
<h3 id="条件随机场的定义与形式"><a href="#条件随机场的定义与形式" class="headerlink" title="条件随机场的定义与形式"></a>条件随机场的定义与形式</h3><h4 id="条件随机场的定义"><a href="#条件随机场的定义" class="headerlink" title="条件随机场的定义"></a>条件随机场的定义</h4><p>条件随机场是给定随机变量$X$条件下，随机变量$Y$的马尔可夫随机场。本文主要介绍线性链条件随机场，该模型可用于标注等问题。这时，在条件概率模型$P(Y|X)$中，$Y$是输出变量，表示标记序列(状态序列)，$X$是输入变量，表示需要标注的观测序列。学习时，利用训练数据集通过极大似然估计或正则化的极大似然估计得到条件概率模型$\hat{P}(Y|X)$;预测时，对于给定的输入序列$x$,求出条件概率$\hat{P}(y|x)$最大的输出序列$\hat{y}$。<br>首先给出一般的条件随机场的定义:</p>
<blockquote>
<p><strong>条件随机场</strong>：设$X$和$Y$是随机变量，$P(Y|X)$是在给定$X$条件下$Y$的条件概率分布。若随机变量$Y$构成一个由无向图$G = (V,E)$表示的马尔可夫随机场，即：</p>
<script type="math/tex; mode=display">
    P(Y_v|X,Y_w,w \neq v) = P(Y_v|X,Y_w,w\sim v)</script><p>对任意节点$v$成立，则称条件概率分布$P(Y|X)$为条件随机场。公式中$w \sim v$表示在图$G = (V,E)$中与节点$v$有边连接的所有节点$w$,$w \neq v$表示节点$v$以外的所有节点，$Y<em>v,Y_w,Y</em>{\mu}$为节点$v,\mu,w$所对应的随机变量。</p>
</blockquote>
<p>虽然在定义中并没有要求$X$和$Y$具有相同的结构，但在现实中，一般假设$X$和$Y$具有相同的结构，而对于线性链，则是图$G = (V,E)$可以表示成：</p>
<script type="math/tex; mode=display">
    G = (V = \{ 1,2,\dots,n\}, E = \{(i,i+1)\}),\quad i = 1,2,\dots,n-1</script><p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/SRF.png" alt="线性链条件随机场"><br>下面给出线性链条件随机场的定义：</p>
<blockquote>
<p><strong>线性链条件随机场</strong>：设$X = (X_1,X_2,\dots,X_n),Y= (Y_1,Y_2,\dots,Y_n)$均为线性链表示的随机变量序列，若在给定随机变量序列$X$的条件下，随机变量序列$Y$的条件概率分布$P(Y|X)$构成条件随机场，即满足马尔可夫性：</p>
<script type="math/tex; mode=display">
    P(Y_i|X,Y_1,\dots,Y_{i-1},Y_{i+1},\dots,Y_n) = P(Y_i|X,Y_{i-1},Y_{i+1}),i =1,\dots,n</script><p>则称$P(Y|X)$为线性链条件随机场。在标注问题中，$X$表示输入观测序列，$Y$表示对应的输出标记序列或状态序列。</p>
<h4 id="条件随机场的参数化形式"><a href="#条件随机场的参数化形式" class="headerlink" title="条件随机场的参数化形式"></a>条件随机场的参数化形式</h4><p>下面给出条件随机场的参数化形式：<br><strong>线性链条件随机场参数化形式</strong>：设$P(Y|X)$为线性链条件随机场，则在随机变量$X$取值为$x$条件下，随机变量$Y$取值为$y$的条件概率具有如下形式:</p>
<script type="math/tex; mode=display">
    P(y|x) = \frac{1}{Z(x)} exp(\sum_{i,k} \lambda_k t_k(y_{i-1},y_i,x,i) + \sum_{i,l} \mu_l s_l(y_i,x,i) )</script><p>其中$Z(x)$为归一化因子，保证$P(y|x)$满足概率形式，$t_k$和$s_l$是特征函数，$\lambda_k$和$\mu_l$是对应的权值。</p>
</blockquote>
<p>定义中公式表示给定输入序列$x$，对输出序列$y$预测的条件概率。$t_k$是定义在边上的特征函数，称为转移特征，依赖于当前和前一个位置；$s_l$是定义在节点上的特征函数，称为状态特征，依赖于当前位置。$t_k$和$s_l$都依赖于位置，是局部特征函数。通常，特征函数$t_k$和$s_l$取值为0或1，当满足特征条件时取值为1，否则为0。条件随机场完全由特征函数$t_k,s_l$和对应的权值$\lambda_k,\mu_l$确定。<br>为便于理解，下面给出一个线性链条件随机场的栗子：</p>
<blockquote>
<p><strong>🌰：</strong> 设有一标注问题：输入观测序列为$X = (X_1,X_2,X_3)$,输出标记序列为$Y = (Y_1,Y_2,Y_3)$,输出标记取之于$\mathcal{Y} = { 1,2 }$<br>假设特征$t_k,s_l$和对应的权值$\lambda_k,\mu_l$如下：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        t_1 &=  t_1(y_{i-1} = 1,y_i = 2,x,i) \quad i =2,3, \lambda_1 = 1 \\
        t_2 &= t_2(y_1 = 1,y_2 = 1,x,2),\quad \lambda_2 = 0.6 \\
        t_3 &= t_3(y_2 = 2,y_3 =1,x,3), \quad \lambda_3 = 1 \\
        t_4 &= t_4(y_1 = 2,y_2 = 1,x,2), \quad \lambda_4 = 1 \\
        t_5 &= t_5(y_2 = 2,y_3 =2,x,3),\quad \lambda_5 = 0.2 \\
        s_1 &= s_1(y_1 = 1,x,1), \qquad \qquad \mu_1 = 1 \\
        s_2 &= s_2(y_i =2,x,i),i =1,2 \quad \mu_2 = 0.5 \\
        s_3 &= s_3(y_i =1,x,i),i =1,2 \quad \mu_2 = 0.8 \\
        s_4 &= s_4(y_3 =2,x,3),i =1,2 \quad \mu_2 = 0.5  
    \end{aligned}</script><p>对于给定的观测序列，求标记序列为$y = (y_1,y_2,y_3) = (1,2,2)$的非规范条件概率(不进行归一化)<br><strong>解</strong>：由线性链条件随机场的参数化形式可得:</p>
<script type="math/tex; mode=display">
    P(y_1 = 1,y_2 = 2,y_3 =2|x) \propto exp(3.2)</script></blockquote>
<h4 id="条件随机场的简化形式"><a href="#条件随机场的简化形式" class="headerlink" title="条件随机场的简化形式"></a>条件随机场的简化形式</h4><p>注意到条件随机场的参数化形式中同一特征在各个位置都有定义，因此可以考虑对同一个特征在各个位置求和，将局部特征函数转化成一个全局特征函数，这样就可以将条件随机场写成权值向量和特征向量的内积形式，即条件随机场的简化形式。<br>假设有$K_1$个转移特征，$K_2$个状态特征，$K = K_1 + K_2$,记：</p>
<script type="math/tex; mode=display">
    f_k(y_{i-1},y_i,x,i) = \begin{cases}
        t_k(y_{i-1},y_i,x,i), & k =1,2,\dots,K_1 \\
        s_l(y_i,x,i), & k = K_1 + l; l = 1,2,\dots,K_2
    \end{cases}</script><p>然后对转移与状态特征在各个位置$i$求和，记做：</p>
<script type="math/tex; mode=display">
    f_k(y,x) = \sum_{i=1}^n f_k(y_{i-1},y_i, x,i),\quad k = 1,2,\dots,K</script><p>用$w_k$表示特征$f_k(y,x)$的权值，即：</p>
<script type="math/tex; mode=display">
    w_k = \begin{cases}
        \lambda_k, & k =1,2,\dots, K_1 \\
        \mu_l , & k = K_1 + l; l= 1,2,\dots,K_2
    \end{cases}</script><p>于是条件随机场参数化可以写成更加紧凑的形式：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
         P(y|x) &= \frac{1}{Z(x)} exp \sum_{k=1}^K w_k f_k(y,x)  \\
         Z(x) &= \sum_y exp \sum_{k=1}^K w_k f_k(y,x)
    \end{aligned}</script><p>若以$\boldsymbol{w}$表示权值向量，即：</p>
<script type="math/tex; mode=display">
    \boldsymbol{w} = (w_1,w_2,\dots,w_K)^T</script><p>以$\boldsymbol{F(y,x)}$表示全局特征向量:</p>
<script type="math/tex; mode=display">
    \boldsymbol{F(y,x)} = (f_1(y,x),f_2(y,x),\dots, f_K(y,x))^T</script><p>则条件随机场可以以两个向量内积的形式来表示:</p>
<script type="math/tex; mode=display">
    P_w(y|x) = \frac{exp(\boldsymbol{w \cdot F(y,x)})}{Z_w(x)}</script><h4 id="条件随机场的矩阵形式"><a href="#条件随机场的矩阵形式" class="headerlink" title="条件随机场的矩阵形式"></a>条件随机场的矩阵形式</h4><p>假设$P<em>w(y|x)$是线性链条件随机场，表示对给定观测序列，相应的标记序列$y$的条件概率。对每个标记序列引入特殊的起点和终点状态标记$y_0 = start$和$y</em>{n+1} = stop$,这时标注序列的概率可以通过矩阵形式表示并有效计算。<br>对观测序列$x$的每一个位置$i =1,2,\dots,n+1$,由于$y_{i-1}$和$y_i$在$m$个标记中取值，因此可以定义一个$m$阶矩阵随机变量：</p>
<script type="math/tex; mode=display">
    M_i(x) = [M_i(y_{i-1},y_i|x)]</script><p>矩阵随机变量元素为:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        M_i(y_{i-1},y_i|x) &= exp(W_i(y_{i-1},y_i|x)) \\
        W_i(y_{i-1},y_i|x) &= \sum_{k=1}^K w_k f_k(y_{i-1},y_i,x,i)
    \end{aligned}</script><p>这样，给定观测序列$x$,相应的标记序列$y$的非规范概率可以通过该序列$n+1$个矩阵的适当元素的乘积<br>$\prod<em>{i=1}^{n+1} M_i(y</em>{i-1},y_i|x)$,于是，条件概率$P_w(y|x)$可以表示为：</p>
<script type="math/tex; mode=display">
    P_w(y|x) = \frac{1}{Z_w(x)} \prod_{i=1}^{n+1} M_i(y_{i-1},y_i|x)</script><p>其中$Z<em>w(x) = \sum_y \prod</em>{i=1}^{n+1} M<em>i(y</em>{i-1},y_i|x)$,可以证明，该归一化因子也可以表示成$n+1$个矩阵连乘积的矩阵的元素。<br>下面的部分依次介绍条件随机场的三个经典问题：</p>
<ul>
<li>概率计算问题，即给点条件随机场$P(Y|X)$,输入序列$x$和输出序列$y$,计算相应条件概率的问题</li>
<li>学习问题，即在给定训练数据集情况下估计条件随机场模型参数的问题</li>
<li>预测问题，即在给定条件随机场$P(Y|X)$和输入序列$x$,求条件概率最大的输出序列$y^*$,即对观测序列进行标注。</li>
</ul>
<p>概率计算问题比较简单，也是后两个问题的基础，而在实际进行应用中，我们首先需要明确线性链条件随机场是否适用于待解决的问题，然后利用已有的训练数据来进行模型学习，最终再用学习得到的模型进行预测(标注)。</p>
<h3 id="条件随机场概率计算问题"><a href="#条件随机场概率计算问题" class="headerlink" title="条件随机场概率计算问题"></a>条件随机场概率计算问题</h3><p>与隐马尔可夫模型的概率计算类似，对于这种有明显前后关联的概率模型， 往往都是采用递推方式来进行概率计算，通过引入前向-后向向量，递归地进行概率计算，该算法也被称为前向-后向算法。</p>
<h4 id="前向-后向算法"><a href="#前向-后向算法" class="headerlink" title="前向-后向算法"></a>前向-后向算法</h4><p>对每个指标$ i =0,1,\dots,n+1$,定义前向向量$\alpha_i(x)$:</p>
<script type="math/tex; mode=display">
    \alpha_0(y|x) = \begin{cases}
        1, &y = start \\
        0, & other  
    \end{cases}</script><p>递推公式为:</p>
<script type="math/tex; mode=display">
    \alpha_i^T(y_i|x) = \alpha_{i-1}^T(y_{i-1}|x)[M_i(y_{i-1},y_i|x)],\quad i = 1,2,\dots,n+1</script><p>也可表示为：</p>
<script type="math/tex; mode=display">
    \alpha_i^T(x) = \alpha_{i-1}^T(x) M_i(x)</script><p>$\alpha<em>i(y_i|x)$表示在位置$i$的标记是$y_i$，并且从1到$i$的前部分标记序列的非规范化概率，$y_i$可以取的值有$m$个，在上述公式中，$\alpha</em>{i-1}(x)$是一个$m$维列向量，而$M<em>i(x)$是一个$m$阶矩阵，实际上$y_i$的任意取值均可能由$y</em>{n-1}$的$m$种状态转移过来，因此上述的计算实际上是对各种转移可能性的求和。<br>同样，对每个指标$i = 0,1,\dots,n+1$,定义后向向量$\beta_i(x)$:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \beta_{n+1}(y_{n+1|x}) &= \begin{cases}
            1, & y_{n+1} = stop \\
            0, & other 
        \end{cases} \\
        \beta_i(y_i|x) &= [M_{i+1}(y_i,y_{i+1}|x)] \beta_{i+1}(y_{i+1}|x)
    \end{aligned}</script><p>又可表示为：</p>
<script type="math/tex; mode=display">
    \beta_i(x) = M_{i+1}(x) \beta_{i+1}(x)</script><p>$\beta_i(y_i|x)$表示在位置$i$的标记为$y_i$并且从$i+1$到$n$后半部分标记序列的非规范化序列。</p>
<h4 id="概率计算"><a href="#概率计算" class="headerlink" title="概率计算"></a>概率计算</h4><p>按照前向后向概率的定义，很容易计算标记序列在位置$i$是标记$y<em>i$的条件概率和在位置$i-1$和$i$是标记$y</em>{i-1}$和$y_i$的条件概率：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        P(Y_i = y_i|x) &= \frac{\alpha_i^T(y_i|x) \beta_i(y_i|x)}{Z(x)} \\
        P(Y_{i-1} = y_{i-1},Y_i = y_i|x) &= \frac{\alpha_{i-1}^T(y_{i-1}|x)M_i(y_{i-1},y_i|x) \beta_i(y_i|x)}{Z(x)}
    \end{aligned}</script><p>其中，</p>
<script type="math/tex; mode=display">
    Z(x) = \alpha_n^T(x) \boldsymbol{1} = \boldsymbol{1} \beta_1(x)</script><p>$\boldsymbol{1}$是元素全为1的$m$维列向量</p>
<h4 id="期望值计算"><a href="#期望值计算" class="headerlink" title="期望值计算"></a>期望值计算</h4><p>利用前向、后向向量，可以计算特征函数关于联合分布$P(X,Y)$和条件分布$P(Y|X)$的数学期望。<br>特征函数$f_k$关于条件分布$P(Y|X)$的数学期望是:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        E_{P(Y|X)}[f_k] &= \sum_y P(y|x) f_k(y,x)   \\
        &= \sum_{i=1}^{n+1} \sum_{y_{i-1},y_i} f_k(y_{i-1},y_i,x,i)  P(Y_{i-1} = y_{i-1},Y_i = y_i|x) \\
        &\qquad k = 1,2,\dots,K 
    \end{aligned}</script><p>能够这样进行展开，实际上还是从$f_k(y,x)$的定义出发：</p>
<script type="math/tex; mode=display">
    f_k(y,x) = \sum_{i=1}^{n+1} f_k(y_{i-1},y_i, x,i),\quad k = 1,2,\dots,K</script><p>展开之后便是上述形式，这中写法也显示了在概率图中，联合概率分布可以表示成一系列局部概率分布的乘积形式。<br>假设经验分布为$\tilde{P}(X)$,则特征函数关于联合分布$P(X,Y)$的数学期望可以表示为：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        E_{P(X,Y)}[f_k] &= \sum_{x,y}P(x,y) \sum_{i=1}^{n+1} f_k(y_{i-1},y_i,x,i)  \\
        &= \sum_{x} \tilde{P}(x) \sum_{i=1}^{n+1} \sum_{y_{i-1},y_i} f_k(y_{i-1},y_i,x,i)  P(Y_{i-1} = y_{i-1},Y_i = y_i|x) \\
        &\quad, i =1,2,\dots,K 
    \end{aligned}</script><p>有了前向、后向算法，对于给定的观测序列$x$与标记序列$y$，可以通过一次前向扫描计算$\alpha_i$及$Z(x)$,通过一次后向扫描计算$\beta_i$,从而计算所有的概率和特征的期望。</p>
<h3 id="条件随机场的学习算法"><a href="#条件随机场的学习算法" class="headerlink" title="条件随机场的学习算法"></a>条件随机场的学习算法</h3><p><strong>条件随机场模型实际上是定义在时序数据上的对数线性模型</strong>，其学习方法包括极大似然估计和正则化的极大似然估计，具体的优化实现算法有改进的迭代尺度法IIS、梯度下降法及拟牛顿法。</p>
<h4 id="改进的迭代尺度法"><a href="#改进的迭代尺度法" class="headerlink" title="改进的迭代尺度法"></a>改进的迭代尺度法</h4><p>已知训练数据集，由此可知经验概率分布$\tilde{P}(X,Y)$，可以通过极大化训练数据的对数似然函数来求模型参数。<br>训练数据的对数似然函数为:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        L(w) &= L_{\tilde{P}}(P_w)  = \log \prod_{x,y} P_w(y|x)^{\tilde{P}(x,y)} = \sum_{x,y} \tilde{P}(x,y) \log P_w(y|x) \\
        &= \sum_{x,y} [\tilde{P}(x,y) \sum_{k=1}^K w_k f_k(y|x) -\tilde{P}(x,y) \log Z_w(x)] \\
        &= \sum_{j=1}^N \sum_{k=1}^K w_k f_k(y_j,x_j) - \sum_{j=1}^N \log Z_w(x_j)
    \end{aligned}</script><p>这一部分先挖坑，等我补一下相关知识再来填坑……..</p>
<h3 id="条件随机场预测算法"><a href="#条件随机场预测算法" class="headerlink" title="条件随机场预测算法"></a>条件随机场预测算法</h3><p>条件随机场的预测问题是指给定条件随机场$P(Y|X)$和输入序列(观测序列)$x$,求条件概率最大的输出序列$y^*$,即对观测序列进行标注。与HMM模型中的预测问题类似，该问题可以通过维特比算法进行解决。<br>由条件随机场的简化形式:</p>
<script type="math/tex; mode=display">
    P_w(y|x) = \frac{exp(\boldsymbol{w \cdot F(y,x)})}{Z_w(x)}</script><p>可知：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        y^* &= \arg \max_{y} P_w(y|x) \\
            &= \arg \max_{y} \frac{exp(\boldsymbol{w \cdot F(y,x)})}{Z_w(x)} \\
            &= \arg \max_{y} exp(\boldsymbol{w \cdot F(y,x)}) \\ 
            &= \arg \max_{y}   \boldsymbol{w \cdot F(y,x)}
    \end{aligned}</script><p>于是，条件随机场的预测问题成为求非规范概率最大的最优路径问题：</p>
<script type="math/tex; mode=display">
    \max_y (\boldsymbol{w \cdot F(y,x)})</script><p>这里路径表示标记序列，其中:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \boldsymbol{w} &= (w_1,w_2,\dots,w_K)^T \\
        \boldsymbol{F(y,x)} &= (f_1(y,x),f_2(y,x),\dots,f_K(y,x))^T  \\
        f_k(y,x) &= \sum_{i=1}^n f_k(y_{i-1},y_i,x,i),\quad k = 1,2,\dots,K
    \end{aligned}</script><p>为了求解方便，考虑将优化问题写成如下形式：</p>
<script type="math/tex; mode=display">
    \max_y \sum_{i=1}^n \boldsymbol{w} \cdot F_i(y_{i-1},y_i,x)</script><p>其中:</p>
<script type="math/tex; mode=display">
    F_i(y_{i-1},y_i,x) = (f_1(y_{i-1},y_i,x,i),f_2(y_{i-1},y_i,x,i),\dots,f_K(y_{i-1},y_i,x,i))</script><p>是局部特征向量。下面给出维特比算法流程:</p>
<blockquote>
<p><strong>维特比算法</strong>：<br>输入:模型特征向量$\boldsymbol{F(y,x)}$,权值向量$\boldsymbol{w}$,观测序列$\boldsymbol{x} = (x_1,x_2,\dots,x_n)$<br>输出:最优路径$\boldsymbol{y^\ast = (y_1^\ast,y_2^\ast,\dots,y_n^\ast)}$</p>
<ol>
<li>初始化：<script type="math/tex; mode=display">
 \delta_1(j) = \boldsymbol{w} \cdot F_1(y_0 = start,y_1=j,x), \quad j = 1,2,\dots,m</script></li>
<li>递推：对$i = 2,3,\dots,n$<script type="math/tex; mode=display">
 \begin{aligned}
     \delta_i(l) &= \max_{1 \le j \le m}\{ \delta_{i-1}(j) + \boldsymbol{w} \cdot F_i(y_{i-1} = j,y_i = l,x)\},\quad l = 1,2,\dots,m  \\
     \varphi_i(l) &= \arg \max_{1 \leq j \leq m}\{ \delta_{i-1}(j) + \boldsymbol{w} \cdot F_i(y_{i-1} = j,y_i = l,x)\},\quad l = 1,2,\dots,m 
 \end{aligned}</script></li>
<li>终止:<script type="math/tex; mode=display">
 \begin{aligned}
     \max_y(\boldsymbol{w} \cdot \boldsymbol{F(x,y)}) &= \max_{1 \leq j \leq m} \delta_n(j) \\
     y_n^\ast &= \arg \max_{1 \leq j \leq m} \delta_n(j)
 \end{aligned}</script></li>
<li>回溯，得最优路径:<script type="math/tex; mode=display">
 y_i^\ast = \varphi_{i+1}(y_{i+1}^\ast),\quad i = n-1,n-2,\dots,1</script>求得最优路径$\boldsymbol{y^\ast} = (y_1^\ast,y_2^\ast,\dots,y_n^\ast)$</li>
</ol>
</blockquote>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>概率图，条件随机场</tag>
      </tags>
  </entry>
  <entry>
    <title>概率分布中的距离度量</title>
    <url>/2020/08/26/gai-lu-fen-bu-zhong-de-ju-chi-du-liang/</url>
    <content><![CDATA[<p>在$k$近邻章节中，我总结了在样本空间中常用的两种距离度量:$L_p$距离以及马氏距离。但在一些机器学习任务中，我们期望能够得到一个分布与目标分布尽可能接近，这也就引出了一个新的问题:</p>
<blockquote>
<p>如何度量两个概率分布之间的距离(差异程度)？</p>
</blockquote>
<p>本文将介绍一些常见的概率分布之间的距离度量，按照以下结构组织:</p>
<ul>
<li>信息量与熵</li>
<li>KL散度(相对熵)</li>
<li>交叉熵</li>
<li>JS散度</li>
<li>推土机理论与Wasserstein距离<span id="more"></span>
</li>
</ul>
<h3 id="信息量与熵"><a href="#信息量与熵" class="headerlink" title="信息量与熵"></a>信息量与熵</h3><h4 id="信息量"><a href="#信息量" class="headerlink" title="信息量"></a>信息量</h4><p>任何事件都会承载着一定的信息量，包括已经发生的事件和未发生的事件，只是它们承载的信息量有所不同：</p>
<blockquote>
<p>🌰：对于两个事件：昨天下雨与明天下雨。昨天下雨这个事件，因为已经发生，既定事实，那么它的信息量就为0；而对于明天会下雨这个事件，因为未有发生，那么该事件的信息量就大。</p>
</blockquote>
<p>从上面栗子可以看出信息量是一个与事件发生概率相关的概念，而且可以得出，事件发生的概率越小，其信息量越大。这也很好理解，因为所谓的“搞个大新闻”,也就是发生了不太可能发生的事情，”大新闻”则意味着该事件蕴含着更多的信息。从这个角度出发， 定义信息量:</p>
<blockquote>
<p><strong>信息量:</strong> 假设$X$是一个离散型随机变量，其取值集合为$\mathcal{X}$，其概率分布为:</p>
<script type="math/tex; mode=display">
    p(x) = P(X = x), x \in \mathcal{X}</script><p>则定义事件$X = x_0$的信息量为:</p>
<script type="math/tex; mode=display">
    I(x_0) = -\log(p(x_0))</script></blockquote>
<h4 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h4><p>首先给出熵的定义：</p>
<blockquote>
<p>在信息论与概率统计中，熵是表示<strong>随机变量不确定性</strong>的度量，设$X$是一个取有限个值的离散随机变量，其概率分布为:</p>
<script type="math/tex; mode=display">
    P(X = x_i) = p_i, \quad i =1,2,\dots,n</script><p>则随机变量$X$的熵定义为:</p>
<script type="math/tex; mode=display">
    H(X) = - \sum_{i=1}^n p_i \log p_i</script></blockquote>
<p>有了信息量的定义后，再看关于熵的定义式可以看出，熵不过是在概率分布$P$下对信息量求的期望，所以说熵实际上就是<strong>事件信息量的期望</strong>。<br>若$p_i = 0$,则定义$0\log 0 =0$,式中的对数一般取以2为底或者以$e$为底，这时熵的单位被称作比特或纳特，由定义可知，熵只依赖于$X$的分布，而与$X$的取值无关，因此也可将$X$的熵记作$H(p)$,熵越大，随机变量的不确定性越大。因为$p_i \leq 0$,由$H(p)$函数性质(凹函数，应用拉格朗日乘子法可求最大值)可知:</p>
<script type="math/tex; mode=display">
    0 \leq H(p) \leq \log n</script><h3 id="KL散度-相对熵"><a href="#KL散度-相对熵" class="headerlink" title="KL散度(相对熵)"></a>KL散度(相对熵)</h3><p>KL散度又称相对熵，如果我们对同一个随机变量有两个独立的概率分布$P(x)$和$Q(x)$，我们可以使用KL散度来衡量这两个分布的差异,下面给出KL散度的定义式:</p>
<blockquote>
<p>在机器学习中，$P$往往用来表示样本的真实分布，$Q$用来表示模型所预测的分布，那么$KL$散度就可以计算两个分布之间的差异，也就是Loss损失值:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
         D_{KL}(P||Q) &= -\sum_{i=1}^n p(x_i) \log(\frac{q(x_i)}{p(x_i)}) \\
            &= -\sum_{i=1}^n p(x_i) \log(q(x_i)) - (-\sum_{i=1}^n p(x_i) \log p(x_i))
    \end{aligned}</script><p>由于$-\log x$为凸函数，由凸函数性质可知:</p>
<script type="math/tex; mode=display">
     -\sum_{i=1}^n p(x_i) \log(\frac{q(x_i)}{p(x_i)}) \geq  \log \sum_{i=1}^n q(x_i) = 0</script><p>这说明KL散度具有非负的性质，这也说明$P(x)$与其他分布的交叉熵恒大于熵。</p>
</blockquote>
<p>这里需要说明的是，虽然KL散度具有非负性，但其并不满足度量的另外两个性质:</p>
<ul>
<li>对称性</li>
<li>三角不等式</li>
</ul>
<h3 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h3><p>KL散度由两部分组成，第一部分是交叉熵，第二部分则是$P(x)$的熵，$P(x)$因为是真实的分布，所以其熵为固定值。在机器学习任务中，我们需要评估样本固有label与我们算法的预测$predict$之间的差距，在优化过程中，我们只需关注交叉熵，所以在分类任务中，往往采用交叉熵作为loss函数。</p>
<h3 id="JS散度"><a href="#JS散度" class="headerlink" title="JS散度"></a>JS散度</h3><p>JS散度只是KL散度的变形，其解决了KL散度的非对称问题，其表达式如下:</p>
<script type="math/tex; mode=display">
    JS(P||Q) = \frac{1}{2} KL(P(x)||\frac{P(x) + Q(x)}{2}) + \frac{1}{2}KL(Q(x)||\frac{P(x)+ Q(x)}{2})</script><p>若$\log$以2为底，则JS散度的范围为$[0,1]$,若$\log$以$e$为底，则JS散度范围为$[0,\ln 2]$。当两个分布完全相同时取下界，当两个分布完全不同时取上界。<br>这也就带来了一个问题，若优化时两个分布完全没有交集时,JS散度就是一个常数($1$或$\ln 2$),此时会出现梯度消失问题，导致无法进行优化。</p>
<h3 id="Wasserstein距离"><a href="#Wasserstein距离" class="headerlink" title="Wasserstein距离"></a>Wasserstein距离</h3><p>首先说明下KL散度与JS散度存在的问题:</p>
<blockquote>
<p>若两个分布$P,Q$完全没有重叠，则会导致KL散度无意义($\log 0$),而JS散度是一个常数，也就是说出现了梯度消失问题。</p>
</blockquote>
<p>而Wasserstein距离可以一定程度上解决该问题。</p>
<h4 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h4><p>对于两个分布$P$和$Q$，考虑从将一个分布转换成另一个分布所需的代价入手来定义概率分布的差异。下面以一个栗子来说明该距离的思想:</p>
<blockquote>
<p>🌰: 考虑两个离散分布$P$和$Q$:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        P_1 &= 3, P_2 = 2, P_3 = 1, P_4 = 4 \\
        Q_1 &= 1, Q_2 = 2, Q_3 = 4, Q_4 = 3 
    \end{aligned}</script><p>下面讨论应该如何”移土”，才能够使得两个分布相同:</p>
<ul>
<li>为了让$P_1$与$Q_1$相同，我们需要把$P_1$的3分2到$P_2$去，这样$P_1$和$Q_1$都等于1，此时$P_2$等于4 </li>
<li>同理，为了让$P_2$和$Q_2$相同，需要将$P_2$的土填到$P_3$时，这一步将从$P_2$挖2分土填到$P_3$</li>
<li>为了让$P<em>3,Q_3$相等，最后一步需要将$Q_3$的1分土挖给$Q_4$<br>每一步的代价计算公式为$\delta</em>{i+1} = \delta_i + P_i - Q_i$,由此可得:<script type="math/tex; mode=display">
  \begin{aligned}
      \delta_0 &= 0 \\
      \delta_1 &= 0 +3 -1 = 2 \\
      \delta_2 &= 2 + 2 - 2 = 2 \\
      \delta_3 &= 2 + 1 -4 = -1 \\
      \delta_4 &= -1 + 4 - 3 = 0 
  \end{aligned}</script>所以最终的总代价，也就是Wasserstein距离为$W = \sum |\delta_i| = 5$。该栗子可以形象的用下图表示:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/W_dis.png" alt="推土机距离"></li>
</ul>
</blockquote>
<h4 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h4><p>从上面的离散栗子了解了Wasserstein距离的思想之后，下面给出一般连续分布Wasserstein距离计算公式:</p>
<blockquote>
<script type="math/tex; mode=display">
    W(p_r,p_g) = \inf_{\gamma \in \prod(p_r,p_g)} \quad E_{(x,y)\sim \gamma}[||x-y||]</script><p>公式中$\prod(p_r,p_g)$指代$p_r$和$p_g$所有可能的联合概率分布$\gamma(x,y)$,直观上来说，$\gamma(x,y)$表示将分布$p_r$转化成$p_g$所需要多少“土”，Wasserstein指代花费最少的运输方案。</p>
</blockquote>
<p>Wasserstein相对于传统的KL散度和JS散而言，当两个分布具有完全不同的支撑集合时，KL散度会是无穷，JS散度会是一个常值，而W距离此时仍能反映两个分布的远近。下面以一个栗子来说明Wasserstein距离的优势所在:</p>
<blockquote>
<p>🌰: 变量$Z \sim U[0,1]$,下面给出两个分布:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &P_0 (x_1), \quad x_1 = (0,Z) \in R^2  \\
        & P_1(x_2), \quad x_2 = (\theta,z) \in R^2
    \end{aligned}</script><p>对于这个简单的栗子，不同概率密度距离度量得到的数值如下:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        W(P_0,P_1) &= |\theta| \\ 
        JS(P_0,P_1) &= \begin{cases}
             \log 2  & if \theta \neq 0 \\
             0  & if \theta = 0  
        \end{cases} \\
        KL(P_0||P_1) &= \begin{cases}
             +\infty  & if \theta \neq 0 \\
             0  & if \theta = 0  
        \end{cases}
    \end{aligned}</script><p>在Wasserstein度量下，随着$\theta<em>t \rightarrow 0$,概率分布序列$(P</em>{\theta<em>t})</em>{t \in N}$ 收敛到$P_0$,但在其他度量下并不能收敛，W距离与JS散度在该问题中对比如下图所示:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/W.png" alt="$W VS JS$"></p>
</blockquote>
<h4 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h4><p>尽管Wasserstein度量具有很多优点，但其缺点也十分明显：</p>
<blockquote>
<p>计算非常复杂，优化问题不易解</p>
</blockquote>
<p>目前能够显示计算出Wasserstein的只有两种情况：</p>
<blockquote>
<p>一维概率分布<br>高斯分布 </p>
</blockquote>
<p>对于两个离散的一维概率分布，可以直接使用<code>scipy.stats.Wasserstein_distance</code>函数:</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">import numpy as np
from scipy.stats import wasserstein_distance
p = [0,5,9]
q = [2,5,7]
w = wasserstein_distance(q,p)
print(w)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出:</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">1.3333333333333335
<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>KL散度，JS散度，推土机距离</tag>
      </tags>
  </entry>
  <entry>
    <title>概率密度函数估计</title>
    <url>/2020/07/27/gai-lu-mi-du-han-shu-gu-ji/</url>
    <content><![CDATA[<p>在使用贝叶斯理论进行决策时，我们需要知道先验概率$P(\omega)$,类条件概率密度函数$p(x|\omega)$,而在这一部分，我们便讨论下如何从样本集中将这些所需的概率密度函数估计出来<span id="more"></span>，本文主要讨论以下几个问题：</p>
<ul>
<li>如何利用样本集估算$p(x|\omega)$和$P(\omega)$</li>
<li>估计量性质</li>
<li>利用样本集估算错误率</li>
</ul>
<p>从样本集推断总体概率分布的方法可以分为以下几种类型:</p>
<ul>
<li>监督参数估计——样本所属的类别以及总体概率密度函数的形式为已知，而概率密度函数的某些参数是未知的</li>
<li>非监督参数估计——已知总体概率密度函数形式，但未知样本所属种类，要求推断出概率密度函数某些参数</li>
<li>非参数估计——已知样本类别，但未知总体概率密度函数形式，要求我们直接推断概率密度函数本身</li>
</ul>
<h3 id="最大似然估计"><a href="#最大似然估计" class="headerlink" title="最大似然估计"></a>最大似然估计</h3><p>最大似然估计是进行参数估计的常用方法，它有两个假设：</p>
<ul>
<li>待估计的参数$\theta$是一个确定的、未知的量</li>
<li>概率分布函数的形式已知</li>
<li>样本为独立抽取</li>
</ul>
<p>若记$\theta$为待估计参数(比如正态分布中的$\mu,\sigma$),$\mathcal{X}$为样本集合：</p>
<script type="math/tex; mode=display">\mathcal{X} = \{ x_1,x_2, \dots, x_n\}</script><p>概率密度函数形式已知，记做$p(x|\theta)$，由于假设样本为独立抽取，则似然函数可以写做：</p>
<script type="math/tex; mode=display">l(\theta) = p(\mathcal{X}|\theta) = \prod_{i=1}^n p(x_i|\theta)</script><p>对数似然函数为：</p>
<script type="math/tex; mode=display">H(\theta) = ln(l(\theta)) = \sum_{i=1}^n lnp(x_i|\theta)</script><p>首先来看似然函数，它表征了在参数为$\theta$情况下，得到样本集合$\mathcal{X}$的概率，直观来看，这个概率越大，则证明估计得到的参数更好,至于为何使用对数似然函数，这是因为我们需要求$l(\theta)$的最大值，但连乘积求导非常复杂，而取对数运算是单调的，并不改变最值位置，同时计算上大大简化。因此最终最大似然估计值为:</p>
<script type="math/tex; mode=display">\frac{\partial H(\theta)}{\theta} = 0</script><p>实践中常见的概率分布为正态分布，其最大似然估计值为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
    \hat{\mu} &= \frac{1}{n} \sum_{i=1}^n x_i \\\\
    \hat{\sigma^2} &= \frac{1}{n} \sum_{i=1}^n (x_i - \hat{\mu})^2
\end{aligned}</script><h3 id="贝叶斯估计"><a href="#贝叶斯估计" class="headerlink" title="贝叶斯估计"></a>贝叶斯估计</h3><p>首先回顾下贝叶斯决策：</p>
<ul>
<li>状态空间:$\Omega = { \omega_1, \omega_2, \dots , \omega_c }$</li>
<li>待识别对象: $\mathbf{x} = [x_1,x_2,\dots, x_d]^T$</li>
</ul>
<p>设真实状态为$\omega_j$，而采取决策$a_i$所带来的损失为$\lambda(\omega_j,a_i)$,对于特定$\mathbf{x}$，采取决策$a_i$所带来的平均损失为:</p>
<script type="math/tex; mode=display">R(a_i|\mathbf{x}) = \sum_{j=1}^c \lambda(a_i,\omega_j) p(\omega_j|x)</script><p>整体损失则需要再对$\mathbf{x}$进行积分，在进行贝叶斯决策时，若想使得整体损失最小，则只需要对任意的$\mathbf{x}$，$R(a_i|\mathbf{x})$。<br>下面我们考虑参数估计问题:现在有一个样本集$\mathcal{X}$，要求我们找到最优估计量$\hat{\theta}$(对比决策$a_i$),使得带来的贝叶斯风险最小。由此可见，与贝叶斯决策相比，贝叶斯估计也是立足于使得贝叶斯风险最小，两者对比如下图所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>决策问题</th>
<th style="text-align:right">估计问题</th>
</tr>
</thead>
<tbody>
<tr>
<td>样本$\mathbf{x}$</td>
<td style="text-align:right">样本集$\mathcal{X}$</td>
</tr>
<tr>
<td>决策量$a_i$</td>
<td style="text-align:right">待估计值$\hat{\theta}$</td>
</tr>
<tr>
<td>真实状态$\omega_j$</td>
<td style="text-align:right">真实参数$\theta$</td>
</tr>
<tr>
<td>状态空间$\mathcal{A}$是离散空间</td>
<td style="text-align:right">参数空间$\Theta$是连续空间</td>
</tr>
<tr>
<td>先验概率$P(\omega_j)$</td>
<td style="text-align:right">参数的先验分布$p(\theta)$</td>
</tr>
</tbody>
</table>
</div>
<p>对于样本集$\mathcal{X}$，参数估计值为$\hat{\theta}$所带来的平均损失为：</p>
<script type="math/tex; mode=display">
    R(\hat{\theta}|\mathcal{X}) = \int_{\Theta} \lambda(\hat{\theta},\theta) p(\hat{\theta}|\mathcal{X}) d\theta</script><p>从上式中可以也可以看出贝叶斯决策与贝叶斯估计的区别:</p>
<blockquote>
<p>贝叶斯决策是立足于每一个样本$\mathbf{x}$，只需要保证对每一个样本均做出最优决策，便可保证整体决策最优；而贝叶斯估计则是立足于样本集$\mathcal{X}$</p>
</blockquote>
<p>现在我们要想获得贝叶斯估计，便转化为寻找合适的估计值$\hat{\theta}$,使得$R(\hat{\theta}｜\mathcal{X})$最小，这需要解决两个问题：</p>
<ul>
<li>$p(\hat{\theta}|\mathcal{X})$计算</li>
<li>损失函数$\lambda(\hat{\theta},\theta)$的选择 </li>
</ul>
<p>首先考虑$p(\hat{\theta}|\mathcal{X})$的计算，假设$\theta$的先验概率分布为$p(\theta)$,类条件概率密度函数为$p(\mathbf{x}|\theta)$,样本集$\mathcal{X} = { x_1,\dots, x_n }$,似然函数$p(\mathcal{X}|\theta)$可以表示为：</p>
<script type="math/tex; mode=display">
    p(\mathcal{X}|\theta) = \prod_{i=1}^n p(\mathbf{x_i}|\theta)</script><p>由贝叶斯公式，后验概率可以表示为:</p>
<script type="math/tex; mode=display">
    p(\hat{\theta}|\mathcal{X}) = \frac{p(\mathcal{X}|\hat{\theta})p(\hat{\theta})}{ \int p(\mathcal{X}|\theta)p(\theta) d\theta}</script><p>损失函数$\lambda(\hat{\theta},\theta)$常见的有三种选择:</p>
<ul>
<li>均方误差函数:$\lambda(\hat{\theta},\theta) = (\theta - \hat{\theta})^2$</li>
<li>绝对值误差函数: $\lambda(\hat{\theta},\theta) = |\theta - \hat{\theta}|$</li>
<li>均匀函数: $\lambda(\hat{\theta}, \theta) = \begin{cases}<br>  0 &amp; x \in [-\frac{\Delta}{2}, \frac{\Delta}{2}] \<br>  1 &amp; other<br>\end{cases}$</li>
</ul>
<p>在不同损失函数下，可以推导出不同的结果：</p>
<ul>
<li>均方误差函数:  <script type="math/tex; mode=display">\hat{\theta}_{MS} = \int_{-\infty}^\infty \theta p(\theta| \mathcal{X})d\theta</script></li>
<li>绝对值误差函数:<script type="math/tex; mode=display">\int_{-\infty}^{\hat{\theta_{ABS}}} p(\theta|\mathcal{X}) d\theta = \int_{\hat{\theta_{ABS}}}^{\infty} p(\theta|\mathcal{X}) d\theta</script></li>
<li>均匀误差函数: $\theta_{MAP}$应当取在后验概率密度函数最大之处</li>
</ul>
<p>下面以均方误差函数为例，假设:</p>
<ul>
<li>$p(x|\mu) \sim N(\mu, \sigma^2)$</li>
<li>$p(\mu) \sim N(\mu_0,\sigma_0^2)$ </li>
</ul>
<p>则后验概率密度函数$p(\theta|\mathcal{X})$为:<br>$$<br>\begin{aligned}<br>    p(\mu|\mathcal{X}) &amp;= \frac{p(\mathcal{X}|\mu)p(\mu)}{\int p(\mathcal{X}|\mu)p(\mu)d\mu}  \\<br>    &amp;= a exp{ -\frac{1}{2}[\sum_{k=1}^N (\frac{\mu - x_k}{\sigma})^2 + (\frac{\mu - \mu_0}{\sigma_0})^2] }<br>\end{aligned}</p>
<script type="math/tex; mode=display">
由于该概率密度函数是$\mu$的二次函数指数形式，所以仍是一个正态密度，其均值和方差为：</script><p>\begin{aligned}<br>    \mu<em>N &amp;= \frac{N\sigma_0^2}{N\sigma_0^2 + \sigma^2} \frac{1}{N}\sum</em>{k=1}^N x_k + \frac{\sigma^2}{N\sigma_0^2 + \sigma^2} \mu_0  \\<br>    \sigma_N^2 &amp;= \frac{\sigma_0^2 \sigma^2}{N\sigma_0^2 + \sigma^2}<br>\end{aligned}</p>
<script type="math/tex; mode=display">
因为误差函数为均方误差函数，则其参数估计值应当是后验概率密度意义上的均值，即$\mu_N$
### 非参数估计
在使用最大似然估计或者贝叶斯估计进行参数估计时，需要对类条件概率密度函数$p(\mathbf{x}|\omega)$形式已知，但在某些情况下，我们仅仅拥有样本，但并没有这些先验知识，此时若想要进行概率密度函数的估计，则就用到了非参数估计的方法，该类方法具有以下几点假设：
- 不知道分布函数形式
- $N$个样本服从独立同分布

假设样本点$\mathbf{x}$落在$d$维空间中，在$d$维空间中有一个超立方体$\mathcal{R}$,点$\mathbf{x}$落到该超立方体中的概率记做$P$:</script><pre><code>P = \int_&#123;\mathcal&#123;R&#125;&#125; p(x) dx 
</code></pre><script type="math/tex; mode=display">
若$N$个样本是从密度为$p(x)$的总体中独立抽取的，则$N$个样本中有$k$个落入区域$\mathcal{R}$中的概率符合二项分布，该概率可以写做：</script><pre><code>P_k = C_N^k P^k(1-P)^&#123;N-k&#125;
</code></pre><script type="math/tex; mode=display">
根据二项分布的性质，$k$的期望为：</script><pre><code>E(k) = NP 
</code></pre><script type="math/tex; mode=display">
我们的目的是想获得关于$P$的估计值，因此考虑：
$$ \hat{P} = \frac{k}{N}</script><p>若超立方体$\mathcal{R}$很小，则可以假设在该超球内概率密度函数$p(x)$为定值，此时：</p>
<script type="math/tex; mode=display">
    P = \int_{\mathcal{R}} p(x) dx  = p(x)V</script><p>由此我们便可以获得$p(x)$的估计值：</p>
<script type="math/tex; mode=display">
    \hat{p}(x) = \frac{P}{V} = \frac{k}{NV}</script><p>下面讨论下体积$V$的大小及样本数量多少之间的关系。如果把体积$V$固定，样本数取得越来越多，则比值$\frac{k}{N}$将在概率上收敛，最终得到的$p(x)$估计是在超立方体$\mathcal{R}$上的平均估计，而若想要得到$p(x)$的点估计，则需要区间尽可能小，但区间取得过小又会导致一些区间内没有样本点，这种估计也是没有意义的。<br>下面给出概率密度函数估计值$p_N(x)$收敛于真实概率密度函数$p(x)$的条件：</p>
<ul>
<li>$\lim_{N \rightarrow \infty} V_N = 0$</li>
<li>$\lim_{N \rightarrow \infty} k_N = \infty$</li>
<li>$\lim_{N \rightarrow \infty} \frac{k_N}{N} = 0$</li>
</ul>
<p>第一个条件可以使空间平均$\frac{P}{V}$收敛于$p(x)$,第二个条件可以使频数比在概率意义上收敛于概率$P$。满足以上三个条件的区域序列的选择有两种：</p>
<ul>
<li>Parzen窗法： 使区域序列$V_N$ 以$N$的某个函数的关系不断缩小，但此时需要对$k_N$和$\frac{k_N}{N}$加些限制条件</li>
<li>$k_N$近邻估计，让$k_N$为$N$的某个函数，而$V_N$的选取是使相应的$\mathcal{R_N}$正好包含$x$的$k_N$个近邻。</li>
</ul>
<h4 id="Parzen窗法"><a href="#Parzen窗法" class="headerlink" title="Parzen窗法"></a>Parzen窗法</h4><p>假设$\mathcal{R_N}$为一个超立方体，其棱长为$h_N$,则此时超立方体体积$V_N = h_N^d$,定义窗函数$\phi(\mu)$：</p>
<script type="math/tex; mode=display">
    \phi(\mu) = \begin{cases}
        1, if |\mu_j| \leq \frac{1}{2} \\
        0, other
    \end{cases}</script><p>引入窗函数的的目的主要是对落入区间的样本数$k$进行显示表达，当$x_i$落入以$x$为中心，体积为$V_N$的超立方体内时，$\phi(\mu) = \phi(\frac{x-x_i}{h_N}) = 1$，否则为0，此时落入该超立方体内的样本数为：</p>
<script type="math/tex; mode=display">
    k_N = \sum_{i=1}^N \phi(\frac{x-x_i}{h_N})</script><p>由此便可以得到概率密度函数估计：</p>
<script type="math/tex; mode=display">
    p_N(x) = \frac{k_N}{V_NN} = \frac{1}{N} \sum_{i=1}^N \frac{1}{V_N} \phi(\frac{x-x_i}{h_N})</script><p>事实上，窗函数的主要作用是内插，反映了每一样本$x_i$对$x$点处的概率密度函数的贡献<br>下面我们讨论下，若要使得$p_N(x)$满足概率密度函数特性(在整个空间上积分为1),则窗函数应当具有什么特性:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
          \int p_N(x)dx &= \frac{1}{NV_N} \int \sum_{i=1}^N\phi(\frac{x-x_i}{h_N})dx  \\\\
          &= \frac{1}{N} \sum_{i=1}^N \int \phi(\mu)d\mu \\\\
          & = 1
    \end{aligned}</script><p>因此考虑到$p_N(x)$非负且积分为1,则窗函数应当具备一般概率密度函数所具有的特征：</p>
<ul>
<li>$\phi(\mu) \geq 0 $</li>
<li>$\int \phi(\mu) d\mu = 1$</li>
</ul>
<p>常见的窗函数有以下三种：</p>
<ul>
<li>方窗函数</li>
<li>正态窗函数:$\phi(\mu) = \frac{1}{\sqrt{2\pi}} exp(-\frac{1}{2}\mu^2)$</li>
<li>指数窗函数:$\phi(\mu) = \frac{1}{2} exp(-|\mu|)$</li>
</ul>
<p>窗宽$h_d$的选择非常重要，若$h_d$选择过大，则会使得估计的分辨力降低，若选的过小，又会导致估计的稳定性下降，反映在估计得到的概率密度函数上就是毛刺很多，一般需要折中考虑。<br>下面讨论估计量$p_N(x)$的统计性质，可以证明在某些限制条件下，估计量是渐进无偏和平方误差一致的，限制条件为:</p>
<ul>
<li>总体密度函数$p(x)$在$x$点连续</li>
<li>窗函数满足以下条件：<script type="math/tex; mode=display">\phi(\mu) \geq 0, \int \phi(\mu) d\mu = 1, sup_{u} \phi(\mu)<\infty</script></li>
<li>窗宽满足: <script type="math/tex">\lim_{N \rightarrow \infty} V_N= 0,\lim_{N \rightarrow \infty} NV_N = \infty</script></li>
</ul>
<h4 id="k-N-近邻估计"><a href="#k-N-近邻估计" class="headerlink" title="$k_N$近邻估计"></a>$k_N$近邻估计</h4><p>parzen窗估计是对体积序列进行限制，而$k_N$近邻估计则是对$k_N$序列做出限制</p>
<h3 id="概率密度函数估计的准确性与分类器性能的关系"><a href="#概率密度函数估计的准确性与分类器性能的关系" class="headerlink" title="概率密度函数估计的准确性与分类器性能的关系"></a>概率密度函数估计的准确性与分类器性能的关系</h3><p>因为概率密度函数的估计最终还是需要服务于一些下游任务，比如应用贝叶斯决策进行分类，因此这部分主要讨论分类器的误差来源，误差来源主要有以下几种：</p>
<ul>
<li>贝叶斯误差：这种误差是由于不同的类条件概率分布函数之间的相互重叠引起的，这种误差是问题本身所固有的，在分类器设计阶段无法消除</li>
<li>模型误差：指因为选择了不正确的模型导致的误差</li>
<li>估计误差： 由于采用有限样本进行估计所带来的误差</li>
</ul>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>无监督学习</tag>
      </tags>
  </entry>
  <entry>
    <title>毛选第一卷读后感</title>
    <url>/2020/11/05/mao-xuan-di-yi-juan-du-hou-gan/</url>
    <content><![CDATA[<p>在柳州出差的20多天里，我每天回宾馆后会读上半个小时到1个小时毛选第一卷，回学校后又读了几天，昨晚算是正式将这本书给读完了，在阅读的过程中自己还是颇有所得的，现藉此文系统地总结一下这本书的内容并谈一下我个人的心得体会。<br><span id="more"></span><br>在详细叙述书的内容之前，我希望首先先谈一谈这本书的性质，在之前很久的一段时间里，我认为这本书单纯是一本红色读物。这次阅读的出发点一方面是党支部学习的需要，另一方面也是来验证我自己内心的观点，看一看这本被老一辈奉为圭臬的书究竟价值几分几两。在我读完这本书后，我提供几个读这本书的视角: </p>
<ul>
<li><strong>历史读物:</strong> 毛选第一卷记录的是毛泽东从1921年到1937年的一些发言与信件，读这本书可以跟随当时毛泽东的视角来对当时的社会情况进行把握，进而对那时所处的历史阶段有更加清晰的认识。但需要注意的是，以毛选这种读物来认识当时历史就不可避免的会受到作者视角立场的影响，需要时刻提醒自己所认识到的不过是当时历史的一个切面，而非全部。 </li>
<li><strong>政治读物:</strong> 我们现在的国家的政治制度是一党专政、多党参政，正所谓筚路蓝缕，以启山林，通过阅读毛选，我们可以对政党草创阶段一些政治方针、政策有更加清晰的认识，进而可以结合目前的社会状况产生一些新的思考，读古观今，实一大乐事。 </li>
<li><strong>传记读物:</strong> 毛泽东作为共和国的第一任领袖，其本身经历也足够传奇，而从那些历史教科书中我们所能获得的更多的是其作为党的领袖的一些外在行为，而若想对其人有一个更好的把握，更需要了解其在不同历史阶段在思考什么样的问题，换句话说需要明确支撑其外在行为的内在逻辑是什么，毛选我认为提供了一个很好的认识毛泽东其人的视角。 </li>
<li><strong>哲学读物:</strong> 马克思主义本身是一种哲学思想，毛选第一卷的前大半部分主要是马克思主义哲学的应用层面，将马克思主义哲学应用到斗争中出，应用到具体问题的分析中去，而最后两章《实践论》和《矛盾论》则更多是从理论方面阐明马克思主义哲学的思想，同时相较于传统的哲学著作，这本书因为穿插了大量的实践案例，因此理解起来也是容易许多。</li>
</ul>
<p><strong>当然，认识毛选这本书的视角远不止我所提供的这些，正如一千个人眼中有一千个哈姆雷特一样，但这种认识的角度清晰之后，我们通过阅读所获取的知识可以放在思想中更加恰当精确的位置，进而可以尽可能避免因阅读量的提升而出现自身思想混乱。</strong></p>
<h3 id="全书架构"><a href="#全书架构" class="headerlink" title="全书架构"></a>全书架构</h3><p>毛选第一卷共包含18篇，主要涵盖了两大时间阶段的作品: </p>
<ul>
<li>1924年-1927年: 第一次国内革命战争时期<ul>
<li>中国社会各阶级的分析 </li>
<li>湖南农民运动考察报告 </li>
</ul>
</li>
<li>1927年-1937年: 第二次国内革命战争时期 <ul>
<li>中国的红色政权为什么能够存在 </li>
<li>井冈山的斗争 </li>
<li>关于纠正党内的错误思想 </li>
<li>星星之火，可以燎原 </li>
<li>反对本本主义 </li>
<li>必须注意经济工作 </li>
<li>怎样分析农村阶级 </li>
<li>我们的经济政策 </li>
<li>关心群众生活，注重工作方法 </li>
<li>论反对日本帝国主义的策略 </li>
<li>中国革命战争的战略问题 </li>
<li>关于蒋介石声明的声明</li>
<li>中国共产党在抗日期间的任务 </li>
<li>为争取千百万群众进入抗日民族统一战线而斗争 </li>
<li>实践论 </li>
<li>矛盾论 </li>
</ul>
</li>
</ul>
<p>整体来说，这18篇文章都是服务于革命斗争的需要，前十六篇文章更多地是就特定历史阶段的特定问题进行剖析解读，而《实践论》与《矛盾论》则是从理论层面来阐述马克思主义者认识客观世界的角度，更偏方法论一些。  </p>
<p>后面的内容我主要是分两个章节，第一个章节来挑选前十六篇内容的部分进行总结，这一章节可能更偏政治与历史一些，第二个章节则就《实践论》与《矛盾论》两部分的哲学思想来进行阐释。 </p>
<h3 id="具体问题分析"><a href="#具体问题分析" class="headerlink" title="具体问题分析"></a>具体问题分析</h3><p>我们设想一下一个政党从诞生到发展，它需要考虑哪些问题: </p>
<ul>
<li>政党诞生于一个怎样的环境 </li>
<li>政权为何可以生存</li>
<li>对内: 政党内部存在哪些错误思想   </li>
<li>对外: 政党在一定历史阶段的斗争策略 </li>
</ul>
<p>针对这三个问题，这一部分重点关注四篇内容:</p>
<ul>
<li>中国社会各阶层的分析 </li>
<li>中国的红色政权为什么能够存在 </li>
<li>关于纠正党内的错误思想   </li>
<li>中国革命战争的战略问题 </li>
</ul>
<h4 id="中国社会各阶层的分析"><a href="#中国社会各阶层的分析" class="headerlink" title="中国社会各阶层的分析"></a>中国社会各阶层的分析</h4><h5 id="内容概述"><a href="#内容概述" class="headerlink" title="内容概述"></a>内容概述</h5><blockquote>
<p><strong>谁是我们的敌人，谁是我们的朋友，这是革命的首要问题。中国过去一切革命斗争成效甚少，其基本原因就是因为不能团结真正的朋友，以攻击真正的敌人。</strong></p>
</blockquote>
<p>这句话不仅适用于革命，而且适用于一切政治环境，历史经验告诉我们，在政治环境下骑墙头是没有好下场的。毛泽东在这一篇中细数了一下1925年时社会环境中的各阶级的划分及他们的政治倾向:</p>
<ul>
<li><strong>地主阶级和买办阶级</strong>: 在经济落后的半殖民地的中国，地主阶级和买办阶级完全是国际资产阶级的附庸，其生存和发展，是附属于帝国主义的。<strong>这些阶级代表中国最落后的和最反动的生产关系，阻碍中国生产力的发展</strong>。他们和中国革命的目的完全不相容。特别是大地主阶级和大买办阶级，他们始终站在帝国主义一边，是极端的反革命派。<strong>其政治代表是国家主义派和国民党右派。</strong></li>
<li><strong>中产阶级</strong>: 这个阶级代表中国城乡资本主义的生产关系。中产阶级主要是指民族资产阶级，<strong>他们对于中国革命具有矛盾的态度</strong>：他们在受外资打击、军阀压迫感觉痛苦时，需要革命，赞成反帝国主义反军阀的革命运动；但是当着革命在国内有本国无产阶级的勇猛参加，在国外有国际无产阶级的积极援助，对于其欲达到大资产阶级地位的阶级的发展感觉到威胁时，他们又怀疑革命。<strong>中国的中产阶级，以其本阶级为主体的“独立”革命思想，仅仅是一个幻想。</strong> </li>
<li><strong>小资产阶级</strong>: 自耕农、手工业主、小知识阶层-学生界、中小学教员、小员司、小事务员、小律师，小商人等都属于这一类。这个小资产阶级内的各阶层虽然同处在小资产阶级经济地位，但有三个不同的部分。第一部分是有余钱剩米的，即用其体力或脑力劳动所得，除自给外，每年有余剩；第二部分是在经济上大体上可以自给的；第三部分是生活下降的。</li>
<li><p><strong>半无产阶级</strong>:此处所谓的半无产阶级，包含以下几部分:</p>
<ul>
<li>绝大部分半自耕农 </li>
<li>贫农 </li>
<li>小手工业者 </li>
<li>店员 </li>
<li>小贩</li>
</ul>
<p><strong>这一类人大多期望一个变更现状的革命。</strong></p>
</li>
<li><strong>无产阶级</strong>: 无产阶级一般是指工业无产阶级，中国因经济落后，故现代工业无产阶级人数不多。<strong>工业无产阶级人数虽不多，却是中国新的生产力的代表者，是近代中国最进步的阶级，做了革命运动的领导力量</strong>。他们之所以在中国革命中所处的地位重要，第一个原因是集中和在生产上的重要，第二个原因则是经济地位低下。 </li>
</ul>
<p>毛泽东在分析了中国当时阶段不同阶级人群的特征和政治倾向后，做出了那个阶段谁是敌人、谁是朋友的判断: </p>
<blockquote>
<p>综上所述，可知一切勾结帝国主义的军阀、官僚、买办阶级、大地主阶级以及附属于他们的一部分反动知识界，是我们的敌人。工业无产阶级是我们革命的领导力量。一切半无产阶级、小资产阶级，是我们最接近的朋友。那动摇不定的中产阶级，其右翼可能是我们的敌人，其左翼可能是我们的朋友——但我们要时常提防他们，不要让他们扰乱了我们的阵线。</p>
</blockquote>
<h5 id="体会认识"><a href="#体会认识" class="headerlink" title="体会认识"></a>体会认识</h5><p>首先我们需要明确的一件事情是:</p>
<blockquote>
<p>有人的地方就有阶级。 </p>
</blockquote>
<p>整个社会上的人我们总可以大致划分成两类: </p>
<ul>
<li>既得利益者: 从所处历史阶段的上层建筑中拥有广泛利益的群体，他们通过统治者的政策和政权本身的性质获取较大的利益，甚至大大获取对压迫者极不公平的权利。既得利益者一般倾向于维护现行政治制度和经济制度，维护现状，不期望当前制度被显著改变。 </li>
<li>既失利益者: 与既得利益者相对，这类人在当前的制度中是处于弱势群体，整体在现实生活中并不如意，这些人更期望能够改变现有的政治制度与经济制度以获得更大的生存空间。 </li>
</ul>
<p>而毛泽东在分析那个时间的阶级时也基本是按照这个范式来进行分析的，在进行某一类阶级人群的分析时，主要是从以下三个角度进行分析:</p>
<ul>
<li>代表人群及区别</li>
<li>经济来源及所依赖的权力单位</li>
<li>对革命的倾向</li>
</ul>
<p>通过这三点的分析便清晰地明确了<strong>谁是我们的朋友，谁是我们的敌人</strong>这样一个关键问题。</p>
<p>通过上面的分析，我们可以明确这样一件事:</p>
<blockquote>
<p>各阶级对于政治制度的诉求是不相同的 </p>
</blockquote>
<p>最后我们可以考虑这样一个问题，假如我们作为政权主体，应当采取怎样的措施来避免革命的发生:</p>
<ul>
<li>政权主体至少要在宣传上与大多数人阶级相利益一致</li>
<li>通过税收等制度来在一定程度上减轻阶级分化问题</li>
<li>通过财富再分配的方式来一定程度上填补阶级间的经济鸿沟 </li>
<li>以宣传的的手段来掩饰绝望的阶级鸿沟的存在，同时更多地展现阶级鸿沟的可跨越性</li>
</ul>
<h4 id="中国的红色政权为什么能够存在"><a href="#中国的红色政权为什么能够存在" class="headerlink" title="中国的红色政权为什么能够存在"></a>中国的红色政权为什么能够存在</h4><p><code>中国社会各阶层分析</code>更多地是为革命提供了一个方向性的东西，明确了在革命推动中<strong>谁是我们的敌人，谁是我们的朋友，哪些人时可以团结的，哪些人是必须打倒的。</strong> 而对于一个处在发展中的弱势党派,其必然会面临两个问题需要回答: </p>
<ul>
<li>政党存在的必要性</li>
<li>政党发展的可行性 </li>
</ul>
<p><code>中国的红色政权为什么能够存在</code>这一篇就这两个问题进行了回答，首先文章分析了国内的政治状况: </p>
<blockquote>
<p>现在国民党新军阀的统治，依然是城市买办阶级和乡村豪绅阶级的统治，对外投降帝国主义，对内以新军阀代替旧军阀，对工农阶级的经济的剥削和政治的压迫比从前更加厉害。只要各国帝国主义分裂中国的状况存在，各派军阀就无论如何不能妥协，所有妥协都是暂时的。今天的暂时的妥协，即酝酿着明天的更大的战争。<br><strong>中国迫切需要一个资产阶级的民主革命，这个革命必须由无产阶级领导才能完成。</strong></p>
</blockquote>
<p>这一部分回答了政党存在的必要性问题，但政党领导的红色政权能否得到发展则需要另外进行分析: </p>
<blockquote>
<p>一国之内，在四围白色政权的包围中，有一小块或若干小块红色政权的区域长期地存在，这是世界各国从来没有的事。这种奇事的发生，有其独特的原因。而其存在和发展，亦必有相当的条件。<br>第一，它的发生不能在任何帝国主义的国家，也不能在任何帝国主义直接统治的殖民地，必然是在帝国主义间接统治的经济落后的半殖民地的中国。<strong>因为这种奇怪现象必定伴着另外一件奇怪现象，那就是白色政权之间的战争。</strong> 因为有了白色政权间的长期的分裂和战争，便给了一种条件，使一小块或若干小块的共产党领导的红色区域，能够在四围白色政权包围的中间发生和坚持下来。<br>第二，中国红色政权首先发生和能够长期地存在的地方，不是那种并未经过民主革命影响的地方，例如四川、贵州、云南及北方各省，而是在一九二六和一九二七两年资产阶级民主革命过程中工农兵士群众曾经大大地起来过的地方。<br>第三，小地方民众政权之能否长期地存在，则决定于全国革命形势是否向前发展这一个条件。<br>第四，相当力量的正式红军的存在，是红色政权存在的必要条件。<br>第五，红色政权的长期的存在并且发展，除了上述条件之外，还须有一个要紧的条件，就是共产党组织的有力量和它的政策的不错误。</p>
</blockquote>
<p>这一部分的分析说明了红色政权得以发展的一些条件，同时为接下来红色政权的发展提出了一些要求。 </p>
<h4 id="关于纠正党内的错误思想"><a href="#关于纠正党内的错误思想" class="headerlink" title="关于纠正党内的错误思想"></a>关于纠正党内的错误思想</h4><p>随着革命队伍的扩大，党内思想难免会出现不统一的情况，而这一篇文章则是旨在指出党内有哪些错误思想并给出错误根源，按照其认识，当时党内存在的错误思想有以下几点:</p>
<ul>
<li>单纯军事观点: 认为军事政治是对立的，不承认军事只是完成政治的工具，同时认为政治只是军事的辅助。 </li>
<li>极端民主化: 要求在红军中实行所谓的“由下而上的民主集中制”、“先交下级讨论，再由上级决议”等错误主张。 </li>
<li>非组织观点: 少数人不服从多数人的决议，在党外进行批评</li>
<li>绝对平均主义: 与极端民主化一样，一则见之于政治生活，一则见之于物质生活。</li>
<li>主观主义: 对于政治形势的主观主义分析和对于工作的主观主义指导，其必然的结果，不是机会主义，就是盲动主义。在进行党内批评时，应当明确批评的主要任务是指出政治上的错误和组织上的错误，而若与政治上错误和组织上错误有关联的问题，则不必过分指摘。</li>
<li>个人主义: 红军党内的个人主义思想主要有几种表现: 报复主义、小团体主义、雇佣思想、享乐主义、消极怠工、离队思想。 </li>
<li>流寇思想: 不愿做艰苦工作建立根据地，并由此扩大政治影响；扩大红军，不走由扩大地方赤卫队、地方红军到扩大主力红军的路线，而要走“招兵买马、招降纳叛”的路线；不耐烦跟群众在一起做艰苦斗争，只希望跑到大城市去大吃大喝。 </li>
<li>盲动主义残余: 不顾主观和客观条件的盲干；城市政策执行的不充分、不坚决；军纪松懈，特别是打败仗时，枪毙逃兵和肉刑制度。</li>
</ul>
<p>首先我们需要认识到，其中的部分思想是在战时环境下诞生的，比如单纯军事观点、流寇思想等等，而像极端民主化、绝对平均主义、个人主义等思想在现在还有着存在的土壤，从毛泽东对这些错误思想的批判中我们可以得出以下一些观点:</p>
<ul>
<li>军事只是完成政治的工具，明确是党指挥枪，而不是枪指挥党。</li>
<li>极端民主化是不可取的，试错的代价是一个新生政权所无法承受的，这也是为何在战时一个高度集权的政权能够让一个国家更具战斗力。 </li>
<li>哪怕是在一个阵营内部，一个让所有人都满意的方针或制度也是不可能的，少数服从多数是一个更容易接受的判决方式，“群体”的走向应当取决于“群体中大多数人”的意志。 少数服从多数的决议可能有时并不正确，因此要降低这种决策方式的风险就需要进行不断地讨论来将道理辨明，用来说服少数人，或者将少数人变为多数人。  </li>
<li>绝对平均主义并不合理也难以实现，哪怕是在社会主义阶段，物质的分配也要按照“各尽所能，按劳取酬”的原则来进行，但这就将引出一个新的问题，<strong>“按劳取酬”中的“劳”的定义往往是暧昧的，资本家依赖资本实现高效滚利获取更多社会资源的行为算是“按劳取酬”么？</strong></li>
<li>当人在群体中时，群体利益的最大化方向往往与个人利益的表面最大化方向是有冲突的，而个人往往会忽视个人的能量是依赖于群体的能量，因此就往往就会犯主观主义和个人主义的错误，而个人真正应当做的正确决策是控制个人诉求，而从群体的诉求出发来考虑事情。 </li>
</ul>
<h4 id="中国革命的战略问题"><a href="#中国革命的战略问题" class="headerlink" title="中国革命的战略问题"></a>中国革命的战略问题</h4><p>这篇文章写于遵义会议后，是毛泽东为总结当时第二次国内革命战争的经验所写。这一篇系统地阐述了有关中国革命战争战略方面诸多问题。 </p>
<h5 id="如何研究战争"><a href="#如何研究战争" class="headerlink" title="如何研究战争"></a>如何研究战争</h5><p>战争，有其一般规律，而同时对于具体地战争又有着其特殊性，也就是在一般性中会寓有特殊性。而如果以集合地观点来看待当时国内战争: </p>
<script type="math/tex; mode=display">
    中国革命战争 \sub 革命战争 \sub 战争</script><p>我们要研究当前中国战争的规律，那么<strong>我们不但要研究一般战争的规律，还要研究特殊的革命战争的规律，还要研究更加特殊的中国革命战争的规律。</strong>, 毛泽东也给出了首先分析战争规律的原因: </p>
<blockquote>
<p>无论做什么事情，不懂得那件事的情形，它的性质，它和它以外的事情的关联，就不知道那件事的规律，就不知道如何去做，就不能做好那件事。 </p>
</blockquote>
<p>下面给出<strong>战争、革命战争、中国革命战争</strong>的概述:</p>
<blockquote>
<p><strong>战争:</strong> 从有私有财产和有阶级以来就开始了的、用以解决阶级和阶级、民族和民族、国家和国家、政治集团和政治集团之间、在一定发展阶段上的矛盾的一种最高的斗争形式。不懂得它的情形，它的性质，它和它以外事情的关联，就不知道战争的规律，就不知道如何指导战争，就不能打胜仗。<br><strong>革命战争:</strong> 革命的阶级战争和革命的民族战争，在一般战争的情形和性质之外，有它的特殊的情形和性质。因此，在一般的战争规律之外，有它的一些特殊的规律。不懂得这些特殊的情形和性质，不懂得它的特殊的规律，就不能指导革命战争，就不能在革命战争中打胜仗。<br><strong>中国革命战争:</strong> 不论是国内战争或民族战争，是在中国的特殊环境之内进行的，比较一般的战争，一般的革命战争，又有它的特殊的情形和特殊的性质。因此，在一般战争和一般革命战争的规律之外，又有它的一些特殊的规律。如果不懂得这些，就不能在中国革命战争中打胜仗。</p>
</blockquote>
<p>在实际中，有些人过度依赖于别人的经验，依赖于那些一般的规律，认为直接搬来最为省事，而他们忽视了这样一个道理:</p>
<blockquote>
<p>我们固然应该尊重过去流血的经验，但同时也应该尊重自己流血的经验。 </p>
</blockquote>
<p>对于战争以及战争之外的一切事物，我们都应当用发展的眼光来看待，用变化的眼光来看待: </p>
<blockquote>
<p>一切战争指导规律，依照历史的发展而发展，依照战争的发展而发展；一成不变的东西是没有的。</p>
</blockquote>
<p>战争本身必将伴随着流血，我们必须要明确我们为何要进行战争以及战争的性质: </p>
<blockquote>
<p>战争——这个人类互相残杀的怪物，人类社会的发展终久要把它消灭的，而且就在不远的将来会要把它消灭的。<strong>但是消灭它的方法只有一个，就是用战争反对战争。</strong></p>
<p>我们研究革命战争的规律，出发于我们要求消灭一切战争的志愿，这是区别我们共产党人和一切剥削阶级的界线。</p>
</blockquote>
<p>在明确了我们革命战争的性质之后，接下来需要回答的问题便是何为革命战争的战略问题：</p>
<blockquote>
<p>只要有战争，就有战争的全局。世界可以是战争的一全局，一国可以是战争的一全局，一个独立的游击区、一个大的独立的作战方面，也可以是战争的一全局。凡属带有要照顾各方面和各阶段的性质的，都是战争的全局。</p>
<p>战略问题是研究战争全局的规律性东西  </p>
</blockquote>
<p>以战略的眼光来看待问题其实就是以全局的观念来看待问题，在解决或分析一个问题时，个人往往会陷入问题的局部不能出来，而最终使得问题不能得到解决，我们往往都会有这样的经历: </p>
<blockquote>
<p>在一个事情的规划阶段，我们往往是有着全局观念的，明确要先做这件事，再做另一件事，但当我们陷入局部问题时，又常常会因局部问题的不顺利而陷入局部问题中，甚至会丧失掉全局观念，最终因局部的小问题而导致全局问题满盘皆输。 </p>
</blockquote>
<p>全局问题是由一个个局部问题所组成的，我们不能够抛离局部问题来谈全局问题，但我们也要时刻明确，局部问题应当是为全局问题所服务的，当局部受挫时，我们首先需要明确它对于全局问题的影响是如何的，是否应将重点放在其他局部问题上，而不是深陷局部问题中而丧失全局观念。 </p>
<p>没有一个绝对的奉为圭臬的指南，我们所能做的只有: </p>
<blockquote>
<p>在学习中不断摸索，找到适合于当前阶段的特殊问题的战略。 </p>
</blockquote>
<h5 id="中国共产党和中国革命战争"><a href="#中国共产党和中国革命战争" class="headerlink" title="中国共产党和中国革命战争"></a>中国共产党和中国革命战争</h5><p>在这一部分中，毛泽东阐述了中国共产党与中国革命战争的关系:</p>
<blockquote>
<p>因为半殖民地的中国的社会各阶层和各种政治集团中，只有无产阶级和共产党，才最没有狭隘性和自私自利性，最有远大的政治眼光和最有组织性，而且也最能虚心地接受世界上先进的无产阶级及其政党的经验而用之于自己的事业。因此，只有无产阶级和共产党能够领导农民、城市小资产阶级和资产阶级，克服农民和小资产阶级的狭隘性，克服失业者群的破坏性，并且还能够克服资产阶级的动摇和不彻底性，从而使革命和战争走向胜利的道路。</p>
</blockquote>
<h5 id="中国革命战争的特点"><a href="#中国革命战争的特点" class="headerlink" title="中国革命战争的特点"></a>中国革命战争的特点</h5><p>要想更好地推进中国革命战争，那么就必须要明确中国革命战争的特点，毛泽东认为中国革命战争有四个特点: </p>
<ul>
<li>中国是一个政治经济发展不平衡的半殖民地的大国，而又经过了1924年至1927年的革命。</li>
<li>敌人的强大，红军的敌人是强大的国民党军队。</li>
<li>红军的弱小，红军的数量是少的，红军的武器是非常差的，红军的粮食被服等物质供给是困难的。</li>
<li>共产党的领导和土地革命,红军虽小却有强大的战斗力，<strong>因为在共产党领导下的红军人员是从土地革命中产生，为着自己的利益而战斗的</strong>，而且指挥员和战斗员之间在政治上是一致的。</li>
</ul>
<p>中国革命的客观特点又将作用于中国革命战争的指导路线和许多战略战术的原则:</p>
<blockquote>
<p>第一个特点和第四个特点，规定了中国红军的可能发展和可能战胜其敌人。第二个特点和第三个特点，规定了中国红军的不可能很快发展和不可能很快战胜其敌人，即是规定了战争的持久，而且如果弄得不好的话，还可能失败。</p>
</blockquote>
<p>这就是中国革命的两个方面，这两方面同时存在着，也就是说，既有顺利的条件，也有不利的条件，中国革命战争许多战略思想都是从革命的现状中发展起来的: </p>
<blockquote>
<p>很明显的，正确地规定战略方向，进攻时反对冒险主义，防御时反对保守主义，转移时反对逃跑主义；反对红军的游击主义，却又承认红军的游击性；反对战役的持久战和战略的速决战，承认战略的持久战和战役的速决战；反对固定的作战线和阵地战，承认非固定的作战线和运动战；反对击溃战，承认歼灭战；反对战略方向的两个拳头主义，承认一个拳头主义；反对大后方制度，承认小后方制度；反对绝对的集中指挥，承认相对的集中指挥；反对单纯军事观点和流寇主义，承认红军是中国革命的宣传者和组织者；反对土匪主义，承认严肃的政治纪律；反对军阀主义，承认有限制的民主生活和有威权的军事纪律；反对不正确的宗派主义的干部政策，承认正确的干部政策；反对孤立政策，承认争取一切可能的同盟者；最后，反对把红军停顿于旧阶段，争取红军发展到新阶段——所有这些原则问题，都要求正确的解决。我们现在要讲的战略问题，就是要就中国革命战争的十年血战史的经验，好好地说明这些问题。</p>
</blockquote>
<h5 id="围剿和反围剿-中国内战的主要形式"><a href="#围剿和反围剿-中国内战的主要形式" class="headerlink" title="围剿和反围剿-中国内战的主要形式"></a>围剿和反围剿-中国内战的主要形式</h5><p>中国内战的特点，是在围剿和反围剿中不断反复,但需要注意，说长期反复是战争和战斗形式的反复，而战争和战斗的内容，则是每次都不同的。对于革命战争究竟应当是进攻还是防御这个问题，毛泽东认为: </p>
<blockquote>
<p>革命和革命战争是进攻的，但是也有防御和后退——这种说法才是完全正确的。<strong>为了进攻而防御，为了前进而后退，为了向正面而向侧面，为了走直路而走弯路，是许多事物在发展过程中所不可避免的现象</strong>，何况军事运动. </p>
</blockquote>
<h5 id="战略防御"><a href="#战略防御" class="headerlink" title="战略防御"></a>战略防御</h5><p>这一部分是比较繁琐的，毛泽东就战斗的形式做了详细的阐述，其核心思想有以下两点:</p>
<blockquote>
<ul>
<li>积极防御，又叫攻势防御，又叫决战防御。消极防御，又叫专守防御，又叫单纯防御。消极防御实际上是假防御，只有积极防御才是真防御，才是为了反攻和进攻的防御。</li>
<li>在军事上说来，我们的战争是防御和进攻的交替的应用。对于我们，说进攻是在防御之后，或说进攻是在防御之前都是可以的，因为关键在于打破“围剿”。“围剿”没有打破以前是防御，“围剿”一经打破就开始了进攻，仅仅是一件事情的两个阶段。 </li>
</ul>
</blockquote>
<h3 id="方法论范畴"><a href="#方法论范畴" class="headerlink" title="方法论范畴"></a>方法论范畴</h3><h4 id="实践论"><a href="#实践论" class="headerlink" title="实践论"></a>实践论</h4><blockquote>
<p>认识与时间的关系——知与行的关系 </p>
</blockquote>
<p>马克思以前的唯物论，离开人的社会性，离开人的历史发展，去观察认识问题，因此不能了解认识对社会实践的依赖关系，即认识对生产和阶级斗争的依赖关系。</p>
<blockquote>
<p><strong>首先，马克思主义者认为认为人类的生产活动是最基本的实践活动，是决定其他一切活动的东西。人的认识，主要地依赖于物质地生产活动，逐渐地了解自然地现象、自然地性质、自然地规律性、人和自然的关系，而且经过生产活动，也在各种不同程度上逐渐地认识了人和人之间的相互关系。</strong> </p>
</blockquote>
<p>一切唯物主义思想都认为物质是一切的本源，物质决定意识，而马克思主义则是更进一步，更加专注于人类活动和由此而产生的制度的生成、复制和摧毁，马克思主义是一种<strong>以历史唯物主义、辩证法和对资本主义的批判所发展出的经济、政治和社会世界观。</strong></p>
<p>在后面，毛泽东有进一步阐述了人的社会实践有哪些形式: </p>
<blockquote>
<p>人的社会实践，不限于生产活动一种形式，还有多种其他的形式，阶级斗争，政治生活，科学和艺术的活动，总之社会实际生活的一切领域都是社会的人所参加的。因此，人的认识，在物质生活以外，还从政治生活文化生活中（与物质生活密切联系），在各种不同程度上，知道人和人的各种关系。其中，尤以各种形式的阶级斗争，给予人的认识发展以深刻的影响。在阶级社会中，每一个人都在一定的阶级地位中生活，各种思想无不打上阶级的烙印。</p>
</blockquote>
<p>马克思辩证唯物论中的“物”更多指的是“社会实践活动”: </p>
<blockquote>
<p>辩证唯物论的认识论把实践提到第一的地位，认为人的认识一点也不能离开实践，排斥一切否认重要性、使认识离开实践的错误理论。列宁这样说过:“实践高于理论的认识，因为它不但有普遍性的品格，而且还有<strong>直接现实性</strong>的品格。”</p>
<p>马克思主义哲学辩证唯物论有两个最显著的特点:</p>
<ul>
<li>阶级性: 申明辩证唯物论是为无产阶级服务的。 </li>
<li>实践性: 强调理论对于实践的依赖关系，理论的基础是实践，又转过来为实践服务。实践的观点是辩证唯物论的认识论第一和基本的观点。 </li>
</ul>
</blockquote>
<p>马克思主义哲学在诞生之处是强调其阶级性的，说明其是为广大无产阶级所服务的哲学，是工人阶级的世界观，这也就是其阶级性来源；而实践性则不过是在唯物主义的基础上将一般性的物质由更具“直接现实性”的人类社会实践所替代，更多地强调实践的重要性。 </p>
<p>如果应用此辩证唯物主义来进行人的认识过程的分析，可以得出这样的结论: </p>
<blockquote>
<p>认识的真正任务在于经过感觉而到达于思维，到达于逐步了解客观事物的内部矛盾，了解它的规律性，了解这一过程和那一过程间的内部联系，即到达于论理的认识。</p>
<p>马克思列宁主义认为: ：认识过程中两个阶段的特性，在低级阶段，认识表现为感性的，在高级阶段，认识表现为论理的，但任何阶段，都是统一的认识过程中的阶段。感性和理性二者的性质不同，但又不是互相分离的，它们在实践的基础上统一起来了。我们的实践证明：<strong>感觉到了的东西，我们不能立刻理解它，只有理解了的东西才更深刻地感觉它。感觉只解决现象问题，理论才解决本质问题。</strong></p>
</blockquote>
<p>一个人的知识来源，不外乎两个部分: 直接知识和间接知识，直接知识来自于实践，而间接知识是否可靠则取决于古人直接经验时是否符合于列宁所说的“科学的抽象”，如果这些知识是科学地反映了客观的事物，那么这些知识是可靠的。 </p>
<blockquote>
<p>因此，就知识的总体来说，无论何种知识都是不能离开直接经验的。任何知识的来源，在于人的肉体感官对客观外界的感觉，否认了这个感觉，否认了直接经验，否认亲自参加变革现实的实践，他就不是唯物论者。 </p>
</blockquote>
<p>认识的过程大致分为两步:</p>
<ul>
<li>开始接触外界事物，属于感觉的阶段。 </li>
<li>综合感觉的材料加以整理和改造，属于概念、判断和推理的阶段。</li>
</ul>
<p>从认识论的角度来看，唯物主义者持有的观点是:</p>
<ul>
<li>理性知识来源于感性认识，这是根本区别于唯心主义的一点。</li>
<li>感性认识有待于发展到理性认识。如果认为可靠的认识只是感性认识，那就陷入了“经验主义”的误区。 </li>
</ul>
<p>马克思主义在唯物认识论的基础上，更强调应当将所得的认识作用于实践:</p>
<blockquote>
<p>认识的能动作用，不但表现于从感性的认识到理性的认识之能动的飞跃，更重要的还需表现于从理性的认识到革命的实践这一个飞跃。</p>
</blockquote>
<p>在进行认识的过程中，往往是一个不断往复的过程，从感觉出发而形成感性认识，综合感觉材料加以整理和改造，成为理性认识，然后将所形成的理性认识作用于客观世界，检验认识的正确性，如此往复，方能够使自己的认识更加正确。<br>同时作为马克思主义者应当认识到，在绝对的总的宇宙发展过程中，各个具体过程的发展都是相对的，因而在绝对的真理长河中，人们对于在各个一定发展阶段上的具体过程的认识只是具有相对真理性。 <strong>客观世界的变化运动永远没有完结，人们在实践中对于真理的认识也就永远没有完结。</strong><br>在本篇的最后，毛泽东对于辩证唯物论做了一个总结: </p>
<blockquote>
<p>通过实践而发现真理，又通过实践而证实真理和发展真理。从感性认识而能动地发展到理性认识，又从理性认识而能动地指导革命实践，改造主观世界和客观世界。实践、认识、再实践、再认识，这种形式，循环往复以至无穷，而实践和认识之每一循环的内容，都比较地进到了高一级的程度。这就是辩证唯物论的全部认识论，这就是辩证唯物论的知行统一观。</p>
</blockquote>
<h4 id="矛盾论"><a href="#矛盾论" class="headerlink" title="矛盾论"></a>矛盾论</h4><p>如果说<code>实践论</code>是将认识与实践的关系阐明清楚了的话，那么<code>矛盾论</code>则是阐明应当如何认识客观事物的理论。 </p>
<blockquote>
<p>事物的矛盾法则，即对立统一的法则，是唯物辩证法的根本的法则。</p>
</blockquote>
<p>在这一篇中，重点阐述以下几个哲学问题: </p>
<ul>
<li>两种宇宙观 </li>
<li>矛盾的普遍性 </li>
<li>矛盾的特殊性</li>
<li>主要的矛盾和主要的矛盾方面 </li>
<li>矛盾诸方面的同一性和斗争性</li>
<li>对抗在矛盾中的地位 </li>
</ul>
<h5 id="两种宇宙观"><a href="#两种宇宙观" class="headerlink" title="两种宇宙观"></a>两种宇宙观</h5><p>在人类的认识史中，关于宇宙发展规则的见解可以粗略的分为两种: </p>
<ul>
<li><strong>形而上学:</strong> 形而上学的宇宙观，是属于唯心论的宇宙观，在这种宇宙观下，是用孤立的、静止的和片面的观点去看世界，这种宇宙观把世界一切事物，一切事物的形态和种类都看成是永远彼此孤立和永远不变化的。如果说有变化，也只是数量的增减和场所的变更。形而上学家认为，世界上各种不同事物和事物的特性，从它们一开始存在的时候就是如此。形而上学家们会简单地从事物外部去找发展的原因，否认唯物辩证法所主张的事物因内部慢炖引起发展的学说。</li>
<li><strong>唯物辩证法宇宙观:</strong> 唯物辩证法的宇宙观主张从事物的内部、从一事物对他事物的关系去研究事物的发展，即把事物的发展看做是事物内部的必然的自己的运动。<strong>事物发展的根本原因，不是在事物的外部，而是在事物的内部，在于事物内部的矛盾性。</strong>事物内部的这种矛盾性是事物发展的根本原因，事物间的互相联系和互相影响则是事物发展的第二位的原因。唯物辩证法认为外因是变化的条件，内因是变化的依据，外因通过内因而起作用。 </li>
</ul>
<h5 id="矛盾的普遍性"><a href="#矛盾的普遍性" class="headerlink" title="矛盾的普遍性"></a>矛盾的普遍性</h5><p>矛盾的普遍性或绝对性这个问题有两个方面的意义: </p>
<blockquote>
<ul>
<li><strong>矛盾</strong>存在于一切事物的发展过程中 </li>
<li>每一事物的发展过程中存在着自始至终的<strong>矛盾运动</strong></li>
</ul>
</blockquote>
<p>一切事物中包含的矛盾方面的相互依赖和相互斗争，决定一切事物的生命，推动一切事物的发展。没有什么事物是不包含矛盾的，没有矛盾就没有世界。<br>以个人认识的更新来看，当发现个人对某一事物的认识与自己的感性认识发生矛盾时，人便会倾向于修正自己的认识，修正的过程便是矛盾运动的过程。<br>德波林学派有这样一种见解，认为矛盾不是一开始就在过程中出现，而是须待发展到一定阶段才出现，认为在一定时间之前，事物的发展是由于外因，而过了这个时间之后，事物的发展是由于内因。但德布林学派忽略了世界的每一差异中就已经包含矛盾，差异就是矛盾，只是还未激化展现出来而已。</p>
<h5 id="矛盾的特殊性"><a href="#矛盾的特殊性" class="headerlink" title="矛盾的特殊性"></a>矛盾的特殊性</h5><blockquote>
<p>任何运动形式，其内部都包含着本身特殊的矛盾，这种特殊的矛盾，就构成一事物区别于他事物的特殊的本质。这就是世界上诸多事物所以有千差万别的内在的原因。</p>
</blockquote>
<p>对于矛盾的普遍性与特殊性的关系，该篇做了如下阐述: </p>
<blockquote>
<p>如果不认识矛盾的普遍性，就无从发现事物运动发展的普遍的原因或普遍的根据；但是，如果不研究矛盾的特殊性，就无从确定一事物不同于他事物的特殊的本质，就无从发现事物运动发展的特殊的原因，或特殊的根据，也就无从辨别事物，无从区分科学研究的领域</p>
</blockquote>
<p>在进行矛盾的研究时，我们既要对矛盾的总体、本质有一个把握，同时对于矛盾的特殊性也要有明确的认识: </p>
<blockquote>
<p>不论研究何种矛盾的特性——各个物质运动形式的矛盾，各个运动形式在各个发展过程中的矛盾，各个发展过程的矛盾的各方面，各个发展过程在其各个发展阶段上的矛盾以及各个发展阶段上的矛盾的各方面，研究所有这些矛盾的特性，都不能带主观随意性，必须对它们实行具体的分析。离开了具体的分析，就不能认识任何矛盾的特性。</p>
</blockquote>
<p>同时我们需要认识到矛盾的普遍性和特殊性也并不是绝对的: </p>
<blockquote>
<p>由于事物范围的极其广大，发展的无限性，所以，在一定场合为普遍性的东西，而在另一一定场合则变为特殊性。反之，在一定场合为特殊性的东西，而在另一一定场合则变为普遍性。</p>
</blockquote>
<h5 id="主要的矛盾和主要的矛盾方面"><a href="#主要的矛盾和主要的矛盾方面" class="headerlink" title="主要的矛盾和主要的矛盾方面"></a>主要的矛盾和主要的矛盾方面</h5><p>首先我们需要明确，在复杂事物的发展过程中，其存在的矛盾是多种的，但: </p>
<blockquote>
<p>其中必有一种是主要的矛盾，由于它的存在和发展规定或影响着其他矛盾的存在和发展。</p>
</blockquote>
<p>在进行分析研究时，一定要注意找到主要矛盾，同时对于矛盾的两个方面也不能同等看待: </p>
<blockquote>
<p>对于各种不同的矛盾，需要将它们划分为主要矛盾和次要矛盾，同时主要矛盾的两方面中，必有一方面时主要的，在矛盾中起主导作用，<strong>事物的性质，主要是由取得支配地位的矛盾的主要方面所规定的。</strong></p>
</blockquote>
<p>但我们在看待某个事物/过程时，一定要用辩证的眼光来看待:</p>
<blockquote>
<p>事物的主要矛盾并非一成不变的，同时矛盾的主要方面和非主要方面也是会相互转化的，随着这种转化的发生，事物的性质也就随之发生了变化。 </p>
</blockquote>
<p>有人可能认为有些矛盾两方面的地位并不会发生相互转化，比如生产力和生产关系的矛盾、理论和实践的矛盾、经济基础与上层建筑的矛盾，但我们需要明确: </p>
<blockquote>
<p>诚然，生产力、实践、经济基础，一般地表现为主要的决定的作用，谁不承认这一点，谁就不是唯物论者。然而，生产关系、理论、上层建筑这些方面，在一定条件之下，又转过来表现其为主要的决定的作用，这也是必须承认的。这样进行认识才是规避了机械唯物论，坚持了辩证唯物论。 </p>
</blockquote>
<h5 id="矛盾诸方面的同一性和斗争性"><a href="#矛盾诸方面的同一性和斗争性" class="headerlink" title="矛盾诸方面的同一性和斗争性"></a>矛盾诸方面的同一性和斗争性</h5><p>矛盾的同一性主要指两个方面: </p>
<ul>
<li>事物发展过程中每一种矛盾的两个方面，各自以和它对立着的方面为自己存在的前提，双方共处于一个统一体中。</li>
<li>矛盾着的双方，依据一定的条件，各向着其相反的方面转化。 </li>
</ul>
<p>列宁对于辩证法有这样的认识:</p>
<blockquote>
<p>辩证法是这样一种学说——它研究对立怎样能够统一的，又怎样成为统一的。 </p>
</blockquote>
<p>同一性的第一个方面是显然的，没有上，就无所谓下，没有福，也就无所谓祸。而正因为矛盾的双方具有同一性，因此在一定条件下彼此是可以相互转化的。</p>
<blockquote>
<p>一切矛盾着的东西，互相联系着，不但在一定条件下共处于一个统一体中，而且在一定条件下相互转化，这就是矛盾同一性的全部意义。</p>
</blockquote>
<p>矛盾诸方面的同一性问题回答清楚了，那么什么是矛盾的斗争性呢？斗争性与同一性又有什么样的关系? </p>
<blockquote>
<p>一切过程都有始有终，一切过程都转化为它们的对立物，<strong>一切过程的常住性是相对的，但是一种过程转化为他种过程的变动性是绝对的。</strong></p>
<p>无论什么事物的运动都采取两种状态，相对地静止的状态和显著地变动的状态。两种状态的运动都是由事物内部包含的两个矛盾着的因素互相斗争所引起的。当着事物的运动在第一种状态的时候，它只有数量的变化，没有性质的变化，所以显出好似静止的面貌。当着事物的运动在第二种状态的时候，它已由第一种状态中的数量的变化达到了某一个最高点，引起了统一物的分解，发生了性质的变化，所以显出显著地变化的面貌。</p>
<p><strong>有条件的相对的同一性和无条件的绝对的斗争性相结合，构成了一切事物的矛盾运动。</strong> </p>
</blockquote>
<h5 id="对抗在矛盾中的地位"><a href="#对抗在矛盾中的地位" class="headerlink" title="对抗在矛盾中的地位"></a>对抗在矛盾中的地位</h5><p>在上一部分已经谈到，矛盾的斗争性是无条件的绝对的， 而:</p>
<blockquote>
<p>对抗是矛盾斗争的一种形式，而不是矛盾斗争的一切形式。</p>
</blockquote>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过阅读毛选第一卷，我们可以发现毛泽东对于时局的把握一直是清晰准确的，不论是对于外部环境的把握，还是党内思想的把握，通过这种精准的把握，其可以及时地修正党的路线、方针，使局势变动到对革命有利的状况下，也正是由于这种清晰的认识和坚定的理论自信，他才能一步步将革命带向胜利。 </p>
<p>同时我们也需要认识到，于革命而言，没有扎实的理论指导，实践便很难取的成功，但扎实的理论来源并不能全部来自于外部，必须要结合实践来对理论进行发展，将认识不断完善，使得认识更加贴近某一特定历史阶段的特定环境，然后在正确的理论指导下，革命便可稳步推进。 </p>
<p>但我们需要清醒地认识到，在毛选中的某些论断是为当时特定的场景来服务的，非常具有特殊性，如果贸然认为那就是圭臬，则极易走向“偏左”的道路；实践论与矛盾论两部分是比较精彩的，也是马克思列宁主义的核心，这些多是方法论层面的东西，理解并认同之后对个人精神世界的塑造是颇有益处的。    </p>
]]></content>
      <categories>
        <category>灵魂雕琢</category>
      </categories>
      <tags>
        <tag>毛选、辩证唯物主义</tag>
      </tags>
  </entry>
  <entry>
    <title>毛选第四卷选读</title>
    <url>/2020/11/30/mao-xuan-di-si-juan-xuan-du/</url>
    <content><![CDATA[<p>因为报名了一个讨论毛选第四卷微沙龙活动(想白嫖咖啡喝)，我也就借此机会读一读毛选第四卷，本次主要读以下三个章节的内容: </p>
<ul>
<li>目前的形势和我们的任务 </li>
<li>论人民民主专政 </li>
<li>丢掉幻想，准备战斗 </li>
</ul>
<span id="more"></span> 
<h4 id="目前的形势和我们的任务"><a href="#目前的形势和我们的任务" class="headerlink" title="目前的形势和我们的任务"></a>目前的形势和我们的任务</h4><blockquote>
<p>这篇文章写于1947年12月25日，此时国内革命战争已经进入战略反攻阶段。</p>
</blockquote>
<p>毛泽东对蒋介石发动战争的性质的定性: </p>
<blockquote>
<p>是一个在美帝国主义指挥之下的反对中国民族独立和中国人民解放的反革命战争。</p>
</blockquote>
<p>1946年7月，蒋介石开始发动全国规模的反革命战争，这场战争，在毛泽东看来: </p>
<blockquote>
<ul>
<li>蒋介石军事力量的优势，只是暂时的现象，只是临时起作用的因素；美帝国主义的援助，也只是临时起作用的因素。</li>
<li>蒋介石战争的反人民的性质，人心的向背，则是经常起作用的因素。 </li>
</ul>
</blockquote>
<p>在第三篇里，毛泽东总结了战略防御阶段解放军取得胜利的战略原因: </p>
<ul>
<li>先打分散和孤立之敌，后打集中和强大之敌。 </li>
<li>先取小城市、中等城市和广大乡村，后取大城市。 </li>
<li>以歼灭敌人有生力量为主要目标，不以保守或夺取城市和地方为主要目标。 </li>
<li>每战集中绝对优势兵力，四面包围敌人，力求全歼，不使漏网。 </li>
<li>不打无准备之仗，不打无把握之仗。 </li>
<li>发扬勇敢战斗、不怕牺牲、不怕疲劳和连续作战的作风。</li>
<li>力求在运动中歼灭敌人。 </li>
<li>在攻城问题上，根据城市状况制定相应的夺取策略。 </li>
<li>以俘获敌人的全部武器和大部人员，补充自己。</li>
<li>善于利用两个战役之间的间隙，休息和整训部队。</li>
</ul>
<p>没有绝对正确的战略，只有相对适合的战略，上述战略之所以能够取得成功，也从侧面反映了国民党军队的一些问题: </p>
<ul>
<li>组织调动困难，将领各怀心意。</li>
<li>过分计较一城之得失，以占领城市多少来衡量作战胜利与否。   </li>
<li>战术上的失当。 </li>
</ul>
<p>总结完了前线战争取得胜利的原因之后，毛泽东也对后方根据地巩固的原因进行了总结; </p>
<blockquote>
<p>土地改革，在抗战之前是没收地主土地给农民，抗战期间改为减租减息，抗战结束后又变为没收地主土地，给农民，这样的措施，一方面是团结了根据地的最广大人群，同时因为土地本身的不可移动性，也进一步巩固了根据地的统治，为了团结最广大人群，在进行土地改革时需格外注意<strong>中农</strong>的意见。</p>
</blockquote>
<p>同时毛泽东也强调了随着党员规模的扩大，党员队伍的自我净化的重要性: </p>
<blockquote>
<p>在党内开展批评和自我批评，彻底地揭发各地组织内的离开党的路线的错误思想和严重现象。全党同志必须明白，解决这个党内不纯的问题，整编党的队伍，使党能够和最广大的劳动群众完全站在一个方向，并领导他们前进，是解决土地问题和支援长期战争的一个决定性的环节。 </p>
</blockquote>
<p>新民主主义革命要消灭的对象: </p>
<blockquote>
<p>只是封建主义和垄断资本主义，只是地主阶级和官僚资产阶级，而不是一般地消灭资本主义，不是消灭上层小资产阶级和中等资产阶级。</p>
</blockquote>
<p>在第八篇里，毛泽东分析了国内战争爆发时的国际形势,回答了这么几个问题: </p>
<blockquote>
<p>第二次世界大战以后的美国帝国主义，是否真如蒋介石和各国反动派所设想的那么强大呢？是否真能像流水一样接济蒋介石和各国反动派呢？ </p>
</blockquote>
<p>在毛泽东看来: </p>
<blockquote>
<p>美国国内国外的各种不可调和的矛盾。就像是一座火山，每天都在威胁美帝国主义。 </p>
</blockquote>
<h4 id="论人民民主专政"><a href="#论人民民主专政" class="headerlink" title="论人民民主专政"></a>论人民民主专政</h4><blockquote>
<p>本篇文章写于1949年6月30日，此时国内战争胜负已经基本尘埃落定。</p>
</blockquote>
<p>毛泽东明确说明: </p>
<blockquote>
<p>消灭阶级，消灭国家权力，消灭党，全人类都要走这一条路，问题只是时间和条件。 </p>
</blockquote>
<p>一个新生的全国性政权即将建立，此时需要展望下一步国家的愿景: </p>
<blockquote>
<p>对于工人阶级、劳动人民和共产党，则不是什么被推翻的问题，而是努力工作，创设条件，使阶级、国家权力和政党自然地归于消灭，使人类进入到大同境遇。</p>
</blockquote>
<p>毛泽东首先回顾了中国鸦片战争以来的救亡图存运动，从最开始的效法西方，到十月革命后马克思列宁主义在中国的广泛传播，20多年的新民主主义革命证明了: </p>
<blockquote>
<p>西方资产阶级的文明，资产阶级的民主主义，资产阶级共和国的方案，在中国人民的心目中，一齐破了产。资产阶级的民主主义让位给工人阶级领导的人民民主主义，资产阶级共和国让位给人民共和国。</p>
</blockquote>
<p>同时毛泽东就一些观点进行了相应的分析: </p>
<ul>
<li>“你们一边倒。”</li>
<li>“你们太刺激了。” </li>
<li>“我们要做生意。” </li>
<li>“不要国际援助也可以胜利。”</li>
<li>“我们需要英美政府的援助。” </li>
<li>“你们独裁。”</li>
</ul>
<p>人民是什么？ </p>
<blockquote>
<p>在中国，在现阶段，是工人阶级，农民阶级，城市小资产阶级和民族资产阶级。</p>
</blockquote>
<p>专政的对象是谁？</p>
<blockquote>
<p>向着帝国主义的走狗即地主阶级和官僚资产阶级以及代表这些阶级的国民党反动派及其帮凶实行专政，实行独裁，压迫这些人，只许他们规规矩矩，不许他们乱说乱动。</p>
</blockquote>
<p>总结来说:</p>
<blockquote>
<p>对人民内部的民主方面和反动派的专政方面，互相结合起来，这就是人民民主专政。</p>
</blockquote>
<ul>
<li>人民民主专政的基础是工人阶级、农民阶级和城市小资产阶级的联盟，而主要是工人和农民的联盟。 </li>
<li>人民民主专政需要工人阶级的领导，因为工人阶级最有远见，大公无私，最富革命的彻底性。</li>
</ul>
<p>党的二十八年，斗争经验总结为一句话，那就是: </p>
<blockquote>
<p>工人阶级(经过共产党)领导的以工农联盟为基础的人民民主专政。 </p>
</blockquote>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>毛选，历史，哲学</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习基础</title>
    <url>/2020/09/02/shen-du-xue-xi-ji-chu/</url>
    <content><![CDATA[<p>近些年来，神经网络算法家族蓬勃发展，本部分主要介绍一下这些算法的一些通用原理基础，该部分按照以下结构组织:</p>
<ul>
<li>神经元模型</li>
<li>多层神经网络</li>
<li><strong>反向传播算法(BP)</strong></li>
<li>网络训练中常见问题</li>
<li>常见网络模型介绍</li>
</ul>
<span id="more"></span>
<h3 id="神经元模型"><a href="#神经元模型" class="headerlink" title="神经元模型"></a>神经元模型</h3><p>时至今日，神经网络已经是一个相当大的、多学科交叉的学科领域，下面给出神经网络的定义：</p>
<blockquote>
<p><strong>神经网络:</strong> 神经网络是由具有适应性的简单单元所组成的广泛并进行互联的网络，它的组织能够模拟生物神经系统对真实世界物体所做出的交互反应。</p>
</blockquote>
<p>神经网络的基本组成成分是神经元模型，即神经网络定义中的“简单单元”。在生物神经网络中，每个神经元与其他神经元相连，当它“兴奋”时，就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位超过了一个“阈值”，那么它就会被激活，向其他神经元发送化学物质。</p>
<p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/Neuro-model1.png" alt="神经元"><br>将生物学概念中的神经元模型可以抽象成如下图所示的数学模型，这就是一直沿用至今的“M-P神经元模型”，在这个模型中，神经元接受到来自$n$个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接进行传递，神经元接收到的总输入值将与神经元的阈值做比较，然后同过“激活函数”处理以产生神经元的输出。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/Neuro-model.jpg" alt="神经元模型"><br>理想的激活函数是阶跃函数，它将输入值映射为输出值0或1，1对应着神经元兴奋，0对应着神经元抑制，然而阶跃函数具有不连续、不光滑等性质，因此实际常用sigmoid函数作为激活函数:</p>
<script type="math/tex; mode=display">
    sigmoid(x) = \frac{1}{1 + e^{-x}}</script><p>sigmoid函数能够将在较大范围内变化的输入值压缩到$(0,1)$输出范围内，因此有时也被称为“挤压函数”。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/act_function.png" alt="激活函数"><br>把许多这样的神经元按照一定的层次结构连接起来，就得到了一个神经网络，尽管神经网络类型有很多，但其组成基本单元几乎都是“M-P神经元模型”。从计算机科学的角度看，我们可以先不考虑神经网络是否真的模拟了神经网络，只需要将一个神经网络视为包含了许多参数的数学模型，这个模型是若干函数，例如$y_j = f(\sum_i w_i x_i - \theta_j)$相互嵌套代入而得，有效的神经网络算法大多以数学证明为支撑。</p>
<h3 id="多层感知机"><a href="#多层感知机" class="headerlink" title="多层感知机"></a>多层感知机</h3><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>在前面已经介绍过感知机模型，感知机模型也可以看作一个以符号函数为激活函数的神经网络，只有两层，一个是输入层，一个是输出层,如下图所示<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/Perceptron.jpg" alt="Perceptron"><br>但是这只是一个线性模型，只能够处理线性可分数据，其学习能力非常有限，甚至对于简单的异或问题都无法解决，更一般的，常见的神经网络是多层结构，如下图所示<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/MLP.png" alt="多层感知机"><br>在多层感知机中，每层神经元与下一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接，这样的神经网络结构通常称为“多层前馈神经网络”，其中输入层神经元接收外界输出，隐层与输出层神经元对信号进行加工，最终结果由输出层神经网络输出；换言之，输入层神经元仅是接受输入，不进行函数处理，隐层与输出层包含功能神经元，一个神经网络只要包含隐层，就可以称为多层网络。神经网络的学习过程，就是根据训练数据来调整神经元之间的连接权以及每个功能神经元的阈值；换言之，神经网络学到的东西，蕴含在连接权与阈值之中。</p>
<h4 id="多层感知机逼近能力"><a href="#多层感知机逼近能力" class="headerlink" title="多层感知机逼近能力"></a>多层感知机逼近能力</h4><p>多层感知机的逼近能力由如下定理保证:</p>
<blockquote>
<p><strong>定理：</strong> 令$\phi(\cdot)$ 为有界、非常量单调递增连续函数，$I<em>p$表示$p$维单位超立方体$[0,1]^p$,$C(I_p)$表示定义在$I_p$上的连续函数构成的集合，则给定任意函数$f \in C(I_p)$和$\epsilon &gt;0$ ,存在整数$M$和一组实常数$\alpha_i,\theta_i,w</em>{ij}$,其中$i=1,2,\dots,M;j=1,2,\dots,p$,使得网络输出:</p>
<script type="math/tex; mode=display">
    F(x_1,x_2,\dots,x_p) = \sum_{i=1}^M \alpha_i \phi(\sum_{j=1}^p w_{ij}x_j - \theta_i)</script><p>可任意逼近$f(\cdot)$,即：</p>
<script type="math/tex; mode=display">
    |F(x_1,x_2,\dots,x_p) - f(x_1,x_2,\dots,x_p)| < \epsilon , \forall (x_1,\dots,x_p) \in I</script></blockquote>
<h3 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h3><p>多层网络的学习能力比单层感知机强得多，欲训练多层网络，则需要更加强大的学习算法，误差逆传播(BP)算法就是其中最杰出的代表，它是迄今为止最成功的神经网络学习算法，现实任务中在使用神经网络时，大多是使用BP算法进行训练。</p>
<p>下面对BP算法做简单推导，给定训练集$D = { (\boldsymbol{x<em>1,y_1}),(\boldsymbol{x_2,y_2}),\dots , (\boldsymbol{x_N,y_N})}$ ,其中$\boldsymbol{x_i} \in \mathbb{R}^d,\boldsymbol{y_i} \in \mathbb{R}^l$,即输入是由$d$个属性描述，输出$l$维实值向量，下面以一个三层前馈网络来进行反向传播算法推导，输入层有$d$个神经元，隐藏层有$q$个神经元，输出层有$l$个神经元。输出层第$j$个神经元的阈值用$\theta_j$表示，隐层第$h$个神经元的阈值用$\gamma_h$表示，输入层第$i$个神经元与隐层第$h$个神经元之间的连接权重为$v</em>{ih}$,隐层第$h$个神经元与输出层第$j$个神经元之间的连接权重为$w<em>{hj}$,记隐层第$h$个神经元接收到的输入为$\alpha_h = \sum</em>{i=1}^d v<em>{ih} x_i$,输出层第$j$个神经元输入为$\beta_j = \sum</em>{h=1}^q w_{hj} b_h $,其中$b_h$为隐层第$h$个神经元的输出。假设隐层和输出层神经元都是用Sigmoid函数作为激活函数。<br>对训练例$(\boldsymbol{x_k,y_k})$,假定网络输出为$\hat{\boldsymbol{y}}_k = (\hat{y}_1^k, \hat{y}_2^k, \dots, \hat{y}_l^k)$,即：</p>
<script type="math/tex; mode=display">
    \hat{y}_j^k = f(\beta_j - \theta_j)</script><p>则网络在$(\boldsymbol{x_k,y_k})$用方差和来定义:</p>
<script type="math/tex; mode=display">
    E_k = \frac{1}{2} \sum_{j=1}^l (\hat{y_j}^k - y_j^k)^2</script><p>首先来考虑对于这样一个三层网络，有多少个参数需要确定，权重参数有$d \times q + q \times l$个,阈值参数有$ q + l$个，因此总共需要学习的参数个数为$(d+l+1)q +l$个，BP是一个迭代学习算法，在每一轮中采用广义的感知机策略(链式法则求梯度)进行参数学习，任意参数$v$的更新估计式为:</p>
<script type="math/tex; mode=display">
    v \leftarrow v + \Delta v</script><p>具体参数的求解其实就是一个链式法则求导的过程，比如以隐藏层到输出层的权重$w<em>{hj}$为例，其实只需要找到从$w</em>{hj}$到误差函数中间有哪些中间变量，然后反向传播时便将误差按照变量路径传递回来即可，对于$w_{hj}$,我们可以写出一条变量路径:</p>
<script type="math/tex; mode=display">
    w_{hj} \rightarrow  \beta_j \rightarrow \hat{y}_j^k \rightarrow E_k</script><p>因此由链式法则，可得:</p>
<script type="math/tex; mode=display">
    \frac{\partial E_k}{\partial w_{hj}} = \frac{\partial E_k}{\partial \hat{y}_j^k} \frac{ \partial \hat{y}_j^k}{\partial \beta_j} \frac{\partial \beta_j}{\partial w_{hj}} = (\hat{y}_j^k - y_j^k) \hat{y}_j^k (1 - \hat{y}_j^k) b_h</script><p>$\frac{ \partial \hat{y}_j^k}{\partial \beta_j} $应用了Sigmoid函数$f’(x) = f(x)(1 - f(x))$的性质，由此梯度下降算法原理，可得：</p>
<script type="math/tex; mode=display">
    \Delta w_{hj} = -\eta \frac{\partial E_k}{\partial w_{hj}}</script><p>下面给出$v_{ih}$的前向变量传递路径：</p>
<script type="math/tex; mode=display">
    v_{ih} \rightarrow \alpha_h \rightarrow b_h \rightarrow \beta_1,\dots,\beta_l \rightarrow \hat{y}_1^k, \hat{y}_2^k \dots \hat{y}_l^k \rightarrow E_k</script><p>此时前向路径共有$l$条，因此计算梯度时需要分别极计算$l$部分，计算结果为:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
         \Delta v_{ih} &= -\eta \frac{\partial E_k}{b_h} \frac{\partial b_h}{\partial \alpha_h} \frac{\partial \alpha_h}{\partial v_{ih}}  \\
         &= -\eta [\sum_{j=1}^l \frac{\partial E_k}{\partial \beta_j} \frac{\partial \beta_j}{\partial b_h}] f'(\alpha_h - \gamma_h) x_i 
    \end{aligned}</script><p>其他参数更新也都是同样思路，在这里便不做过多赘述，其实BP算法就只是应用链式求导法则反向计算梯度(更新权重)的方法。与随机梯度下降以及批梯度下降相对应，BP算法也可以分为标准BP算法(一次更新一个实例)，累积BP算法(一次更新所有样例)，在实际中训练时往往采取折中的策略，每次取一批数据进行权重更新。</p>
<h3 id="网络训练中常见问题"><a href="#网络训练中常见问题" class="headerlink" title="网络训练中常见问题"></a>网络训练中常见问题</h3><p>对于这样一个简单BP网络，在训练中也会面临很多问题，这些问题是神经网络算法所固有的一些问题，很多研究也是以解决这些问题为出发点，这部分主要介绍三个问题:</p>
<ul>
<li>过拟合问题</li>
<li>梯度消失与梯度爆炸</li>
<li>局部极小值问题</li>
</ul>
<h4 id="过拟合问题"><a href="#过拟合问题" class="headerlink" title="过拟合问题"></a>过拟合问题</h4><p>正是由于BP网络具有强大的表示能力，BP神经网络经常遭遇过拟合，即随着训练的进行，训练误差进一步降低，但测试误差却可能上升。有两种策略可以缓解过拟合问题：</p>
<ul>
<li>早停：将数据划分为训练集和验证集，训练集用来计算梯度、更新连接权和阈值，验证集用来估计误差，若训练集误差降低但验证集误差升高，则停止训练，并返回具有最小验证集误差的连接权和阈值。</li>
<li>正则化： 在目标误差函数中增加一个用于描述网络复杂度的部分，例如连接权和阈值的平方和，仍令$E_k$表示第$k$个训练样例上的误差，$w_i$表示连接权和阈值，则对于批反向传播的误差函数可以写为:<script type="math/tex; mode=display">
  E = \lambda \frac{1}{m} \sum_{k=1}^m E_k + (1 - \lambda) \sum_i w_i^2</script>其中$\lambda$用于对经验误差和网络复杂度进行折中，常通过交叉验证法进行估计。</li>
</ul>
<h4 id="梯度消失与梯度爆炸"><a href="#梯度消失与梯度爆炸" class="headerlink" title="梯度消失与梯度爆炸"></a>梯度消失与梯度爆炸</h4><p>我们在反向计算梯度时实际上是一个链式求导的过程，假设有一个层数为5的神经网络(包含输入层和输出层)，假设我们欲更新输入层到第一隐层的一个权重$w$，中间需要经过若干变量($w_1,\dots,w_k$)才能到达损失函数,则进行反向传播时，损失函数$L$对$w$求偏导是一个连乘积的形式：</p>
<script type="math/tex; mode=display">
    \frac{\partial L}{\partial w} = \frac{\partial L}{\partial w_k} \cdot \frac{\partial w_k}{\partial w_{k-1}} \dots \frac{\partial w_1}{\partial w}</script><p>若这些连乘积每一项都大于1，则就出现了梯度爆炸情况，导致参数更新不稳定，若连乘积每一项都小于1，则连乘之后就会是一个非常小的值，也就是说出现了梯度消失。<br>梯度在反向传播过程中，没经过一层就会经过一次对激活函数求导的过程，加入选的是Sigmoid函数作为激活函数，其导数$f’(x) \leq 0.25$,因此随着网络的变深，使用Sigmoid函数作为激活函数会不可避免地导致出现梯度消失。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/sigmoid.png" alt="sigmoid"><br>下面介绍三个解决梯度消失/爆炸问题的思路。</p>
<h5 id="Relu激活函数"><a href="#Relu激活函数" class="headerlink" title="Relu激活函数"></a>Relu激活函数</h5><p>为解决使用Sigmoid激活函数导致梯度消失的问题，在深层神经网络的训练中人们往往采用另一种激活函数——Relu以及它的变形Leakage-Relu，函数图像如下图所示:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/relu.jpg" alt="relu"><br>可以看到，Relu函数在被激活后($&gt;0$),梯度恒为1，既不会导致梯度消失也不会导致梯度爆炸，但relu函数有一个明显的缺点:当relu的输入值为负时，输出始终为0，这样会导致神经元不能够更新参数，也就是该神经元无法学习了，为了解决relu函数这个问题，在relu的负半区引入了一个泄漏值，也就是说当输入小于0时仍旧有一个小的梯度，该泄漏值可以指定也可以作为一个参数与神经网络其他参数一同被学习。</p>
<h5 id="Batchnorm"><a href="#Batchnorm" class="headerlink" title="Batchnorm"></a>Batchnorm</h5><p>机器学习领域有一个非常重要的假设:IID，即独立同分布假设， 假设训练数据和测试数据是满足相同分布的，这也是通过训练数据获得的模型能够在测试集获得好的效果的一个基本保障，而：</p>
<blockquote>
<p><strong>Batchnorm就是在深度神经网络训练过程中使每一层神经网络的输入保持相同分布。</strong></p>
</blockquote>
<p>由于深度神经网络往往具有复杂的网络结构，在进行训练过程中，各层神经元的参数都在变化，导致各层神经元的输入分布不断发生偏移，BN的思想相当直观，之所以训练收敛慢，一般是整体分布逐渐往非线性函数取值区间的上下限两端端靠近，这就导致向后传播时低层神经网络出现梯度消失现象，这是训练神经网络收敛越来越慢的本质原因，而BN就是通过一定规范化手段，把每层神经网络任意神经元的输入值强行拉回到均值为0，方差为1的正态分布，这样使得激活函数的输入落在非线性函数对输入较为敏感的区域(以Sigmoid函数为例，落在0附近区域)，这样进行梯度反向传播时求导得到的梯度值就会较大，一定程度上缓和了梯度消失现象。</p>
<p>但是很明显，从Sigmoid函数图像可以看出，0附近区域其实是接近线性的，如果把所有的输入都拉到Sigmoid函数的线性区域内，那么不就相当于是激活函数是线性函数了么，而我们知道多层线性网络与一层线性网络其实是等价的，所以BN为了保持激活函数的非线性，对norm之后的输入又做了一步变换:</p>
<script type="math/tex; mode=display">
    y_i = \gamma \hat{x}_i +    \beta</script><p>每个神经元增加了两个参数：尺度参数$\gamma$，偏移参数$\beta$,这等价于让输入从线性区域向非线性区域移动了一点，引入这两个参数本质上是想找到一个线性和非线性的平衡点，使得网络既具有非线性的强表达能力，又在一定程度上减轻了梯度消失问题。<br>下面给出Batchnorm的具体流程:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/BN.png" alt="Batchnorm"></p>
<h5 id="残差结构"><a href="#残差结构" class="headerlink" title="残差结构"></a>残差结构</h5><p>首先来谈一谈深层网络的退化问题，理论上来说，深层网络的性能应当不会比浅层网络性能更差，因为深层网络可以考虑对浅层网络进行拷贝，然后剩下来的层作为一个恒等映射，这样最起码深层网络的性能应当与浅层网络性能一致，然而事实却并非这样，实验表明，深层网络表现并不总是优于浅层网络。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/deep.png" alt="网络性能对比"></p>
<p>深度网络的退化说明深度网络不易训练，前面讨论到深层网络往往并不能够通过建立恒等映射的形式来达到与浅层网络相同的性能，因此何凯明等考虑显式的引入该恒等映射，而让中间的网络学习一个残差，假设我们希望一个堆叠非线性层(stacked nonlinear layers)学习的映射是$\mathcal{H(x)}$,我们现在让该堆叠非线性层学习另一个映射$\mathcal{F(x)} = \mathcal{H(x)} - x$，通过$\mathcal{F(x)}+x$来重构期望映射， 而在网络中实现这个目的的操作则是“跳连”(shortcut connection)，如下图所示：<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/res.png" alt="resnet"></p>
<p>上图所示的结构一般被称为一个残差单元，下面我们来仔细讨论下这样的结构为什么可以解决梯度消失问题，假设上述残差单元的输入为$x$,则残差单元的输出可以表示为:</p>
<script type="math/tex; mode=display">
    \boldsymbol{y} = \mathcal{F(\boldsymbol{x},\{(\boldsymbol{W_i})\})} + \boldsymbol{x}，i=1,2,\dots,k</script><p>$k$表示该残差单元包含几个权重层，需要说明的是，一个残差单元至少应该包含两个层，若只有一个层，则会出现:</p>
<script type="math/tex; mode=display">
    \boldsymbol{y} = \boldsymbol{W_1^T x + x} = \boldsymbol{(W_1^T + 1)x}</script><p>而若包含两层，则残差单元的输出写做:</p>
<script type="math/tex; mode=display">
    \boldsymbol{y} = \boldsymbol{W_2^T \sigma(W_1^Tx) + \boldsymbol{x}}</script><p>其中,假设$\boldsymbol{x} \in \mathbb{R}^d$,残差单元第一层有$n_1$个神经元，则上式中$\boldsymbol{W_1} \in \mathbb{R}^{d \times n_1}, \boldsymbol{W_2} \in \mathbb{R}^{n_1 \times d}$,损失函数到$\boldsymbol{y}$的梯度为$\frac{\partial L}{\partial \boldsymbol{y}}$,那么我们可以用该梯度表示$\frac{\partial L}{\partial \boldsymbol{x}}$:</p>
<script type="math/tex; mode=display">
    \frac{\partial L}{\partial \boldsymbol{x}} = \frac{\partial L}{\partial \boldsymbol{y}} \frac{\partial \boldsymbol{y}}{\partial \boldsymbol{x}} = \frac{\partial L}{\partial \boldsymbol{y}} (\boldsymbol{I} +  \boldsymbol{(W_1 W_2)^T})</script><p>其中激活函数取得Relu激活函数，可以看到，在进行反向传播过程中，到$\boldsymbol{y}$的梯度会无损再传递到其前层的$\boldsymbol{x}$，哪怕是残差梯度等于0或者是一个大于$-1$的负值，也可以保证有梯度传递到前面的层，这使得Resnet相对于普通的神经网络更不容易发生梯度消失现象。<br>何凯明博士这篇提出Resnet的论文也因为其突出贡献获得了2016年CVPR最佳论文奖，整篇论文非常简洁易懂，非常建议大家去读一下，这里给出论文链接<a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf">Deep Residual Learning for Image Recognition</a></p>
<h4 id="局部极小值问题"><a href="#局部极小值问题" class="headerlink" title="局部极小值问题"></a>局部极小值问题</h4><p>神经网络训练过程其实就是一个参数寻优的过程，反向传播算法可以看作是在神经网络这种架构下梯度下降法的实现形式，因此最终收敛的点往往具有梯度为0的特点，这是一个局部极小点，若优化问题是一个凸问题，则局部极小点同时也是全局极小值，而神经网络的优化大多数情况都是一个非凸优化问题，这也就意味着最终训练收敛的点大概率只是一个“局部极小值点”，而非“全局极小值”点,如下图所示:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/min.png" alt="局部极小与全局极小"><br>在现实任务中，人们常采用以下策略试图跳出局部极小，到达全局极小：</p>
<ul>
<li>以多组不同参数值初始化多个网络，按标准方法训练后，取其中误差最小的解作为最终参数，这相当于从多个不同的初始点开始搜索，这样就可能陷入不同的局部极小，从中进行选择有可能获得更接近全局最小的结果。</li>
<li>使用“模拟退火”策略，模拟退火在每一步都以一定概率接受比当前解更差的结果，从而有助于跳出局部极小，在迭代过程中，接受“次优解“的概率要随着时间推移而逐渐降低，从而保证算法稳定。</li>
<li>使用随机梯度下降(SGD)算法，即便陷入了局部极小点，所计算出的梯度仍可能不为0，这样就有机会跳出局部极小继续搜索。</li>
</ul>
<h3 id="常见网络模型介绍"><a href="#常见网络模型介绍" class="headerlink" title="常见网络模型介绍"></a>常见网络模型介绍</h3><p>神经网络家族成员庞杂，除了前面介绍的BP神经网络外，还有很多类型的神经网络，这部分就一些常见的做简要介绍，后面用到的话再补充。</p>
<h4 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h4><p>卷积神经网络在图像处理领域有着广泛应用，一个完整的卷积神经网络其实包含两个部分:</p>
<ul>
<li><strong>特征提取</strong></li>
<li>分类</li>
</ul>
<p>后面分类所用的网络其实就是前面所讨论的全连接神经网络或者它的一些变形，卷积神经网络名字的由来则主要是在特征提取阶段，下面就以图片处理为例重点讲解一下特征提取过程。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/CNN.png" alt="CNN"><br>其实我们不论做什么样的机器学习任务，都可以分为特征提取和算法学习两个阶段，而CNN则将这两个阶段结合了起来，然后一起优化，是一种“end2end”的算法，对于一张$n \times n$像素的黑白图像，其实该图像所有信息都包含在$n \times n$个值当中，若要完成一个分类任务，最简单粗暴的方法可能是直接将这$n \times n$个值直接作为特征输入到到全连接层来进行分类，但是这样做有以下两个缺点:</p>
<ul>
<li>输入特征维度非常高，因此网络的规模会很大，参数量会非常大，计算开销会非常大，训练困难。</li>
<li>单个像素值本身并不具备什么意义，最终神经网络结果很有可能并不理想。</li>
</ul>
<p>卷积神经网络的出发点也是为了解决这样一个问题，特征提取部分主要包含三种操作:</p>
<ul>
<li>卷积层</li>
<li>ReLu层</li>
<li>池化层</li>
</ul>
<h4 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h4><p>一个图像中的单个像素点并不具备什么含义，但是一簇像素点(比如一幅图像中的眼睛区域)可能就具备某种含义了，而卷积层的出发点就是希望能够提取图像中某部分区域的信息，而具体操作则是通过卷积核与图像区域进行加权求和，这其实本质上就是一个线性映射，如下图所示，图像处理中的卷积与信号处理中的卷积不同之处在于其仅仅只有加权求和操作，而并没有翻转操作。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/conv.png" alt="图像卷积"><br>上图中所示的是一个$3 \times 3$的卷积核，可以看出该卷积核对于一个区域左上角像素与有下降像素更加关注，而一正一负操作则表明该卷积核更关注的是左上角像素值与由下角像素值的差。选用不同的卷积核可以从原始图像中提取不同的特征，因此在实际应用中，一般会选用多个大小不一的卷积核以全面捕捉不同大小的区域所包含的信息。<br>在进行卷积操作时，有时会对图像周围区域进行填充，以提高卷积操作对图像边缘特征提取的能力。</p>
<h4 id="ReLu层"><a href="#ReLu层" class="headerlink" title="ReLu层"></a>ReLu层</h4><p>经过Relu层则主要是为了实现非线性变换，以提高网络的表示能力，比如上图中的-8经过ReLu层之后就变成了0。</p>
<h4 id="池化层-下采样层"><a href="#池化层-下采样层" class="headerlink" title="池化层(下采样层)"></a>池化层(下采样层)</h4><p>经过卷积操作之后，我们得到了一张张有着不同值的特征图(feature map)，尽管数据量比原图少了很多，但还是过于庞大，而池化层的作用就是进一步减少数据量,扩大特征图的感受野。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/Pooling.png" alt="池化"><br>池化一般有两种操作，一种是Max pooling,一种是Average pooling,前一种就是取一个区域的最大值，而后一种则是取一个区域的平均值。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>以上这三种操作就是就是卷积神经网络特征提取部分的三个基本单元，对这三种基本单元进行组合便可以组成特征提取部分，需要说明的是卷积神经网络中一个非常重要的操作就是<strong>共享权重</strong>：</p>
<blockquote>
<p>假设输入图像为$32 \times 32$,用两个$5 \times 5$卷积核，则一幅图片经过卷积操作之后变为$28 \times 28$的特征图，该特征图中每个神经元还有一个偏置，因此连接数为:</p>
<script type="math/tex; mode=display">
    (5 \times 5 + 1) \times 28 \times 28 \times 2</script><p>但在卷积神经网络中，一个特征图共用一套权值，因此实际需要更新的连接权数为:</p>
<script type="math/tex; mode=display">
    (5 \times 5 +1 )\times 2</script></blockquote>
<p>最后给出经过卷积和池化操作后特征图尺寸变化计算公式:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &卷积： Size_{out} = (Size_{in} - Kernel_{conv} + 2*Padding)/Stride + 1 \\
        &池化： Size_{out} = (Size_{in} - Kernel_{pooling}) /stride + 1
    \end{aligned}</script><h3 id="循环神经网络-RNN"><a href="#循环神经网络-RNN" class="headerlink" title="循环神经网络(RNN)"></a>循环神经网络(RNN)</h3><h4 id="标准循环神经网络"><a href="#标准循环神经网络" class="headerlink" title="标准循环神经网络"></a>标准循环神经网络</h4><h5 id="直观理解"><a href="#直观理解" class="headerlink" title="直观理解"></a>直观理解</h5><p>在实际应用中，我们常常会碰到序列数据，这类数据的特点是相邻数据点之间有着较强的联系，比如语句数据、车辆轨迹数据、财经数据等，传统的神经网络已经有着很强的表示能力，但传统的神经网络只能够单独地处理一个接一个输入，前一个输入与后一个输入并没有任何关系，但是对于序列数据，很明显我们对于后一个数据点的预测是依赖于前面的数据的，下面举一个简单的🌰：</p>
<blockquote>
<p><strong>词性标注任务：</strong><br><strong>任务输入：</strong> 我/吃/苹果<br><strong>任务输出：</strong> 我/nn 吃/v 苹果/nn<br>对于这样一个任务，我们当然可以直接用普通的神经网络来做，输入为单独的单词，输出为词性标注好的单词。<strong>但是很明显，一个句子中，前一个单词其实对当前单词的词性预测有很大的影响，比如预测“苹果”词性的时候，由于前面的“吃”是一个动词，那么“苹果”作为名次的概率就会远大于动词的概率，因为动词后面接名次很常见，而动词后面接动词不常见</strong></p>
</blockquote>
<p>为了解决这样类似的问题，更好地处理序列信息，循环神经网络就诞生了，下图就是一个简单的RNN的示意图。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/RNN.png" alt="RNN"><br>如果将上图中$h^{(t-1)} \rightarrow h^{(t)}$的连线断开，那么一个RNN就被分解成了若干独立的三层神经网络，现在加入了隐层之间的连接，就使得时刻靠后的神经网络的输出会依赖于前面时刻神经网络的值，以$O^{(t        )}$为例，往前回推，可以写出一条变量链如下:</p>
<script type="math/tex; mode=display">
    O^{(t)} \rightarrow h^{(t)} \rightarrow x^{(t)},h^{(t-1)} \rightarrow x^{(t)}, x^{(t-1)},h^{(t-2)} \rightarrow \dots</script><p>从该变量链可以看出，$t$时刻的预测输出是依赖于其之前所有的输入。</p>
<h5 id="权重共享"><a href="#权重共享" class="headerlink" title="权重共享"></a>权重共享</h5><p>在RNN中也沿用了权重共享的思想，可以看到，不同时刻的神经网络共享输入权重矩阵$\boldsymbol{U}$，输出权重矩阵$\boldsymbol{V}$以及循环权重矩阵$\boldsymbol{W}$,下面简单分析下这样做的好处：</p>
<ul>
<li>运算量减少，模型训练加快</li>
<li>序列长度可以不固定，模型更具泛化能力</li>
</ul>
<p>在进行BP的时候，由于权重共享，因此误差传递每个时刻都会有，假设序列长度为$T$，要对$\boldsymbol{U}$进行权重更新，可以写出误差传递链为：</p>
<script type="math/tex; mode=display">
    E \rightarrow E_1, E_2,\dots E_T \rightarrow O^{(1)},O^{(2)},\dots,O^{(T)} \rightarrow  \rightarrow h^{(1)}, h^{(2)}, \dots, h^{(T)} \rightarrow x^{(1)}, x^{(2)},\dots,x^{(T)}</script><p>当然，在反向传播的过程中，$h^{t}$到$h^{(t-1)},\dots,h^{(1)}$都是有着传播链条的， 是一个连乘积求和的形式,下面给出$\frac{\partial L_t}{\partial U}$的公式:</p>
<script type="math/tex; mode=display">
    \frac{\partial L_t}{\partial U} = \sum_{k=0}^t \frac{\partial L_t}{\partial O^{(t)}}  \frac{\partial O^{(t)}}{\partial h^{(t)}}(\prod_{j=k+1}^t \frac{\partial h^{(j)}}{\partial h^{(j-1)}}) \frac{\partial h^{(k)}}{U}</script><h5 id="RNN梯度消失"><a href="#RNN梯度消失" class="headerlink" title="RNN梯度消失"></a>RNN梯度消失</h5><p>从上面的梯度表达式可以看出，$L_t$对输入矩阵$U$的梯度由它$t$项组成，由于有着激活函数存在，因此对靠前时刻的$U$求导是连乘积形成，因此随着序列的增长，累加项中距离当前时刻较远的时刻的项会出现梯度消失或者梯度爆炸，这就导致梯度被近距离梯度主导，模型难以学得远距离的依赖关系。</p>
<h4 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h4><p>前面讲到普通的RNN由于存在对远距离依赖的梯度消失或者爆炸现象，因此对于长序列表现并不是很好，为解决这一问题，LSTM便诞生了，首先给出LSTM的结构图。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/LSTM.png" alt="LSTM"><br>与标准RNN相比，LSTM增加了三个门控组建，输入门控制当前时刻$t$的计算输出，<strong>与普通RNN相比，LSTM还另外又用遗忘门来控制之前时刻的细胞状态相连接，这个操作类似于前面介绍的Resnet的跳连(skip connection)操作，通过这样的跳连操作，使得若遗忘门初始化较大(接近1)，则在误差反向传播时，可以通过该通路无损地传递到前面时刻，这在一定程度上缓解了RNN中的梯度消失问题，使得LSTM可以处理较长序列</strong>。下面重点讨论下为何引入这三个门控：</p>
<ul>
<li>输入门$i_t$：输入门控制当前词$\boldsymbol{x_t}$融入细胞状态$\boldsymbol{c_t}$, 在做句子理解任务时，当前词$\boldsymbol{x_t}$可能对整句话的意思很重要，也可能并不重要，要不要将它加入输出中则是由输入门来进行控制。</li>
<li>遗忘门$f<em>t$：$f_t$控制上一时刻的细胞状态$\boldsymbol{c</em>{t-1}}$融入当前细胞状态$\boldsymbol{c_t}$。在理解一句话时，当前词$\boldsymbol{x_t}$可能继续延续上文的意思进行叙述，也可能从当前词$\boldsymbol{x_t}$开始叙述新的内容，与上文无关。</li>
<li>输出们$o_t$：输出门的目的是从细胞状态$\boldsymbol{c_t}$产生隐层单元$\boldsymbol{h_t}$,细胞状态中的信息并非都与输出隐层状态有关，其中可能包含了很多对$\boldsymbol{h_t}$无用的信息，通过输出门可以对细胞状态中的信息进行筛选。</li>
</ul>
<p>总结而言，门机制的引入带来了两点好处：</p>
<ul>
<li>门机制极大地减轻了梯度消失问题，降低了调参难度</li>
<li>门机制引入了特征过滤，将有用的特征保存，没用的特征丢弃，这极大地丰富了我们向量的表示信息。<br>同样RNN的参数共享思想在LSTM中也得到了继承，但由于引入了三个门控组件，LSTM参数量相较于RNN增多，训练速度较RNN要慢一些。</li>
</ul>
<h4 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h4><p>GRU的全称是 Gated Recurrent Unit(门控循环单位)，与LSTM相比，GRU仅仅只有两个门控组件，一个是重置门$r_t$,一个是更新门$z_t$。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/gru.png" alt="GRU"></p>
<p>从上图可以看出，gru实际上就是LSTM的变形，取消了LSTM中的细胞状态(cell state)，只用隐藏状态(hidden state)，并使用更新门来代替LSTM中的输入门与遗忘门，取消了输出门，加入了重置门。实验证明，gru效果与LSTM差不多，但是参数更少，训练计算开销小，训练速度更快。</p>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>BP算法， 深度学习， CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>线性判别分析</title>
    <url>/2020/09/01/te-zheng-ti-qu-yu-te-zheng-xuan-ze/</url>
    <content><![CDATA[<p>线性判别分析(LDA)是一种经典的线性学习方法，在二分类问题上最早由fisher提出，因此线性判别分析又称Fisher线性判别，该部分按照以下结构组织:</p>
<ul>
<li>LDA算法思想</li>
<li>LDA算法推导</li>
<li>多分类任务</li>
</ul>
<span id="more"></span> 
<h3 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h3><p>LDA的思想非常朴素：给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能接近、异类样例的投影点尽可能远离，在对新的样本进行分类时，首先将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/LDA.png" alt="LDA"></p>
<h3 id="理论推导"><a href="#理论推导" class="headerlink" title="理论推导"></a>理论推导</h3><h4 id="投影方向求解"><a href="#投影方向求解" class="headerlink" title="投影方向求解"></a>投影方向求解</h4><p>假设共有$N$个样本点$x_1,x_2,\dots,x_N$,其中有$N_1$个样本属于类别1，$N_2$个样本属于类别2，$N_1 + N_2 = N$, 记第$i$类样本点的均值为$\mu_i$,协方差矩阵为$\Sigma_i$,则有：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \mu_i &= \frac{1}{N_i} \sum_{x_i \in \mathcal{C_i}} x_i \\
        \Sigma_i &= \frac{1}{N_i} \sum_{x_i \in \mathcal{C_i}} (x_i - \mu_i)(x_i - \mu_i)^T
    \end{aligned}</script><p>当将这些样本点向$w$投影后，投影后得到的点为$\tilde{x}_i = w^T x$,记此时类别$i$的均值为$\tilde{\mu}_i$,方差为$\sigma^2_i$,由均值方差计算公式可得:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \tilde{\mu}_i &= \frac{1}{N_i} \sum_{x_i \in \mathcal{C_i}} \tilde{x}_i = w^T \frac{1}{N} \sum_{x_i \in \mathcal{C_i}}  x_i = w^T \mu_i  \\
        \sigma^2_i &= \frac{1}{N_i} \sum_{x_i \in \mathcal{C_i}}(\tilde{x}_i - \tilde{\mu
        }_i)^2 = \frac{1}{N_i} \sum_{x_i \in \mathcal{C_i}} (w^T x_i - w^T \mu_i)^2 \\
                &= w^T [\frac{1}{N_i} \sum_{x_i \in \mathcal{C_i}} (x_i - \mu_i)(x_i - \mu_i)^T] w \\
             &= w^T \Sigma_i w
    \end{aligned}</script><p>LDA有两个目标，一个是同类的点投影后尽可能接近，另一个目标则是不同类的点尽可能远离：</p>
<ul>
<li>第一个目标我们通过投影后各类点的方差来进行刻画，使同类点的方差尽可能小:<script type="math/tex; mode=display">
  \min \quad w^T \Sigma_1 w + w^T \Sigma_2 w</script></li>
<li>第二个目标通过不同类的均值尽可能远来进行刻画,使不同类的均值尽可能远:<script type="math/tex; mode=display">
  \max \quad (w^T \mu_1 - w^T \mu_2)^2 = w^T (\mu_1 - \mu_2)(\mu_1 - \mu_2)^T w</script></li>
</ul>
<p>这两个目标可以通过一个目标函数来刻画：</p>
<script type="math/tex; mode=display">
    \max \quad \frac{w^T (\mu_1 - \mu_2)(\mu_1 - \mu_2)^T w}{w^T \Sigma_1 w + w^T \Sigma_2 w }</script><p>下面做如下标记,记$S_w = \Sigma_1 + \Sigma_2$为类内离散度矩阵，记$S_b = (\mu_1 - \mu_2)(\mu_1 - \mu_2)^T$ 为类间离散度矩阵，由此便得目标函数形式为:</p>
<script type="math/tex; mode=display">
    \max \quad \frac{w^T S_b w}{w^T S_w w}</script><p>这是一个广义瑞利熵形式的优化问题，因为分子分母均是$w$的二次项，因此该优化问题的解仅与$w$的方向有关(因为用$cw$ 替代$w$并不影响目标函数的值)，不失一般性，可以限制$w^T S_w w = 1$，上述优化问题可以写为:</p>
<script type="math/tex; mode=display">
    \max \quad w^T S_b w  \quad s.t. \quad w^T S_w w = 1</script><p>该优化问题可以通过拉格朗日乘子法来进行求解,首先写出拉格朗日函数：</p>
<script type="math/tex; mode=display">
    L(w,\lambda) = w^T S_b w - \lambda (w^T S_w w - 1)</script><p>上式对$w$求导可得:</p>
<script type="math/tex; mode=display">
    \frac{\partial L(w, \lambda)}{\partial w} = S_b w - \lambda S_w w</script><p>令偏导等于0，可得$w$应当满足条件:</p>
<script type="math/tex; mode=display">
    S_b w = \lambda S_w w</script><p>其中$S_b w = (\mu_1 - \mu_2)(\mu_1 - \mu_2)^Tw = c(u_1 - u_2)$,又因为前面讨论过优化目标的取值仅仅与$w$的方向有关，因此不妨取$c = \lambda$,可得:</p>
<script type="math/tex; mode=display">
    \mu_1 - \mu_2 = S_w w</script><p>因此可得最终$w$最优取值:</p>
<script type="math/tex; mode=display">w^\ast = S_w^{-1}(\mu_1 - \mu_2)</script><p>这里需要说明一下，因为从前面我们可以推出这样一个表达式$S_w^{-1} S_b w = \lambda w$,这说明$w$应当是矩阵$S_w^{-1} S_b$的特征值，目标函数最大值应当是该矩阵的最大的特征值，最优$w$应当是该最大特征值所对应的特征向量，但后面求解为何没有没有从这个角度入手，这是该问题的特殊性，为解释这一点，首先看$S_b$表达式:</p>
<script type="math/tex; mode=display">
    S_b = (\mu_1 - \mu_2)(\mu_1 - \mu_2)^T</script><p>这说明矩阵$S_b$的秩等于1($\mu_1 \neq \mu_2$),所以$S_w^{-1}S_b$秩也为1，这说明该矩阵有且仅有一个大于0的特征值，前面的推导相当于是构造性的给出了该最大特征值及对应特征向量表达式,将$w^\ast$代入$S_w^{-1}S_b w$:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
         S_w^{-1} S_b w^\ast &= S_w^{-1} (\mu_1 - \mu_2)(\mu_1 - \mu_2)^T S_w^{-1}(\mu_1 - \mu_2) \\
         &= C S_w^{-1}(\mu_1 -\mu_2)
    \end{aligned}</script><p>其中$C = (\mu_1 - \mu_2)^TS_w^{-1}(\mu_1 - \mu_2) &gt;0 $($S_w$对称且可逆，推出其正定)，这说明$S_w^{-1}S_b$的最大特征值就是$C$,对应的特征向量刚好是$w^\ast$!<br>考虑到数值的稳定性，在实践中往往会首先对$S_w$进行特征值分解$S_w = U \Sigma U^T$,然后再求逆。</p>
<h4 id="在线分类"><a href="#在线分类" class="headerlink" title="在线分类"></a>在线分类</h4><p>在得到最佳投影向量后，需要设定一个策略，来对新来的样本进行分类，该策略选择通常有以下几种:</p>
<ul>
<li>设定阈值，阈值选择通常有以下两种:<ul>
<li>均值取平均<script type="math/tex; mode=display">t = \frac{\tilde{\mu}_1 + \tilde{\mu}_2}{2}</script></li>
<li>根据样本点个数进行加权<script type="math/tex; mode=display">t = \frac{N_2 \tilde{\mu}_1 + N_1 \tilde{\mu}_2}{N_1 + N_2}</script></li>
</ul>
</li>
<li>在一维上估计概率密度函数，用Bayes决策方法分类<h3 id="多分类任务"><a href="#多分类任务" class="headerlink" title="多分类任务"></a>多分类任务</h3>LDA 也可以推广到多分类任务中，假定存在$N$类，且第$i$类的样本数为$m_i$,首先定义全局散度矩阵:<script type="math/tex; mode=display">
  S_t = S_w + S_b = \sum_{i=1}^m(x_i - \mu)(x_i - \mu)^T</script>其中$\mu$ 是所有样本点的均值，将类内离散度矩阵定义为每个类别的离散度矩阵之和:<script type="math/tex; mode=display">
  S_w = \sum_{i=1}^N S_{w_i}, \quad S_{w_i} = \sum_{x \in \mathcal{X_i}} (x - \mu_i)(x - \mu_i)^T</script>然后求出类间离散度矩阵表达式:<script type="math/tex; mode=display">
  S_b = S_t -S_w = \sum_{i=1}^N m_i(\mu_i - \mu)(\mu_i - \mu)^T</script>优化目标函数可以写成:<script type="math/tex; mode=display">
  \max_{W} \frac{tr(W^T S_b W)}{tr(W^T S_w W)}</script>该问题的求导与前面一样，同样根据$W$的尺度不变性将上述优化问题转化为：<script type="math/tex; mode=display">
  \max_{W} \quad tr(W^T S_b W) \quad s.t. tr(W^T S_w W) = 1</script>应用拉格朗日乘子法，并对$W$求导令导数为0可得:<script type="math/tex; mode=display">
  S_b W = \lambda S_w W</script>$W$的闭式解则是$S_w^{-1} S_b$的$d’$个最大非零广义特征值所对应的特征向量组成的矩阵，需要注意的是最终降的维数应当满足$d’ \leq N-1$,这是因为矩阵$S_b$本身最大只有$N-1$维，因此$S_w^{-1}S_b$至多有$N-1$个非零特征值。<br>若将$W$视为一个投影矩阵，则多分类LDA相当于将样本投影到$d’$空间，$d’$通常远小于数据原有的属性数$d$,于是可以通过这个投影来达到讲维的目的，同时这个过程中也应用了类别的信息，因此$LDA$也常被视为一种经典的监督降维技术。</li>
</ul>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>线性判别分析</tag>
      </tags>
  </entry>
  <entry>
    <title>生成对抗网络GAN</title>
    <url>/2020/09/09/sheng-cheng-dui-kang-wang-luo-gan/</url>
    <content><![CDATA[<p>这一部分介绍一种特殊的神经网路模型——生成对抗网络(GAN)，生成对抗网络由<a href="https://en.wikipedia.org/wiki/Ian_Goodfellow">Lan Goodfellow</a>于2014年提出，该算法在形式上表现为两个神经网络的彼此对抗，对于生成对抗网络，我们可以从以下几个角度来对其进行限定：</p>
<ul>
<li><strong>本质：</strong> 学习训练数据集的分布  </li>
<li><strong>作用：</strong> 产生新的样本，对于小样本任务可以起到数据增强的作用 </li>
<li><strong>实现形式：</strong> 两个神经网络彼此对抗 </li>
</ul>
<p>本文按照以下结构进行组织:</p>
<ul>
<li>GAN算法思想</li>
<li>GAN背后数学推导  </li>
<li>GAN<code>pytorch</code>实现 </li>
</ul>
<span id="more"></span>
<h3 id="GAN-算法思想"><a href="#GAN-算法思想" class="headerlink" title="GAN 算法思想"></a>GAN 算法思想</h3><p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/GAN.jpg" alt="GAN"><br>考虑这样一个场景，一个小镇里有一个造假钞的人，同时有一个警察，它们两个各自的目标分别是：</p>
<ul>
<li><strong>罪犯：</strong> 不断提高自己的造假钞技术，使得自己的假钞足以以假乱真，让警察鉴别不出来</li>
<li><strong>警察：</strong> 不断提高自己的鉴别水平，能够准确地识别小偷制造的假钞</li>
</ul>
<p>从博弈论的角度来看，这其实是一个零和博弈：</p>
<blockquote>
<p>小偷的造假技术越高超，则警察鉴别起来就越困难;反之，警察的鉴别技术越高超，则小偷造出能欺骗过警察的假钞就更加困难，在对抗中，两个人都在变强。</p>
</blockquote>
<p>接下来我们分析构想一个场景，我们有一组数据，但是数据的量不足，我们期望能够找到这样一个”造假数据”的人帮助我们产生一些新的图像，以达到数据增强的目的。但在这个”造假数据”的人造出一个假数据之后，我们需要判断一下这个数据到底合不合格，因此我们就需要另外一个鉴别”假数据”的”警察”。 </p>
<p>其实我们的本质目的是为了<strong>造假数据</strong>,但这个任务若无监督是很难进行下去的，因此我们需要为其提供一个”警察”对其进行监督，因此我们就需要有两个学习器，一个学习如何生成”假数据”，另一个则需要学习如何判别出这些”假数据”，在这两个学习器博弈的过程中我们最终得到了一个”造假数据”比较高超学习器。</p>
<h3 id="GAN-背后数学推导"><a href="#GAN-背后数学推导" class="headerlink" title="GAN 背后数学推导"></a>GAN 背后数学推导</h3><blockquote>
<p><strong>沃兹基</strong>曾经说过：算法思想也就图一乐，真涨姿势还是要看数学推导</p>
</blockquote>
<h4 id="从最大似然估计谈起"><a href="#从最大似然估计谈起" class="headerlink" title="从最大似然估计谈起"></a>从最大似然估计谈起</h4><p>因为我们本质上是希望能够得到一个学习器，使得其产生的数据的能够与训练集数据同分布，那么数学推导就从分布入手，假设训练集数据概率分布为$p(x|\theta)$,其中$\theta$为该概率分布所依赖的参数，当我们得到一组数据$X = (x_1,x_2,\dots, x_N)$时，我们想要对参数进行估计，那么此时就要祭出已经老生常谈的<strong>最大似然估计</strong>，假设样本独立同分布，则写出似然函数如下:</p>
<script type="math/tex; mode=display">
    L(X|\theta) = \prod_{i=1}^N p(x_i | \theta)</script><p>而$\theta$的求解其实就是一个优化问题:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \theta^* &= argmax L(X|\theta) \\
        &= argmax \ln L(X|\theta) \\  
        &= argmax \frac{1}{N} L(X|\theta) \\
        &= argmax \frac{1}{N} \sum_{i=1}^N \ln p(x_i|\theta) \\
        &= argmax E_{x \sim p(x)} \ln p(x|\theta)  \\
        &= argmax \int_{x} p(x) \ln p(x|\theta) dx
    \end{aligned}</script><p>这里需要特别说明一下这一步：</p>
<script type="math/tex; mode=display">
    argmax \frac{1}{N} \sum_{i=1}^N \ln p(x_i|\theta) \Leftrightarrow argmax E_{x \sim p(x)} \ln p(x|\theta)</script><p>当样本数量足够大时，空间中每个样本点都被覆盖，而具体空间中某一个点$x<em>i$会落入多少样本点则取决于数据分布$p(x)$在该点概率密度函数的大小，换句话说，如果从采样的角度，要对某点的概率密度函数进行估计，那么只需要原始数据进行采样，采样$N$个点，若最终有$n</em>{x_i}$个点落在了$x_i$处，那么该点的概率密度函数就可以估计为:</p>
<script type="math/tex; mode=display">
    p(x_i) = \frac{n_{x_i}}{N}</script><p>于是上面的等价性也是可以按照这种思想推导出来：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \lim_{N \rightarrow \infty} \frac{1}{N} \ln p(x_i|\theta) &= \sum_{x} \frac{n_{x}}{N} \ln p(x_i|\theta)  \\
        &= \int_x p(x) \ln p(x|\theta)  dx  \\
        &= E_{x \sim p(x)} \ln p(x|\theta)  
    \end{aligned}</script><p>最大似然函数估计的目的是找到一组最合适的参数$\theta$使得分布$p(x|\theta)$更加符合数据分布，但是能够应用最大似然估计的场合一般是对数据分布有一个假设，这样才有参数可以优化，搜索空间限制在$\mathcal{p(x|\theta)}$,现在我们将这个约束去掉，在所有可能分布中找到一个分布$q(x)$,使得$q(x)$能够尽可能接近原始数据分布$p_{data}(x)$。 至此我们证明了：</p>
<script type="math/tex; mode=display">
    \theta^* = argmax L(X|\theta)  \Leftrightarrow  argmax E_{x \sim p(x)} \ln q(x)</script><h4 id="最大似然估计与KL散度"><a href="#最大似然估计与KL散度" class="headerlink" title="最大似然估计与KL散度"></a>最大似然估计与KL散度</h4><p>紧接上文，我们来看下$E_{x \sim p(x)} \ln q(x)$:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
    argmax_{q(x)}    E_{x \sim p(x)} \ln q(x) &= argmax_{q(x)}\int_x p(x) \ln q(x) dx  \\ 
    &= argmin_{q(x)} -\int_x p(x) \ln q(x) dx  \\
    &= argmin_{q(x)} -\int_x p(x) \ln q(x) dx + \int_x p(x) \ln p(x) dx \\
    &= argmin_{q(x)} D_{KL}(p(x)||q(x))
    \end{aligned}</script><p>这说明我们要找到一个分布$q(x)$使得其对于原始分布$p(x)$产生数据的极大似然函数最大就等价于找到一个分布$q(x)$使得两个分布之间的KL散度最小(不知道啥是KL散度的，来<a href="https://xuejy19.github.io/2020/08/26/%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83%E4%B8%AD%E7%9A%84%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F/#more">这里</a>补课)。同时中间结果则是也等价于最小化交叉熵，所以我们又得到了一个有用的结论:</p>
<blockquote>
<p>最大化似然函数 $\Leftrightarrow$ 最小化交叉熵 $\Leftrightarrow$ 最小化KL散度</p>
</blockquote>
<p>然后为了解决KL散度的不对称性，又引入了JS散度：</p>
<script type="math/tex; mode=display">
    JS(p(x)||q(x)) = \frac{1}{2} D_{KL}(p(x)||\frac{p(x)+ q(x)}{2}) + \frac{1}{2} D_{KL} (q(x) || \frac{p(x) + q(x)}{2})</script><p>本来想推导下优化KL散度等价于优化JS散度，但没推出来，只有一个不等关系:</p>
<script type="math/tex; mode=display">
    JS(p||q) \leq \frac{1}{4} D_{KL}(p||q) + \frac{1}{4} D_{KL}(q||p)</script><p>本身KL散度的取值范围是$[0, +\infty]$,而JS散度的取值范围是$[0,1]$($\log$以2为底)，但是KL散度与JS散度取最小值的条件是一样的，即两个分布完全相同，因此使用JS散度或者KL散度进行优化，应当是同样的优化效果。 因此可以继续将结论补充：</p>
<blockquote>
<p>最大化似然函数 $\Leftrightarrow$ 最小化交叉熵 $\Leftrightarrow$ 最小化KL散度$\Leftrightarrow$ 最小化JS散度</p>
</blockquote>
<h4 id="生成对抗网络"><a href="#生成对抗网络" class="headerlink" title="生成对抗网络"></a>生成对抗网络</h4><p>之前进行分布拟合，一般通过假设分布是一个高斯分布(或混合高斯分布)，然后对参数进行优化，使得对数据有一个较好的拟合效果，但高斯分布假设很多时候并不满足，因此需要一个更大的模型搜索空间。随着神经网络科学的发展，人们开始思考，能否使用神经网络来将一个高斯分布映射为我们期望的分布$p<em>G$，但由于$p</em>{data}$是未知的，我们并不知道应该如何衡量两个分布之间的差异，因此就需要有一个判别器。GAN的目标函数如下:</p>
<script type="math/tex; mode=display">
    V(D, G) = E_{x \sim data} \log D(x) + E_{x \sim p_G} \log (1 - D(x))</script><p>前一项中的$D(x)$表示判别器对来自训练集数据的评分，后一项中的$D(x)$表示判别器对来自生成器数据的评分，如果想提高判别器的性能，则要求判别器对来自训练数据集的数据评分较高，对来自生成器生成数据评分较低，因为$D(x) \in [0,1]$,因此$D(x)$也可以认为是一个样本是来自原始分布的概率。下面我们将$V(D,G)$写开:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        V(D,G) &=  E_{x \sim data} \log D(x) + E_{x \sim p_G} \log (1 - D(x)) \\ 
        &= \int_x p_{data}(x) \log D(x) dx + \int_x p_G(x) \log(1-D(x)) dx \\
        &= \int_x [p_{data}(x) \log D(x) + p_G(x) \log(1 - D(x))] dx  
    \end{aligned}</script><p>判别器希望最大化$V(D,G)$,即对于来自于真实样本分布的样本的打分尽可能多，对来自于生成器的样本的打分尽可能低，想要优化上式，即低于任意一个输入$x$，判别器应当:</p>
<script type="math/tex; mode=display">
    \max_{D} v(D) = p_{data}(x) \log D(x) + p_G(x) \log(1 - D(x))</script><p>该函数是一个凹函数，可以直接通过求导等于0求得$D(x)$最优解：</p>
<script type="math/tex; mode=display">
    \frac{\partial v(D)}{\partial D(x)} = \frac{p_{data}(x)}{D(x)} - \frac{p_G(x)}{1 - D(x)} = 0</script><p>可以求得： </p>
<script type="math/tex; mode=display">
    D^*(x) = \frac{p_{data}(x)}{p_{data}(x) + p_{G}(x)}</script><p>将求得的$D(x)$回代$V(D,G)$:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
         V(D^*,G) &= \int_x p_{data}(x) \log \frac{p_{data}(x)}{p_{data}(x) + p_{G}(x)} dx + \int_x p_G(x) \frac{p_{G}(x)}{p_{data}(x) + p_{G}(x)}  dx \\
         &= -2\log2 + 2JS(p_{data}(x) || p_G(x)) 
    \end{aligned}</script><p>所以说我们接下来对生成器G的优化，其实就是:</p>
<script type="math/tex; mode=display">
    G^* = \arg \min_G V(D^*,G) = \arg \min_{G} JS(p_{data}(x)||p_G(x))</script><p>这说明我们对生成器进行优化，实质上就是期望能够找到一个分布，使得$p<em>G(x)$与原始数据分布$p</em>{data}(x)$的JS散度最小，由前面的等价性，其实就是找到一个分布使得对训练数据的最大似然函数最大。 因此整个优化问题可以写做:</p>
<script type="math/tex; mode=display">
    \min_{G} \max_{D} V(D,G)</script><h4 id="GAN-Pytorch实现"><a href="#GAN-Pytorch实现" class="headerlink" title="GAN Pytorch实现"></a>GAN <code>Pytorch</code>实现</h4><p>在实现的时候需要关注的问题我觉得主要有以下几个：</p>
<ul>
<li>损失函数选择 </li>
<li>网络结构设计 </li>
<li>优化顺序 <h4 id="损失函数选择"><a href="#损失函数选择" class="headerlink" title="损失函数选择"></a>损失函数选择</h4>首先讨论下损失函数选择，对于判别器而言，其面临的其实就是一个二分类问题，我们看下$V(D,G)$:<script type="math/tex; mode=display">
  \begin{aligned}
      V(D,G) &= E_{x \sim data} \log D(x) + E_{x \sim p_G} \log (1 - D(x)) 
  \end{aligned}</script>从采样的角度来看，$V(D,G)$可以写做:<script type="math/tex; mode=display">
  \begin{aligned}
      V(D,G) = \sum_{i=1, x \sim p_{data}(x)}^{batch\_size} \log D(x) + 
      \sum_{i=1, x \sim p_{G}(x)}^{batch\_size} \log (1 - D(x))
  \end{aligned}</script>若设置来自于真实数据集的数据的label为1，来自于生成器的数据的label为0，则上式其实可以看作两个二分类交叉熵的和，二分类交叉熵计算公式为：<script type="math/tex; mode=display">
  BCE(x_n,y_n) = -[y_n \log x_n + (1-y_n) \log (1 - x_n)]</script>对于label为1的样本，保留前一项；而对于label为0的样本，保留后一项，刚好就是$V(D,G)$。当然也可以通过直接就两个类别做one-hot，然后使用普通的交叉熵损失函数也可以。 </li>
</ul>
<p>在对生成器进行优化的时候，因为我们期望造出的假样本能够尽可能真，因此只需要将假样本的label设置为1，然后进行反向传播优化生成器即可。</p>
<h4 id="网络结构设计"><a href="#网络结构设计" class="headerlink" title="网络结构设计"></a>网络结构设计</h4><p>生成对抗网络是出了名的难训练，因此合理的网络结构非常重要，对于新入门的人来说就只能参考一些现成的网络结构,同时对于不同的任务也应当选用不同的网络结构。目前生成对抗网络在图像处理领域较多，因此往往采用卷积神经网络。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/generative-adversarial-network.png" alt="GAN"></p>
<h4 id="优化顺序"><a href="#优化顺序" class="headerlink" title="优化顺序"></a>优化顺序</h4><p>生成对抗网络的优化是一个交替优化的过程，一般是先对判别器进行优化，接下来再对生成器进行优化，两者进行交替优化，互相博弈，下面简单地写下计算图：</p>
<blockquote>
<p><strong>判别器：</strong><br>真实样本、虚假样本(生成器生成) $\rightarrow$ 判别器网络D $\rightarrow$  predict $\rightarrow$ Loss_D<br><strong>生成器：</strong><br>虚假样本 $\rightarrow$ 生成器网络 $\rightarrow$ 虚假样本 $\rightarrow$ 判别器 $\rightarrow$ predict $\rightarrow$ Loss_G  </p>
</blockquote>
<h4 id="pytorch-代码实现"><a href="#pytorch-代码实现" class="headerlink" title="pytorch 代码实现"></a><code>pytorch</code> 代码实现</h4><p>数据集采用的是<a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">celeb-A faces Dataset</a>,代码实现如下:</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">import argparse
import os
import random
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation
from tqdm import tqdm   
from IPython.display import HTML

import torch 
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data 
import torchvision.datasets as datasets
import torchvision.transforms as transforms
import torchvision.utils as vision_utils
def matplotlib_imshow(img , one_channel = False):
    if one_channel:
        img = img.mean(dim = 0)
    img = img/2 + 0.5
    npimg = img.numpy()
    if one_channel:
        plt.imshow(img, cmap = 'Greys') 
    else:
        npimg  = np.transpose(npimg, (1,2,0)) 
        plt.imshow(npimg)
    plt.show()
def load_data(dataroot, image_size, batch_size, num_workers):
    transform = transforms.Compose([
                   transforms.Resize(image_size) ,
                   transforms.CenterCrop(image_size),
                   transforms.ToTensor(),
                   transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])
    dataset = datasets.ImageFolder(root = dataroot, transform = transform) 
    # Create the dataloader
    dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, 
                                        shuffle = True, num_workers = num_workers)
    # plot some training images 
    # real_batch, _ = iter(dataloader).next()

    #batch_image = vision_utils.make_grid(real_batch, padding = 2) 
    #matplotlib_imshow(batch_image)
    return dataloader
def weights_init(model):
    classname = model.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(model.weight.data, 0.0, 0.02) 
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(model.weight.data, 1.0, 0.02)
        nn.init.constant_(model.bias.data, 0)

class Generator(nn.Module):
    def __init__(self, nz, ngf, nc):
        super(Generator, self).__init__() 
        # nz = 100 H_out = (H_in - 1)*stride - 2*padding + kernel_size
        self.conv1 = nn.Sequential(
            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias = False),
            nn.BatchNorm2d(ngf*8),
            nn.ReLU())  
        # state size: (ngf*8)*4*4
        self.conv2 = nn.Sequential(
            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias = False),
            nn.BatchNorm2d(ngf*4),
            nn.ReLU())
        # state size: (ngf*4)*8*8 
        self.conv3 = nn.Sequential(
            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias = False),
            nn.BatchNorm2d(ngf*2),
            nn.ReLU())
        # state size: (ngf*2)*16*16 
        self.conv4 = nn.Sequential(
            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias = False),
            nn.BatchNorm2d(ngf),
            nn.ReLU()) 
        # state size: ngf*32*32 
        self.conv5 = nn.Sequential(
            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias = False),
            nn.Tanh())
    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.conv4(x)
        return self.conv5(x)
class Discriminator(nn.Module):
    def __init__(self, nc, ndf):
        super(Discriminator,self).__init__()
        # input size: nc*64*64 
        self.conv1 = nn.Sequential(
            nn.Conv2d(nc, ndf, 4, 2, 1, bias = False), 
            nn.LeakyReLU(0.2)) 
        # state size: ndf*32*32 
        self.conv2 = nn.Sequential(
            nn.Conv2d(ndf, 2*ndf, 4, 2, 1, bias = False),
            nn.BatchNorm2d(2*ndf),
            nn.LeakyReLU(0.2))  
        # state size: (ndf*2)*16*16 
        self.conv3 = nn.Sequential(
            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias = False),
            nn.BatchNorm2d(ndf*4),
            nn.LeakyReLU(0.2)) 
        # state size: (ndf*4)*8*8 
        self.conv4 = nn.Sequential(
            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias = False),
            nn.BatchNorm2d(ndf*8),
            nn.LeakyReLU(0.2)) 
        # state size: (ndf*8)*4*4
        self.conv5 = nn.Sequential(
            nn.Conv2d(ndf*8,1, 4,1,0,bias = False),
            nn.Sigmoid()) 
        # state size: 1*1 [0,1] 
    def forward(self, x):
        x = self.conv1(x) 
        x = self.conv2(x) 
        x = self.conv3(x)
        x = self.conv4(x)
        return self.conv5(x)
def get_model():
    device = args.device
    netG = Generator(args.nz, args.ngf, args.channels).to(device)
    netG.apply(weights_init)
    netD = Discriminator(args.channels, args.ndf).to(device) 
    netD.apply(weights_init)
    optimizerD = optim.Adam(netD.parameters(), lr=args.lr, betas = (args.beta1,0.999))
    optimizerG = optim.Adam(netG.parameters(), lr=args.lr, betas = (args.beta1,0.999))
    criterion = nn.BCELoss() 
    return netG, netD, optimizerD, optimizerG, criterion
def plot_figure(G_loss, D_loss, Dx, D_z1, D_z2, img_list):
    plt.figure(figsize = (10,5)) 
    plt.title('Generator and Discriminator Loss During Training') 
    plt.plot(G_loss, label = 'G') 
    plt.plot(D_loss, label = 'D') 
    plt.xlabel('iterations') 
    plt.ylabel('Loss') 
    plt.legend()
    plt.savefig('curve_folder/Loss.png')
    plt.figure(figsize = (10, 5)) 
    plt.title('Dx and Dz') 
    plt.plot(Dx, label = 'Dx') 
    plt.plot(D_z1, label = 'Dz1')
    plt.plot(D_z2, label = 'Dz2') 
    plt.xlabel('iterations')
    plt.ylabel('P') 
    plt.legend() 
    plt.savefig('curve_folder/D.png') 
    for i in range(len(img_list)):
        fig = plt.figure(figsize = (8,8)) 
        plt.axis('off') 
        plt.imshow(np.transpose(img_list[i], (1,2,0))) 
        plt.savefig('fake_image/fake_img' + str(i) + '.png')
def fit(epoches, dataloader, device, netG, netD, optimizerG, optimizerD):
    # Lists to keep track of progress 
    img_list = [] 
    G_losses = [] 
    D_losses = []
    Dx_list = [] 
    Dz1_list = []
    Dz2_list = []
    iters = 0
    real_label = 1.0
    fake_label = 0.0
    fixed_noise = torch.randn(64, args.nz, 1, 1, device = device)
    print('Starting Training Loop...') 

    for epoch in range(epoches):
        for i, data in enumerate(dataloader, 0):
            # Update D network: maximize log(D(x)) + log(1-D(G(z))) 
            ## Train with all real batch
            netD.zero_grad() 
            image_batch = data[0].to(device) 
            batch_size = image_batch.shape[0] 
            label = torch.full((batch_size,), real_label, dtype = torch.float,device = device) 
            #Forward pass real batch through D 
            output = netD(image_batch).view(-1) 
            errD_real = criterion(output, label)
            #Calculate gradients for D in backward pass 
            errD_real.backward() 
            D_x = output.mean().item() 

            ## Train with all-fake batch 
            # Generate batch of latent vectors  
            noise = torch.randn(batch_size,args.nz, 1, 1, device = device)  
            # Generate fake image batch with G 
            fake = netG(noise) 
            label.fill_(fake_label)
            # Classify all fake batch with D 
            # use detach() to make sure only change netD params 
            output = netD(fake.detach()).view(-1)  
            errD_fake = criterion(output, label) 
            errD_fake.backward() 
            D_G_z1 = output.mean().item() 
            errD = errD_real + errD_fake
            # update D 
            optimizerD.step() 

            #############################
            #(2) Update G network: maximize log(D(G(z))) 
            ############################# 
            netG.zero_grad() 
            label.fill_(real_label) # fake labels are real for generator cost
            # Since we just updated D, perform another forward pass of all fake
            # batch through D
            output = netD(fake).view(-1) 
            # Calculate G's loss based on this output 
            errG = criterion(output, label) 
            # Calculate gradients for  G
            errG.backward() 
            D_G_z2 = output.mean().item() 
            # Update G 
            optimizerG.step() 

            # Output training stats 
            if i%50 == 0:
                print('[%d/%d][%d/%d]\tLoss_D: %.4f\t Loss_G: %.4f\tD(x):%.4f\tD(G(z)): %.4f/%.4f' % (epoch, epoches, i,
                    len(dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))
                # Save Losses for plotting later
                G_losses.append(errG.item()) 
                D_losses.append(errD.item()) 
                Dx_list.append(D_x) 
                Dz1_list.append(D_G_z1)
                Dz2_list.append(D_G_z2)
                # Check how the generator is doing by saving G's output on
                # fixed noise
                if iters % 50 == 0:
                    with torch.no_grad():
                        fake = netG(fixed_noise).detach().cpu()
                    img_list.append(vision_utils.make_grid(fake[:64], padding=2,
                        normalize = True)) 
                iters += 1

    plot_figure(G_losses, D_losses, Dx_list, Dz1_list, Dz2_list, img_list)

if __name__ == '__main__':
    manualSeed = 999
   # print('Random Seed: ', manualSeed) 
    random.seed(manualSeed)
    torch.manual_seed(manualSeed)

    # argparse 
    parser = argparse.ArgumentParser(description = 'Train DCGAN') 
    parser.add_argument('--root', type = str, default = 'data', 
                        help = 'Root directory for dataset') 
    parser.add_argument('--device', type = str, default= 'cuda:0',
                        help = 'Choose the training device')
    parser.add_argument('--workers', type = int, default = 2, 
                        help = 'Number of workers for dataloader')
    parser.add_argument('--batch_size', type = int, default = 128, 
                        help = 'Batch size during training')
    parser.add_argument('--image_size', type = int, default = 64,
                        help = 'Spatial size of training images')
    parser.add_argument('--channels', type = int, default = 3,
                        help = 'Number of channels in the training images')
    parser.add_argument('--nz', type = int, default = 100,
                        help = 'Size of generator input')
    parser.add_argument('--ngf', type = int, default = 64,
                        help = 'Size of feature maps in generator') 
    parser.add_argument('--ndf', type = int, default = 64,
                        help = 'Size of feature maps in discriminator') 
    parser.add_argument('--epoches', type = int, default = 10,
                        help = 'Number of training epoches') 
    parser.add_argument('--lr', type = float, default = 2e-4,
                        help = 'Learning rate for optimizer') 
    parser.add_argument('--beta1', type = float, default = 0.5,
                        help = 'Beta1 hyperparam for Adam optimizer') 
    args = parser.parse_args() 
    dataloader = load_data(args.root, args.image_size, args.batch_size,
                           args.workers)
    netG, netD, optimizerD, optimizerG, criterion = get_model()

    fit(args.epoches, dataloader,args.device, netG, netD, optimizerG, optimizerD)
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>最后附上一些结果图：<br><strong>celeb-A faces Dataset</strong><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/Loss.png" alt="Loss"><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/fake_image.png" alt="fake_image"></p>
<p><strong>MNIST</strong><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/Loss_mn.png" alt="Loss"><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/mnist_gan.png" alt="fake_msist"></p>
<p>网络结构比较简单，真正在使用时应当需要根据任务来进行调整，参数初始化以及部分超参数选择，<strong>沃兹基</strong>曾经说过：</p>
<blockquote>
<p>深度神经网络理论学习是一门学问，代码实现又是一门学问，网络调参更是一门学问，想把神经网络搞掂，三种学问缺一不可。</p>
</blockquote>
<p>GAN目前还面临很多问题，比如训练困难，在图像处理之外的领域效果并不理想，同时在理论支撑方面也不够扎实，如果想进一步学习GAN，可以阅读下面几篇文章：</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/56943597">这份攻略帮你「稳住」反复无常的 GAN</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/75789936">海量案例！生成对抗网络（GAN）的18个绝妙应用</a></li>
</ul>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title>疫中居家</title>
    <url>/2020/02/17/yi-zhong-ju-jia/</url>
    <content><![CDATA[<blockquote>
<p>庚子年春，适新冠肆虐，余宅家无所事，聊以为文，以抒心意</p>
</blockquote>
<p>&emsp;新冠者，源于蝠属，起于武汉，适逢春运，以至蔓于天下，一时人心浮动，谈冠色变。遥忆己亥岁末，余初闻新冠，以其癣疥之疾，然须臾，武汉闭城，举国百姓皆锁足于室，医者仁心，挽袖前线。<br>&emsp;余宅家，手机为伴，藉网络以察新冠其事，或感动，或痛心，或苦笑。新冠者，镜也，映崇高精神，映无用之官，映复杂人心。余窃以为，此诚危急之秋也，宜上下一下，共度难关，则疫情之终，不日将至矣。<br>&emsp;宅家不可碌碌终日，会余察己日本史所知甚浅，故阅日本史数册以会其意。以吾观之，詹姆斯之《日本史》堪称佳作，然其古史不足，实为大憾；吴廷璆之《日本史》内容翔实，然书中偏见少许，是其瑕疵。纵观日本史，源义经、楠木正成者，皆兵败身殒，然以其悲情命运而传美名于后世；丰臣秀吉者，生前位极人臣，然其后嗣绝于家康之手；德川家康者，韬光养晦，创江户幕府基业，死后被视为神（东照大神），然200余年后，倒幕声起，幕府轰然倒地，故所谓千秋万代者，实为儿戏之言。历史之回响，不过“诸事无常”四字耳。<br>&emsp;愿新冠之终结，医者之凯旋，天下之安康</p>
]]></content>
      <categories>
        <category>闲谈</category>
      </categories>
      <tags>
        <tag>疫中有感</tag>
      </tags>
  </entry>
  <entry>
    <title>相机基本知识</title>
    <url>/2020/10/25/xiang-ji-ji-ben-zhi-shi/</url>
    <content><![CDATA[<p>俗话说，没有金刚钻就不揽瓷器活，既然要进行摄影的系统性学习，那么自然就首先从设备讲起，本文按照以下结构进行组织:</p>
<ul>
<li>单反与微单 </li>
<li>传感器 </li>
<li>相机推荐<span id="more"></span>
</li>
</ul>
<h3 id="单反与微单"><a href="#单反与微单" class="headerlink" title="单反与微单"></a>单反与微单</h3><p>单反与微单的区别:</p>
<ul>
<li>单反: 大、重、靠谱 </li>
<li>微单: 轻便易学，未来以来</li>
</ul>
<p>单反当年之所以需要加入反光镜和五棱镜然后在取景器中看到实时画面，当按下快门时，反光板抬起，光线打到CMOS传感器时最终成像，但这样就导致单反存在两个致命缺点: </p>
<ul>
<li>由于有反光镜和五棱镜的存在，单反一般都比较笨重。 </li>
<li>从取景器中看到的景象与我们人眼直接看到的并无不同，但会与最终在CMOS传感器上的成像有所差异，也就是说所见并不为所得。 </li>
</ul>
<p>虽然随着数码感光元件的发展，部分单反相机也都配上了一块LCD液晶屏，但在进行实际拍摄的过程中会出现对焦慢、出片延迟大的问题。 而微单则是彻底的抛弃了光学取景器，采用电子取景器，在进行拍摄时所见及所得，而两者的数码感光元件并没有太大差异，因此也就是说，只要钱到位了，两者都能够拍出质量很高的照片。<br>整体而言，光学取景OVF较电子取景EVF而言，其发展已经没什么潜力了，未来随着电子取景技术的不断发展，光学取景可能就会被淘汰了。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%8D%95%E5%8F%8D%E5%92%8C%E6%97%A0%E5%8F%8D.jpeg" alt="单反和微单"></p>
<h3 id="光学传感器"><a href="#光学传感器" class="headerlink" title="光学传感器"></a>光学传感器</h3><p>在进行相机选购的时候，光学传感器是重中之重，<strong>从根本上来说，传感器的大小决定了相机可用于创建图像的光量</strong>。虽然像素在细节上起着重要的作用，但决定相机曝光平衡、动态范围以及清晰度的是光线的捕获量，这也是为什么如今1600万像素和2000万像素的单反相机拍摄的图像看起来仍然比今天七八千万像素的手机所拍摄的图像看起来更好的原因。 </p>
<p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E7%9B%B8%E6%9C%BA%E4%BC%A0%E6%84%9F%E5%99%A8.jpeg" alt="相机传感器"></p>
<p>上面这张图给出了目前的相机传感器尺寸，我们接触最多是两种传感器: </p>
<ul>
<li>半/残幅传感器: APS-C半画幅 23.6 $\times$ 15.6 </li>
<li>全画幅传感器: 135全画幅 36 $\times$ 24 mm </li>
</ul>
<p><strong>全画幅相机与残幅相机最明显的差异可能就是视野大小了</strong>，我们可以将圆形区域看成是一支镜头的视角能够捕捉到的所有画面范围，而红色框线是全画幅的大小，蓝色框线则是APS-C画幅大小，这也就意味着在使用全画幅镜头时，残幅机身只能捕捉到更小的画面。这在实际拍摄中最直观的感觉就是当拍同样景别图像时，持全画幅相机的人往往要向后移一移以达到与半画幅相机同样的取景效果。一般而言全画幅相机配50mm镜头与APS-C相机配35mm镜头取景范围差不多，等效系数一般是1.5，也就是说50mm全画幅镜头接到APS-C半画幅机身上，大致上相当于75mm半画幅镜头效果，<strong>因此在购买镜头时一定要注意是买的全画幅镜头还是仅支持APS-C的镜头，但在标示时一般都是按照全画幅标准进行标称，比如APS-C 23mm镜头，实际上是35mm焦距镜头</strong>。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%85%A8%E7%94%BB%E5%B9%85%E5%92%8C%E6%AE%8B%E5%B9%85.png" alt="全幅和半幅"></p>
<p>另一方面来说，全画幅相机相较半画幅相机具有更高的感光度，在较昏暗环境中能够捕捉到更多光线，提高ISO值不易出现噪点。</p>
<h3 id="相机推荐-摄影协会大佬"><a href="#相机推荐-摄影协会大佬" class="headerlink" title="相机推荐-摄影协会大佬"></a>相机推荐-摄影协会大佬</h3><ol>
<li>4000以内<br> 无推荐</li>
<li>5000以内<ul>
<li>相机推荐<ul>
<li>佳能 EOS M50 </li>
<li>佳能 EOS 200D2 </li>
<li>Sony Alpha 6000L </li>
<li>Sony Alpha 6100L </li>
</ul>
</li>
<li>镜头推荐<ul>
<li>适马 16mm F1.4 </li>
<li>适马 30mm F1.4 </li>
<li>适马 56mm F1.4 </li>
</ul>
</li>
</ul>
</li>
<li><p>10000以上 </p>
<ul>
<li>相机推荐 <ul>
<li>佳能 <ul>
<li>佳能 EOS R 12899¥ 3000w像素</li>
<li>佳能 EOS R6</li>
<li>佳能 EOS R5 </li>
<li>小痰盂 50mm/f1.8 镜头 </li>
</ul>
</li>
<li>Sony <ul>
<li>Sony A 7C 2400w像素</li>
<li>Sony A 7III 2400w像素 </li>
<li>Sony A 7R III 4200w像素<br>Sony相机较佳能优势: CMOS工艺，对焦性能，除了机身，其他都贵 </li>
</ul>
</li>
<li>富士<br>富士基本都是APS-C画幅 </li>
</ul>
</li>
</ul>
<p>三家相机各自特点: </p>
<ul>
<li>佳能: 屏幕好，直出人像色彩好，镜头多而强 </li>
<li>富士: 相机长得好看，直出色彩好，买镜头要计算系数 </li>
<li>Sony: 最好的续航，最多的原生镜头群，最好的自动追焦 </li>
</ul>
</li>
</ol>
<h3 id="相机基础知识"><a href="#相机基础知识" class="headerlink" title="相机基础知识"></a>相机基础知识</h3><blockquote>
<p>相机说明书是最好的摄影书 </p>
</blockquote>
<h4 id="曝光"><a href="#曝光" class="headerlink" title="曝光"></a>曝光</h4><p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E6%9B%9D%E5%85%89.jpg" alt="曝光"><br>曝光可以简单理解为图像亮度，映像曝光主要有三个参数:</p>
<ul>
<li>光圈<br>首先给出$F$值的计算公式: <script type="math/tex; mode=display">
  光圈 =  \frac{焦距}{通光孔直径}</script>如果把光圈值看作一个函数值，那么这个值就与焦距成正相关，而与通光孔直径负相关，这其实也与我们直观感觉相对应，焦距越长，则发光物体距离我们就越远，相机也就更难捕捉光线，而通光孔直径则是直接控制进光量。<br>通光孔越大，则单位时间进入的光越多，带了两点好处:<ul>
<li>更多的进光量。</li>
<li>浅景深，背景虚化。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%85%89%E5%9C%88.jpeg" alt="光圈"><br>如果仅仅调整通光孔直径来改变进光量的话，那么通光孔直径增大$\sqrt{2}$倍，进光量增加两倍，这也是为啥光圈都是差1.4倍，比如F1.4,F2,F2.8等等。</li>
</ul>
</li>
<li><p>快门速度<br>快门在相机里是时间单位，比如”$\frac{1}{100}s, \frac{1}{1000}s$”等，快门时间越短，会带来两点影响: </p>
<ul>
<li>进光量较少，容易出现欠曝 </li>
<li>可以定格某些瞬间，比如水滴溅开等</li>
</ul>
<p>当拍摄夜景或者想获得水流拉丝效果时，可以提高快门时间，此时一般需要三脚架辅助。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%BF%AB%E9%97%A8%E6%97%B6%E9%97%B4.jpg" alt="快门速度"></p>
</li>
<li><p>感光度<br>相机感光度iso的值本质上是算法调节，因此调整感光度来使画面变亮并不是相机真正获得了更多的光线，而仅仅是通过算法将已有的光进行了放大，因此随着感光度的提升，噪点也会相应增多，如下图所示:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E6%84%9F%E5%85%89%E5%BA%A6.jpg" alt="感光度iso"></p>
</li>
<li><p>综合<br>最后我们通过下面这张图来看下三个因素的综合影响:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E6%9B%9D%E5%85%89%E7%BB%BC%E5%90%88.jpg" alt="曝光"></p>
</li>
</ul>
<h4 id="变焦与对焦"><a href="#变焦与对焦" class="headerlink" title="变焦与对焦"></a>变焦与对焦</h4><p>首先我们的镜头是分两类的:</p>
<ul>
<li>变焦镜头: 即可以进行焦距的调整 </li>
<li>定焦镜头: 焦距是固定的 </li>
</ul>
<p>变焦镜头与定焦镜头相比有以下优缺点: </p>
<ul>
<li>优点: 更加地灵活，可以通过变焦来拍摄远景和近景，而对于定焦镜头则只能通过人移动来实现拍摄近景或者远景。</li>
<li>缺点: 更加重，同时因为定焦镜头更容易将光圈做大，因此更容易获得梦幻般的虚化效果。</li>
</ul>
<p>长焦距镜头可以拍到更远地方的景物而不损失像素，超短焦距镜头也被称为广角镜头，可以获得非常大的取景范围。 </p>
<ul>
<li><p>焦距<br>  焦距直接影响的是相机的取景范围，人双目的取景范围大致与50mm焦距镜头相当，单目的取景范围大致与35mm焦距镜头相当。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E7%84%A6%E8%B7%9D.jpg" alt="焦距"></p>
</li>
<li><p>透视<br>  透视本质上其实就是近大远小，应用透视技巧可以进行一些好的构图<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E9%80%8F%E8%A7%86.jpg" alt="透视"></p>
</li>
<li><p>对焦<br>在讲对焦之前首先给出一个光学公式: </p>
<script type="math/tex; mode=display">
  \frac{1}{u} + \frac{1}{v} = \frac{1}{f}</script><p>也就是说物距的倒数与像距的倒数之和为焦距的倒数。 在变焦时是调整$f$，而在对焦时则是调整$u,v$。 </p>
</li>
<li><p>景深<br>景深通俗来讲就是清晰的范围，影响景深的因素有三个: </p>
<ul>
<li>焦距长景深浅 </li>
<li>光圈大景深浅</li>
<li>与焦点的距离近景深浅 </li>
</ul>
<p>景深的形成则是因为在焦点前后都会有一个容许弥散圆，这两个弥散圆之间的距离就叫景深，其光学原理大致如下图所示:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E6%99%AF%E6%B7%B1.png" alt="景深"><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E6%99%AF%E6%B7%B11.png" alt="景深计算公式"><br>从公式也可以看出，光圈值越小，对焦距离越小，焦距越大，则景深越小， 也就是说更容易拍出虚化效果。<br>一般而言，景深也与传感器大小有关，全画幅相机更容易获得浅景深。</p>
</li>
</ul>
<h3 id="实际操作-曝光和对焦"><a href="#实际操作-曝光和对焦" class="headerlink" title="实际操作-曝光和对焦"></a>实际操作-曝光和对焦</h3><h4 id="曝光-1"><a href="#曝光-1" class="headerlink" title="曝光"></a>曝光</h4><p>机器曝光常见模式有以下几种:   </p>
<ul>
<li>M档: 纯手动档，光圈、快门均手动调节 </li>
<li>A档: 光圈优先，可以手动调整光圈，然后相机会根据测光情况自动调整快门和iso</li>
<li>S档: 快门优先，可以手动调整快门时间，然后相机会根据测光情况自动调整光圈和iso </li>
<li>P/Auto档: 傻瓜档位，啥也不需要设置  </li>
</ul>
<p>如果自己对于曝光满意可以通过曝光补偿来进行曝光调节。 </p>
<h4 id="对焦"><a href="#对焦" class="headerlink" title="对焦"></a>对焦</h4><p>常见对焦模式有以下几种: </p>
<ul>
<li>MF: 手动对焦 </li>
<li>AF-S: 单次自动对焦 </li>
<li>AF-C: 多次自动对焦，广域-眼部对焦</li>
<li>DMF: AF-S + MF </li>
</ul>
<p>注意: </p>
<blockquote>
<p>对焦和曝光没有关系 </p>
</blockquote>
]]></content>
      <categories>
        <category>点滴生活</category>
      </categories>
      <tags>
        <tag>相机，单反</tag>
      </tags>
  </entry>
  <entry>
    <title>社会学的想象力</title>
    <url>/2020/11/30/she-hui-xue-de-xiang-xiang-li/</url>
    <content><![CDATA[<p>为了适当打破一下自己固化的圈子，也为了读一本新书，自己鬼使神差般报名了乐学组织的读书打卡活动，我所选读的书是:</p>
<blockquote>
<p>社会学的想象力 </p>
</blockquote>
<p>因为本次打卡要求记录每日读书心得，本篇博客便做此用，本书共359页，活动时间共21天，因此初步计划每天读20页左右。<span id="more"></span> </p>
<h4 id="Day1-11月30日"><a href="#Day1-11月30日" class="headerlink" title="Day1: 11月30日"></a>Day1: 11月30日</h4><p>总序</p>
<blockquote>
<p>1997年，国际社会选出了20世纪最具影响力的十部社会学著作，米尔斯的 《社会学的想象力》高居第二，仅次于马克斯韦伯的《经济与社会》。</p>
</blockquote>
<p>总序中有一个读历史书、社会学书我非常认同的观点: </p>
<blockquote>
<p>我们今天读米尔斯，<strong>不在于书中的历史细节与政策是非</strong>，而在于他迫使我们反思一个核心问题:<strong>社会学家应如何想象？</strong></p>
</blockquote>
<p>米尔斯关于<strong>社会学家如何想象？</strong>这个问题给出了自己的看法: </p>
<blockquote>
<ul>
<li>社会学家应直面时代的大问题: 米尔斯反对为学术而学术、为审美而审美的研究理念，在米尔斯看来，社会学的技艺在于<strong>转译</strong>和<strong>赋权</strong>。 <strong>社会学家有责任向一般读者阐明，他们的私人困扰并不只是个人命运的问题，而是和全社会的结构性问题密不可分；社会结构若不发生根本性转变，他们的私人境遇就不可能得到真正的改善。我们是不是让术语和数据掩盖了事实本身？有没有忘记自己投身学术最初的感动？社会总体结构如何？它在人类历史上的位置如何？这个社会中的获利者是谁？</strong> </li>
<li>社会学研究不可脱离历史维度: 在米尔斯看来，<strong>社会科学本身就属于历史学科……所有名副其实的社会学都是“历史社会学“。具有想象力的社会学必然是具有历史穿透力的社会科学，因为社会结构是历史事件的产物。</strong>  </li>
<li>社会学研究必须基于研究者自身的体验: 米尔斯并不主张大而无当的无病呻吟，而强调“大”和“小”的辩证关系，<strong>正确的社会学研究的思路应当是，先反思自身的个人经历，再将个人经历同社会变迁结合起来。</strong>对于中国的社会学者，我们缺乏的并非是事实，而是缺乏<strong>由小见大、大中见小的社会学想象力。</strong></li>
</ul>
</blockquote>
<p>第一章 承诺 </p>
<blockquote>
<p>现如今，人们往往觉得，自己的私人生活就是一道又一道的陷阱。</p>
</blockquote>
<p>普通人意识到什么，努力做什么，这都囿于其私人圈子，这样一个由社会结构所塑造的圈子为他设了一个又一个陷阱，<em>对于超出他们切身所处的那些抱负和威胁，他们越是有所意识，无论这意识多么模糊。似乎就会感到陷得越深。</em> </p>
<blockquote>
<p>当代历史的诸般史时，也正是芸芸众生胜负成败的故事。</p>
</blockquote>
<p>随着历史的变迁，普通人的命运也随之沉浮，然而身在其中的人往往并不自知:</p>
<blockquote>
<p>普通人很少会意识到，自己生活的模式与世界历史的进程之间，有着错综复杂的关联。他们通常并不知道，这种关联如何影响到自己会变成哪种人，如何影响到自己可能参与怎样的历史塑造。 </p>
</blockquote>
<p>米尔斯给出了社会学的想象力的定义:</p>
<blockquote>
<p>他们所需要的，以及他们感到他们所需要的，是一种特定的心智品质，这种心智品质有助于他们运用信息，发展理性，以求清晰地概括出周边世界正在发生什么，他们自己又会遭遇到什么。</p>
</blockquote>
<h4 id="Day2-12月1日"><a href="#Day2-12月1日" class="headerlink" title="Day2: 12月1日"></a>Day2: 12月1日</h4><blockquote>
<p>个体若想理解自己的体验，估测自己的命运，就必须将自己定位到所处的时代；他想要知晓自己的生活机会，就必须搞清楚所有与自己境遇相同的个体的生活机会。</p>
</blockquote>
<p>众生芸芸，于红尘中挣扎，自以为他的悲剧只是个人的悲剧，而这种个人的悲剧似乎还不足以让人绝望，而当一个人能够真正地“估测自己的命运”时，他可能会意识到，他个人的悲剧更是某个社会群体的悲剧、时代的悲剧在个人身上的具像化，意识到这一点往往会带来更大的痛苦:</p>
<blockquote>
<p>这个教益往往会是痛苦的一课，但又常常让人回味无穷。究竟是坚毅卓绝还是自甘堕落，是沉郁痛苦还是轻松欢快，是乐享肆意放纵的快活还是品尝理性思考的醇美。 </p>
</blockquote>
<p>个人的命运与历史的洪流相比是微不足道的，但历史的洪流正是由无数个人的命运所堆叠交织而成的，因此我们在反思个人于社会与历史的关系时，既要看到个人的微不足道，又要看到个人作为总体组成部分的重要之处: </p>
<blockquote>
<p>个人活出了一场人生，而这场人生又是在某个历史序列中演绎出来的，但只要个人在这个世界活过，他就为这个社会的形貌、为这个社会的历史进程出了一份力，无论这份力量是多么微不足道。</p>
</blockquote>
<p>社会学的想象力的本质在于:</p>
<blockquote>
<p>把握历史，把握人生，把握这两者在社会当中的关联。</p>
</blockquote>
<p>而这也正是社会学家工作的承诺，由于这种承诺的存在，社会学家无论在研究什么样的问题，都会不断追问:</p>
<blockquote>
<ul>
<li>这个特定的社会作为整体的结构是什么？它的基本要素有哪些，彼此如何关联？它与其他社会秩序有何分别？在其内部，任一具体特征对该社会的维系和变迁具有什么意义？</li>
<li>这个社会在人类历史上居于什么位置，是什么样的动力在推动着它不断变迁？在整个人类的发展中，它居于什么位置，又具有什么意义？我们所考察的任一具体特征，是如何影响它所属的历史时期，它具有哪些基本特定？它与其他时期有何差别？它塑造历史的方式有着怎样的特色？</li>
<li>在这个社会、这个时期，男人和女人的主流类型一般是什么样子？未来的趋势如何？他们是怎样被选择、被塑造、被解放或被压迫，又是怎样变得敏感或迟钝的？在这个社会、这个时期，我们观察到的行为和性格中，揭示出了哪些类型的“人性”？我们所考察的社会的方方面面，对于“人性”有着怎样的意义？</li>
</ul>
</blockquote>
<p>前两个问题可以看作是两个“大视角”，而第三个问题则是聚焦于个人命运的“小视角”。</p>
<blockquote>
<p>在运用社会学的想象力时，最富收益的区分或许就是“源于周遭情境的个人困扰”与“关乎社会结构的公共议题”。</p>
</blockquote>
<p>当社会中出现极个别现象时，可能此时问题只是源自少数人的“个人困扰”，而随着某个现象规模的扩大，那么此时问题的解决便需落脚于“社会结构”，就业如此、战争如此、婚姻也是如此。<br>因此当我们碰到某个问题，或者以旁观者的身份来分析某个问题时，一定要注意区分: </p>
<blockquote>
<p>该问题是“个人困扰”，还是更深层次的“结构问题”，将大的问题以小的视角来进行隐藏以及将小的问题以大的视角来刻意放大都是不可取的。</p>
</blockquote>
<p>而我们个人在种种情境中的体验，往往是由结构性的变迁所引起的:</p>
<blockquote>
<p>要相对社会结构的观念有清醒认识，并能敏锐运用它，就要有能力透过纷繁多样的情境捕捉到不同情境之间的关联以及情境与背后社会结构的关联。 </p>
</blockquote>
<p>米尔斯根据个人与其所珍视价值的关系，对社会中的个人的情绪做了这样的归类:</p>
<ul>
<li><strong>安乐:</strong> 人们珍视某些价值，并且不觉得它们面临什么威胁。 </li>
<li><strong>危机:</strong> 人们珍视某些价值，但感到这些价值面临威胁。</li>
<li><strong>漠然:</strong> 人们对自己珍视什么价值浑浑噩噩，可能还伴随着不安及不适。</li>
</ul>
<p>米尔斯认为其所处时代美国的公众情绪主要是<strong>漠然</strong>与<strong>不安</strong>。两个说法很有意思:</p>
<blockquote>
<ul>
<li><em>人的主要敌人和危险就是他自己的桀骜本性，就是他心中被禁锢的黑暗力量。</em></li>
<li><em>人的主要危险乃在于当代社会本身桀骜难训的力量，以及其令人异化的生产方式、严丝合缝的政治支配技术、国际范围的无政府状态。</em></li>
</ul>
</blockquote>
<p>前一个说法来自欧内斯特琼斯，是一个心理学家；后一个说法来自米尔斯，是一个社会学家。两个说法其实从字面上来说并没有错，前一个说法的出发点是从个人的心理出发，后一个说法则是认为个人的心理其实也来自于社会的塑造，本质上危险还是来自于社会。</p>
<blockquote>
<p>粗想的话感觉米尔斯的见解更加深刻，但是需要指明的是，个人心理的塑造主要来自于所处社会，但又不仅仅是，正如同样一块石子在不同人心中会激起不同的浪花，前一个观点更加是强调这种个体差异间的共性，而后一个观点则更加是强调一种统计上的有效性，即社会上的“大多数人”的心理状态是由所处社会本身所塑造的。</p>
</blockquote>
<p>其实这种社会学的想象力并不只存在于社会学的研究之中，很多文学作品和政治分析通常要求具备这种想象力的品质，一部好的叙事电影作品一般都需要具备这样的品质，如何将个人小命运与时代大背景同时结合表现出来其实就是这种想象力的体现。</p>
<blockquote>
<p>社会学的想象力是一种特别的心智品质，似乎以极其令人瞩目的方式，<strong>承诺</strong>要结合更广泛的社会现实，来理解我们自身的私密的现实。所有这类感受力，其实就是人的<strong>理性</strong>本身。</p>
</blockquote>
<h4 id="Day3-12月2日"><a href="#Day3-12月2日" class="headerlink" title="Day3: 12月2日"></a>Day3: 12月2日</h4><p>米尔斯本人相较于“社会科学”一词，更喜欢“社会研究”一词，然而20世纪是科学主导的时代，任何学科都期望倚仗“科学”的声望，在注释里面一句话让我忍俊不禁了:</p>
<blockquote>
<p><strong>今日快乐源泉:</strong>至于所谓“行为科学”，根本就是空中楼阁。我猜想，人们捏造出它，只是一种宣传伎俩，用来从基金会和把“社会科学”与“社会主义”混为一谈的国会议员那里为社会研究谋取经费。</p>
</blockquote>
<p>米尔斯提到了部分社会科学家的不安: </p>
<blockquote>
<p>并非人人都有这种不安，只不过有些人对于承诺念兹在兹，心怀赤诚，足以承认当前许多努力外表矫饰，实质平庸；对于他们来说，许多人并无不安这一事实本身，只会加剧他们的不安。 </p>
</blockquote>
<p>希望自己也能够一直做一个不忘承诺，心怀赤诚之人～<br>米尔斯作为一名社会学家，表明了他对于所处时代的社会学研究的令人遗憾的趋势: </p>
<ul>
<li>趋向一种历史理论: 社会学是一种百科全书式的努力，它既是历史性的，也是系统性的，在这种观点下，关于人类历史的理论一不小心就会被扭曲成一件<strong>跨历史的紧身衣</strong>，在这件紧身衣中，人类历史的各种素材都会被强塞进去，有关未来的先知预言般的观点则会从中硬拽出来。 </li>
<li>趋向一种有关“人与社会的本质”的系统理论: 社会学旨在将社会关系逐一归类，并洞察它们据说普遍一致的特征，以相当静态和抽象的眼光来看待社会结构诸要素，这种趋势可能会使社会学变成精致而乏味的形式论，为了证明理论的正确性，则需要没完没了地对各个“概念”进行拆分与重组。 </li>
<li>趋向针对当前社会事实和社会问题的经验研究: 这种趋势很容易导致社会学沦为罗列有关情境的一系列事实，彼此互不关联，往往也无关紧要。</li>
</ul>
<p>其实并不只是社会学领域，如今各个研究领域都会面临类似的趋势，只是具体的表现形式有所差异而已，对于米尔斯所描述的第一种趋势，我觉得中国的学生还是比较有体会的，因为回头来看自己所接受的历史教育，会发现由马克思理论所衍生出的唯物史观更多地会强调一种<strong>历史的必然性</strong>，而这种历史的必然性其实就是米尔斯所谓的<strong>跨历史的紧身衣</strong>。第二种趋势将历史进行去除，来对历史的某个切面的社会做精巧的分析，然而这样就丢失了太多的信息，为了维持理论的相对正确性只能不断地定义新的名词；第三种趋势现在就太多了，纯粹的“实用主义”思想，放弃追求一种更高架构上的“统一”。 </p>
<p>在第一章的最后，米尔斯给出了后面文章的组织:</p>
<blockquote>
<ul>
<li>第二章到第六章: 社会科学中一些久而成习的<strong>偏向</strong> </li>
<li>第七章到第十章: 社会科学的各项承诺</li>
</ul>
</blockquote>
<h4 id="Day4-12月3日"><a href="#Day4-12月3日" class="headerlink" title="Day4: 12月3日"></a>Day4: 12月3日</h4><p>第二章 宏大理论<br>开篇的帕森斯的《社会系统》把我看懵了，然后我竟然被米尔斯给预判了: </p>
<blockquote>
<p>可能有的读者现在很想跳到下一章了，我希望他们不要放纵这种冲动。</p>
</blockquote>
<p>所谓“宏大理论”，也就是概念与概念之间的组合与拆解，指的深究一番。就我自身而言，社会学的“宏大”理论还是非常具有理解难度的。米尔斯对这些“宏大理论”的态度如下: </p>
<blockquote>
<p>确实有些干货，虽然埋藏颇深，但毕竟不乏洞见。</p>
</blockquote>
<p>所以面对这些“宏大理论”，社会学家应当做的是:</p>
<blockquote>
<p>扫除理解意涵的一切障碍，将有望理解的东西呈现出来后，宏大理论到底说了些什么？ </p>
</blockquote>
<p>后面米尔斯转译了一些帕金斯在《社会系统》中的论述，该部分建议就不要读《社会系统》原文了，简直是折磨2333。</p>
<blockquote>
<p>标准与约制的来源: 人们相互配合，针对彼此而展开行事。人人都会考虑他人的期望。当这类期望足够确定、足够持久时，我们就称其为<strong>标准</strong>。每个人也会期望他人将对自己之所为做出反应，我们称这些被期望的反应为“约制”。 </p>
</blockquote>
<p>后面米尔斯用四段话转译了《社会系统》，我继续以工科生的思维进行总结: </p>
<blockquote>
<p>期望 -&gt; 共享价值标准 -&gt; 规范 -&gt; 社会均衡；维持社会均衡主要有两种思路-“社会化”和“社会控制”，可以简单理解为道德与法律。</p>
</blockquote>
<p>米尔斯期望: </p>
<blockquote>
<p>帮助宏大理论家们走下华而不实的高坛！ </p>
</blockquote>
<p>宏大理论一般是这样产生的: </p>
<blockquote>
<p>一开始就选择了特别一般化的思考层次，导致其践行者无法下降到观察层次。 </p>
</blockquote>
<p>一个词语有两种特性: </p>
<ul>
<li>句法特性: 结合其他词语来考察它。</li>
<li>语义特性: 该词语所代表的意义 </li>
</ul>
<p>“宏大理论”往往沉溺于“句法”，而无视“语义”。而研究一旦脱离“语义”，那么研究便更像是“概念”游戏。当我们在进行研究时:</p>
<blockquote>
<p>应当对于自己所使用的每一个术语背后含义做精确定义，这样的心智习性正是通向系统性思考的必经之道；一旦缺失，势必通向对“概念”的盲目崇拜。</p>
</blockquote>
<h4 id="Day5-12月4日"><a href="#Day5-12月4日" class="headerlink" title="Day5: 12月4日"></a>Day5: 12月4日</h4><blockquote>
<p>那些把持权威的人，为了使自己对于制度的统治正当化，会努力将其与被人广泛相信的道德符号、神圣象征和法律条文相联系，仿佛这种统治乃是顺理成章之事。</p>
</blockquote>
<p>而这些符号被称为“主导符号”，这类主导符号被私人接受后变得很重要，往往会成为个人行动动机，引导人们进入角色，并制约他们对于角色的具体实施。因此有些人相信，符号领域是自我决定的，而诸如此类的“价值”或许真能支配历史: </p>
<blockquote>
<p>进行统治地是“观念”，而不是使用观念的阶层或人。 </p>
</blockquote>
<p>完全基于“符号”的社会结构，是一种极端而纯粹的类型，在现实中，往往: </p>
<blockquote>
<p>从符号到行为并反诸符号的距离很长，并且也并不是所有整合都建立在符号之上。</p>
</blockquote>
<p>言行不一致往往是人的特点，但力求协调同样也是。</p>
<blockquote>
<p>强制是权力的“终极”形式，另外两种表现是权威和操纵。 </p>
</blockquote>
<p>对于“宏大理论家”来说，“系统”一旦确立，就不仅是稳定的，而且本质上就是和谐的，而混乱必然是被“引入”系统的，而这样的假设显然与实际的社会结构并不相符。</p>
<blockquote>
<p>宗教领域，其实可以称之为“救赎市场”，这个词很有意思。 </p>
</blockquote>
<p>不同社会具有不同的整合形式，期待一个完美的范式是不智的: </p>
<blockquote>
<p>在一个经典的自由主义社会，“整合”可能是通过彼此竞争的独立的人的自由进取精神，而在纳粹社会中，这种整合更是通过各项制度高度集中化的“协调”完成。 </p>
</blockquote>
<p>在米尔斯的观察下，美国社会的整合形式也在发生变迁: </p>
<blockquote>
<p>最近100年(19世纪中叶-20世纪中叶)的美国历史展现出，美国大体上通过契合整合起来的社会结构，转换成了更多通过协调达成整合的社会结构。 </p>
</blockquote>
<h4 id="Day6-12月5日"><a href="#Day6-12月5日" class="headerlink" title="Day6: 12月5日"></a>Day6: 12月5日</h4><p>第三章 抽象经验主义<br>米尔斯为了解释什么是所谓的“抽象经验主义”，则为我们举了一个“大众传媒的效果“问题的例子，这种研究往往是基于统计的研究，在米尔斯看来： </p>
<blockquote>
<p>这些研究无论多么精确，其研究结果也只是个别的以及暂时的，并不能发展成一套有关大众传媒的社会意义的理论。 </p>
</blockquote>
<p>美国大选刚刚过去，而关于“选举行为”的研究则是抽象经验主义学派研究的首要主题，通过这样的研究，我们可以了解哪个地区的人民更加倾向共和党，在同一个地区中，什么身份的人更倾向于民主党等直接的结论。</p>
<blockquote>
<p>但米尔斯认为这样的研究是不够深入的，是过分“经验主义”的，我们并不能通过这些研究对现象背后的深刻事实有更多理解。</p>
</blockquote>
<p>如果以朴实的语言来总结“抽象经验主义”，那其实就是:</p>
<blockquote>
<p>以现代科学的方法“就事论事”。 </p>
</blockquote>
<p>在米尔斯看来:</p>
<blockquote>
<p>这些研究堆砌着细节，却对形式关注不够。而细节无论多么众多，也不会说服我们相信任何值得相信的东西。 </p>
</blockquote>
<p><em>其实我们以现在的视角来看，米尔斯口中的“抽象经验主义”其实更像现在的“社会科学”领域。</em><br>在米尔斯那个时代，米尔斯认为社会科学哲学似乎包括两类努力：</p>
<ul>
<li>哲学家们尝试考察社会研究过程的实况，然后对那些看上去最富前景的探究步骤进行概括，并使之统贯一体。 </li>
<li>抽象经验主义的社会研究的风格，往往像是在努力以特定的方式重述和搬用自然科学的哲学，并由此为社会科学工作打造一套规划和典范。</li>
</ul>
<p>其实做科研都是如此，每个人都期待能够做出米尔斯所言的第一类成果，提出一种“概括性”的理论，解决“本质相同”的一类问题，然而这样做风险是高的，没产出论文就毕不了业；所以大多数科研人还是会选择去做“抽象经验主义”的研究工作，就事论事，做一些细节的工作。<br>从具体到一般，可以大致划分为方法、方法论以及认识论: </p>
<ul>
<li>方法: 人们试图理解或说明某事时所使用的程序。 </li>
<li>方法论: 对方法的研究，具体的方法是由一般的方法论所衍生出来的。 </li>
<li>认识论: “知识”的性质，就我个人理解而言，认识论可以简单地理解为那些知识是可信任的，目前主导的自然是科学认识论。 </li>
</ul>
<p>很多顶尖的科学家往往最终都会不可避免地走入哲学范畴，这是因为随着一个人认知的不断深入，从具体的方法，再到一般的方法论，最后到本质的认识论，所期望概括的边界会越来越广，而这种总结与概括本身，便已经进入了哲学的范畴。<br>拉扎菲尔德认为，社会学正在经历从“社会哲学家”和“个体观察者”到“组织有序、充分发展的经验科学”的转变，该转变有四个特征: </p>
<ul>
<li>从注重制度史和观念史转向注重人的具体行为。 </li>
<li>不是趋向单单研究世间人事的某一领域，而是将其关联到其他领域。</li>
<li>偏重于研究那些反复重现而非昙花一现的社会情境和社会问题。</li>
<li>越来越强调当代的而非历史上的社会事件。 </li>
</ul>
<p>需要说明的是，米尔斯对这四种转变的描述并不是十分认同。</p>
<blockquote>
<p>P90:这是米尔斯的观点么？<em>社会学家就该作为科学制造者、工具制造者、解释监管者，安居于研究机构。</em></p>
</blockquote>
<p>对于抽象经验主义，目前流行两种辩护: </p>
<ul>
<li>求取真理的经济学，即研究的成本，与求取真理的政治学，即通过研究来阐明具有重要意义的议题，并使政治论证更贴近现实，两者似乎互相抵触，即“抽象经验主义”实际是对前者的妥协。</li>
<li>批评者只是缺乏耐心，量变才能积累出质变。</li>
</ul>
<p>第二种辩护是假设零碎的研究的结果能够被“汇总”，进而成为“一门整合性社会科学”。为了反驳这种辩护，米尔斯首先探讨社会科学家(其实并不只是社会科学家)考虑问题时应当采取的策略: </p>
<blockquote>
<p>较为宏大的观念和可以细致阐发的领域，孰先孰后？ </p>
</blockquote>
<h4 id="Day7-12月6日"><a href="#Day7-12月6日" class="headerlink" title="Day7:12月6日"></a>Day7:12月6日</h4><p>在米尔斯看来，抽象经验主义最终所得的结论往往例证了人们所知的那种心理主义，这也是由于抽象经验主义研究的结论往往是通过个体抽样所得的。如果我们肯定了抽象经验主义的做法，那也就是说我们肯定了社会的制度性结构，是可以经由有关个体的数据得到理解的。然而，处在特定情境中的人们对于所处情境中的许多变迁的原因往往是不知晓的，从个体抽样的角度很难理解某些变迁，在这里，总体视野与心里主义正好构成两极对立</p>
<blockquote>
<p><em>苏联解体时期的苏联社会或许是一个佐证？，不过要研究该问题就需要调研相关资料。</em></p>
</blockquote>
<p>从另一个方面来看，抽象经验主义这种研究风格，由于太多细致，导致研究失去了空间、时间角度的多样性，然而这种多样性往往是梳理某些问题的关键。 </p>
<p>米尔斯还提出了经验主义者中晚近的一种趋势: </p>
<blockquote>
<p>在数据已经收集并“成文”后再来概述“问题的相关文献”，使经验研究披上“理论”的包装，并“赋予”其意义，讲一个故事。 </p>
</blockquote>
<p>在米尔斯看来是晚近的趋势，但在我看来，在目前科研环境里已经是司空见惯的操作了。 </p>
<blockquote>
<p>凡此种种，等于是用统计结果来刻画一般性论点，又用一般性论点来刻画统计结果，一般性论点既没有得到检验，也没有变得具体。它们只是被调整以适应数据，就像数据被安排调整以适应它们。</p>
</blockquote>
<p>米尔斯并非是单纯地反对细节性研究，而是期望: </p>
<blockquote>
<p>在研究的设问阶段和说明阶段，在更为广泛的阐发与更具细节性的信息之间，应当有公开而清晰的融汇贯通。</p>
</blockquote>
<p>如果只是关注“广泛的阐发”，那么就会走向“宏大理论”的误区，如果单纯关注细节，则又走向了“抽象经验主义”。<br>米尔斯在本章的最后一节，阐述了自己的态度: </p>
<blockquote>
<p>他并不排斥所谓的定量方法，但希望切入问题的角度能够是站在一个结构性的总体视野上，找到关键的位置进行研究，而该研究是服从于结构性研究的，单纯为了用方法而用是没有意义的。 </p>
<ul>
<li><strong>应当用概念和观念来指导事实调查，而细节性调查又应当被用来核查及重塑概念。</strong> </li>
</ul>
</blockquote>
<p>米尔斯最后对“宏大理论”和“抽象经验主义”做了形象的概括: </p>
<blockquote>
<p>前者靠的是讲究形式但云山雾罩的隐晦艰涩，而后者靠的是讲究形式但空洞无物的天真精巧。 </p>
</blockquote>
<p>第四章 各种实用取向 </p>
<blockquote>
<p>不能从事实陈述或观念界定中推出价值判断。 </p>
</blockquote>
<p>休谟的名言: </p>
<blockquote>
<p>我们不能基于自己的信念，推出我们该如何作为。我们也不能从我们相信自己应当如何做推出其他人应如何作为。</p>
</blockquote>
<p>人在进行各种活动时，其实都在受到自己的观念影响(虽然可能并不自觉): </p>
<blockquote>
<p>我们选择研究哪些问题，涉及价值；我们使用哪些核心观念来阐述这些问题，涉及价值；而解答这些问题的过程，也受到价值的影响。</p>
</blockquote>
<p>米尔斯对这种现象的看法是: </p>
<blockquote>
<p>就观念而言，目标应当是尽可能多地使用“价值中立”的术语，自觉意识到残存的价值意涵，并主动加以阐明。就问题来说，目标同样应当是清楚了解选择问题时所秉承的价值，然后尽可能避免在解答问题时怀有评价偏见，无论这个解答把人引向何方，也不管它可能具有怎样的道德意涵或政治意涵。</p>
</blockquote>
<p><strong>其实如果深刻地剖析自己所存的种种观念，就会发现这些观念基本都是带有价值判断的，而当我们进一步应用这些观念进行事实分析时，分析所得的结果必然也是带有价值判断的，但很多人往往以为自己的观念是纯净的、理性的，所以在进行事实判断时往往以为自己是客观分析，混淆了主客观。而问题本身往往是基于某种价值判断所提出的，因此当我们要就某个问题进行作答时，不妨先分析问题本身，看看其本身包含了什么样的价值倾向，而这种价值倾向则往往意味着提出问题的人期望着具备这种价值倾向的回答。</strong></p>
<blockquote>
<p>任何人只要献身于研究社会并公开发表成果，无论他是否愿意，也不管他是否清楚意识到，他的所做所为都带有道德意味，往往也带着政治的意味。</p>
</blockquote>
<p>在书里，作者常常试图说服别人接受其思考的结论；而在教室里，教师应当努力向别人展示一个人是怎样思考的，同时也展现出，当他思考颇有所得时，感觉有多美妙。</p>
<blockquote>
<p>在米尔斯看来，教师应当把各种预设、事实、方法和判断都说得十分明确，不应当有任何隐瞒，而应当循序渐进，随时反复揭启所有可能的道德方案，然后才给出他自己的选择。</p>
</blockquote>
<p>在求学路上，能够碰到这样的老师实在是人生一大幸事！ </p>
<h4 id="Day8-12月7日"><a href="#Day8-12月7日" class="headerlink" title="Day8: 12月7日"></a>Day8: 12月7日</h4><blockquote>
<p>每个社会都持有标明其自身属性的意向，尤其是那些为其权力体制和有权势者的做派提供正当性辩护的意向和口号。社会学家所搞出的研究也必然包含某些意象或观念，这些意象和观念为权力的安排和有权势的支配地位提供正当化辩护，就此将权力转换成权威。 </p>
</blockquote>
<p>诸如此类的应用并不一定会是社会科学家有意为之，事实或许就是这样，但社会科学家一般也都会意识到自己所做研究的政治意涵。 </p>
<p>读到现在我才大致明白了本章标题”各种实用取向”的含义，这种实用取向指的是为权力的安排和有权势的支配地位提供正当化辩护。 这其实反映了米尔斯对于现有事实，然后通过研究来刻意为事实“正名”这样的倾向的担忧。这种学者我一般称为“解释型学者”。</p>
<blockquote>
<p>无论历史是什么或应该是什么，它都很容易变成不堪重负地被重新塑造的各种国族神话和阶级神话。</p>
</blockquote>
<p>并不是因为存在某些理论，然后出现了被这些理论演绎出来的事实，很多时候是先有的事实/政策，然后再设计理论为这些事实/政策寻找合理化注脚。基于这种现象，米尔斯倡导: </p>
<blockquote>
<p>对于理论的政治意涵，清楚阐明总好过遮遮掩掩。 </p>
</blockquote>
<p>美国社会科学的历史中所蕴含的自由主义实用取向: </p>
<blockquote>
<p>偏向细碎散落的研究，偏向事实性的调查，以及与此相伴的信条:多元主义立场下的多因混融观。</p>
</blockquote>
<p>一元主义是极端，多元主义是否又是另一种极端，过分地强调原因的多元性，是否因过分追求形式性和据统的合理性，而降低了我们看清现代社会结构全貌的可能性。 </p>
<blockquote>
<p>自由主义实用取向就是一种道德化的情境社会学。 </p>
</blockquote>
<p>学到了一个新的概念: </p>
<blockquote>
<p>文化滞后: 在现代变迁中，物质文化的变迁总是先于非物质文化， 两者失调，不能保持原有关系时，就发生时滞；非物质文化缺少发明，非物质文化的功能障碍，社会的差异性等，是产生时滞的主要原因。</p>
</blockquote>
<h4 id="Day9-12月8日"><a href="#Day9-12月8日" class="headerlink" title="Day9: 12月8日"></a>Day9: 12月8日</h4><p>被自由主义实用派当成“问题”的，往往属于以下情况: </p>
<ul>
<li>偏离中产阶级和小城镇习惯的生活方式。 </li>
<li>不遵从追求稳定和秩序的乡村原则。</li>
<li>与“文化滞后”的乐观主义进步观口号不合拍。</li>
<li>不切合适当的“社会进步”。 </li>
<li>“调适”以及其对立面“失调”</li>
</ul>
<p>在米尔斯眼中，这是旧的实用主义倾向: </p>
<blockquote>
<p>对于自由主义实用派而言，理想的人就是“社会化了的”人。这种理念往往意味着他在伦理上是“自私”的对立面。</p>
</blockquote>
<p>新的实用主义倾向: </p>
<blockquote>
<p>服务于大制度大机构的宗旨才能称得上是“实用的”宗旨。 </p>
</blockquote>
<p>对于这种实用主义倾向，米尔斯举了一个“工厂人际学派”的例子: </p>
<blockquote>
<p>“士气”观念存在着两种相关价值: </p>
<ul>
<li>工人的快活或满足，也就是未被异化的人。 </li>
<li>工作做的富有效率，以最短的时间，最少的麻烦，最小的开支，完成最多的工作。</li>
</ul>
</blockquote>
<p>商人和政客有着他们的实用主义倾向，社会学家们也有着自己的倾向: </p>
<blockquote>
<p>美国的社会科学家们作为一个群体大规模地参与政治，这种事情就算有，也是相当罕见的，而转向技术专家角色的趋势更加加固了他们与政治无涉的姿态。</p>
</blockquote>
<h4 id="Day10-12月9日"><a href="#Day10-12月9日" class="headerlink" title="Day10: 12月9日"></a>Day10: 12月9日</h4><p>第五章 科层制气质<br>“科层式”的发展: </p>
<ul>
<li>抽象经验主义风格的学术操作努力要把社会研究的每一个阶段都变得标准化、合理化，就此越来越变得“科层式”。 </li>
<li>这些操作如此做派，使得有关人的研究往往变得集体化、系统化。</li>
<li>而这两种发展趋势又在很大程度上关系到在学校职员工中筛选和塑造新型心智品质，这些品质既有思想上的，也有政治上的。 </li>
</ul>
<blockquote>
<p>如果社会科学并不独立自主，就不可能成为一项对公众负责的事业。</p>
</blockquote>
<h4 id="Day11-12月10日"><a href="#Day11-12月10日" class="headerlink" title="Day11: 12月10日"></a>Day11: 12月10日</h4><p>第六章 各种科学哲学 </p>
<blockquote>
<p>无论是“方法”还是“理论”，割裂开来看，都不能充当社会研究的实际工作的要素。 </p>
</blockquote>
<p>关于常识: </p>
<ul>
<li>常识中的日常经验主义充斥着有关这个或那个特定社会的预设与刻板印象，因为常识决定了人们能看到什么，又如何去说明所看到的东西。 </li>
</ul>
<blockquote>
<p>如果你试图借助抽象经验主义摆脱这种状况，最终会停留在微观层次或亚历史层次，你会努力逐渐积累有关所处理的东西的抽象细节。如果你试图借助宏大理论摆脱常识的经验主义，就会从所处理的概念中抽离出清晰的、当下的经验指涉。 </p>
</blockquote>
<p>米尔斯又论证了想法与内容的关系: </p>
<blockquote>
<p>想法相对于内容而言过于宽泛，就容易滑入宏大理论的陷阱；如果内容吞噬了想法，你又容易坠入抽象经验主义的圈套。 </p>
</blockquote>
<h4 id="Day12-12月11日"><a href="#Day12-12月11日" class="headerlink" title="Day12: 12月11日"></a>Day12: 12月11日</h4><p>第七章 人的多样性</p>
<blockquote>
<p>社会科学家力图以某种有序的方式来理解人的多样性，但考虑到这种多样性的广度与深度，他很可能面临这样的追问：这真的可能吗？ </p>
</blockquote>
<p>“社会机构”这个观念最通常的用法: </p>
<blockquote>
<p>根据各自执行的功能来分类的各项制度的组织。有鉴于此，社会科学家最宽广的目标就是逐一理解社会结构的组成要素和总体上的多样性。</p>
</blockquote>
<p>大多数经济学家和政治学家都认为，显然，自己的收腰研究单位是民族国家。即使他们在考虑“国际经济”和”国际关系“，也必然是紧密结合各式各样具体的民族国家来进行研究。 </p>
<p>第八章 历史的运用 </p>
<blockquote>
<p>社会科学所处理的问题关乎人生，关乎历史，也关乎它们在社会结构中的相互交织。人生、历史与社会这三者就是有关人的恰当研究的坐标点。 </p>
</blockquote>
<p>历史研究是否应当被视为一门社会科学争论不休，历史学家大致可以分为两类: </p>
<ul>
<li>有些历史学家明显只是在编纂所谓事实，力图避免“解释”，力图呈现“客观”的史料。 </li>
<li>有些历史学家则超越了历史学，沉迷于有关末日降至或是荣耀将临的跨历史视野中，常常也能颇有成果。</li>
</ul>
<blockquote>
<p>历史学家的主要任务就在于秉笔直录人间世事。历史学家呈现着人类有组织的记忆，而这种记忆作为书面历史，可塑性相当大，在不同的历史学家之间，它往往会发生剧烈的变化。它之所以发生变化，原因不仅仅是日后有更加细致的研究将新的事实和文献引入记录，还因为关注点有了改变，构筑记录的通行框架也有了改变。 </p>
</blockquote>
<p>有这样一种观点，社会科学本身就属于历史学科，有这样几点原因: </p>
<ul>
<li>我们在陈述何者有待说明时，需要非常充分的涉猎，而只有了解人类社会在历史上的多样性才能提供这样的背景。 </li>
<li>非历史的研究通常倾向于对有限情境做静态或者相当短期的研究。当更大的结构发生变迁时，我们很容易就会意识到它们的存在；而只有当我们开阔眼界，含括足够合适的历史跨度时，我们才有可能意识到这类变迁。</li>
<li>要理解一个社会，了解有关它的历史的知识往往不可或缺。 </li>
<li>即使我们的研究并不具备的比较性质，即使我们关注的只是某一国内社会结构的某个有限区域，我们也需要历史材料。</li>
</ul>
<h4 id="Day13-12月12日"><a href="#Day13-12月12日" class="headerlink" title="Day13: 12月12日"></a>Day13: 12月12日</h4><blockquote>
<p>我们要理解当代某个社会结构中的动态变迁，就必须努力捕捉其更为长远的发展态势，并据此追问: 这些趋势赖以发生的机制是什么？这个社会的结构赖以发生变迁的机制是什么？</p>
</blockquote>
<p>我们必须牢记，自己正在处理历史材料，它们的确会迅速变化，但也会有反向趋势存在: </p>
<blockquote>
<p>一面是摇摆不变的当下的即时性，一面是要梳理出特定趋势对于整个时期意味着什么所需要的普遍性。</p>
</blockquote>
<h4 id="Day14-12月13日"><a href="#Day14-12月13日" class="headerlink" title="Day14: 12月13日"></a>Day14: 12月13日</h4><blockquote>
<p>想要理解众生男女的人生，理解他们何以变成纷繁多样的个体，就必须结合那些让他们的日常生活情境在其中组织起来的历史结构。</p>
</blockquote>
<p>有一种心理学反思的风格，已经有了两大推进:</p>
<ul>
<li>他们超越了有关单个有机体的生理学，开始研究那些发生令人恐惧的事件的小家庭圈子。 </li>
<li>在精神分析的透视之下，尤其是通过应该被称作有关超我的社会学研究，社会要素也被大大扩展了。 </li>
</ul>
<p>把人看作是一种社会性生物，这样的视角使我们的探究大大深入，而不仅限于作为一系列社会角色的外在人生历程。</p>
<blockquote>
<p>这也就意味着对于个体的研究，是不能够抛开个体所在的社会，任何有关人个体的结论，如果抛开了其所处社会结构，都是泛泛之谈。 </p>
</blockquote>
<h4 id="Day15-12月14日"><a href="#Day15-12月14日" class="headerlink" title="Day15: 12月14日"></a>Day15: 12月14日</h4><blockquote>
<p>无论何处，人们眼下都在努力获知自己正身居何处，又将去往何方，而对于在当下创造历史，为未来担当责任，他们如果可以有所作为，又该如何行事。对于此类问题，没有人能够给出一劳永逸的回答。 </p>
</blockquote>
<p>弗洛伊德的研究的进退曲折，字里行间都隐含着这样的假设:</p>
<blockquote>
<p>个体想要自由，就必须具备更多的理性自觉；治疗有助于让理性更有机会在个体生活进程中自由地发挥作用。</p>
</blockquote>
<p>同样的假设也支撑着马克思主义作品的主线: </p>
<blockquote>
<p>人深陷于生产的非理性无政府状态，必须对自己在社会中的位置有理性的自觉；他们必须获得“阶级自觉”。</p>
</blockquote>
<p>自由主义与社会主义这两种意识形态都源于启蒙运动，其实共享着许多假设与价值。两者都认为，合理性的增长是自由增长的首要条件，理性推动进步的解放性观念。<br>20世纪社会科学家从启蒙运动哲人那里继承下来的最重要的主题: </p>
<blockquote>
<p>自由个体作为理性载体。 </p>
</blockquote>
<p>但在目前(20世纪60年代)这两项价值已经陷入危险:</p>
<blockquote>
<p>芸芸众生困于日常生活的有限情境，往往没有能力理性思考自己所处情境所臣属的庞大结构，无论后者是否具备合理性。有鉴于此，他们往往会执行一系列貌似具备合理性的行动，却对所致力的目标浑然无知。</p>
</blockquote>
<p>合理化趋势甚嚣尘上，产生种种效应，个体也因此“竭尽所能”:</p>
<blockquote>
<p>他的渴望、他的工作，都维系于他所处的情境，从中他找不到任何出路。他并不是在寻求逃脱之路，而是在摸索求适之道。他先是与生产异化，与工作异化，现在也与消费异化，与真正的休闲异化。<strong>个体的这种求适及其对于他所处情境和自我的效应，不仅导致他丧失了获取理性的机会，假以时日，也会导致他丧失获取理性的能力和意志。</strong></p>
</blockquote>
<p><strong>自我合理化</strong>，指的是深陷合理化庞大组织的有限局部中的个体，怎样逐步系统性地调控自己的冲动与渴望，调控自己的生活方式和思考方式，与“组织的规章条令”保持高度一致。</p>
<blockquote>
<p>但需要注意到，有些“合理性”是<strong>非理性</strong>的合理性。这样的合理性不会与自由共进退，而是自由的毁灭者。</p>
</blockquote>
<p>什么是自由？ </p>
<blockquote>
<p>自由并非单纯地有机会任性而为，也不是单纯的有机会在一系列替代方案中做出选择。自由首先是有机会梳理出可以利用的选择，并加以探讨权衡；接下来才是有机会做出选择。 </p>
</blockquote>
<p>自由与理性的关系: </p>
<blockquote>
<p>如果人的理性在世间人事中的作用不能扩大，自由也就无法存在。在一个个体的人生历程中，在一个社会的历史中，理性所承担的社会任务就在于梳理出各种选择，扩大人的决策在塑造历史过程中的作用范围。 </p>
</blockquote>
<p><strong>也许，并非所有人都发乎自然的想要自由，并非所有人都愿意尽全力或能够尽全力获取自由所必须的理性。</strong><br>对于“人类塑造历史”这一普罗米修斯式的理念，目前的威胁是双重的: </p>
<ul>
<li>一方面，历史塑造过程可能是放任自流的，人们可以继续放弃自愿去塑造的努力，如此便只是随波逐流。 </li>
<li>另一方面，历史也确实可以被塑造出来，但只是出自狭小的精英圈子之手，而对于那些必须努力从他们的决策和疏失的后果生存下来的人，他们却不承担实质性的责任。 </li>
</ul>
<p>第十章 论政治<br>社会科学诸传统中蕴含着三种主导性的政治理念:</p>
<ul>
<li>真实的价值，事实的价值，践行社会科学首先就是践行有关真实的政治。</li>
<li>理性在世间人事中所扮演的角色的价值: 研究结果的真实性、调查的准确性与世间人事可能相关，也可能不相关。 </li>
<li>人的自由</li>
</ul>
<p>如果说人的理性将在塑造历史的过程中扮演更重要、更明确的角色，那么社会科学家必然会是其主要承载者之一。这是因为，社会科学家在工作中表现出了理性在理解世间人事时的用途。<br>米尔斯简要区分了三种社会科学家可能扮演的政治角色：</p>
<ul>
<li>哲人王: “理性”的加冕也应当意味着“占有理性的人”的加冕。 </li>
<li>国王的顾问: 在这种角色下，社会科学本身也往往倾向于变成一套功能合理化的机器，社会科学家个体往往会失去其道德自主和实质理性。 </li>
<li>社会科学: 保持独立，做属于自己的工作，选择属于自己的问题。</li>
</ul>
<blockquote>
<p>如果人们不去塑造历史，他们就越来越倾向于变成塑造历史的人的工具，成为历史塑造过程的单纯对象。 </p>
</blockquote>
<p>马克思在《路易波拿巴的雾月十八日》中写下这段话: </p>
<blockquote>
<p>人们自己创造自己的历史，但是他们并不是随心所欲的创造，并不是在他们自己选定的条件下创造。 </p>
</blockquote>
<p>命运，或者“必然性”，必然涉及历史中的某些事件，它们不受任何哪怕是具备一下子三点特征的圈子或人群控制: </p>
<ul>
<li>足够紧密，可被辨识。 </li>
<li>足够强大，可以做出有一定后果的决策。 </li>
<li>所处位置能够预见到这些后果，因此要为他们负责。 </li>
</ul>
<p>根据这个观念: </p>
<blockquote>
<p>事件就是无数人的无数决策所产生的意图之外的总和后果。 </p>
<ul>
<li>他们所做出的每一项决策在后果上都是微小的，容易被其他这类决策勾销或增强。</li>
<li>任一个人的意图与无数决策的总和结果之间不存在任何关联。 </li>
<li>事件超出了人的决策: 历史是背着人们被塑造的</li>
</ul>
</blockquote>
<ul>
<li>坚持不懈地将个人困扰转译为公共议题，并针对形形色色的个体，将公共议题转译成人文意涵的表达，这就是社会科学家的政治任务，也是所有通识教育者的政治任务。</li>
<li>道德困境: <strong>人们的利益所在，有别于人们的兴趣所在</strong> <ul>
<li>如果我们采取简单的民主观点，认为人们的兴趣所在就是我们所需关注的全部，我们就等于接受了既得利益者一向以来有意无意灌输的那些价值。</li>
<li>如果我们采取教条的观点，认为人们的利益所在是我们在道德上所需关注的全部，那么我们就会冒违背民主价值的风险。</li>
</ul>
</li>
</ul>
<p>附: 论治学之道</p>
<ul>
<li>投身学术，既是选择一种职业生涯，也是选择一种生活方式。</li>
<li>一名从事实际研究的社会科学家，应当定期评估“我的问题和计划研究的现状”。</li>
<li>仅仅是从一本书里做一则笔记，就常常会刺激你思考。</li>
</ul>
<p>米尔斯文章末尾的总结:</p>
<ul>
<li>做一名巧匠：避免任何刻板的程序套路。</li>
<li>避免陷入拜占庭式错综繁复的拆解和组合各类“概念”的怪癖，摆脱繁文冗语的矫饰做派。</li>
<li>只要你认为自己的工作需要，就尽量多做些跨历史的建构，同时也深入历史内部的细节。</li>
<li>不要只是一个接一个孤立地研究小情境，要研究将其中的情境组织起来的社会结构。</li>
<li>要认识到你的目标在于对世界历史上曾有以及现存的各种社会结构进行充分的比较性理解。</li>
<li>始终关注有关人性的整体观念。 </li>
<li>不要让按照官方方式梳理的公共议题，或者按照私人感受呈现的困扰，来确定你拿来研究的问题。</li>
</ul>
<h4 id="Day16-12月15日"><a href="#Day16-12月15日" class="headerlink" title="Day16: 12月15日"></a>Day16: 12月15日</h4><p>新版跋——托德吉特林</p>
<blockquote>
<p>米尔斯的作品充斥着对人的生机活力与失望情绪的敏锐觉察，对人的探险精神与尊严持久的深沉情怀。</p>
</blockquote>
<p>在《社会学的想象力》及其他著述中，米尔斯坚定地主张，人生与历史之间的相互交织是社会学家应有的研究主题。</p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>米尔斯，社会学</tag>
      </tags>
  </entry>
  <entry>
    <title>剑指offer题目总结</title>
    <url>/2022/09/29/suan-fa-ti-zong-jie/</url>
    <content><![CDATA[<h3 id="剑指offer题目总结"><a href="#剑指offer题目总结" class="headerlink" title="剑指offer题目总结"></a>剑指offer题目总结</h3><h4 id="链表题目"><a href="#链表题目" class="headerlink" title="链表题目"></a>链表题目</h4><ul>
<li>从尾到头打印链表  </li>
<li>反转链表 </li>
<li>合并两个排序的链表(递归/遍历)</li>
<li>两个链表的第一个公共节点(双指针/哈希表) </li>
<li>链表中环的入口节点(快慢指针/字典) </li>
<li>链表中倒数最后k个节点(快慢指针) </li>
<li>复杂链表的复制(1. 复制 2. 随机指针复制 3.打断两个链表) -手写可能出错 </li>
<li>删除链表中的节点(简单遍历)<span id="more"></span>
<blockquote>
<p>总结：简单遍历+快慢指针+哈希 </p>
</blockquote>
</li>
</ul>
<h4 id="树题目"><a href="#树题目" class="headerlink" title="树题目"></a>树题目</h4><ul>
<li>二叉树的深度(简单递归/队列辅助层次遍历)</li>
<li>按之字顺序打印二叉树(层次遍历 + flag判断奇偶层)</li>
<li>二叉搜索树的第k个节点(深度优先遍历，结合二叉搜索树的特点)</li>
<li>重建二叉树(递归 + 结合前序中序遍历的特点) </li>
<li>树的子结构(递归，注意三种匹配情况) </li>
<li>二叉树的镜像(递归，左右子树镜像，交换)</li>
<li>从上往下打印二叉树(简单的层次遍历) </li>
<li>二叉搜索树的后序遍历序列(递归，后序遍历，根节点) </li>
<li>二叉树中和为某一值的路径1(递归，不需保存路径)</li>
<li>二叉树中和为某一值的路径2(递归，保存路径, dfs)</li>
<li>二叉搜索树与双向链表(中序遍历，维护一个pre_node)</li>
<li>判断是不是平衡二叉树(递归判断，专门写一个判断树深度的函数即可)</li>
<li>二叉树的下一个节点(获取中序遍历序列/分情况讨论)</li>
<li>对称的二叉树(递归，输入两棵树，左右子树是否match， 因为单一递归，同时只能到一部分，需要两部分同步递归)</li>
<li>把二叉树打印成多行(用队列实现树的BFS)</li>
<li>序列化二叉树(确定规则，指针遍历，节点值后面加符号来分割树节点) </li>
<li>二叉树中和为某一值的路径3(层次遍历 + dfs/借助哈希表，一次遍历)</li>
<li>在二叉树中找到两个节点的最近公共祖先(dfs+最后一个共同节点/递归)</li>
<li>二叉搜索树的最近公共祖先(简单递归，利用二叉搜索树的特点)</li>
</ul>
<blockquote>
<p>总结: 树的题目基本都是围绕递归遍历展开 </p>
<ul>
<li>几种遍历方式: 前序、中序、后序、层次 </li>
<li>合理考虑递归边界，特殊情况 </li>
</ul>
</blockquote>
<h4 id="队列-amp-栈"><a href="#队列-amp-栈" class="headerlink" title="队列&amp;栈"></a>队列&amp;栈</h4><ul>
<li>用两个栈实现队列(进行两次压栈操作即可) </li>
<li>包含min函数的栈(普通栈+最小栈) </li>
<li>栈的压入弹出序列(辅助栈模拟) </li>
<li>翻转单词序列(两次翻转/直接split+join)</li>
<li>滑动窗口的最大值(双向队列，维护前向最大值)</li>
</ul>
<blockquote>
<p>总结：数据结构特点的基础应用 </p>
</blockquote>
<h4 id="搜索算法"><a href="#搜索算法" class="headerlink" title="搜索算法"></a>搜索算法</h4><ul>
<li>数字在升序数组中出现的次数(二分查找 target-0.5 target+0.5) </li>
<li>二维数组中的查找(有序数组，从角落开始搜索)</li>
<li>旋转数组中的最小数字(二分查找，特殊情况考虑，注意等号) </li>
<li>字符串的排列(遍历) </li>
<li>数字序列中的某一位数字(模拟, 几位数字位数关系) </li>
</ul>
<blockquote>
<p>总结：二分搜索 or 模拟遍历  </p>
</blockquote>
<h4 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h4><ul>
<li>连续子数组的最大和(一维dp, 可以不另外开辟数组) </li>
<li>连续子数组最大和(二)(一维dp,维护起始位置，可以不另外开辟数组) </li>
<li>跳台阶(斐波那契数列) </li>
<li>斐波那契数列 </li>
<li>正则表达式匹配(二维dp) </li>
<li>跳台阶扩展问题($2^{n-1}$) </li>
<li>矩阵覆盖(斐波那契数列)</li>
<li>买股票的最好时机(一维dp) </li>
<li>礼物的最大价值(二维dp, 可以不另外开辟数组) </li>
<li>最长不含重复字符的子字符串(借助字典，1维dp)</li>
<li>把数字翻译成字符串(一维dp) </li>
</ul>
<blockquote>
<p>总结： 这类问题的关键在于</p>
<ul>
<li>状态的定义 </li>
<li>状态转移方程的形式 </li>
</ul>
</blockquote>
<h4 id="回溯"><a href="#回溯" class="headerlink" title="回溯"></a>回溯</h4><ul>
<li>矩阵中的路径(dfs + 标志矩阵)</li>
<li>机器人的运动范围(dfs + 标志矩阵)</li>
</ul>
<blockquote>
<p>dfs + 标志矩阵  </p>
</blockquote>
<h4 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h4><ul>
<li>数组中重复的数字(哈希/位置重排) </li>
<li>数组中的逆序对(归并排序) </li>
<li>最小的k个数 </li>
<li>数据流中的中位数 </li>
</ul>
<blockquote>
<p>总结：熟练掌握归并排序和快速排序 </p>
</blockquote>
<h4 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h4><ul>
<li>不用加减乘除做加法(异或运算获取非进位和，与运算加左移算子获取进位信息) </li>
<li>二进制中1的个数(n&amp;n-1, 将低位1变为0，注意处理负数) </li>
<li>数值的整数次方(借助二进制运算实现快速幂) </li>
<li>数组中只出现一次的两个数字(异或运算的特点) </li>
<li>求1+2+…+n(通过与运算终止递归) </li>
</ul>
<h4 id="模拟"><a href="#模拟" class="headerlink" title="模拟"></a>模拟</h4><ul>
<li>顺时针打印矩阵(简单模拟，通过边界控制循环结束)</li>
<li>扑克牌顺子(借助hash)</li>
<li>把字符串转换成整数(去空格，找符号，转换，取模)</li>
<li>表示数值的字符串 </li>
</ul>
<h4 id="其他算法"><a href="#其他算法" class="headerlink" title="其他算法"></a>其他算法</h4><ul>
<li>构建乘积数组 </li>
<li>第一个只出现一次的字符 </li>
<li>替换空格 </li>
<li>调整数组顺序使奇数位于偶数前面 </li>
<li>数组中出现超过一半次数的数字 </li>
<li>整数中1出现的次数 </li>
<li>把数组排成最小的数 </li>
<li>丑数 </li>
<li>和为S的连续正数序列 </li>
<li>和为S的两个数字 </li>
<li>左旋转字符串 </li>
<li>孩子们的游戏(约瑟夫环)</li>
<li>字符流中第一个不重复地字符 </li>
<li>剪绳子 </li>
<li>调整数组顺序使奇数位于偶数前面</li>
<li>剪绳子(进阶版)</li>
<li>打印从1到最大的n位数<h4 id="python中常用数据结构模块"><a href="#python中常用数据结构模块" class="headerlink" title="python中常用数据结构模块"></a>python中常用数据结构模块</h4></li>
</ul>
<ol>
<li>队列 <code>queue.Queue()</code> </li>
</ol>
<ul>
<li><code>Queue().qsize()</code>: 返回队列的大小 </li>
<li><code>Queue().empty()</code>: 如果队列为空返回<code>True</code>，反之返回<code>False</code> </li>
<li><code>Queue().full()</code>: 如果队列满了，返回<code>True</code>,反之返回<code>False</code> </li>
<li><code>Queue().get()</code>: 获取队列的第一个值，出队列 </li>
<li><code>Queue().put()</code>: 写入队列 </li>
<li>题目: 从上往下打印二叉树 <pre class="line-numbers language-lang-python"><code class="language-lang-python">import queue 
class Solution:
  def PrintFromTopToBottom(self , root: TreeNode) -> List[int]:
      # write code here 
      res = [] 
      if not root:
          return res 
      q = queue.Queue() 
      q.put(root) 
      while not q.empty(): 
          cur_node = q.get() 
          res.append(cur_node.val) 
          if cur_node.left: 
              q.put(cur_node.left) 
          if cur_node.right: 
              q.put(cur_node.right) 
      return res
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
</ul>
<ol>
<li>双向队列<code>collections.deque()</code> </li>
</ol>
<ul>
<li><code>deque()</code>: 创建 </li>
<li><code>deque().append()</code>: 向队列中添加元素 </li>
<li><code>deque().pop()</code>: 抛出最后一个元素 </li>
<li><code>deque().leftpop()</code>: 抛出第一个元素 </li>
<li><code>deque().extend()</code>: 添加list项到原<code>deque()</code>中 </li>
<li><code>deque().extendleft()</code>: 添加list项到原<code>deque()</code>头部 </li>
<li><p>题目: 滑动窗口的最大值 </p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">from collections import deque 
class Solution:
  def maxInWindows(self , num: List[int], size: int) -> List[int]:
      # write code here 
      res = [] 
      dq = deque()
      if size > len(num) or not size: 
          return [] 

      for i in range(size): 
          while len(dq) > 0 and num[dq[-1]] < num[i]: 
              dq.pop() 
          dq.append(i) 

      for i in range(size, len(num)): 
          res.append(num[dq[0]]) 
          while len(dq) > 0 and dq[0] < i - size + 1: 
              dq.popleft() 
          while len(dq) > 0 and num[dq[-1]] < num[i]:
              dq.pop() 
          dq.append(i) 
      res.append(num[dq[0]]) 
      return res
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
</ul>
<ol>
<li>小根堆<code>heapq</code></li>
</ol>
<ul>
<li><code>heapq.heappush(pq, value)</code> 入堆 </li>
<li><code>heapq.heapreplace(pq,value)</code> 替换堆中元素 </li>
<li><code>heapq.pop(pq)</code> 出堆 </li>
</ul>
<ol>
<li><code>collections.defaultdict()</code><br><code>dict</code>的一个子类，可以使创建的字典具有默认值，可以预先指定默认值类型：<pre class="line-numbers language-lang-python"><code class="language-lang-python">import collections 
mp = collections.defaultdict(list) # 默认值为[]
mp = collections.defaultdict(int)  # 默认值为0
mp = collections.defaultdict(lambda:999) # 默认值为999
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
在python中，可哈希的数据类型有：</li>
</ol>
<ul>
<li>数字类型(<code>int</code>、<code>float</code>、<code>bool</code>), 字符串<code>str</code>、元组<code>tuple</code></li>
</ul>
<p>不可哈希的数据类型有:</p>
<ul>
<li>字典<code>dict</code>、列表<code>list</code>、集合<code>set</code><h4 id="算法题常用解题思路"><a href="#算法题常用解题思路" class="headerlink" title="算法题常用解题思路"></a>算法题常用解题思路</h4><h5 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h5></li>
<li>什么样的问题可以用递归解决? <ul>
<li>主问题可以拆分为若干子问题 </li>
<li>主问题和子问题的解题思路一致</li>
<li>存在终止条件 </li>
</ul>
</li>
<li>递归问题如何解决？ <ul>
<li>找到递推公式 </li>
<li>找到终止条件 </li>
<li>翻译成代码 </li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>算法岗八股文</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>纯粹理性批判</title>
    <url>/2020/12/14/chun-cui-li-xing-pi-pan/</url>
    <content><![CDATA[<p>在一年前我磕磕绊绊读完《西方哲学简史》后，试图想要征服康德的《纯粹理性批判》，然而《纯粹理性批判》实在晦涩难读，加之以当时我自身哲学素养不够，我最终读到百分之十左右时便放弃了。时至今日，我再次尝试精读一下《纯粹理性批判》这本书，这篇博客也就用来记录一下我读期间的一些所思所感。 <span id="more"></span></p>
<h4 id="第一版前言"><a href="#第一版前言" class="headerlink" title="第一版前言"></a>第一版前言</h4><p>主要的问题: </p>
<blockquote>
<p>知性和理性脱离开一切经验能够认识什么、认识多少？</p>
</blockquote>
<p>论证的明晰性主要体现在: </p>
<ul>
<li>概念的推论(逻辑的)明晰性，这是本文所重视的。</li>
<li>直观的、亦即凭借具体的实例和其他说明的直觉的(感性的)明晰性，本文并不注重，康德给出的理由是：明晰性的辅助手段虽然在各个部分上有所助益，但却往往在整体上分散精力。</li>
</ul>
<p>本文的基本思路: </p>
<ul>
<li>在自然的形而上学这个标题自身下面提供出纯粹理性的一个体系，即论述清楚待批判的对象本身。 </li>
<li>对纯粹理性的批判。</li>
</ul>
<h4 id="第二版前言"><a href="#第二版前言" class="headerlink" title="第二版前言"></a>第二版前言</h4><p>逻辑学的界限: </p>
<blockquote>
<p>一门仅仅详尽地阐明和严格地证明一切思维的形式规则的科学。</p>
</blockquote>
<p>形而上学的做法迄今为止还只是一种来回摸索，而最糟糕的是仅仅在概念中间来回摸索。<br>如何才能寻找到一条科学的可靠道路？ </p>
<blockquote>
<p>反省对数学和自然科学这两门学科来说变得如此有益的思维方式变革的本质性部分，并在这里就它们作为理性知识与形而上学的类似所允许，至少尝试效仿它们。</p>
</blockquote>
<p>康德对纯粹理性批判这一工作的概述: </p>
<blockquote>
<p>纯粹思辨理性的这一批判的工作就在于那种尝试，即通过我们按照几何学家和自然研究者的范例对形而上学进行一场完全的革命，来变革形而上学迄今为止的做法。</p>
</blockquote>
<p>纯粹思辨理性自身具有的特征: </p>
<blockquote>
<p>它能够而且应当根据它为自己选择思维客体的方式的不同来衡量它自己的能力，甚至完备地列举出为自己提出任务的各种方式，并这样来描画形而上学体系的整个轮廓。</p>
</blockquote>
<p>形而上学本身的优势在于当它被这种批判带上一门科学的道路之后，它就完全能把握住属于它的知识的整个领域，从而完成自己的事业。<br>但问题在于，<strong>凭借这样一种通过批判澄清的、但因此也达到一种恒定状态的形而上学究竟是一笔怎样的财富？</strong></p>
<blockquote>
<p>永远不要冒险通过思辨理性去超越经验的界限，但同时，它借此同时排除了限制或者有完全根除理性的实践应用的危险的障碍，事实上却具有积极的和非常重要的用处。 </p>
</blockquote>
<p>在批判的分析部分将证明，空间和时间不过是感性直观的形式，因而只不过是作为显像的物实存的条件，此外除非能够被给予与知性概念相应的直观，否则我们就没有任何知性概念，从而也根本没有任何达到物的知识的要素，于是我们对于<strong>任何作为物自身的对象</strong>都不可能有知识，而只有在它作为<strong>感性直观的客体、即作为显象</strong>时才能有知识。由此当然也就能够得出，一切思辨的理性知识，都仅仅限制在经验的对象之上。<br>但从另一个角度来说，正是这些作为物自身的对象，我们即使不能认识，至少也必须能够思维。我能够思维我想思维的任何东西，只要我不与自己本身相矛盾，也就是说，只要我的概念是一个可能的思想，即使我不能保证在所有可能性的总和中是否也有一个客体与它相对应。但是，要赋予这样一个概念以客观的有效性(实在的可能性)，就要求某种更多的东西。但这种更多的东西恰好不需要在理论的知识来源中寻找，它也可能存在于实际的知识来源之中。<br>同一个意志就在显象中被设定为必然遵守自然规律的、就此而言是不自由的，但在另一方面又被设想为属于一个物自身而不服从自然规律的，从而就被设想为自由的。</p>
<blockquote>
<p>批判告诉我们，就物自身而言，我们不可避免地无知，我们在理论上能够认识的一切仅仅限制在显像上。‘</p>
</blockquote>
<p>康德的对纯粹理性的批判更多的是针对形而上学中的“独断论者”。</p>
<blockquote>
<p>批判并不与理性在其作为科学的纯粹知识中的独断方法对立，而是与独断论对立，也就是说，与凭借一种从概念出发的纯粹知识按照理性早已运用的原则、从不调查理性达到这种知识的方式和权利就能前进的僭妄对立。</p>
</blockquote>
<h4 id="导论"><a href="#导论" class="headerlink" title="导论"></a>导论</h4><h5 id="论纯粹理性知识与经验性知识的区别"><a href="#论纯粹理性知识与经验性知识的区别" class="headerlink" title="论纯粹理性知识与经验性知识的区别"></a>论纯粹理性知识与经验性知识的区别</h5><blockquote>
<p>我们的一切知识都以经验开始，这是毋庸置疑的。在时间上，我们没有任何知识先行于经验，一切知识都是从经验开始。 </p>
</blockquote>
<p>但需要明确的是，<strong>尽管我们的一切知识都以经验开始，它们却并不因此都产生自经验</strong>，这句话看似有一些矛盾，但康德想表达的意思是: </p>
<blockquote>
<p>我们的知识并不仅仅是来自于经验，而是<strong>印象所接受的东西</strong>与<strong>我们自己的认识能力从自己本身提供的东西</strong>的一个复合物。</p>
</blockquote>
<p>我们的这个<strong>附加</strong>则是一个需要讨论的重点，由此便引出了一个关键问题:</p>
<blockquote>
<p><strong>是否有一种独立于经验，甚至独立于一切感官印象的知识。</strong> 人们称这样的知识为<strong>先天的</strong>，并把它们与那些具有后天的来源、即在经验中具有其来源的经验性的知识区别开来。</p>
</blockquote>
<p>同时康德为了更加精确地定义<strong>先天知识</strong>，举了一个人挖墙角的例子: </p>
<blockquote>
<p>关于某个挖墙脚的人，人们会说:” 他能够先天的知道房子会倒，也就是说，他不必等待这房子真的倒下来以获得经验。 然而，他并不能完全先天地知道这一点，“房子会倒”这样的认识也是来自于经验“物体是有重量的”。 </p>
</blockquote>
<p>因此，康德给出了他认为的先天知识的定义: </p>
<blockquote>
<p>先天知识指<strong>绝对不依赖于一切经验而发生的知识。</strong></p>
</blockquote>
<p>与这些知识相反的是经验性的知识，或者是<strong>仅仅后天地、即通过经验才可能的知识。</strong> 同时康德对先天知识又进行了划分:</p>
<blockquote>
<p>先天知识中根本不掺杂任何经验性因素的知识叫做<strong>纯粹的先天知识</strong>。<br> 在本节最后，康德举了一个后面还会经常提到的例子:<br>“每一变化皆有其原因”这个命题就是一个先天命题，但并不是纯粹的，因为变化是一个只能从经验中取得的概念。 </p>
</blockquote>
<h5 id="我们拥有某些先天知识，甚至普通的知性也从不缺少它们"><a href="#我们拥有某些先天知识，甚至普通的知性也从不缺少它们" class="headerlink" title="我们拥有某些先天知识，甚至普通的知性也从不缺少它们"></a>我们拥有某些先天知识，甚至普通的知性也从不缺少它们</h5><p>虽然在上一节给出了先天知识和经验性知识的定义，但从哪些特征出发可以清晰地分辨两种特征？ </p>
<blockquote>
<ul>
<li>如果有一个命题与它的必然性一同被思维，那么它就是一个先天判断。 </li>
<li>除了自身又是作为一个必然命题而有效的命题之外，它也不是从任何命题派生出的。 </li>
<li>经验永远不赋予自己的判断以真正的或者严格的普遍性，而是只赋予它们以假定的、相对的普遍性。 </li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>灵魂雕琢</category>
      </categories>
      <tags>
        <tag>康德，哲学</tag>
      </tags>
  </entry>
  <entry>
    <title>线性判别函数</title>
    <url>/2020/08/11/xian-xing-pan-bie-han-shu/</url>
    <content><![CDATA[<p>在这一部分将总结一下关于感知机的一些相关知识点，不过首先我想要介绍下统计学习相关算法的一种分类标准。该部分内容将按照以下几部分进行组织：</p>
<blockquote>
<ul>
<li>模型分类-生成式模型与判别式模型</li>
<li>线性判别-感知机</li>
</ul>
</blockquote>
<span id="more"></span>
<h3 id="模型分类-生成式模型与判别模型"><a href="#模型分类-生成式模型与判别模型" class="headerlink" title="模型分类-生成式模型与判别模型"></a>模型分类-生成式模型与判别模型</h3><p>监督学习的任务便是学习一个模型，应用这一模型，对给定的输入$X$预测相应的输出$Y$，该模型一般具有两种形式：</p>
<ul>
<li>$Y = f(X)$</li>
<li>$P = (Y|X)$</li>
</ul>
<p>第一种模型我们称为判别模型，是函数形式；后一种我们称为生成模型，为条件概率分布的形式。下面列一个表格来对常见机器学习算法按照该标准进行分类：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>生成式模型</th>
<th>判别式模型</th>
</tr>
</thead>
<tbody>
<tr>
<td>朴素贝叶斯模型,HMM,GMM</td>
<td>感知机,SVM,k近邻,AdaBoost</td>
</tr>
</tbody>
</table>
</div>
<h3 id="线性判别-感知机"><a href="#线性判别-感知机" class="headerlink" title="线性判别-感知机"></a>线性判别-感知机</h3><p>感知机模型是一种非常简单的判别式模型，该算法出发点有以下几点：</p>
<ul>
<li>二分类问题</li>
<li>假设存在一个超平面，可以将两类样本分开，即要求模型线性可分</li>
</ul>
<p>对于一个判别式模型，我们需要解决三个问题：</p>
<ol>
<li>明确模型类</li>
<li>确定准则函数</li>
<li>利用准则函数，结合数据进行模型学习</li>
</ol>
<h4 id="模型类"><a href="#模型类" class="headerlink" title="模型类"></a>模型类</h4><p>首先给出感知机函数定义：</p>
<blockquote>
<p>假设输入空间(特征空间)是$\mathcal{X} \subseteq R^n$,输出空间是$\mathcal{Y} = {-1,+1}$。输入$x\in \mathcal{X}$表示实例的特征向量，对应于输入空间(特征空间)的点；输出$y \in \mathcal{Y}$表示实例的类别。由输入空间到输出空间的函数可表示为:</p>
<script type="math/tex; mode=display">
    f(x) = sign(\omega x+ b)</script></blockquote>
<p>感知机是一种线性分类模型，属于判别模型。感知机模型的假设空间是定义在特征空间中的所有线性分类模型或线性分类起，即函数集合${ f|f(x) = \omega x + b}$。</p>
<h4 id="准则函数-损失函数"><a href="#准则函数-损失函数" class="headerlink" title="准则函数(损失函数)"></a>准则函数(损失函数)</h4><p>损失函数的一个自然选择是误分类点个数。但是这样的损失函数不是参数$\omega,b$的连续可导函数，不易优化。损失函数的另一个选择则是误分类点到超平面的总距离，为此先写出输入空间$R^n$中任意一点$x_0$到超平面$S$的距离：</p>
<script type="math/tex; mode=display">
    d= \frac{|\omega x_0 +b|}{|| \omega ||}</script><p>其次，对于误分类的数据$(x_i,y_i)$来说:</p>
<script type="math/tex; mode=display">
    -y_i(\omega \cdot x_i + b) >0</script><p>因此，误分类点$x_i$到超平面的距离为：</p>
<script type="math/tex; mode=display">
    \frac{-y_i(\omega x_i +b)}{|| \omega ||}</script><p>因此，若假设超平面$S$的误分类点集合为$M$,那么所有误分类点到超平面$S$的距离为：</p>
<script type="math/tex; mode=display">
    L = -\frac{1}{||\omega||} \sum_{x_i \in M} y_i (\omega x_i + b)</script><p>由此可见，在该目标函数下，若所有样本均被正确分类，则损失函数为0,因此不管是带范数的几何间隔，还是去掉范数的函数间隔，最终都将收敛到0，为计算方便，因此考虑将损失函数中的$||\omega||$去掉，写出目标函数如下：</p>
<script type="math/tex; mode=display">
    L(\omega,b) = -\sum_{x_i \in M} y_i (\omega x_i + b)</script><h4 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h4><p>在目标函数确定的情况下，对于该问题的优化考虑采用随机梯度下降法(SGD),首先求的目标函数对$\omega, b$的偏导：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \nabla_{\omega} L(\omega,b) &= -\sum_{x_i \in M}y_i x_i \\\\
        \nabla_{b} L(\omega,b) &= -\sum_{x_i \in M} y_i
    \end{aligned}</script><p>接下来对参数进行更新:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
         \omega &\leftarrow \omega + \eta y_i x_i  \\\\
         b &\leftarrow b + \eta y_i
    \end{aligned}</script><h4 id="感知机算法收敛性"><a href="#感知机算法收敛性" class="headerlink" title="感知机算法收敛性"></a>感知机算法收敛性</h4><p>在该部分将给出定理，但不加证明：</p>
<blockquote>
<p>设训练数据集是线性可分的，则：</p>
<ul>
<li>存在满足条件$||\omega|| = 1$的超平面将训练数据集完全分开，且存在$\gamma &gt;0$,对所有$i=1,\dots,N$:<script type="math/tex; mode=display">
  y_i\omega x_i \geq \gamma</script></li>
<li>令$R = max ||x_i||$,则感知机算法在训练集上的误分类次数$k$满足不等式:<script type="math/tex; mode=display">
  k \leq (\frac{R}{\gamma})^2</script></li>
</ul>
</blockquote>
<p>需要注意的是，当数据线性不可分时，感知机算法便不会收敛，当训练集线性可分时，感知机算法存在无穷多个解，其解由于不同的初值或者迭代顺序而可能有所不同</p>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>线性判别,感知机</tag>
      </tags>
  </entry>
  <entry>
    <title>聚类算法</title>
    <url>/2020/09/21/ju-lei-suan-fa/</url>
    <content><![CDATA[<p>聚类是将样本集合中相似的样本(实例)分配到相同的类，不相似的样本分配到不同的类。聚类时，样本通常是欧式空间中的向量，类别不是事先给定，而是从数据中自动发现，但<strong>类别的个数</strong>通常要预先给定。样本之间的相似度或距离由<strong>度量</strong>决定。如果一个样本只能属于一个类，则称为硬聚类；如果一个样本可以属于多个类，则称为软聚类。<br><span id="more"></span><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/clustering.png" alt="聚类"></p>
<p>在这一部分主要介绍四种聚类算法:</p>
<ul>
<li>$k$均值聚类 </li>
<li>层次聚类</li>
<li>谱聚类 </li>
<li>DBSCAN </li>
</ul>
<h3 id="k-均值聚类"><a href="#k-均值聚类" class="headerlink" title="$k$均值聚类"></a>$k$均值聚类</h3><h4 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h4><p>$k$均值聚类的思想非常直观:</p>
<blockquote>
<p>如果一团样本分布的足够紧凑，那么就可以认为这些样本属于一类，而一团样本的紧凑程度可以通过这些样本距离该团样本中心的距离和来衡量，距离和越小则说明该团样本越紧凑。</p>
</blockquote>
<h4 id="算法推导"><a href="#算法推导" class="headerlink" title="算法推导"></a>算法推导</h4><p>假设对于样本集$\mathcal{X}$, 初始时随机将样本分成$c$类，那么根据$k$均值的算法思想可以定义损失函数为:</p>
<script type="math/tex; mode=display">
    J(e) = \sum_{i=1}^c \sum_{y \in \Gamma_i} ||y - m_i||^2</script><p>公式中$m_i$是目前划归第$i$类样本的均值。想要求得使$J(e)$最小的最优样本划分并不容易，是一个NP难的问题，因此在优化时采用贪心策略，通过迭代优化的形式来进行求解。在迭代过程中，每次移动一个样本点来使$J(e)$减小，为此我们需要计算将一个样本点$y$从$\Gamma_i$类转移到$\Gamma_k$类对损失函数的影响，因为损失函数是依类别进行计算然后累加的，不妨将$\Gamma_i$的类的损失记做$J_i$。在将$y$移动之后，$\Gamma_i$和$\Gamma_k$类均发生了变化，均值分别变为:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        m'_i &= m_i + \frac{m_i - y}{N_i - 1} \\
        m'_k &= m_k  + \frac{y - m_k}{N_k + 1}
    \end{aligned}</script><p>据此，可以分别计算出$J’_i$和$J’_k$并用$J_i, J_k$表示:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        J'_i &= J_i - \frac{N_i}{N_i - 1} ||y - m_i||^2 \\ 
        J'_k &= J_k + \frac{N_k}{N_k + 1} ||y - m_k||^2 
    \end{aligned}</script><p>如果$J’_i &gt; J’_k$，就将样本从$i$类移动到$k$类，由此便可以得到$k$均值聚类步骤:</p>
<blockquote>
<p><strong>$k$均值:</strong> </p>
<ul>
<li>Step1: 把样本初始划分成$C$类，并计算$J_e$ </li>
<li>Step2: 选择一个样本$y$，假设$y \in \Gamma_i$ </li>
<li>Step3: 若$N_i = 1$, 则转Step2 </li>
<li>Step4: 计算<script type="math/tex; mode=display">
   \rho_j = \begin{cases}
       \frac{N_j}{N_j + 1} ||y - m_j||^2 & j \neq i \\
       \frac{N_i}{N_i - 1} ||y - m_i||^2 & j = i
   \end{cases}</script></li>
<li>Step5: 若对$\forall j, \rho_k \leq \rho_j$, 则将$y$从$\Gamma_i$移动到$\Gamma_k$中去。</li>
<li>Step6: 修正$m_i,m_k$和$J_e$ </li>
<li>Step2: 若连续迭代$N$次(将样本遍历一遍)不变，则算法终止，否则回到Step2</li>
</ul>
</blockquote>
<h4 id="算法分析"><a href="#算法分析" class="headerlink" title="算法分析"></a>算法分析</h4><h5 id="算法时间复杂度"><a href="#算法时间复杂度" class="headerlink" title="算法时间复杂度"></a>算法时间复杂度</h5><p>假设算法迭代$t$次后收敛，样本个数为$n$，样本维数为$d$， 类别数目为$k$，则算法时间复杂度为:</p>
<script type="math/tex; mode=display">
    O(tndk)</script><h5 id="算法超参数"><a href="#算法超参数" class="headerlink" title="算法超参数"></a>算法超参数</h5><p>算法要求预先制定聚类类别个数$k$</p>
<h5 id="局部极小"><a href="#局部极小" class="headerlink" title="局部极小"></a>局部极小</h5><p>因为$k$均值算法本质上是贪心算法，因此很有可能陷入局部最优，可以通过更新聚类个数以及不同的初始化来一定程度上减轻局部最优，来获得较好的聚类效果。 </p>
<h3 id="层次聚类"><a href="#层次聚类" class="headerlink" title="层次聚类"></a>层次聚类</h3><h4 id="算法思想-1"><a href="#算法思想-1" class="headerlink" title="算法思想"></a>算法思想</h4><p>层次聚类首先将各个样本点划分为1类，然后将距离最近的两类进行合并，建立一个新的类，重复这个步骤直到聚类结果满足要求。<br>从定义来看，层次聚类算法是自下而上进行聚类，在应用该聚类算法时需要明确三个问题:</p>
<ul>
<li>相似性度量的选择</li>
<li>合并规则，即如何定义两个类别的相似程度 </li>
<li>停止条件  </li>
</ul>
<p>下面就这三个关键问题进行分析。</p>
<h4 id="算法详述"><a href="#算法详述" class="headerlink" title="算法详述"></a>算法详述</h4><h5 id="相似性度量"><a href="#相似性度量" class="headerlink" title="相似性度量"></a>相似性度量</h5><p>任何一个聚类算法会面临相似性度量的选择问题，实际中常用的相似性度量有:</p>
<ul>
<li>欧式距离 </li>
<li>马氏距离 </li>
<li>测地距离</li>
<li>…… </li>
</ul>
<p>具体选择什么样的度量来刻画相似度需要根据实际数据样本的分布情况和待解决的问题来确定。 </p>
<h5 id="合并规则"><a href="#合并规则" class="headerlink" title="合并规则"></a>合并规则</h5><p>合并规则一般是类间距离最小，若记$\Delta(\Gamma_i, \Gamma_j)$为类间距离，$\delta(x,y)$,为$x$和$y$之间的距离，则类间距离一般有以下几种定义:</p>
<ul>
<li>最近距离 <script type="math/tex; mode=display">
  \Delta(\Gamma_i, \Gamma_j) = \min_{y \in \Gamma_i, \tilde{y} \in \Gamma_j} \delta(y, \tilde{y})</script></li>
<li>最远距离 <script type="math/tex; mode=display">
  \Delta(\Gamma_i, \Gamma_j) = \max_{y \in \Gamma_i, \tilde{y} \in \Gamma_j} \delta(y, \tilde{y})</script></li>
<li>均值距离<script type="math/tex; mode=display">
  \Delta(\Gamma_i, \Gamma_j) = \delta(m_i, m_j)</script></li>
</ul>
<h5 id="停止条件"><a href="#停止条件" class="headerlink" title="停止条件"></a>停止条件</h5><p>如果不加停止条件，则最终所有样本都会归于一类，停止条件一般有2种选择:</p>
<ul>
<li>类别个数: 当类别个数到达期望值$k$时，便停止合并，聚类结束。 </li>
<li>类间距离: 当类间距离大于某个值时便停止合并，聚类结束。</li>
</ul>
<h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4><p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/hc.png" alt="聚类树"><br>层次聚类算法流程总结如下: </p>
<blockquote>
<p><strong>层次聚类:</strong><br><strong>输入:</strong> $n$个样本组成的样本集合及样本之间的距离<br><strong>输出:</strong> 对样本集合的一个层次化聚类<br><strong>算法流程:</strong></p>
<ul>
<li>根据选定的相似性度量方法，计算$n$个样本两两之间的距离$d_{ij}$,得到距离矩阵$D$ </li>
<li>构造$n$个类，每个类只包含一个样本 </li>
<li>合并类间距离最小的两个类，构成一个新类，并计算新类与当前各类之间的距离。</li>
<li>若满足聚类终止条件，则聚类终止，否则返回第3步 </li>
</ul>
</blockquote>
<h3 id="谱聚类"><a href="#谱聚类" class="headerlink" title="谱聚类"></a>谱聚类</h3><h4 id="算法思想-2"><a href="#算法思想-2" class="headerlink" title="算法思想"></a>算法思想</h4><p>谱聚类算法是从图论中衍生出的一种算法，后来在聚类问题中得到了广泛的应用。它的主要思想是把所有的数据看做空间中的点，这些点之间可以用边连接起来。距离较远的两个点之间的边权重值较低，而距离较近的两个点之间的边权重值较高，通过对所有数据点组成的图进行切图，让切图后不同的子图间边权重和尽可能的低，而子图内的边权重和尽可能的高，从而达到聚类的目的。</p>
<p>学习谱聚类算法主要需要理清两个问题:</p>
<ul>
<li>无向权重图的相关定义 </li>
<li>拉普拉斯矩阵</li>
<li>图的切割任务 </li>
</ul>
<p>下面就按这个思路来对谱聚类算法进行介绍。 </p>
<h4 id="无向权重图"><a href="#无向权重图" class="headerlink" title="无向权重图"></a>无向权重图</h4><p>对于我们的样本集$\mathcal{X} \subseteq \mathbb{R}^d$，可以将每一个样本点看作高维空间中的一个点，若将这些点以某种方式连接起来则构成了一个图，如果对于相连的两个节点$x$和$y$，若并不区分$x \rightarrow y$和$y \rightarrow x$，则构成了一个无向图。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/AG.jpg" alt="无向图"></p>
<p>但对于我们的聚类任务，我们期望距离较近的点它们之间的连接权重大一些，距离较远的样本点之间的权重小一些么，从这样的一个想法出发，我们有以下几种方式来构造相似性图:</p>
<ul>
<li>$k$近邻图: 若$v_i$是$v_j$的$k$近邻，则$v_i$和$v_j$之间存在一条边，边上权重设置为1。</li>
<li>对称$k$近邻图: 若两个点互为$k$近邻，则这两个点之间存在一条边。</li>
<li>$\epsilon$-近邻图: 任意两个距离小于$\epsilon$的点之间存在一条边 </li>
<li>全连接图: 相似性大于0的两个点之间均存在一条边，常用高斯核函数来进行相似性度量:<script type="math/tex; mode=display">
  W_{ij} = S_{ij} = \exp(- \frac{||x_i - x_j||^2}{2 \sigma^2})</script></li>
</ul>
<p>下面给出一些符号定义:</p>
<ul>
<li>$w_{ij}$： 边权重 </li>
<li>节点$v<em>i \in V$的度: $d_i = \sum</em>{j=1}^n w_{ij}$ </li>
<li>度矩阵: $D = diag(d_1,d_2, \dots, d_n)$ </li>
<li>加权邻接矩阵: $W = (w<em>{ij})</em>{i,j= 1,\dots,n}$  </li>
</ul>
<h4 id="拉普拉斯矩阵"><a href="#拉普拉斯矩阵" class="headerlink" title="拉普拉斯矩阵"></a>拉普拉斯矩阵</h4><p>拉普拉斯矩阵的定义非常简单：</p>
<script type="math/tex; mode=display">
    L = D - W</script><p>拉普拉斯矩阵具有很多很好的性质: </p>
<ul>
<li>拉普拉斯矩阵是对称矩阵，该性质可由$D$和$W$的对称性质得到</li>
<li>对于任意的向量$f \in \mathbb{R}^n$,有:<script type="math/tex; mode=display">
  f^T L f = \frac{1}{2} \sum_{i,j=1}^n w_{ij} (f_i - f_j)^2</script></li>
<li>$L$是半正定矩阵，该性质由上一条性质可以直接得出</li>
</ul>
<p>另一种常用形式是拉普拉斯矩阵的归一化形式:</p>
<script type="math/tex; mode=display">
    L_{rw} = D^{-1} L = I - D^{-1} W</script><p>为了保证$L_{rw}$也是对称形式，常采用另一种形式:</p>
<script type="math/tex; mode=display">
    L_{rw} = D^{-\frac{1}{2}} W D^{-\frac{1}{2}}</script><p>这样，$L_{rw}$也具有原始拉普拉斯矩阵的一些好的性质，比如对称性，半正定等性质。</p>
<h4 id="图的切割任务"><a href="#图的切割任务" class="headerlink" title="图的切割任务"></a>图的切割任务</h4><p>在已经定义好权重无向图的情况下，现在我们考虑这样一个任务: </p>
<blockquote>
<p>将已经得到的图进行划分，使得不同点集边的权重较小，而同一点集内的边权重较大。以这种思想来完成聚类任务。 </p>
</blockquote>
<p>直接想到的损失函数是如下形式:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        cut(A_1,A_2,\dots, A_k) &:= \frac{1}{2} \sum_{i=1}^k W(A_i, \bar{A}_i) \\
        W(A, B) &:= \sum_{i \in A, j \in B} w_{ij}
    \end{aligned}</script><p>但选择这样形式的损失函数，最后往往是有一类包含非常多的点， 其他类都是单独的点。以聚成两类为例，假设有12个点，若两类各6个点，则最终计算损失函数时，需要将$2<em>6</em>6=72$项求和，若一类11个点，一类1个点，则最终计算时只需要将$2<em>1</em>11=22$项求和，这也是为何选用上述损失函数容易得到单独的点。<br>我们在聚类时，往往期望各个类别的样本点个数比较均衡，因此考虑在损失函数中对样本点较少的类别进行惩罚，由此便可得到两种损失函数定义:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        RatioCut(A_1, A_2, \dots, A_k) &:= \frac{1}{2} \sum_{i=1}^k \frac{W(A_i, \bar{A}_i)}{|A_i|} = \sum_{i=1}^k \frac{cut(A_i, \bar{A}_i)}{|A_i|} \\
        Ncut(A_1,A_2, \dots, A_k) &:= \frac{1}{2} \sum_{i=1}^k \frac{W(A_i, \bar{A}_i)}{Vol(A_i)} = \sum_{i=1}^k \frac{cut(A_i, \bar{A}_i)}{Vol(A_i)}
    \end{aligned}</script><p>其中$|A_i|$表示集合$A_i$中的元素个数，$vol(A_i)$表示集合$A_i$中元素度的总和。 </p>
<h5 id="RatioCut-切图"><a href="#RatioCut-切图" class="headerlink" title="$RatioCut$切图"></a>$RatioCut$切图</h5><p>若以Ratiocut作为目标函数，则优化问题可以写做:</p>
<script type="math/tex; mode=display">
    \min_{A_1, A_2, \dots, A_k} RatioCut(A_1,A_2,\dots, A_k)</script><p>这个问题是很难直接求解的，因此牛人们考虑通过另一种方式来对$RatioCut$进行表示，我们引入指示向量$h<em>j = {  h_1, h_2, \dots, h_k}, j = 1,2, \dots, k$,对于任意一个向量$h_j$,它是一个$n$维向量，我们定义$h</em>{ji}$为:</p>
<script type="math/tex; mode=display">
    h_{ji} = \begin{cases}
        0 & v_i \notin A_j \\
        \frac{1}{\sqrt{|A_j|}} & v_i \in A_j 
    \end{cases}</script><p>那么我们对于$h_i^T L h_i$, 有: </p>
<script type="math/tex; mode=display">
    \begin{aligned}
        h_i^T L h_i &= \frac{1}{2} \sum_{j=1}^n \sum_{k=1}^n w_{jk}(h_{ij} - h_{ik})^2 \\
        &= \frac{1}{2} [\sum_{j \in A_i, k \notin A_i} w_{jk} (\frac{1}{\sqrt{|A_i|}} - 0)^2 + \sum_{j \notin A_i, k \in A_i} w_{jk} (0 - \frac{1}{\sqrt{|A_i|}})^2] \\
        &= \frac{1}{2} [\sum_{j \in A_i, k \notin A_i} w_{jk} \frac{1}{|A_i|} + \sum_{j \notin A_i, k \in A_i} w_{jk} \frac{1}{|A_i|}] \\ 
        &= \frac{1}{2} (cut(A_i, \bar{A}_i) \frac{1}{|A_i|} + cut(\bar{A}_i, A_i)\frac{1}{|A_i|} ] \\
        &= RatioCut(A_i, \bar{A}_i) 
    \end{aligned}</script><p>因此若以$RatioCut$作为目标函数，则可以表示为:</p>
<script type="math/tex; mode=display">
    RationCut(A_1,A_2, \dots, A_k) = \sum_{i=1}^k h_i^T L h_i = trace(H^T L H)</script><p>其中:</p>
<script type="math/tex; mode=display">
    H = [h_1, h_2, \dots, h_k]</script><p>因此我们如果要最小化$RatioCut$切图可以近似等价于优化如下问题:</p>
<script type="math/tex; mode=display">
    \arg \min_{H} tr(H^T L H)  \quad s.t. H^TH = I，     h_{ji} = \begin{cases}
        0 & v_i \notin A_j \\
        \frac{1}{\sqrt{|A_j|}} & v_i \in A_j 
    \end{cases}</script><p>但因为在上面推导过程中我们对矩阵$H$的形式做了限制，这是一个离散优化问题，找到满足优化目标的$H$矩阵是一个NP难的问题，因此我们考虑将离散约束放松，求解近似问题:</p>
<script type="math/tex; mode=display">
    \arg \min_{H} tr(H^T L H)  \quad s.t. H^TH = I</script><p>该优化问题其实就是一个瑞丽熵优化问题，如果要聚成$k$类，只需要取矩阵$L$的前$k$小的特征值所对应的特征向量即可。同时注意到$L$矩阵有着很好的性质:</p>
<blockquote>
<p>拉普拉斯矩阵的的最小特征值为0，特征值0的重数等于图$G$连通分量$A<em>1, \dots, A_k$的个数，且相应的特征空间可由$\mathbf{1</em>{A<em>1}}, \dots, \mathbf{1</em>{A<em>k}}$张成，其中$\mathbf{1</em>{A_i}}$中与$A_i$相对应的分量为1，其余分量为0。<br><strong>证明:</strong>  特征值0所对应的特征向量$f$应当满足:</p>
<script type="math/tex; mode=display">
    0 = f^T L f = \frac{1}{2} \sum_{i,j=1}^n w_{ij} (f_i - f_j)^2</script><p>也就是说对于$w_{ij} \neq 0$(两点之间连通)的情况，应当有$f_i = f_j$。</p>
</blockquote>
<p>而该特征向量刚好与上面最小割优化问题中$h<em>i$的要求相吻合，但因为我们根据相似性度量所构造的图可能是一个全连接图或者连通分量的个数与我们的聚类个数并不相等，则最终得到的$H</em>{n \times k}$很可能是如下的形式(以$n=5,k=3$为例,未对特征向量做归一化):</p>
<script type="math/tex; mode=display">
    H = \begin{bmatrix}
        0.95 & 0.01 & 0.01 \\
        0.96 & 0.01 & 0.01 \\ 
        0.01 & 0.95 & 0.01 \\
        0.01 & 0.95 & 0.01 \\
        0.01 & 0.01 & 0.95  
    \end{bmatrix}</script><p>因此在在降维之后，往往会对图分割向量$h_i$再做一次k-means聚类。若选用$NCut$作为优化目标，则最终可以推导出等价于优化如下问题:</p>
<script type="math/tex; mode=display">
    \arg \min_{F} tr(F^T D^{-\frac{1}{2}} L D^{-\frac{1}{2}} F) \quad s.t. F^TF  =I</script><p>所以最终只需要取归一化对称拉普拉斯矩阵的前$k$小的特征值所对应的特征向量组成$F_{n \times k}$，然后再使用k-means算法进行一次聚类就可以。</p>
<h4 id="谱聚类算法流程总结"><a href="#谱聚类算法流程总结" class="headerlink" title="谱聚类算法流程总结"></a>谱聚类算法流程总结</h4><p>下面给出谱聚类算法流程:</p>
<blockquote>
<p><strong>谱聚类算法:</strong><br><strong>输入:</strong> 样本集$D = (x_1, x_2, \dots, x_n)$,相似矩阵生成方式，聚类类别$k$，输入聚类方法<br><strong>输出:</strong> 簇划分$C = (A_1, A_2, \dots, A_k)$<br><strong>步骤:</strong> </p>
<ul>
<li>根据输入的相似矩阵生成方式构建样本的相似矩阵$S$ </li>
<li>根据相似矩阵$S$构建邻接矩阵$W$和度矩阵$D$ </li>
<li>计算拉普拉斯矩阵$L = D - W$或归一化拉普拉斯矩阵$L_{rw} = D^{-\frac{1}{2}} L D^{-\frac{1}{2}}$ </li>
<li>计算(归一化)拉普拉斯矩阵最小的$k$个特征值所对应的特征向量 </li>
<li>利用$k$个特征向量构成矩阵$F_{n\times k}$</li>
<li>每一行原始样本在$k$维空间的投影点，利用输入聚类方法(常用k-means)进行聚类 </li>
<li>得到簇划分$C = (A_1, A_2, \dots, A_k)$ </li>
</ul>
</blockquote>
<h3 id="DBSCAN"><a href="#DBSCAN" class="headerlink" title="DBSCAN"></a>DBSCAN</h3><p>前面介绍的几种聚类算法可以归为“基于距离的聚类”，即在某种距离度量下，距离较近的点划归一类。但对于某些数据，使用基于距离的聚类方法可能并不理想，比如下图:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/dbscan.png" alt="数据点"><br>我们人眼直觉上会将外圈(蓝色样本点)划分为一类，将内圈(红色样本点)划分为一类，我们会有这样的直觉是因为外圈和内圈的样本点是分别连续的，为了让计算机能够实现这种情况下样本的聚类，基于密度的聚类算法便诞生了。<br>密度聚类算法假设聚类结构能够通过样本分布的紧密程度确定。通常情形下，密度聚类算法从样本密度的角度来考察样本之间的可连接性，并基于可连接样本不断扩展聚类簇以获得最终的聚类结果。<br><strong>DBSCAN</strong>是一种著名的密度聚类算法，它基于一组邻域参数($\epsilon, Minpts$)来刻画样本分布的紧密程度，给定数据集$D = (x_1, x_2, \dots, x_n)$, 定义下面几个概念:</p>
<ul>
<li>$\epsilon$-邻域: 对$x_j \in D$,其$\epsilon$-邻域中包含样本集$D$中与$x_j$的距离不大于$\epsilon$的样本，即:<script type="math/tex; mode=display">
  N_\epsilon(x_j) = \{ x_i \in D | dist(x_i, x_j) \leq \epsilon \}</script></li>
<li>核心对象: 若$x<em>j$的$\epsilon$-邻域中至少包含$MinPts$个样本，即$|N</em>\epsilon(x_j)| \geq MinPts$, 则$x_j$是一个核心对象。</li>
<li>密度直达: 若$x_j$位于$x_i$的$\epsilon$邻域中，且$x_i$是核心对象，则称$x_j$由$x_i$密度直达。</li>
<li>密度可达: 对$x<em>i$与$x_j$，若存在样本序列$p_1,p_2,\dots, p_n$，其中$p_1 = x_i, p_n = x_j$,且$p</em>{i+1}$由$p_i$密度直达，则称$x_j$由$x_i$密度可达。 </li>
<li>密度相连: 对$x_i$与$x_j$,若存在$x_k$使得$x_i$与$x_j$均由$x_k$密度可达，则称$x_i$与$x_j$密度相连。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/Minpts.png" alt="邻域概念"></p>
<p>基于这些概念，DBSCAN将“簇”定义为:</p>
<blockquote>
<p>由密度可达关系导出的最大的密度相连样本集合，形式化地说，给定邻域参数$(\epsilon, Minpts)$,簇$C \subseteq D$是满足以下性质的非空样本子集:</p>
<ul>
<li>连接性: $x_i \in C, x_j \in C \Rightarrow$ $x_i$与$x_j$密度相连</li>
<li>最大性: $x_i \in C$, $x_j$由$x_i$密度可达 $\Rightarrow x_j \in C$ </li>
</ul>
</blockquote>
<p>在给出了聚类簇的定义后，我们需要解决的问题便是如何从数据集$D$中找出满足以上性质的聚类簇。实际上，若$x$为核心对象，则$x$密度可达的所有样本组成的集合记为$X = { x’ \in D | x’由 x 密度可达 }$,容易证明$X$即为满足连接性与最大性的簇。</p>
<p>于是，<strong>DBSCAN</strong>算法先任选数据集中的一个核心对象作为“种子”，再由此出发确定相应的聚类簇，算法流程如下:</p>
<blockquote>
<p><strong>DBSCAN算法</strong><br><strong>输入:</strong> 样本集$D = (x_1,\dots,x_n)$,邻域参数$(\epsilon, MinPts)$<br><strong>输出:</strong> 簇划分$C = (A_1, A_2, \dots, A_k)$<br><strong>算法流程:</strong></p>
<ul>
<li>初始化核心对象集合$\Omega = \varnothing$ </li>
<li>遍历所有样本点，将所有核心对象放入集合$\Omega$ </li>
<li>初始化聚类簇数$k=0$, 初始化未访问样本集合$\Gamma = D$ </li>
<li>随机从$\Omega$中取一个核心对象，然后基于该核心对象得到聚类簇$C_k$,更新:<script type="math/tex; mode=display">
  \Omega = \Omega \backslash C_k, \Gamma = \Gamma \backslash C_k</script></li>
<li>重复以上步骤直到$\Omega$为空</li>
</ul>
</blockquote>
<p>但需要注意的是，采用$DBSCAN$聚类方法，如果邻域参数$(\epsilon, MinPts)$选择不恰当会导致一些样本点不会被归到任何类别。</p>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>kmeans，层次聚类，谱聚类</tag>
      </tags>
  </entry>
  <entry>
    <title>自然语言处理学习</title>
    <url>/2022/10/06/zi-ran-yu-yan-chu-li-xue-xi/</url>
    <content><![CDATA[<p>最近打算入门一下nlp,选择的课程是<a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/">CS224n: Natural Language Processing with Deep Learning</a>，打算以该课程的课件为脉络来了解nlp领域，本篇博客用来进行学习记录。<span id="more"></span> </p>
<h4 id="Lecture1-Introduction-and-word-vectors"><a href="#Lecture1-Introduction-and-word-vectors" class="headerlink" title="Lecture1: Introduction and word vectors"></a>Lecture1: Introduction and word vectors</h4><h4 id="传统的词表示"><a href="#传统的词表示" class="headerlink" title="传统的词表示"></a>传统的词表示</h4><p>如何让计算机理解自然语言的含义？ </p>
<ul>
<li><code>Wordnet</code>: 包含同义词集和上位词列表的同义词库，通过维护一个分类清晰的庞大词表使计算机能够理解某个单词在语言框架中所处的位置(<code>词性</code>、<code>含义</code>、<code>上位词</code>)。但这样做存在以下问题: <ul>
<li>无法区分词之间的细微差别 </li>
<li>不够完整，难以保持up-to-date </li>
<li>带有主观性 </li>
<li>依赖于人力构建 </li>
<li>无法计算词之间的相似度 </li>
</ul>
</li>
<li>在传统的NLP，我们将单次看作离散的符号，通过one-hot编码的形式来表示每个单词<br><img src="/.io//onehot.jpg" alt><ul>
<li>两个不同的词的one-hot表征是彼此正交的，没有办法衡量两个词之间的相似度 <ul>
<li>通过<code>Wordnet</code>等词表来获取单词之间的相似度，但仍具有上述问题 </li>
<li><strong>在向量空间对相似度进行编码</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Word-vectors"><a href="#Word-vectors" class="headerlink" title="Word vectors"></a>Word vectors</h4><p>针对如何在向量空间对单词相似度进行编码，后续又有了一系列的工作: </p>
<ul>
<li><strong>分布语义</strong>：一个单词的意义是由经常出现在其旁边的单词给出的 </li>
<li>考虑通过一个单词的上下文来构建该单词的表示<br><img src="/.io//context.jpg" alt></li>
</ul>
<blockquote>
<p><strong>Word vectors/embeddings/representations</strong>: 为每个单词找到一个稠密向量表示，使得出现在相似上下文的单词具有相似的向量表示 </p>
</blockquote>
<ul>
<li><p>Word2Vec: Overview</p>
<ul>
<li>有大量单词的文本语料库 </li>
<li>词汇表中的每个单词都用一个向量(one-hot)表示 </li>
<li>对于文本中的每个位置，都有一个中心单词$c$和上下文单词集合$\mathbf{o}$</li>
<li>考虑使用中心单词$c$的单词向量来预测上下文单词$\mathbf{o}$(反之亦然) </li>
<li>调整单词向量使得对上下文/中心向量的预测尽可能准确，最大化$p(\mathbf{o}|t)$<br><img src="/.io//wordvector.jpg" alt></li>
</ul>
</li>
<li><p>推导 </p>
<ul>
<li>似然函数 <script type="math/tex; mode=display">
L(\theta)=\prod_{\substack{t=1}} \prod_{\substack{m \leq j \leq m \\ j \neq 0}} P\left(w_{t+j} \mid w_t ; \theta\right)</script></li>
<li>一般进行优化都是最小化负对数似然: <script type="math/tex; mode=display">
J(\theta)=-\frac{1}{T} \sum_{t=1}^T \sum_{\substack{m \leq j \leq m \\ j \neq 0}} \log P\left(w_{t+j} \mid w_t ; \theta\right)</script></li>
<li>条件概率$P(w_{t+j}|w_t;\theta)$：softmax function <script type="math/tex; mode=display">
P(o \mid c)=\frac{\exp \left(u_o^T v_c\right)}{\sum_{w \in V} \exp \left(u_w^T v_c\right)}</script></li>
</ul>
</li>
<li>两种模型<ul>
<li>Skip-gram: 用中间单词来预测上下文</li>
<li>Continuous Bag of Words(CBOW): 用上下文单词预测中间单词 </li>
</ul>
</li>
</ul>
<h5 id="CBOW"><a href="#CBOW" class="headerlink" title="CBOW"></a>CBOW</h5><p>基本思想是用上下文单词来预测中间单词，流程如下： </p>
<blockquote>
<ul>
<li>假设词库容量为$V$, 窗口宽度为$m$, embedding维度为$N$, 单个句子$x$, 中心单词位置$c$</li>
<li>task: $(x<em>{c-m}, x</em>{c-m+1}, … , x<em>{c-1}, x</em>{c+1}, … , x_{c+m}) \rightarrow x_c$</li>
</ul>
</blockquote>
<p><img src="/.io//CBOW.jpg" alt> </p>
<ul>
<li>2个矩阵<ul>
<li>Embedding mat $W_e \in \mathbb{R}^{V \times N}$</li>
<li>Predict mat $W_p \in \mathbb{R}^{N \times V}$ </li>
</ul>
</li>
<li>流程 <ul>
<li>通过$W_e$得到各个单词的embedding $v_i = W_e^Tx_i \in \mathbb{R}^{N \times 1}$(本质上就是抽取了$W_e$的某一行) </li>
<li>取平均： $\hat{v} = \frac{v<em>{c-2m} + … + v</em>{c+2m}}{2m}$  </li>
<li>通过$W_p$得到预测结果： $z = W_p^T \hat{v} \in \mathbb{R}^{V \times 1}$ </li>
<li>将该预测结果通过softmax函数转换成概率形式: $\hat{y} = softmax(z)$ </li>
</ul>
</li>
</ul>
<h5 id="Skip-Gram-Model"><a href="#Skip-Gram-Model" class="headerlink" title="Skip-Gram Model"></a>Skip-Gram Model</h5><p>基本思想是使用中间单词来预测其上下文单词 </p>
<blockquote>
<ul>
<li>假设词库容量为$V$, 窗口宽度为$m$, embedding维度为$N$, 单个句子$x$, 中心单词位置$c$</li>
<li>task: $x<em>c \rightarrow (x</em>{c-m}, x<em>{c-m+1}, … , x</em>{c-1}, x<em>{c+1}, … , x</em>{c+m})$</li>
</ul>
</blockquote>
<ul>
<li>流程: 基本就是CBOW的逆过程 </li>
</ul>
<h5 id="负采样-Negative-sampling"><a href="#负采样-Negative-sampling" class="headerlink" title="负采样(Negative sampling)"></a>负采样(Negative sampling)</h5><p>如果不进行优化，那么两种wordvec方法在计算过程中都需要更新词汇表中所有单词用于训练，而对于输出层，正样本其实只对应着极少数的样本，而其余均是大量的负样本(输出结果的one-hot编码不匹配)，负采样的直观想法便是随机选择一小部分negative words来更新权重，可以大大提高计算效率 </p>
<h5 id="Hierachical-softmax"><a href="#Hierachical-softmax" class="headerlink" title="Hierachical softmax"></a>Hierachical softmax</h5><p>通过分层的形式将一个$V$分类问题变成了$logV$个二分类问题，</p>
]]></content>
      <tags>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title>自编码器AE</title>
    <url>/2020/10/10/zi-bian-ma-qi-ae/</url>
    <content><![CDATA[<p>在进行数据降维和数据降噪时常用的深度学习方法是自编码器<code>AutoEncoder</code>类算法，其具有以下特点:</p>
<ul>
<li>自编码器类算法属于无监督学习范畴</li>
<li>从结构上来看自编码器类算法包含编码器和解码器两部分 </li>
<li>自编码器算法常用做特征提取 </li>
</ul>
<p>本文按照以下结构进行组织:</p>
<ul>
<li>自编码器AE</li>
<li>变分自编码器VAE </li>
<li>降噪自编码器DAE <span id="more"></span>
<h3 id="自编码器AE"><a href="#自编码器AE" class="headerlink" title="自编码器AE"></a>自编码器AE</h3></li>
</ul>
<h4 id="自编码器算法思想"><a href="#自编码器算法思想" class="headerlink" title="自编码器算法思想"></a>自编码器算法思想</h4><p>所谓的自编码器从名称上来理解，便是对自己进行编码，首先给出维基百科上关于自编码器的定义:</p>
<blockquote>
<p><strong>自编码器:</strong> 自编码，也称自动编码器，是一种人工神经网络，在无监督学习中用于有效编码。自编码的目的是对一组数据学出一种表示，通常用于降维。 </p>
</blockquote>
<p>一个自编码器一般具有如下结构:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/AE.png" alt="自编码器"></p>
<p>从上图可以看出，自编码器模型主要由编码器和解码器组成，其主要目的是将输入变量映射到中间变量$z$，然后再将中间变量$z$映射成$x’$， 模型训练的目标是$x$和$x’$尽可能接近，编码器和解码器分别实现了以下功能: </p>
<ul>
<li>编码器: 将输入数据映射到隐含特征空间 </li>
<li>解码器: 基于隐含特征来重构原始数据 </li>
</ul>
<p>单纯从形式上来看，自编码器就是一个普通的神经网络，只是网络输出为输入数据本身；但如果从算法思想的角度，我们一般所接触的神经网络所开展的任务往往是有监督学习问题，比如分类和回归预测，而对于无监督学习问题，比如聚类、降维，还是统计学习中的一些传统算法应用较多，而自编码器则就给予了我们一个应用深度学习方法来开展无监督学习的思路。</p>
<p>初学者在开展自编码器学习过程中绕不开的一个问题就是:</p>
<blockquote>
<p>训练这样一个恒等映射网络有什么意义? </p>
</blockquote>
<p>我在刚了解自编码器算法思想时也有这样的疑问，但在对无监督学习思想有了更多理解之后我认为构建这样一个恒等映射网络有以下几方面应用: </p>
<ul>
<li><strong>数据压缩/降维:</strong> 在图像压缩领域，一个图像可能动辄几MB甚至几十MB，在进行传输中需要大量的流量，而假设我们已经有了一个训练好的自编码神经网络，而特征空间维度较低，我们就可以在发送端应用训练好的自编码器进行数据压缩，然后将压缩后的数据传输到接收端，接收端再使用解码器来对图像进行还原。</li>
<li><strong>特征提取:</strong> 数据压缩本身也是一种特征提取，而具体提取什么样的特征则是与数据相关的，而自编码器提取特征的标准则是希望提取的隐层特征能够在自编码器神经网络框架下较精确地重构原始数据，提取后的特征可以送入下游机器学习算法中以完成下游任务。</li>
</ul>
<p>在进行自编码器算法应用时，需要注意以下两点问题: </p>
<ul>
<li>自动编码器是数据相关的，这也就意味着自动编码器只能压缩那些与训练数据类似的数据，如果从概率分布的角度来进行理解，编码器其实就是学到了一个映射，将原始空间的数据分布映射到特征空间的某个概率分布，这也就意味着如果模型训练的比较充分且新来的样本与训练样本同分布，则自编码器就能较好地对新样本数据进行编码。 </li>
<li>自动编码器是有损的，这是因为经过编码解码后的输出与输入相比还是有误差的/退化的，这个误差我们一般称之为重构误差。</li>
<li>自动编码器算法属于一种无监督学习算法。</li>
</ul>
<h4 id="自编码器搭建及学习"><a href="#自编码器搭建及学习" class="headerlink" title="自编码器搭建及学习"></a>自编码器搭建及学习</h4><p>自编码器其实可以看作一整个神经网络，包含编码器与解码器两部分，分别学习不同的映射: </p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &Encoder: x \rightarrow f(x) \quad \mathbb{R}^d \rightarrow \mathbb{R}^{d'}\\ 
        &Decoder: f(x) \rightarrow x' \quad \mathbb{R}^{d'} \rightarrow \mathbb{R}^d
    \end{aligned}</script><p>如果对自编码器的算法思想理解了同时具备神经网络搭建训练方面的知识，则自编码器的搭建及训练不需要再单独学习。</p>
<h4 id="常见自编码器类型"><a href="#常见自编码器类型" class="headerlink" title="常见自编码器类型"></a>常见自编码器类型</h4><p>常用自编码器有以下集中几种类型: </p>
<ul>
<li><strong>堆栈自编码器</strong>: 所谓堆栈自编码器实际上就是最普通的自编码器，编码器和解码器网络结构层数均大于1。</li>
<li><strong>欠完备自编码器</strong>: 如果编码器输出特征维度$h$小于原始数据特征维度$d$，则对应的自编码器称为欠完备自编码器，在进行数据降维时一般都是采用欠完备自编码器。</li>
<li><strong>正则自编码器</strong>: 普通的堆栈自编码器只是学习了一个恒等映射，而我们有时候期望降维后的特征能够具有某些特性，这些特性包括系数表示、对噪声鲁棒性等，而要达成这样的目的往往会在目标函数上添加一个正则项。</li>
<li><strong>降噪自编码器</strong>: 降噪自编码器与其说是一个算法结构，实际上更像是一种模型训练的trick，降噪自编码器以损坏/缺失的数据作为输入，然后来预测原始的未损坏/缺失的数据，从而使自编码器学习到从缺失数据恢复为未缺失数据的能力。   <h3 id="变分自编码器VAE"><a href="#变分自编码器VAE" class="headerlink" title="变分自编码器VAE"></a>变分自编码器VAE</h3><h4 id="自编码器生成内容局限性"><a href="#自编码器生成内容局限性" class="headerlink" title="自编码器生成内容局限性"></a>自编码器生成内容局限性</h4>在训练好了一个自编码器以后，我们可能会考虑这样一个问题:<blockquote>
<p>能否应用自编码器来进行数据生成?<br>如果隐空间足够规则，我们是否可以从隐空间中随机取一个点并将其解码以获得新的内容，就像生成对抗网络中的生成器那样。 </p>
</blockquote>
</li>
</ul>
<p>这样做是并不行的，主要是因为两个原因:</p>
<blockquote>
<ul>
<li>隐空间缺乏可解释和可利用的结构，缺乏规则性( lack of regularity )，关于这一点我们可以举一个极端的例子，假设编码器和解码器足够强大，将$N$个样本分别映射到了一维的隐空间，分别对应着$1~N$。这也就导致你如果随便取隐空间一个点，然后用解码器进行解码，那么大概率不能生成有用样本。 </li>
<li>在进行降维时，由于自编码器过于强大，导致很多原始空间中数据的结构信息并没有得到保留，在隐空间中是稀疏的。 </li>
</ul>
</blockquote>
<p>换句话说，普通的自编码器并不是生成式模型，其更像是学习了某种确定性映射，并不能用于生成新的样本。</p>
<h4 id="变分自编码器思想"><a href="#变分自编码器思想" class="headerlink" title="变分自编码器思想"></a>变分自编码器思想</h4><p>为了能够能够使得自编码器的解码器用于生成目的，我们需要保证隐空间足够规则，获得这种规律性的一种可能方案是在训练过程中引入显示的正则项。<strong>因此，变分自编码器可以看作是一种自编码器，其训练过程经过正则化以避免过拟合，同时使隐变量$z$分布服从某一特定分布，在进行数据生成时便可以从该分布中采样然后送入解码器以进行数据生成。</strong></p>
<p>变分自编码器与普通自编码器在形式上的不同点在于:</p>
<blockquote>
<p>某个输入变量$x$并不是被编码成隐空间中一个点，而是隐空间中的一个概率分布。 </p>
</blockquote>
<script type="math/tex; mode=display">
    \begin{aligned}
        &AE: x \rightarrow Encoder: z = f(x) \rightarrow Decoder: x' = g(z) \\
        &VAE: x \rightarrow Encoder: z \sim N(x|\mu, \sigma^2) \rightarrow Sample \ z  \rightarrow Decoder: x' = g(z)
    \end{aligned}</script><p>我们一般假设隐空间中隐变量的分布是高斯分布，而编码器实际上就是学习对应高斯分布的均值和方差,整个变分自编码器的结构如下图所示:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/VAE.png" alt="VAE"><br>需要注意的是，由多少个样本，则最终在隐空间就会有多少个高斯分布。因为在进行解码之前有一个采样的操作，而采样本身是并不可导的，因此在实际中都是采用一个叫做<code>重参数</code>的技巧，也就是说每一次都是从标准正态分布中采样，然后通过:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        z &= \mu + \sigma \odot \epsilon  \\
        \epsilon &\sim N(0,1)
    \end{aligned}</script><p>来重构隐变量，这样$\mu$和$\sigma$就变成了一个参数，是可以应用反向传播进行参数更新。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/VAE1.png" alt="VAE"><br>在进行模型训练时，主要是以下步骤:</p>
<ul>
<li>将输入编码为隐空间上一个高斯分布(均值$\mu$, 方差$\sigma^2$) </li>
<li>从该分布中采样隐空间中一个点</li>
<li>对采样点进行解码并计算出重构误差 </li>
<li>重构误差通过网络进行反向传播</li>
</ul>
<p>而实现隐空间正态规则化最简单的实现方式便是在目标函数中添加正则项，该正则项期望输入映射到隐空间的这个正态分布能够尽可能接近标准正态分布，度量方式一般选用KL散度，因此最终目标函数一般是如下形式:</p>
<script type="math/tex; mode=display">
    loss = ||x - x'||^2 + D_{KL}(N(\mu_x, \sigma_x^2) || N(0,1))</script><h4 id="关于正则化直观解释"><a href="#关于正则化直观解释" class="headerlink" title="关于正则化直观解释"></a>关于正则化直观解释</h4><p>为了使生成过程成为可能，我们期望隐空间具有规则性，而规则性可以通过两个主要属性表示: </p>
<ul>
<li>连续性: 隐空间中的两个相邻点解码后不应呈现两个完全不同的内容 </li>
<li>完整性: 针对给定的分布，从隐空间采样的点在解码后应提供“有意义”的内容 </li>
</ul>
<p>VAE将输入编码为分布而不是点并不足以确保连续性和完整性，如果没有明确地定义正则化项，即模型目标函数仅仅期望重构误差尽可能小，那么模型会倾向于让分布的方差等于0以获得更小的重构误差，而此时变分自编码器也就退化成了普通的自编码器。</p>
<p>因此，为了避免该问题，我们必须同时对协方差矩阵和编码器返回的分布均值进行正则化，在实际应用中则是通过计算投影分布与标准正态分布之间的KL散度作为正则项。 </p>
<p>使用该正则化项，可以防止模型在隐空间中的编码相互远离，并鼓励尽可能多的返回分布发生重叠，从而满足预期的连续性和完整性条件。自然的对于任何正则化项，都会以训练数据上更高的重建误差为代价。然而，可以调整重建误差和KL散度之间的权重，我们将在下一节中看到如何从形式推导中自然得出平衡的表达。</p>
<h4 id="数学推导"><a href="#数学推导" class="headerlink" title="数学推导"></a>数学推导</h4><h5 id="概率框架和假设"><a href="#概率框架和假设" class="headerlink" title="概率框架和假设"></a>概率框架和假设</h5><p>我们首先定义一个概率图模型来描述我们的数据，用$x$表示我们的数据变量，并且假定$x$是由未直接观察到的潜在变量$z$生成。因此对于每个数据点，假设以以下两个步骤进行生成:</p>
<ul>
<li>首先，从先验分布p(z)中采样一个隐空间表示$z$</li>
<li>第二，按条件概率$p(x|z)$采集数据$x$<script type="math/tex; mode=display">
  z \rightarrow x</script></li>
</ul>
<p>在这种概率模型下，我们可以重新定义编码器和解码器的概念。实际上，与考虑使用确定性编码器和解码器的简单自编码器不同，我们现在将考虑这两个对象的概率版本。自然地，“概率解码器”由$p(x|z)$定义，描述由给定已编码变量到解码变量的分布，而“概率编码器”由$p(x|z)$定义，描述根据原始变量给出编码变量的分布。</p>
<p>我们假设隐空间中编码变量$z$遵循先验分布$p(z)$,则由贝叶斯公式，编码条件概率分布可以表示为:</p>
<script type="math/tex; mode=display">
    p(z|x) = \frac{p(x|z) p(z)}{p(x)} = \frac{p(x|z)p(z)}{\int_z p(x|z) p(z) dz}</script><p>我们假设$p(z)$是标准高斯分布，而$p(x|z)$是高斯分布，其均值由变量$z$的确定性函数$f$定义，并且协方差矩阵定义为$\Sigma = cI$,因此我们有:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &z \sim N(0,1)  \\
        &x|z \sim N(f(z), cI),f \in F, c>0 
    \end{aligned}</script><p>从理论上讲，我们知道$p(z)$和$p(x|z)$，便可以使用贝叶斯定理来进行计算$p(z|x)$,但是这种计算由于有分母的积分存在，直接计算并不容易，因此需要采用变分推断技术来近似获得$p(x)$。 </p>
<h5 id="变分推断技术"><a href="#变分推断技术" class="headerlink" title="变分推断技术"></a>变分推断技术</h5><p>首先给出变分贝叶斯方法的维基百科定义:</p>
<blockquote>
<p><strong>变分贝叶斯方法</strong>是一类用于近似贝叶斯推理和机器学习中产生的棘手积分的技术。它们通常用于由观察变量以及未知参数和潜在变量组成的复杂统计模型中，如图模型描述，这三种类型的随机变量之间具有各种关系。变分贝叶斯方法主要用于两个目的:</p>
<ul>
<li>为了对未观察变量的为了对未观察变量的后验概率提供解析近似，以便对这些变量进行统计推断。</li>
<li>得出观察数据的边际可能性（有时称为“证据”）的下限（即，给定模型的数据的边际概率，对未观察变量进行边际化）。这通常用于执行模型选择，通常的想法是，给定模型的边际可能性越高，表明该模型对数据的拟合度越高，因此，所讨论的模型是生成数据的模型的可能性就越大。（另请参阅贝叶斯因子文章。）</li>
</ul>
</blockquote>
<p>变分推断是一种近似复杂分布的技术，基本的思路便是设置一个参数化的分布，并在该族中寻找目标分布的最佳近似，分布差异之间的度量一般采用<a href="https://soundofwind.top/2020/08/26/gai-lu-fen-bu-zhong-de-ju-chi-du-liang/">KL散度</a>来作为分布之间的度量指标。在这里，我们将通过高斯分布$q_x(z)$来近似后验概率$p(z|x)$，我们可以写出如下表示:</p>
<script type="math/tex; mode=display">
    q_x(z) = N(g(x), h(x)), g \in G, h \in H</script><p>我们期待这个合适的参数$g(x), h(x)$以尽可能缩小两个变量之间的KL散度: </p>
<script type="math/tex; mode=display">
    \begin{aligned}
        (g^\ast, h^\ast) &= \arg \min_{g,h} D_{KL}(q_x(z), p(z|x)) \\
        &= \arg \min_{g,h} E_{z \sim q_x} (log q_x(z)) - E_{z \sim q_x } (log \frac{p(x|z) p(z)}{p(x)}) \\ 
        &= \arg \min_{g,h} E_{z \sim q_x} (log q_x(z))  - E_{z \sim q(x)} (log p(z)) - E_{z \sim q_x} (log p(x|z)) + E_{z \sim q_x} (log p(x)) \\
        &= \arg \max_{g,h} E_{z \sim q_x} (log p(x|z)) - KL(q_x(z), p(z)) \\ 
        &= \arg \max_{g,h} E_{z \sim q_x} (-\frac{||x-f(z)||^2}{2c}) - KL(q_x(z), p(z))
    \end{aligned}</script><p>从最终优化目标的表达式来看，一方面期望最大化重构出的样本的对数似然最大，另一方面期望$q_x(z)$接近先验分布$p(z)$。这种折衷体现了在贝叶斯推理中，在数据置信度与先验分布置信度之间的平衡。</p>
<h5 id="条件变分自编码器CVAE"><a href="#条件变分自编码器CVAE" class="headerlink" title="条件变分自编码器CVAE"></a>条件变分自编码器CVAE</h5><p>用VAE生成数据的一个问题是，我们对于生成的数据没有任何控制。例如, 如果我们用MNIST数据集训练VAE，并尝试通过相解码器输入$Z \sim N(0,1)$来生成图像，它也会产生不同的随机数字图像，但我们并不能控制究竟生成哪一个数字的图像，而我们拿到的数据是有着标签信息，因此我们期望能够将标签信息也融入到训练过程当中，以使编码器具有生成任意标签数据的能力。<br>为此，我们需要对VAE体系进行修改，假设给定一个输入标签$Y$，我们希望生成模型能够输出该标签对应的图像，那么可以在普通自编码器基础上做如下修改，在进行编码时同时加上标签信息，然后在进行解码时也加上标签信息，整个生成过如下:</p>
<script type="math/tex; mode=display">
    y,x \rightarrow z,y \rightarrow x</script><p>在这里编码器学习后验概率分布$p(z|x,y)$实际上相当于是将标签信息从隐空间分离表征，然后在进行解码时再加入标签信息，表明需要生成哪一类的样本。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/CVAE.png" alt="CVAE"></p>
<h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>到目前为止，如果假设函数$f$是已知且固定的，则我们可以使用变分推理技术来近似后验$p(z|x)$。但是实际上，定义解码器的函数$f$是未知的，而且也需要求解。但我们最初的目标是找到一种性能良好的编码/解码方案，其隐空间又足够规则，可以用于生成目的。如果规则性主要由在隐空间上假定的先验分布所决定，则整个编码-解码方案的性能高度取决于函数$f$的选择。确实，由于$p(z|x)$可以从$p(z)$和p(x|z)近似（通过变分推论），而$p(z)$是简单的标准高斯模型，仅存的两个需要我们优化的对象是参数$c$(决定了分布的协方差)和函数$f$(决定了分布的均值)。</p>
<p>对于$F$中的任意一个函数$f$都定义了一个概率解码器(p(x|z)),然后可以得到$p(z|x)$的最佳近似$q^\ast_x(z)$,然后当给定从$q_x^\ast(z)$中的一次采样$z$时，我们期望选择函数$f$使$x$的期望对数似然概率最大。<strong>换句话说，对于给定的输入$x$,当我们从分布$q_x^\ast(z)$采样$z$然后从分布$p(x|z)$采样$\hat{x}$时，我们希望寻找到合适的参数$f$，使得 $x = \hat{x}$的概率最大。</strong></p>
<p>将上面所有部分总在一起，我们正在寻找最优的$f^\ast, h^\ast, g^\ast$，使得:</p>
<script type="math/tex; mode=display">
\left(f^{*}, g^{*}, h^{*}\right)=\arg \max _{(f, g, h) \in F \times G \times H}\left(\mathbb{E}_{z \sim q_{x}}\left(-\frac{\|x-f(z)\|^{2}}{2 c}-K L\left(q_{x}(z), p(z)\right)\right)\right)</script><p>常数$c$决定了两个条件之间的平衡，$c$越高，则表示我们对重构误差的容忍度越大，更加关注正则化项，如果$c$低，则相反。</p>
<h4 id="将神经网络引入模型"><a href="#将神经网络引入模型" class="headerlink" title="将神经网络引入模型"></a>将神经网络引入模型</h4><p>到目前为止，我们已经建立了一个依赖于三个函数$f, g$和$h$的概率模型，我们无法轻松地在整个函数空间上进行优化，因此我们限制了优化域，并将$f,g,h$用神经网络来定义。因此，$F,G,H$分别对应于网络体系结构上的参数族。</p>
<p>实际上，$g$和$h$不是由两个完全独立的网络定义的，而是共享它们一部分结构和参数，因此我们可以:</p>
<script type="math/tex; mode=display">
    g(x) = g_2(g_1(x)),h(x) = h_2(h_1(x)),g_1(x) = h_1(x)</script><p>解码器则是一般的神经网络结构，这样就获得了整体的网络结构，可以进行优化。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/beta-VAE.png" alt="VAE"> </p>
<h3 id="正则自编码器"><a href="#正则自编码器" class="headerlink" title="正则自编码器"></a>正则自编码器</h3><p>变分自编码器也可以看作是一种特殊的正则自编码器, 这部分主要介绍下降噪自编码器和稀疏自编码器。 </p>
<h4 id="降噪自编码器DAE"><a href="#降噪自编码器DAE" class="headerlink" title="降噪自编码器DAE"></a>降噪自编码器DAE</h4><p>降噪自编码的核心思想是，建立一个恒等映射的自编码器未必是好的，能够将“损坏”的数据还原成“好”的数据的自编码器才是好的。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/Denoising-Autoencoder_qm5AOQM.png" alt="DAE"><br>因此网络输入往往会对输入$x$做加噪处理$\hat{x}$，然后经过自编码器重构未加噪的输入$x$,这样训练得到的自编码器可以获得一定的对于原始数据波动的鲁棒性。</p>
<h4 id="稀疏自编码器"><a href="#稀疏自编码器" class="headerlink" title="稀疏自编码器"></a>稀疏自编码器</h4><p>我们有时期望能够获得输入数据的高维稀疏表示，则需要对加入一个正则项来实现这个目的，稀疏自编码器一般是一个三层的神经网络，其目标函数包含两部分，一部分是重构误差，另一部分则是稀疏正则项。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/xishu.jpg" alt="稀疏自编码"><br>若输入样本个数为$m$个，隐层神经元个数为$s_2$个，在这里首先定义隐层神经元$j$对于所有训练数据的平均激活度:</p>
<script type="math/tex; mode=display">
    \hat{\rho}_j = \frac{1}{m} \sum_{i=1}^m [a_j^{(2)} (x^{(i)})]</script><p>其中$a_j^{(2)}(x^{(i)})$为隐层第$j$个神经元对第$i$个样本的响应输出，然后我们会设置一个稀疏系数$\rho = 0.05/0.1$,通过KL散度来度量$\rho, \hat{\rho}_j$之间的差异:</p>
<script type="math/tex; mode=display">
    D_{KL}(\rho || \hat{\rho}_j) = \rho log \frac{\rho}{\hat{\rho}_j} + (1-\rho) log \frac{1-\rho}{1-\hat{\rho}_j}</script><p>因为有$s_2$个隐层神经元，因此最终稀疏正则项表达式为:</p>
<script type="math/tex; mode=display">
    sparse_{loss} = \sum_{j=1}^{s_2} D_{KL} (\rho || \hat{\rho}_j)</script><p>通过这样的一项稀疏正则化，最终训练得到的编码器将会把输入$x$编码为高维空间的稀疏表达，有助于提取更具意义的边缘特征。</p>
<p>可以这样简单进行理解，使用普通的自编码器对图像进行压缩/编码是在像素级别上的编码，而对于图像而言，像素层次上的编码往往并不具备意义，通过加入稀疏正则化项，网络会更加关注一些high level的特征，比如眼睛是大是小，嘴巴形状等等，而不仅仅是拘泥于像素层级的特征提取。 </p>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>自编码，变分自编码，降噪自编码</tag>
      </tags>
  </entry>
  <entry>
    <title>致时光</title>
    <url>/2020/09/25/zhi-shi-guang/</url>
    <content><![CDATA[<p>我很久之前就想写这一篇文章了，但或是感触未深，或是时光未老，迟迟不知如何落笔。<br>今天是2020年9月25月，我的人生的第24个年头已经悄然逝去过半；上个月我姐生下了小宝宝安宁，我也正式升格为舅舅；明天我大哥也就要结婚了，我们这一辈已经开始慢慢化身我儿时父辈的角色。时光的巨轮已然于我之身滚动两旬，新旧两代交替的音符已然在空中交响。<br><span id="more"></span><br>如果让我为自己的人生划分章节，我倾向于将自己的人生划为四个章节。</p>
<ul>
<li>初识人间，懵懵懂懂 </li>
<li>渐知人事，似懂非懂 </li>
<li>洞察人事，知己知人 </li>
</ul>
<p>下面我就按照我自己划分的人生章节来对我24年的人生进行一个阶段性总结。</p>
<h3 id="初识人间，懵懵懂懂"><a href="#初识人间，懵懵懂懂" class="headerlink" title="初识人间，懵懵懂懂"></a>初识人间，懵懵懂懂</h3><p>1997年1月30日，伴随着一声啼哭，我来到了这个人世间，掀开了我的人生篇章。那时的我，并没有太多的想法与感情，驱动我的只有最基本的感觉，比如饥饿感，不适感，满足感等等，我觉得舒服了就开心地笑笑，我觉得不舒服了就在那里哭。我并不清楚我诞生在了一个什么样的地方，我的父亲、母亲究竟是什么样的人，也并不了解周围大人的欢喜与忧愁。</p>
<p>诞生之初，我的脑中并没有任何的行为准则，在周围亲人的引导下，我渐渐学会了喊“爸爸”和“妈妈”等一系列亲人的称谓，了解了当我有需求的时候可以向哪些人求助，整体而言，我的行为是缺乏约束的，我的欢喜与忧愁并不受周围环境影响，我的言语也并不受周围人影响，所谓童言无忌。</p>
<p>如果要对人生的这一阶段做一个比喻，我觉得孩子诞生之初就是一张白纸，然后父母开始帮忙在这张纸上写写画画，教我尊重长辈，教我约束行为，以他们的语言和经历向我描述他们眼中的世界。这一阶段我的记忆是模糊的，没有特别好的记忆，也没有特别差的记忆，依我看来，这一段人生时光是不易留下记忆的，但若留下记忆便可能会影响孩子的一生，毕竟人生的构建是自下而上。</p>
<p>我曾经思考过这样一个问题，如果将所有知识、习俗对一个孩子进行隔绝，那么这个孩子会是什么模样？ 我思考的答案是这个孩子将会成为一个原始人，与整个人类社会格格不入。每念及此，我常心怀感激之情，感激这几千年的文化知识传承，让我出生便站在了一个古人难以企及的起点上；感激父母赐予我生命，让我能够来此世间一游，写下属于我的故事。</p>
<h3 id="渐知人事，似懂非懂"><a href="#渐知人事，似懂非懂" class="headerlink" title="渐知人事，似懂非懂"></a>渐知人事，似懂非懂</h3><p>随着年龄的增长，我也开始陆陆续续见识到种种事物。</p>
]]></content>
      <categories>
        <category>闲谈</category>
      </categories>
      <tags>
        <tag>时光，岁月，人生</tag>
      </tags>
  </entry>
  <entry>
    <title>规则学习</title>
    <url>/2020/08/27/gui-ze-xue-xi/</url>
    <content><![CDATA[<p>首先讲一个有意思的现象，早期的主流人工智能专注于以逻辑为基础来进行形式化和推理，但这样很难定量地对不确定事件进行表达和处理，后来随着机器学习算法的井喷，大家都更加关注于对定量的数据进行处理。但现在，很多人发现在解决某些任务的时候，加入一些行业中的常识知识可能会让任务解决地更好，而现在定性知识与定量数据之间似乎有着一道鸿沟，唯一的联系就是进行算法设计的人可能会依赖于他的领域知识来选择合适的算法并对算法进行调参。基于学习下定性知识如何表达的想法，这部分介绍下周志华老师🍉书的倒数第二章——规则学习，这部分内容安扎以下结构组织:</p>
<ul>
<li>基本概念 </li>
<li>序贯覆盖</li>
<li>剪枝优化</li>
<li>一阶规则学习</li>
<li>归纳逻辑程序设计 </li>
</ul>
<span id="more"></span>
<h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>首先给出机器学习中规则和规则学习的概念：</p>
<blockquote>
<p><strong>规则:</strong> 在机器学习领域中，“规则”通常是指语义明确、能描述数据分布所隐含的客观规律或领域概念，可以写成”若….,则….”形式的逻辑规则。<br><strong>规则学习:</strong> “规则学习”是从训练数据中学习出一组能用于对未见示例进行判别的规则。</p>
</blockquote>
<p>形式化来看，一条规则形如：</p>
<script type="math/tex; mode=display">
    \oplus \leftarrow f_1 \land f_2 \dots \land f_L</script><p>公式中$\leftarrow$右侧部分称为”规则体”，表示该条规则的前提，左边部分称为”规则头”,表示该条规则的结果。规则体是由逻辑文字$f_k$所组成的合取式(conjuction)，每个文字$f_k$都是对示例属性进行检验的布尔表达式，例如”(色泽 = 乌黑)”或者”$\neg$(根蒂 = 硬挺)”。$L$是规则体中逻辑文字的个数,称为规则的长度,规则头的”$\oplus$”,同样是逻辑文字，一般用来表示所判定的目标的类别或概念，比如”好瓜”，这样的逻辑规则也被称为<strong>if-then规则</strong>。<br>与神经网络、支持向量机这样的”黑箱模型”相比，规则学习具有以下几个优点:</p>
<ul>
<li>可解释性较强</li>
<li>很强的表达能力，绝大多数的人类知识都能够通过数理逻辑进行简洁的刻画和表达，例如”父亲的父亲是爷爷”这样的知识不易用函数式表达，而用一阶逻辑则可以方便地写为：<script type="math/tex; mode=display">
  爷爷(X,Y) \leftarrow 父亲(X,Z) \land 父亲(Z,Y)</script></li>
<li>逻辑规则的抽象描述能力在处理一些高度复杂的AI任务时具有显著的优势，例如在问答系统中有时可能遇到非常多、甚至无穷种可能的答案，此时若能基于逻辑规则进行抽象表述或者推理，则将带来极大的便利。</li>
</ul>
<p>假设我们从西瓜数据集中学得规则集合$\mathcal{R}$:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &规则1: 好瓜 \leftarrow (根蒂 = 蜷缩) \land (脐部 = 凹陷) \\
        &规则2: \neg好瓜 \leftarrow (纹理 = 模糊)
    \end{aligned}</script><p>规则集合中的每条规则都可看作一个子模型，规则集合是这些子模型的一个集成。当同一个示例被判别结果不同的多条规则覆盖时，则称发生了“冲突”，解决冲突的办法则称为”冲突消解”，常用的冲突消解的方法有投票法、排序法、元规则法，投票法就是常用的少数服从多数策略，排序法则是指定规则优先级，出现冲突时使用排序靠前的规则。所谓元规则，其实就是规则的规则，例如”发生冲突时使用长度最小的规则“，然后根据元规则的指导来使用规则集。<br>此外，从训练集学得的规则集合也许并不能覆盖所有可能的未见示例，此时规则学习算法通常会设置一条默认规则，由它来处理规则集合未覆盖的样本；例如为$\mathcal{R}$增加一条默认规则：“未被规则1,2覆盖的都不是好瓜”。<br>从形式语言表达能力而言，规则可分为两类：“命题规则”和“一阶规则”：</p>
<blockquote>
<ul>
<li>命题规则是由“原子命题(propositional atom)”和逻辑连接词“与($\land$)”、”(或($\lor$))”、“非($\neg$)”和“蕴含”($\leftarrow$)构成的简单陈述句；例如规则集$\mathcal{R}$就是一个命题规则集，”根蒂 = 蜷缩”，“脐部 = 凹陷”都是元子命题。</li>
<li>一阶规则的基本成分是能表述事物的属性或关系的”原子公式”，例如表达父子关系的谓词(predict)“父亲$(X,Y)$”就是原子公式，再如表示加1操作”$\sigma(X) = X+1$”的函数$\sigma(X)$也是原子公式。如果进一步使用谓词“自然数$(X)$”表示$X$是自然数，“$\forall X$”表示对任意$X$成立，”$\exists Y$”表示”存在$Y$使之成立”,那么”所有自然数加1都是自然数”就可以写做:<script type="math/tex; mode=display">
  \forall X, \exists Y  \leftarrow 自然数(X) \land (Y = \sigma(X))</script>或者表示成更加简洁的形式:<script type="math/tex; mode=display">
  \forall X, 自然数(\sigma(X)) \leftarrow 自然数(X)</script>这样的规则就是一阶规则，其中$X$和$Y$称为逻辑变量，$\forall,\exists$用于限定变量的取值范围，称为”量词”，显然，一阶规则可以表达复杂的关系，因此也被称为“关系型规则”。若我们简单地把属性当作谓词来定义示例与属性值之间的关系，则命题规则集$\mathcal{R}$可以改写为一阶规则集$R’$:<script type="math/tex; mode=display">
  \begin{aligned}
      &规则1: 好瓜(X) \leftarrow 根蒂(X,蜷缩) \land 脐部(X,凹陷) \\
      &规则2: \neg 好瓜(X) \leftarrow 纹理(X,模糊)
  \end{aligned}</script>从形式语言系统角度来看，命题规则是一阶规则的特例，因此一阶规则的学习比命题规则要复杂得多。</li>
</ul>
</blockquote>
<h3 id="序贯覆盖"><a href="#序贯覆盖" class="headerlink" title="序贯覆盖"></a>序贯覆盖</h3><p>规则学习的目标是产生一个可以覆盖尽可能多样例的规则集，最直接的做法就是“序贯覆盖”，即逐条归纳:在训练集上每学到一条规则，就将该规则覆盖的训练样例去除，然后以剩下的训练样例组成训练集重复上述过程。由于每次只处理一部分数据，因此也被称为”分治”策略。<br>序贯覆盖法的关键是如何从训练集学出单条规则，显然，对规则学习目标$\oplus$ 产生一条规则就是寻找最优的一组逻辑文字构成规则体，这是一个搜索问题。形式化上来说，给定正例集合与反例集合，学习任务是基于候选文字集合$\mathcal{F} = { f<em>k }$来生成最优规则$r$。在命题规则学习中，候选文字是形如”$R(属性_i,属性值</em>{ij})$”的布尔表达式，$R(x,y)$则是判断$x,y$是否满足关系$R$的二元布尔函数。<br>而具体的学习方法则是从空规则$”\oplus \leftarrow”$开始，将正例类别作为规则头，再逐个遍历训练集中的每个属性及取值，尝试将其作为逻辑文字增加到规则体中，若能使当前规则体仅覆盖正例，由此产生一条规则，然后去除已被覆盖的正例并基于剩余样本生成下一个规则：通俗来说，这种方法的思想便是挑选出所有仅覆盖正例的特征和仅覆盖反例的特征。<br>而原始的穷尽搜索的做法在属性和候选值较多时会由于组合爆炸而不可行,现实任务中一般有两种策略来产生规则:</p>
<ul>
<li>自顶向下:从比较一般的规则开始，逐渐添加新文字以缩小规则覆盖范围，直到满足预定条件为止，该策略也称为“生成测试”法，是规则逐渐特化的过程。</li>
<li>自底向上:从比较特殊的规则开始,逐渐删除文字以扩大规则覆盖范围，直到满足条件为止，该种策略是规则逐渐泛化的过程。</li>
</ul>
<h3 id="剪枝优化"><a href="#剪枝优化" class="headerlink" title="剪枝优化"></a>剪枝优化</h3><p>规则生成本质上是一个贪心搜索的过程，需有一定的机制来缓解过拟合的风险，最常见的做法是剪枝。与决策树相似，剪枝可以分为预剪枝与后剪枝。在实际操作时通常是基于某种性能度量指标来评估增/删逻辑文字前后的规则性能，或增/删规则集前后的规则集性能，从而判断是否需要进行剪枝。<br>经常使用的预剪枝算法为$CN2$算法，使用似然率统计量作为指标；后剪枝常用策略为“减错剪枝”，即将样例集进行划分，划分为训练集和验证集，根据在验证集上的表现优劣来对从训练集中学出的模型进行剪枝。、</p>
<h3 id="一阶规则学习"><a href="#一阶规则学习" class="headerlink" title="一阶规则学习"></a>一阶规则学习</h3><p>命题逻辑的基本单元是“原子命题”，这也就导致命题规则学习很难处理对象之间的”关系”，而关系信息在很多任务中非常重要。例如，当我们在瓜摊挑瓜时,通常很难把水果摊上所有西瓜的特征用属性值表示出来，因为我们很难判断:色泽看起来多深才叫”色泽青绿”？敲起来声音多低才叫”敲声沉闷”？比较现实的做法是将西瓜进行比较，例如，”瓜1的颜色比瓜2更深，并且瓜1的根蒂比瓜2更蜷”，因此“瓜1比瓜2更好”。然而，这已经超越了命题逻辑的表达能力，需要用一阶逻辑来表达，并且要使用一阶规则进行学习。</p>
<p>首先我们需要将命题逻辑数据转换为关系数据，比如对于瓜的色泽，我们可以定义:</p>
<script type="math/tex; mode=display">
    色泽深度：乌黑>青绿>浅白</script><p>那么“瓜1色泽乌黑，是好瓜；瓜2色泽青绿，不是好瓜”，就可以表示为:</p>
<script type="math/tex; mode=display">
    色泽更深(瓜1，瓜2)，更好(瓜1，瓜2)</script><p>这样的数据直接描述了样例之间的关系，称为“关系数据”，其中由原样本属性转化而来的“色泽更深”、“根蒂更蜷”等原子公式称为“背景知识”，而由样本类别转化而来的关于“更好”，“$\neg$更好”等原子数据称为关系数据样例，下面给出一个一阶规则示例：</p>
<script type="math/tex; mode=display">
    (\forall X,\forall Y)(更好(X,Y)) \leftarrow 根蒂更蜷(X,Y) \land 脐部更凹(X,Y)</script><p>与命题规则相比，一阶规则的规则头、规则体都是一阶逻辑表达式，个体对象”瓜1，瓜2”被逻辑变量$X,Y$替换，全称量词$\forall$ 表示该规则对所有个体对象均成立；通常，在一阶规则中所有出现的变量都被全称量词限定，所以有时会将全称量词省去,一阶规则有着强大的表达能力，例如它能简洁地表达递归概念，如:</p>
<script type="math/tex; mode=display">
    更好(X,Y) \leftarrow 更好(X,Z) \land 更好(Z,Y)</script><p>一阶规则学习能够容易地引入领域知识，这是它相对于命题规则学习的另一大优势。在命题规则学习乃至一般的统计学习中，若欲引入领域知识，通常有两种做法:<strong>在现有属性的基础上基于领域知识构造出新属性，或基于领域知识设计某种函数机制(如正则化)来对假设。</strong> 然而现实任务中并非所有的领域知识都能够容易地通过属性重构和函数约束来表达。例如，假定我们获得包含了某未知元素的化合物$X$，欲通过实验来发现它与已知化合物$Y$的化学表达式,我们可以重复多次实验，测出每次结果中化合物的组份含量，虽然我们对反应中的未知元素的性质一无所知，但知道一些普遍成立的化学原理，例如金属原子一般产生离子键、氢原子之间一般都是共价键，并且也了解已知元素间可能发生反应，这些领域知识非常重要，但往往很难在基于命题表示的学习中加以利用。<br>下面介绍一种著名的一阶规则学习算法</p>
<h4 id="First-Order-inductive-Learner"><a href="#First-Order-inductive-Learner" class="headerlink" title="First-Order inductive Learner"></a>First-Order inductive Learner</h4><p>FOIL是著名的一阶规则学习算法，它遵循序贯覆盖框架且采用自顶向下的规则归纳策略，由于有逻辑变量的存在，FOIL在规则生成时需考虑不同的变量组合。这也是和命题规则所不同的地方,在命题规则的学习中只需要考虑原子命题之间的组合，而在一阶逻辑规则学习中，除了要考虑原子公式的组合，还应当考虑公式中变量的组合。<br>FOIL使用“FOIL增益”来选择文字:</p>
<script type="math/tex; mode=display">
    F_{Gain} = \hat{m}_+ \times (\log_2 \frac{\hat{m}_+}{\hat{m}_+ + \hat{m}_-}-\log_2 \frac{m_+}{m_+ + m_-})</script><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>规则学习是”符号主义学习”，是最早开始研究的机器学习技术之一。序贯覆盖是规则学习的基本框架，CN2采用集述搜索，是最早考虑过拟合问题的规则学习算法，现实出后剪枝在缓解规则学习过拟合中的优势。<br>由于命题规则的表述能力有限，一阶逻辑学习开始发展，FOIL通过变量替换等操作把命题规则学习转化为一阶规则学习。<br>近年来随着机器学习技术进入更多应用领域，在富含结构信息和领域知识的任务中，逻辑表达的重要性逐渐凸显出来，因此出现了一些将规则学习与统计学习相结合的努力，例如给贝叶斯网中的节点赋予逻辑意义的“关系贝叶斯网络”、贝叶斯逻辑程序、马尔可夫逻辑网络，统称为”统计关系学习”。</p>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>规则学习，定性关联</tag>
      </tags>
  </entry>
  <entry>
    <title>论牺牲</title>
    <url>/2020/11/19/lun-xi-sheng/</url>
    <content><![CDATA[<p>本篇文章围绕以下问题做个简单讨论:</p>
<blockquote>
<p>人应该什么时候拿出牺牲自我的逻辑，什么时候拿出保护自己利益的逻辑？  </p>
<p>当所处的小团体与包含小团体的大团体利益发生冲突时，此时是否应当牺牲小团体？ </p>
</blockquote>
<span id="more"></span>
<h4 id="关于牺牲本身"><a href="#关于牺牲本身" class="headerlink" title="关于牺牲本身"></a>关于牺牲本身</h4><p>既然要讨论这个问题，我们首先要将问题本身定义清楚，为了使得接下来的讨论更加精确，我首先来更加精确地定义以下<strong>牺牲</strong>，其实我们看到的牺牲大致有两种: </p>
<ul>
<li><strong>第一种牺牲</strong>: 对于一个眼光长远的人来说，<strong>短暂的牺牲不过是为了更长远的利益</strong>，因此这种有目的的<strong>牺牲</strong>其实是一种更加隐蔽的<strong>利己</strong>，有时候对自己所谓的牺牲从这个视角来看，会有不一样的收获。</li>
<li><strong>第二种牺牲</strong>: 这种牺牲是不考虑回报的牺牲，即就牺牲者自己的视角来看，在牺牲行为中，他/她是<strong>为某种东西损失个人利益而不问回报。</strong></li>
</ul>
<p>当然，这两种牺牲有时会导致同样的结局，毕竟人的认知是有差异的，但我在定义这两种牺牲，考虑的更多是<strong>动机</strong>，一种是<strong>以退为进</strong>的牺牲，另一种则是<strong>无保留</strong>的牺牲。对于待讨论的问题，我认为问题中所指的牺牲大概是我所定义的第二种牺牲，那么我们<strong>接下来所讨论的牺牲都是指代第二种牺牲。</strong></p>
<h4 id="牺牲的对象"><a href="#牺牲的对象" class="headerlink" title="牺牲的对象"></a>牺牲的对象</h4><p>既然要讨论牺牲本身，那么我们首先从<strong>牺牲的对象</strong>来开始讨论，以具体的牺牲的行为来解构抽象的概念<strong>牺牲</strong>本身。<br>以笔者目前的认知水平，牺牲的对象大概可以粗分为三类: </p>
<blockquote>
<ul>
<li>具象的个人，比如亲人和爱人 </li>
<li>个人身处的团体</li>
<li>某种理想或价值观念 </li>
</ul>
</blockquote>
<p>下面就这三种牺牲的对象来进行分别讨论: </p>
<ul>
<li><strong>具象的个人</strong>: 对于亲人与爱人，这种牺牲一般是出于对某种关系的妥协，血浓于水，琴瑟和鸣，我们愿意为了维系或加深这种关系而做出个人利益的让步；对于同事或朋友所做出的牺牲也大致是如此，对于个人高度认可，对于两人关系高度认可。</li>
<li><strong>个人身处的团体</strong>: 我们既然加入这样一个团体，必然个体与团体之间是有着一致性的，对于兴趣社团，这种一致性表现为个人兴趣可以得到更好发展；对于公司，这种一致性表现在个人以劳动换取酬金，以改善客观生活。当我们决定为团体所做牺牲时，这说明个人对团体的认可程度较高，这时可能牺牲的对象就不只是简单的<strong>团体</strong>，其中或多或少包含着对<strong>团体中个人</strong>的情感。 </li>
<li><strong>理想或价值观念</strong>: 这种牺牲则是出于对理想与价值观念的高度认同。</li>
</ul>
<p>需要注意的是，基本上任何组织或团队都是三者耦合而成，会谈优秀的个人、高质量的团队、团队的价值观，而加入团体的人则是形形色色，大家奔着不同的目的(至少权重不同)加入了这样一个群体。 </p>
<blockquote>
<p>那么通过上面具体的讨论，我们会发现所谓牺牲的对象，其实本质上都是一种<strong>认可</strong>，对个人关系的认可，对团体的认可，对理想/价值观的认可，这种<strong>认可</strong>会驱使我们在某些情况下做出牺牲。</p>
</blockquote>
<h4 id="回到问题本身"><a href="#回到问题本身" class="headerlink" title="回到问题本身"></a>回到问题本身</h4><blockquote>
<p>Q1：人什么时候应该拿出自我牺牲的逻辑呢？ </p>
</blockquote>
<p>下面从两个角度来进行回答: </p>
<ul>
<li>主观角度: 从这个角度来说，当对某个人、某个团体认可程度超过自己心中阈值之时，便可做出牺牲，这样的论断是简单的，这样做人也是舒服的。 </li>
<li>从主客观结合角度: 当人要做出牺牲，总是担心自己<strong>白白牺牲</strong>: <ul>
<li>帮助了一个朋友，但他/她是个白眼狼；毫无保留爱了一个人，结果受到欺骗。 </li>
<li>为团体做出了牺牲，但却并未得到认可，甚至团体中人认为你是想出风头。 </li>
<li>为某种理想、价值观做出牺牲，但万一这种理想、价值观本身就错误呢?<br><strong>从这个角度来考虑，那么我们的牺牲就不但要考虑作为牺牲的主体，同时也需要考虑牺牲的客体，重新认识牺牲客体对于牺牲行为本身的看法，以使自己不白白牺牲。</strong></li>
</ul>
</li>
</ul>
<p>就我个人而言，对亲人、爱人的个人牺牲，我更倾向于从主观角度进行思考，而对团体的牺牲，我需要从主客观结合的角度来思考，毕竟一个团体中鱼龙混杂，奔着不同目的的人混在了一个团体之中，此时盲目的主观牺牲就会成为”白白牺牲”。</p>
<blockquote>
<p>Q2: 当所处的小团体与包含小团体的大团体利益发生冲突时，此时是否应当牺牲小团体？ </p>
</blockquote>
<p>这个问题我认为其实是包含在第一个问题之中的，我们在一个团体中时，首先需要明确自己认可的东西是什么，认可的东西是在小团体里面还是一个所谓的大团体之中，此时千万要警惕站在<strong>别人</strong>的角度考虑这样一个问题。</p>
]]></content>
      <categories>
        <category>闲谈</category>
      </categories>
      <tags>
        <tag>无感而发</tag>
      </tags>
  </entry>
  <entry>
    <title>贝叶斯分类补充</title>
    <url>/2020/10/05/bei-xie-si-fen-lei-bu-chong/</url>
    <content><![CDATA[<p>在前面我已经介绍过有关贝叶斯决策的相关知识，在进行实际应用时如果假设在给定类别情况下，各特征是彼此独立的:</p>
<script type="math/tex; mode=display">
    Ind(x_1,x_2, \dots, x_d |y)</script><p>则这样导出的分类器称为朴素贝叶斯分类器，这部分我主要总结一些贝叶斯分类器中容易忽视的知识点,具体的推导部分前面已经总结，这里不再给出:<br><span id="more"></span></p>
<blockquote>
<ul>
<li>贝叶斯分类器是最优分类器，分类错误率最小。</li>
<li>朴素贝叶斯模型是贝叶斯网络的一种特殊形式。</li>
<li>常用的参数估计方法有极大似然估计和贝叶斯估计，使用贝叶斯估计要求拥有待估计参数的先验知识，有助于缓解参数估计的过拟合。</li>
<li>朴素贝叶斯模型可以应用离散特征也可应用于连续特征，但这时需要给出概率密度$p(x|y)$的形式，常用的是高斯分布。</li>
</ul>
</blockquote>
<p>下面则讨论一下朴素贝叶斯算法与$logistic$回归的关系:</p>
<blockquote>
<ul>
<li>朴素贝叶斯模型是生成式模型，显式地给出了$p(y)$和$p(x|y)$的形式，即给出了数据生成所需的参数，在进行决策时采用贝叶斯公式计算后验概率$p(y|x)$进行决策。</li>
<li>$logistic$回归是判别式模型，直接以$sigmoid$函数的形式给出$p(y|x)$，然后学习函数中相关参数进行决策。</li>
<li>当采用朴素贝叶斯分类器进行分类，$p(x｜y)$的形式为高斯形式，且假设对于不同类别，高斯分布的方差满足:<script type="math/tex; mode=display">
   \Sigma_1 = \Sigma_2 = diag(\sigma_1, \sigma_2, \dots, \sigma_d)</script>则应用贝叶斯公式可以推出:<script type="math/tex; mode=display">
  p(y=1|x,\pi,\mu,\Sigma) = \frac{1}{1 + \exp(-w^Tx - w_0)}</script>在形式上与$logistic$回归等价。</li>
<li>朴素贝叶斯算法是通过参数估计的方法来估计概率密度函数中的参数，而$logistic$回归则是通过迭代优化的方法来求解一个凸优化问题。 </li>
<li>对于有限数据，如果特征条件独立性满足，则两种模型表现接近，若条件独立性并不满足，则$logistic$回归模型表现要优于朴素贝叶斯模型。 </li>
<li>高斯朴素贝叶斯模型相较于$logistic$回归模型，一般需要的数据更少，但随着数据量的增多，$logistic$回归模型表现一般会超过朴素贝叶斯模型。</li>
</ul>
</blockquote>
<p>最后从线性分类器与非线性分类器的角度来进行讨论:</p>
<blockquote>
<ul>
<li>朴素贝叶斯分类器是否是线性分类器取决于一些参数共享假设，如果假设不同类别特征共享一个$\Sigma$，则此时导出的决策面就是一个超平面，而如果不共享方差参数，则导出的分类面不再是平面，此时朴素贝叶斯分类器便不是线性分类器。</li>
<li>对于$logistic$回归，若是二分类，则是线性分类器。若是分类类别大于2，则最终的分类器是分段线性的，即任意两个类别之间是线性超平面。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/NB2.png" alt="朴素贝叶斯"></li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>贝叶斯分类，逻辑回归</tag>
      </tags>
  </entry>
  <entry>
    <title>赛尔号插件下载地址</title>
    <url>/2022/09/08/sai-er-hao-cha-jian-xia-zai-di-zhi/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉, 这个密码看着不太对, 请再试试." data-whm="抱歉, 这个文章不能被校验, 不过您还是能看看解密后的内容.">
  <script id="hbeData" type="hbeData" data-hmacdigest="4d290510b6709c91c117269e5f5b09f572bf07b11751014a01b284c7c21c8455">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-blink">
      <input class="hbe hbe-input-field hbe-input-field-blink" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-blink" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-blink" data-content="需要密码,请前往B站关注up爱玩赛尔号的思考猫,私聊up主即可获得密码.">需要密码,请前往B站关注up爱玩赛尔号的思考猫,私聊up主即可获得密码.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>游戏</category>
      </categories>
      <tags>
        <tag>插件管理</tag>
      </tags>
  </entry>
  <entry>
    <title>近邻法</title>
    <url>/2020/08/25/jin-lin-fa/</url>
    <content><![CDATA[<p>这一部分介绍一下$k$近邻算法，该算法于1968年由Cover和Hart提出，$k$近邻法是一种基本分类与回归方法，本文结构如下:</p>
<ul>
<li>$k$近邻算法</li>
<li>压缩近邻法</li>
<li>$k$近邻实现：$kd$树<span id="more"></span>
<h3 id="k-近邻算法"><a href="#k-近邻算法" class="headerlink" title="$k$近邻算法"></a>$k$近邻算法</h3></li>
</ul>
<h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4><p>$k$近邻的算法非常简单朴素:</p>
<blockquote>
<p>给定一个数据集，对新的输入实例，在训练数据集中找到与该实例<strong>最邻近</strong>的$k$个实例，这$k$个实例中的多数属于某个类，就把该输入实例分为这个类。</p>
</blockquote>
<p>$k$近邻的算法思想可以说是非常符合人的直觉，正如俗语所说:”物以类聚，人以群分“，对于分类问题就是，想要看这个样本点是什么类别，只需要看其周围的点都是啥类别就可以了。 下面给出一般$k$近邻算法的定义:</p>
<blockquote>
<p><strong>$k$近邻法</strong><br><strong>输入</strong>: 训练数据集</p>
<script type="math/tex; mode=display">
    T = \{(x_1,y_1), (x_2,y_2),\dots, (x_N,y_N) \}</script><p>其中，$x_i \in \mathcal{X} \subseteq R^n$为实例的特征向量，$y_i \in \mathcal{Y} = { c_1, c_2, \dots, c_K}$为实例的类别<br><strong>输出</strong>: 实例$x$所属的类$y$<br><strong>算法流程</strong>:</p>
<ol>
<li>根据给定的距离度量，在训练集中找出与$x$最邻近的$k$个点，涵盖这$k$个点的$x$的邻域记做$N_k(x)$ </li>
<li>在$N_k(x)$中根据分类决策规则(如多数表决)决定$x$的类别$y$:<script type="math/tex; mode=display">
 y = \arg \max_{c_j} \sum_{x_i \in N_k(x)} I(y_i = c_j),\quad i = 1,2,\dots,N;j=1,2,\dots,K</script></li>
</ol>
</blockquote>
<p>若$k=1$，则此时$k$近邻算法被称为最近邻算法，$k$近邻算法没有显示的学习过程</p>
<h4 id="距离度量"><a href="#距离度量" class="headerlink" title="距离度量"></a>距离度量</h4><h5 id="L-p距离"><a href="#L-p距离" class="headerlink" title="$L_p距离$"></a>$L_p距离$</h5><p>使用$k$近邻算法的一个关键问题是需要明确如何定义<strong>最近</strong>，即选择什么样的距离度量，下面介绍下一般通用的距离度量$L_p$距离：</p>
<blockquote>
<p>设特征空间$\mathcal{X}$是$n$维实数向量空间$R^n$,$x_i,x_j \in \mathcal{X}$,$x_i = (x_i^1,x_i^2,\dots,x_i^n),x_j = (x_j^1,x_j^2,\dots,x_j^n)$,则$x_i,x_j$之间的$L_p$距离定义为:</p>
<script type="math/tex; mode=display">
    L_p(x_i,x_j) = (\sum_{i=1}^n |x_i^{(l)} - x_j^{(l)}|^p)^{\frac{1}{p}}</script></blockquote>
<p>这一类距离度量都是由范数导出的：</p>
<ul>
<li>$p = 1$,对应的是由1范数导出的曼哈顿距离</li>
<li>$p = 2$,对应的是由2范数导出的欧几里得距离 </li>
<li>$p = \infty$,对应的是由无穷范数导出的切比雪夫距离 <script type="math/tex; mode=display">
  L_\infty(x_i,x_j) = \max_l |x_i^{(l)} - x_j^{(l)}|</script><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/Lp.png" alt="$L_p$距离"><br>上图显示的是在不同的$p$下距离原点距离为1的点所组成的等高线。</li>
</ul>
<h5 id="马氏距离"><a href="#马氏距离" class="headerlink" title="马氏距离"></a>马氏距离</h5><p>马氏距离是另一种常用的距离度量,首先给出维基百科中关于马氏距离的定义:</p>
<blockquote>
<p>马氏距离(Mahalanobis distance)是由印度统计学家马哈拉诺比斯(P. C. Mahalanobis)提出的，表示数据的协方差距离。它是一种有效的计算两个未知样本集的相似度的方法，与欧式距离不同的是，它考虑到各种特性之间的联系(如体重与身高是相关联的)，并且是尺度无关的，即马氏距离独立于测量尺度。对于一个均值为$\mu$,协方差矩阵为$\Sigma$的变量，其马氏距离为:</p>
<script type="math/tex; mode=display">
    \sqrt{(x - \mu)^T \Sigma^{-1} (x - \mu)}</script><p>马氏距离也可以定义为两个服从同一分布并且其协方差矩阵为$\Sigma$的随机变量$x$与$y$的差异程度:</p>
<script type="math/tex; mode=display">
    d_M(x,y) = \sqrt{(x - y)^T \Sigma^{-1} (x - y)}</script><p>若协方差矩阵为单位阵，则此时马氏距离便退化为欧式距离，若协方差矩阵为对角阵，此时马氏距离称为正规化的马氏距离:</p>
<script type="math/tex; mode=display">
    d(x,y) = \sqrt{\sum_{i=1}^p \frac{(x_i - y_i)^2}{\sigma_i^2}}</script></blockquote>
<p>下面我对马氏距离做一个简要的说明，首先协方差矩阵是一个对称半正定矩阵，可以进行特征值分解:</p>
<script type="math/tex; mode=display">
    \Sigma = U \Lambda U^T</script><p>其中,$U$是酉矩阵，满足$U^T = U^{-1}$,是由矩阵$\Sigma$的特征向量组成(列向量)，而$\Lambda$是一个对角矩阵，对角元素是相应特征向量所对应的特征值。下面我们考虑将协方差矩阵写成下面的形式:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \Sigma &= U \Lambda^{\frac{1}{2}} \Lambda^{\frac{1}{2}} U^T \\
        &=  U \Lambda^{\frac{1}{2}} (U \Lambda^{\frac{1}{2}})^T \\
        &= AA^T
    \end{aligned}</script><p>其中$A = U \Lambda^{\frac{1}{2}}$,所以马氏距离计算公式中的$\Sigma^{-1}$可以写做:</p>
<script type="math/tex; mode=display">
    \Sigma^{-1} = (A^T)^{-1} A^{-1}</script><p>下面计算样本点$x,y$的马氏距离的平方:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        d_M(x,y)^2 &= (x-y)^T \Sigma^{-1} (x - y) \\
            &= (x-y)^T (A^T)^{-1} A^{-1} (x-y) \\
            &= [A^{-1}x - A^{-1}y]^T[A^{-1}x - A^{-1} y] 
    \end{aligned}</script><p>若记$A^{-1}x = x’,A^{-1}y = y’$,则$d_M(x,y)^2$可以写做：</p>
<script type="math/tex; mode=display">
    d_M(x,y)^2 = || x' - y'||^2</script><p>这也就是说在原始空间计算$x,y$之间的马氏距离相当于计算变换后空间中对应点的欧式距离！最后我们看一下这个变换做了什么事情：</p>
<script type="math/tex; mode=display">
    A^{-1} = \Lambda^{-\frac{1}{2}} U^T</script><p>$U^T$是一个旋转操作，相当于按照主成分方向旋转，消除各个维度之间的联系，而$\Lambda^{-\frac{1}{2}}$是一个scale操作，将变换后的各个维度的点再除以对应分布的标准差以消除由于分布不同带来的距离度量的差异。<br>最后总结下马氏距离与欧式距离的区别:</p>
<ol>
<li>马氏距离的计算是建立在总体样本的基础上的，也就是说，如果拿同样的两个样本，放入两个不同的总体当中，最后计算得出的两个样本的马氏距离通常是不相同的。</li>
<li>在计算马氏距离过程中，要求总样本数大于样本的维数，否则协方差矩阵不满秩，无法求逆</li>
</ol>
<p>马氏距离的优缺点:</p>
<ul>
<li>优点：它不受量纲的影响，两点之间的马氏距离与原始数据的测量单位无关，由标准化数据和中心化数据计算出的两点之间的马氏距离相同。马氏距离还可以排除变量之间相关性的干扰</li>
<li>缺点: 夸大了变化微小的变量的作用</li>
</ul>
<h4 id="k-值选取"><a href="#k-值选取" class="headerlink" title="$k$值选取"></a>$k$值选取</h4><p>$k$是近邻法中一个重要的超参数，下面首先说明两种极端情况:</p>
<ul>
<li>$k=1$,此时整个样本空间相当于被分割成了$N$块($N$为训练样本个数)，对于一个新的样本，需要判断它落在那一块，便将它归入对应中心点的类别，此时模型非常复杂。</li>
<li>$k =N$,这也就意味着对于一个新的样本点，直接将它归为整个训练实例中最多的类，此时模型又过于简单。</li>
</ul>
<p>总结来看，若选择较小的$k$值，对与近邻实例点非常敏感，如果原始数据噪声较大，则会导致错分，$k$值的减小就意味着整体模型变得更加复杂，容易发生过拟合；若$k$值较大，就相当于用较大邻域中的训练数据进行预测，这一定程度上减轻了数据噪声对预测结果的影响，但因为将邻域扩大，导致一些不相似的样本点也在邻域中，这可能会导致分类错误。<br>下图是使用$k$近邻方法在MNIST数据集上的结果，距离度量选用的是欧几里得距离，图中横坐标表示训练样本规模，纵坐标则是分类错误率，从图中可以看出，当样本数量较少时，选取较小的$k$得到分类效果较好，但随着训练样本数的增加，不同$k$值的分类效果开始接近。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/k.png" alt="$k$值选取"></p>
<h4 id="算法复杂度分析"><a href="#算法复杂度分析" class="headerlink" title="算法复杂度分析"></a>算法复杂度分析</h4><p>需要注意的是，$k$近邻法的时间复杂度非常高，假设特征空间维数为$n$，样本集容量为$N$，则每来一个样本，首先要计算该样本点$x$到样本集中各点的距离($O(N*n$)),然后需要对这$N$个距离进行排序($O(N\log N)$),因此对单个样本进行类别划分的复杂度便已经是:</p>
<script type="math/tex; mode=display">
    O(N * n) + O(N \log N)</script><p>对于高维的数据，直接应用$k$近邻法的时间开销是非常大的，因此在应用中往往首先考虑对高维数据进行将维。</p>
<h3 id="压缩近邻法"><a href="#压缩近邻法" class="headerlink" title="压缩近邻法"></a>压缩近邻法</h3><p>由于$k$近邻法计算复杂度过高，因此有很多旨在降低近邻法复杂度的算法被提出，压缩近邻法是其中一种，下面给出其算法流程:</p>
<blockquote>
<p><strong>压缩近邻法</strong>：<br>Step1: 从Grabbag中选择一个样本放入Store中<br>Step2: 用store中样本以近邻法测试Grabbag中样本。如果分错，则将该样本放入store<br>Step3: 重复上面方法直到Grabbag中没有样本再转入到Store中，或Grabbag为空则停止<br>Step4: 用Store中样本作为近邻法设计集合</p>
</blockquote>
<p>压缩近邻法的思想也很简单，原始样本数据集中并不是所有的数据点都对分类有帮助，因此考虑挑选出一些具有代表性的点来组成新的训练集，该集合比之前的集合要小，当新来一个数据时，便用前面挑选出的那些点应用近邻法判断数据点类别。</p>
<h3 id="kd-树"><a href="#kd-树" class="headerlink" title="$kd$树"></a>$kd$树</h3><h4 id="kd-树定义"><a href="#kd-树定义" class="headerlink" title="$kd$树定义"></a>$kd$树定义</h4><p>$kd$树是一种对$k$维空间中的实例点进行存储以便对其进行快速检索的树形数据结构。$kd$树是二叉树，表示对$k$维空间的一个划分。构造$kd$树相当于不断地用垂直于坐标轴的超平面将$k$维空间切分，构成一系列的$k$维超矩形区域，$kd$树的每一个节点对应于一个$k$维超矩形区域。</p>
<h4 id="kd-树构造"><a href="#kd-树构造" class="headerlink" title="$kd$树构造"></a>$kd$树构造</h4><p>$kd$树的构造流程如下:</p>
<blockquote>
<p><strong>构造平衡$kd$树</strong><br><strong>输入:</strong> $k$维空间数据集$T = { x_1,x_2,\dots,x_N }$,其中$x_i = (x_i^1,x_i^2,\dots,x_i^k)^T$<br><strong>输出:</strong> $kd$树 </p>
<ul>
<li>开始：构造根节点，根节点对应于包含$T$的$k$维空间的超矩形区域。选择$x^1$为坐标轴，以$T$中所有实例的$x^1$坐标的中位数为切分点，将根节点对应的超矩形区域切分为两个子区域。由根节点生成深度为$1$的左、右子节点：左子节点对应于坐标$x^1$小于切分点的子区域，右子节点对应于坐标$x^1$大于切分点的子区域。将落在切分超平面上的实例点保存在该节点。</li>
<li>重复：对深度为$j$的节点，选择$x^l$为切分的坐标轴，$l = j(mod k) +1$,以该节点的区域中所有实例的$x^l$坐标的中位数为切分点，将对应的超矩形区域再次分割为两个子区域。</li>
<li>直到两个子区域没有实例存在时停止，从而形成$kd$树的区域划分。</li>
</ul>
</blockquote>
<h4 id="kd-树搜索"><a href="#kd-树搜索" class="headerlink" title="$kd$树搜索"></a>$kd$树搜索</h4><p>下面给出$kd$树的最近邻搜索算法：</p>
<blockquote>
<p><strong>kd树搜索算法</strong><br><strong>输入:</strong> 已构造的$kd$树，目标点$x$<br><strong>输出:</strong> $x$的最近邻</p>
<ul>
<li>在$kd$树中找到包含目标点$x$的叶节点：从根节点出发，递归向下搜索即可</li>
<li>以此叶节点为”当前最近点”</li>
<li>递归地向上回退，在每个节点进行以下操作:<ul>
<li>如果该节点保存的实例点比当前最近点距离目标点更近，则以该实例点为当前最近点</li>
<li>检查另一子节点对应的区域是否与以目标点为球心、以目标点与“当前最近点”间的距离为半径的超球体相交。如果相交，则可能在另一个子节点对应的区域内存在距目标点更近的点，移动到另一个子节点。接着递归地进行最近邻搜索</li>
</ul>
</li>
<li>当回退到跟节点时，搜索结束。最后的”当前最近点”即为$x$的最近邻点。</li>
</ul>
</blockquote>
<p>如果实例点是随机分布的，$kd$树搜索的平均计算复杂度是$O(\log N)$,$kd$树更适用于训练实例数远大于空间维数时的$k$近邻搜索，当空间维数接近训练实例数时，它的效率会迅速下降，接近线性扫描。</p>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>分类，k近邻</tag>
      </tags>
  </entry>
  <entry>
    <title>降维算法</title>
    <url>/2020/09/21/jiang-wei-suan-fa/</url>
    <content><![CDATA[<p>降维是将训练数据中的样本(实例)从高维空间转换到低维空间。假设样本原本存在于低维空间，或者近似地存在于低维空间，通过降维则可以更好地表示样本数据的结构，即更好地表示样本之间的关系。高维空间通常是高维的欧式空间，而低维空间则是低维的欧式空间或者流形(manifold)。低维空间不是事先给定，而是从数据中自动发现，其维数通常是事先给定的。从高维到低维的降维中，要保证样本的信息损失最少。<br><span id="more"></span><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/dimension.png" alt="降维"></p>
<p>本文主要介绍四种降维方法：</p>
<ul>
<li>主成分分析法(PCA)</li>
<li>多维缩放(MDS)</li>
<li>等距特征映射(ISOMAP) </li>
<li>局部线性嵌入(LLE)</li>
<li>实验部分</li>
</ul>
<p>在详述各种降维方法之前，我们需要明确这样一件事：</p>
<blockquote>
<p>进行降维的过程实际上也是进行特征提取的过程，选择什么样的降维算法取决于我们期望提出哪些特征，比如我们希望提取的特征能够尽可能将样本点区分开来，就可以采用PCA</p>
</blockquote>
<h3 id="主成分分析法-PCA"><a href="#主成分分析法-PCA" class="headerlink" title="主成分分析法(PCA)"></a>主成分分析法(PCA)</h3><h4 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h4><p>首先我们考虑这样一个问题：</p>
<blockquote>
<p>对于正交属性空间中的样本点，如何用一个超平面对所有样本进行恰当的表达？</p>
</blockquote>
<p>我们直观上来思考这个问题，若存在这样的超平面，那么它大概具有这样的性质:</p>
<ul>
<li>最近重构性：样本点到这个超平面的距离都足够近</li>
<li>最大可分性： 样本点在这个超平面上的投影能够尽可能分开 </li>
</ul>
<p>有趣的是，从上面两个角度出发，能分别得到主成分分析的两种等价推导，PCA算法的推导有一个基本前提:</p>
<blockquote>
<p><strong>前提假设：假设样本数据进行了中心化，即$\sum_i x_i = 0$</strong> </p>
</blockquote>
<p>现在考虑样本空间$R^d$中的一组基${ w<em>1, w_2, \dots, w_d }$, 其中$w_i$是标准正交基向量，$||w_i||_2 = 1, w_i^Tw_j = 0(i \neq j)$,若丢弃新坐标系中的部分坐标，即将维度降低到$d’ &lt; d$,则样本点$x_i$在低维坐标系中的投影是$z_i = (z</em>{i1}, z<em>{i2}, \dots, z</em>{id’})$,其中$z<em>{ij} = w_j^T x_i$是$x_i$在低维坐标系下第$j$维的坐标，若基于$z_i$来重构$x_i$,则会得到$\hat{x}_i = \sum</em>{j=1}^{d’} z_{ij} w_j$,基于上面叙述，我们下面从两个角度来推导主成分分析。</p>
<h5 id="最近重构性"><a href="#最近重构性" class="headerlink" title="最近重构性"></a>最近重构性</h5><p>假设有$m$个样本点，则从原样本点到到基于投影重构的样本点$\hat{x}_i$的距离平方的均值为:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \frac{1}{m}\sum_{i=1}^m || x_i - \hat{x}_i||^2   &=  \frac{1}{m}\sum_{i=1}^m|| \sum_{j=1}^{d'} z_{ij}w_j - x_i||^2   \\
        &= \frac{1}{m} (\sum_{i=1}^m \sum_{j=1}^{d'} z_{ij}^2 - 2\sum_{i=1}^m \sum_{j=1}^{d'} z_{ij} w_j^T x_i  + \sum_{i=1}^m x_i^T x_i)  \\
        &= \frac{1}{m}(\sum_{i=1}^m \sum_{j=1}^{d'} w_j^T x_i x_i^T w_j - 2 \sum_{i=1}^m \sum_{j=1}^{d'} w_j^T x_i x_i^T w_j + \sum_{i=1}^m x_i^Tx_i) \\
        &= -\frac{1}{m}(\sum_{i=1}^m \sum_{j=1}^{d'} w_j^T x_i x_i^T w_j + const) \\
        &= -tr(W^T \frac{1}{m} \sum_{i=1}^m x_i x_i^T W) 
    \end{aligned}</script><p>其中$W = (w<em>1, w_2, \dots, w</em>{d’})$, 因为我们数据已经做了零均值化，因此$\frac{1}{m}\sum<em>{i=1}^m x_i x_i^T$刚好是样本集协方差矩阵，不妨记$\Sigma = \frac{1}{m} \sum</em>{i=1}^m x_i x_i^T$,因此从这个角度导出来的优化问题为:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &\max_{W} tr(W^T \Sigma W) \\
        &s.t. W^T W = I_{d' \times d'}
    \end{aligned}</script><h5 id="最大可分性"><a href="#最大可分性" class="headerlink" title="最大可分性"></a>最大可分性</h5><p>若投影向量基选为$W = (w<em>1, w_2, \dots, w</em>{d’})$,则样本点在新空间的坐标为$W^T x_i$,根据最大可分性的定义，我们期望所有样本点的投影能够尽可能分开，也就是说投影后的样本集的方差尽可能大，因为对原始空间的样本点做了0均值化，因此投影后样本集的均值也是零，协方差矩阵则是：</p>
<script type="math/tex; mode=display">
    \frac{1}{m} \sum_{i=1}^m W^T x_i x_i^T W</script><p>我们的优化目标是向各个坐标轴投影的坐标方差尽可能大，目标函数可以写做:</p>
<script type="math/tex; mode=display">
    \frac{1}{m} \sum_{i=1}^m \sum_{j=1}^{d'} w_j^T x_i x_i^T w_j = tr(W^T \Sigma W)</script><p>因此优化问题可以写做:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        & \max_{W} tr(W^T \Sigma W) \\ 
        & s.t. W^TW = I_{d' \times d'}
    \end{aligned}</script><p>从优化问题推导来看，从两个角度进行推导，我们得到了相同的优化问题。 </p>
<h4 id="优化问题求解"><a href="#优化问题求解" class="headerlink" title="优化问题求解"></a>优化问题求解</h4><p>该优化问题是带等式约束的优化问题，考虑采用Lagrange乘子法求解，首先写出Lagrange函数:</p>
<script type="math/tex; mode=display">
    L = \sum_{i=1}^{d'} w_i^T \Sigma w_i - \sum_{i=1}^m \lambda_i (w_i^T w_i - 1)</script><p>需要注意的是，该Lagrange乘子法的写法相当于是将原始优化问题放松了，因为少了$w_i$两两彼此正交的条件，因此我们通过该Lagrange乘子法求得最优解后，需验证其是否满足正交性。 让$L$对$w_i$求偏导并令偏导为0:</p>
<script type="math/tex; mode=display">
    \frac{\partial L}{\partial w_i} = 2 \Sigma w_i - 2 \lambda_i w_i = 0</script><p>由此我们得到了$w_i$应当满足的条件:</p>
<script type="math/tex; mode=display">
  \Sigma w_i = \lambda_i w_i</script><p>上式说明$w_i$应当是矩阵$\Sigma$的特征向量，而其对应的特征值为$\lambda_i$,将该结论回代目标优化式可得:</p>
<script type="math/tex; mode=display">
    target = \sum_{i=1}^{d'} \lambda_i</script><p>因此若想让目标函数尽可能大，则应当选取矩阵$\Sigma$的较大的特征值所对应的特征向量作为投影向量。据此我们便可得到PCA算法的流程:</p>
<blockquote>
<p><strong>主成分分析法：</strong><br><strong>输入：</strong> 样本集$D = { x<em>1, x_2, \dots, x_m}$, 低维空间维数$d’$<br><strong>输出：</strong> 投影矩阵$W^{\ast} = [w_1, w_2, \dots, w</em>{d’}]$<br><strong>步骤：</strong> </p>
<ul>
<li>对所有样本点进行中心化$x<em>i \leftarrow x_i - \frac{1}{m} \sum</em>{i=1}^m x_i$ </li>
<li>计算样本的协方差矩阵$\Sigma = \frac{1}{m} X X^T$ </li>
<li>对协方差矩阵$\Sigma$做特征值分解 </li>
<li>取最大的$d’$个特征值所对应的特征向量构成投影矩阵 </li>
</ul>
</blockquote>
<p>对于主成分分析法，我们可以从多个角度进行理解，从重构损失最小的角度来看，由于原始数据维度很高，但可能其主要的信息仅仅只在几个主成分方向上，因此沿主成分方向进行分解，则可以在保留尽可能多信息的情况下对数据进行降维。从最大可分性的角度来看，将原始空间的样本向主成分方向投影，可以使得样本在这个方向上能够尽可能分开,从这个角度我们对比一下线性判别分析(LDA),LDA是有监督的降维方法，希望不同类别的样本点能够在某个方向上尽可能分开，而PCA则是无监督的降维，是针对整个样本集，期望样本集在某个方向上投影方差尽可能大。</p>
<h4 id="降维维数-d’-的确定"><a href="#降维维数-d’-的确定" class="headerlink" title="降维维数$d’$的确定"></a>降维维数$d’$的确定</h4><p>降维后低维空间的维数$d’$通常需要用户事先指定， 或者对于特定任务，通过交叉验证的方法来选取较好的维数，但如果我们从重构损失的角度来看，我们往往期望$\hat{x}$能够尽可能接近$x$，而如何衡量重构效果呢？这里就与信息论相一致，认为一个变量方差越大，则其所包含的信息越多，因此就通过累积方差来横量重构效果，比如$\Sigma$最大的特征值所对应的特征向量为$w_1$，则将原始空间样本点向该特征向量投影，所得到的值的方差为:</p>
<script type="math/tex; mode=display">
    w_1^T \Sigma w_1 =  \lambda_1 w_1^T w_1 = \lambda_1</script><p>而所谓累积方差则是因为我们将原始空间的点向$d’$个主成分方向投影，在这$d’$个方向上的方差和为:</p>
<script type="math/tex; mode=display">
    \sum_{i=1}^{d'} \lambda_i</script><p>贡献率则是在$d’$个方向上投影的累积方差与向所有$d$个方向投影的累积方差之比:</p>
<script type="math/tex; mode=display">
    contribute = \frac{\sum_{i=1}^{d'} \lambda_i}{\sum_{i=1}^d \lambda_i}</script><p>因此在选择降维维数时，我们也可以从重构贡献率的角度入手，限定贡献率阈值来选取降维维数$d’$。</p>
<h4 id="PCA降维有效性分析"><a href="#PCA降维有效性分析" class="headerlink" title="PCA降维有效性分析"></a>PCA降维有效性分析</h4><p>使用PCA将样本点从$d$维降到$d’$维必然会导致信息的损失，这是因为对应于$\Sigma$最小的$d - d’$个特征值所对应的特征向量被舍去了，但有时舍弃这部分信息是必要的，因为:</p>
<ul>
<li>原始空间维度过大，但信息仅仅只在某些主成分方向，通过降维可以便于数据传输，降低传输难度</li>
<li>舍弃这部分信息能够使得样本的采样密度增大 </li>
<li>当数据受到噪声影响时，小的特征值所对应的特征向量往往与噪声有关， 舍弃它们能在一定程度上起到去噪的效果。</li>
</ul>
<h3 id="多维尺度分析-MDS"><a href="#多维尺度分析-MDS" class="headerlink" title="多维尺度分析(MDS)"></a>多维尺度分析(MDS)</h3><h4 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h4><p>PCA降维的出发点是期望能够保留尽可能多的信息，使得投影后方差尽可能大，而多维尺度分析(MDS)的思想则是期望原空间中样本点之间的相似关系能够在低维空间中得到保留。而这种相似性一般是通过距离矩阵来进行度量，假设有$n$个样本，距离矩阵$D$定义为:</p>
<script type="math/tex; mode=display">
    D = \begin{bmatrix}
        d_{11}^2 & d_{12}^2 & \dots & d_{1n}^2  \\
        d_{21}^2 & \ddots & \dots & d_{2n}^2  \\
        \vdots & \ddots & \ddots & \vdots \\ 
        d_{n1}^2 & d_{n2}^2 & \dots & d_{nn}^2  
    \end{bmatrix}</script><p>其中$d_{ij}$ 表示样本点$i,j$之间的距离，距离度量方法需要结合实际问题来确定。假设原始样本空间为$d$维，降维后空间为$d’$维，则我们期望在降维后的空间里，样本点之间的距离矩阵能够基本与原始空间距离矩阵一样，即将高维空间中的相似关系在低维空间中得到保留。</p>
<h4 id="数学推导"><a href="#数学推导" class="headerlink" title="数学推导"></a>数学推导</h4><p>使用MDS进行降维一般需要知道距离矩阵$D$，即原始空间中样本点之间的距离关系是已知的，然后我们期望能够在低维空间能够保持这种距离关系。若我们知道各个样本点的位置，然后计算距离矩阵$D$是比较自然的，现在我们要做的则是逆过程，即根据距离矩阵来还原原始空间中点的坐标，我们首先直观上就可以感到这种还原肯定不是唯一的。<br>现在我们要做的就是找到一种方法来求解这个逆过程，求解思路则是借助于内积矩阵，而距离矩阵与内积矩阵是有着对应关系的，下面我们来分两部分推导:</p>
<ul>
<li>距离矩阵与内积矩阵的关系 </li>
<li>内积矩阵与低维空间样本坐标的关系 </li>
</ul>
<h5 id="距离矩阵与内积矩阵"><a href="#距离矩阵与内积矩阵" class="headerlink" title="距离矩阵与内积矩阵"></a>距离矩阵与内积矩阵</h5><blockquote>
<p><strong>前提：</strong><br>对样本点做了零均值化，即$\sum_{i=1}^n x_i = 0$</p>
</blockquote>
<p>假设原始空间中的样本点为$(x_1, x_2, \dots, x_n)$，其中$x_i \in \mathbb{R}^d$, 那么内积矩阵$B$可以表示为:</p>
<script type="math/tex; mode=display">
    B = \begin{bmatrix}
        x_1 & x_2 & \dots & x_n
    \end{bmatrix}^T 
    \begin{bmatrix}
        x_1 & x_2 & \dots & x_n
    \end{bmatrix} = X^T X</script><p>其中任意一个元素$b_{ij}$表示为:</p>
<script type="math/tex; mode=display">
    b_{ij} = x_i^T x_j</script><p>而距离矩阵中的元素$d_{ij}^2$在欧氏空间表示为:</p>
<script type="math/tex; mode=display">
    d_{ij}^2 = || x_i - x_j ||^2 = x_i^T x_i - 2 x_i^T x_j + x_j^T x_j</script><p>由此我们可以推出:</p>
<script type="math/tex; mode=display">
    b_{ij} = x_i^T x_j = \frac{1}{2}(-d_{ij}^2 + x_i^T x_i + x_j^T x_j)</script><p>接下来的问题则是考虑如何用$d_{ij}^2$来表示$x_i^T x_i$和$x_j^T x_j$,下面就需要利用原始样本零均值的条件,可以得到:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \frac{1}{n} \sum_{i=1}^n d_{ij}^2 &= \frac{1}{n}\sum_{i=1}^n x_i^T x_i + x_j^T x_j \\
        \frac{1}{n}\sum_{j=1}^n d_{ij}^2 &= x_i^T x_i + \frac{1}{n}\sum_{j=1}^n x_j^T x_j \\
        \frac{1}{n^2} \sum_{i=1}^n \sum_{j=1}^n d_{ij}^2 &= \frac{2}{n} \sum_{i=1}^n x_i^T x_i
    \end{aligned}</script><p>由此我们便可以得到$x_i^T x_i$ 和$x_j^T x_j$的表达式:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        x_i^T x_i &= \frac{1}{n} \sum_{j=1}^n d_{ij}^2 - \frac{1}{2 n^2} \sum_{i=1}^n \sum_{j=1}^n d_{ij}^2 \\ 
        x_j^T x_j &= \frac{1}{n} \sum_{i=1}^n d_{ij}^2 - \frac{1}{2 n^2} \sum_{i=1}^n \sum_{j=1}^n d_{ij}^2
    \end{aligned}</script><p>回代前面$b_{ij}$的表达式可得:</p>
<script type="math/tex; mode=display">
    b_{ij} = -\frac{1}{2} ( d_{ij}^2 - \frac{1}{n} \sum_{j=1}^n d_{ij}^2 - \frac{1}{n} \sum_{i=1}^n d_{ij}^2 + \frac{1}{n^2} \sum_{i=1}^n \sum_{j=1}^n d_{ij}^2)</script><p>为便于表示，做如下标记:</p>
<script type="math/tex; mode=display">
    a_{ij} = -\frac{1}{2} d_{ij}^2, a_{i.} = \frac{1}{n} \sum_{j} a_{ij}, a_{.j} = \frac{1}{n} \sum_{i} a_{ij}, a_{..} = \frac{1}{n^2} \sum_{i} \sum_{j} a_{ij}</script><p>记由$a_{ij}$组成的矩阵为$A$, 则通过上面的推导我们有:</p>
<script type="math/tex; mode=display">
    b_{ij} = a_{ij} - a_{i.} - a_{.j} + a_{..}</script><p>若将$B$表示成矩阵的形式，则有:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
          B &= (I - \frac{1}{n} \mathbf{1}_{n \times n}) A (I - \frac{1}{n} \mathbf{1}_{n \times n })  = H A H \\
          A &= -\frac{1}{2} D
    \end{aligned}</script><h5 id="内积矩阵与坐标矩阵"><a href="#内积矩阵与坐标矩阵" class="headerlink" title="内积矩阵与坐标矩阵"></a>内积矩阵与坐标矩阵</h5><p>上一部分我们推导了距离矩阵与内积矩阵的关系，这一部分讨论下如何由内积矩阵得到坐标矩阵，假设降维后的坐标矩阵为：</p>
<script type="math/tex; mode=display">
    X = [x_1, x_2, \dots, x_n]_{d'*n}</script><p>则内积矩阵与坐标矩阵应当有如下关系:</p>
<script type="math/tex; mode=display">
    B = X^T X</script><p>同时因为$B$是实对称矩阵，进行特征值分解可得：</p>
<script type="math/tex; mode=display">
    B = V \Lambda V^T = X^T X</script><p>此时只要取:</p>
<script type="math/tex; mode=display">
    X = \Lambda^{\frac{1}{2}} V^T</script><p>则$X$便能完全重构出距离矩阵$D$，但因为我们的目的是降维，因此只需选取部分维度即可，我们来将$V\Lambda V^T$ 展开： </p>
<script type="math/tex; mode=display">
    X^T X = V \Lambda V^T = \lambda_1 v_1 v_1^T + \lambda_2 v_2 v_2^T + \dots + \lambda_n v_n v_n^T</script><p>因此我们只需要取特征值较大的$\lambda<em>1, \lambda_2, \dots, \lambda</em>{d’}$即可较好地重构距离矩阵，因此最终假设要降到$d’$维，则只需要取$B$矩阵的前$d’$大的特征值构成$\Lambda^{\frac{1}{2}}$:</p>
<script type="math/tex; mode=display">
    \Lambda^{\frac{1}{2}} = diag(\lambda_1, \lambda_2, \dots, \lambda_{d'})</script><p>然后取这些特征值对应的特征向量构成$V^T$:</p>
<script type="math/tex; mode=display">
    V^T = \begin{bmatrix}
        v_1^T \\
        v_2^T  \\
        \vdots  \\
        v_{d'}^T 
    \end{bmatrix}</script><p>降维后的数据矩阵记为:</p>
<script type="math/tex; mode=display">
    X = \Lambda^{\frac{1}{2}} V^T = [x_1, x_2, \dots, x_n]</script><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>MDS算法的降维思想是期望能够在低维空间重构原始样本空间中样本之间的距离关系，上面的推导都是在以欧式距离作为距离度量下推导出的，若选择其他距离方式则没有这样的结论，需要求解相对应的优化问题来迭代优化求解。</p>
<h3 id="等距特征映射-ISOMAP"><a href="#等距特征映射-ISOMAP" class="headerlink" title="等距特征映射(ISOMAP)"></a>等距特征映射(ISOMAP)</h3><h4 id="流形学习"><a href="#流形学习" class="headerlink" title="流形学习"></a>流形学习</h4><p>流形学习是一类借鉴了拓扑流形概念的降维方法。“流形”是在局部与欧式空间同胚的空间，换言之，它在局部具有欧式空间的性质，可以用欧式距离来进行距离计算。当低维流形嵌入到高维空间时，则数据样本尽管在高维空间中看起来非常复杂，但在局部仍然具有欧式空间的性质，因此，可以很容易地在局部建立降维映射关系，然后再将局部映射关系推广到全局。下图中作图就是一个二维流形嵌入到了三维空间，若利用流形学习的算法将其降到二维，则如右图所示。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/manifold.png" alt="流形数据"></p>
<h4 id="ISOMAP-思想"><a href="#ISOMAP-思想" class="headerlink" title="ISOMAP 思想"></a>ISOMAP 思想</h4><p>ISOMAP 的思想其实与 多维尺度缩放(MDS)思想一致，区别在于:</p>
<ul>
<li>MDS假设样本点存在于欧式空间中，通过欧式距离来衡量样本的距离。 </li>
<li>ISOMAP假设样本存在于欧式空间的一个低维流形上，在低维流形上，样本之间只有相距较近才可用欧式距离来度量，然后再利用最短路算法构造样本之间的“测地线”距离，即沿流形的最短距离。</li>
</ul>
<p>因此关键问题就在于如何构建“测地线”距离矩阵，这时我们可以利用流形在局部上与欧式空间同胚的特性，对每个点基于欧式距离找到其近邻点，图中近邻点之间存在连接，而非近邻点不存在连接。于是，计算两点之间测地线距离的问题就变成了计算近邻连接图两点最短路径问题，此时采用dijkstra算法求解即可, 最短路算法流程可以参考如下代码:</p>
<pre class="line-numbers language-lang-python"><code class="language-lang-python">def usedijk(dist):
    n = dist.shape[0]
    for i in range(n):
        col = dist[i,:].copy()
        while(1):
            index = np.argsort(col)[1] # 距离最近的点
            if col[index] > 1000:
                break 
            length = dist[i,index] #距离最近的点的距离
            for j in range(n):
                if  dist[i,j] > dist[index,j] + length:
                    col[j] = dist[index,j] + length
                    dist[i,j] = dist[index,j] + length
                    # dist[j,start] = dist[start,j]
            col[index] = np.inf
    return dist
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>不过这样需要注意，因为$a$是$b$的近邻点但$b$未必是$a$的近邻点，因此输入的dist矩阵并不对称，如果想要对称，可以通过对称近邻法，即$a$是$b$的近邻的同时将$b$设置为$a$的近邻，下面总结下ISOMAP算法的流程:</p>
<blockquote>
<p><strong>ISOMAP:</strong><br><strong>输入:</strong> 样本集$D = (x_1,x_2,\dots, x_n)$,近邻参数$k$, 低维空间参数$d’$<br><strong>输出:</strong> 样本集$D$在低维空间中的投影$X = (x_1,x_2, \dots, x_n)$<br><strong>算法流程:</strong> </p>
<ul>
<li>计算距离矩阵$D$，各个样本点$k$近邻的距离保存，其余设置为无穷,复杂度:$O(n^2)$ </li>
<li>调用最短路算法计算任意两样本之间的测地线距离矩阵$D’$, 复杂度: $O(kn^2)$</li>
<li>将$D’$输入MDS算法，返回得到降维后的数据$X$, 复杂度: $O(n^2)$</li>
</ul>
</blockquote>
<h3 id="局部线性嵌入-LLE"><a href="#局部线性嵌入-LLE" class="headerlink" title="局部线性嵌入(LLE)"></a>局部线性嵌入(LLE)</h3><h4 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h4><p>与ISOMAP 试图保持近邻样本之间的距离不同， 局部线性嵌入试图保持邻域样本之间的线性关系，假设在原始空间中，样本点$x_i$能够通过它的邻域样本$x_j, x_k, x_l$重构：</p>
<script type="math/tex; mode=display">
    x_i = w_{ij} x_j + w_{ik} x_k + w_{il} x_l</script><p>假设我们将样本从原始$d$维空间投影到$d’$维空间，$x_i$及其近邻点在低维空间中的投影点为$x’_i, x’_j,x’_k, x’_l$,我们希望在低维空间中仍能够保留高维空间中的近邻线性重构关系，即:</p>
<script type="math/tex; mode=display">
    x'_i = w_{ij} x'_j + w_{ik} x'_k + w_{il} x'_l</script><p>具体算法思想如下图所示，可以看到所有降维算法的目的都是期望降维后的数据能够与原始空间中的数据尽可能“相似”，选用不同的度量“相似性”的方法也就产生了不同的降维算法。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/lle1.png" alt="Local linear embedding"></p>
<h4 id="数学推导-1"><a href="#数学推导-1" class="headerlink" title="数学推导"></a>数学推导</h4><p>从上面分析中可以看出，整个算法流程大致可以分为两步:</p>
<ul>
<li>在原始样本空间中求解权重矩阵</li>
<li>在低维空间中重构近邻线性关系  </li>
</ul>
<h5 id="权重矩阵求解"><a href="#权重矩阵求解" class="headerlink" title="权重矩阵求解"></a>权重矩阵求解</h5><p>首先假设原始空间中共有$n$个样本$(x<em>1, x_2, \dots, x_n)$, 假设对于样本点$x_i$，其近邻点分别为$x</em>{i1}, x<em>{i2}, \dots, x</em>{ik}$, 则我们期望找到这样一组权重：</p>
<script type="math/tex; mode=display">
    w_i = [w_{i1}, w_{i2}, \dots, w_{ik}]^T</script><p>使得$||x<em>i - \sum</em>{j=1}^k w<em>{ij} x</em>{ij} ||^2$尽可能小，这样目标函数就可以写做:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &target = \sum_{i=1}^n ||x_i - \sum_{j=1}^k w_{ij} x_{ij}||^2  \\
        & s.t. \sum_{j=1}^k x_{ij} = 1 , i=1,2,\dots, n
    \end{aligned}</script><p>我们将目标函数改写一下:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        target &= \sum_{i=1}^n ||x_i - \sum_{j=1}^k w_{ij} x_{ij}||^2  \\
            &= \sum_{i=1}^n ||\sum_{j=1}^k w_{ij}(x_i - x_{ij})||^2 \\
            &= \sum_{i=1}^n || (X_i - N_i)w_i ||^2 \\
            &= \sum_{i=1}^n w_i^T (X_i - N_i)^T (X_i - N_i) w_i  
    \end{aligned}</script><p>上式中：</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        X_i &= [x_i, \dots, x_i]_{d \times k} \\
        N_i &= [x_{i1}, \dots, x_{ik}]_{d \times k} \\
        w_i &= [w_{i1}, w_{i2}, \dots, w_{ik}]^T
    \end{aligned}</script><p>若记$S_i = (X_i -N_i)^T(X_i - N_i)$,则优化问题可以写做:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        & \min \sum_{i=1}^n w_i^T S_i w_i  \\  
        & s.t. w_i^T \mathbf{1} = 1, i = 1,2,\dots, n
    \end{aligned}</script><p>该优化问题可以通过Lagrange乘子法求解，首先写出Lagrange方程:</p>
<script type="math/tex; mode=display">
    L = \sum_{i=1}^n w_i^T S_i w_i  - \sum_{i=1}^n \lambda_i(w_i^T \mathbf{1} - 1)</script><p>对$w_i$求偏导可得:</p>
<script type="math/tex; mode=display">
    \frac{\partial L}{\partial w_i} = 2 S_i w_i - \lambda_i \mathbf{1} = 0</script><p>再应用$w_i^T \mathbf{1} = 1$的条件可得:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        \lambda_i &= \frac{2}{\mathbf{1}^T S_i \mathbf{1}} \\
        w_i &= \frac{S_i^{-1} \mathbf{1}}{\mathbf{1}^T S_i^{-1} \mathbf{1}}
    \end{aligned}</script><p>至此我们便得到了权重系数，为了便于接下来计算，让这些权重系数构成系数矩阵$W$:</p>
<script type="math/tex; mode=display">
    W = [w'_1, w'_2, \dots, w'_n]_{n \times n}</script><p>其中$w’_i$是将除$w_i$以外的其他样本的系数置零得到, $W$是一个稀疏矩阵。</p>
<h5 id="低维空间投影"><a href="#低维空间投影" class="headerlink" title="低维空间投影"></a>低维空间投影</h5><p>我们期望在低维空间$\mathbb{R}^{d’}$中能够保持近邻线性重构关系，也就是说我们期望找到一组样本点:</p>
<script type="math/tex; mode=display">
    Z = (z_1, z_2, \dots, z_n)</script><p>使得:</p>
<script type="math/tex; mode=display">
    \sum_{i=1}^n ||z_i - Z w_i||^2</script><p>能够尽可能小，我们对目标函数做进一步化简:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        target &= \sum_{i=1}^n ||z_i - Z w_i||^2 \\  
               &= \sum_{i=1}^n || Z(I_i - w_i) ||^2  \\
               &= \sum_{i=1}^n (I_i - w_i)^T Z^T Z (I_i - w_i) \\
               &= trace((I-W)^T Z^T Z (I-W)) \\
               &= trace(Z(I-W)(I-W)^T Z^T)  \\
               &= trace(Z M Z^T) 
    \end{aligned}</script><p>式中$M = (I-W)(I - W)^T$,同时需要注意到如果我们对降维后空间点的尺度不加限制，那么只要$(z_1, z_2, \dots, z_n)$的模长不断减小，则目标函数就会不断减小，算法不会收敛，同时考虑到我们只是期望在低维空间中保持高维空间中的近邻线性重构关系，如果在标准尺度下能够重构得很好，那么对所有样本点同时进行缩放后依然能够很好地重构，所以优化问题需要加入一个约束条件$Z Z^T = nI$,优化问题最终可以写做:</p>
<script type="math/tex; mode=display">
    \begin{aligned}
        &\min trace(Z M Z^T)  \\
        & s.t. Z Z^T = nI 
    \end{aligned}</script><p>对于该优化问题的求解依旧是通过Lagrange乘子法，首先写出Lagrange方程:</p>
<script type="math/tex; mode=display">
    L = trace(Z M Z^T) - \lambda (Z Z^T - nI)</script><p>若将变量矩阵$Z$以行向量形式来表示：</p>
<script type="math/tex; mode=display">
    Z = [p_1^T;p_2^T,p_{d'}^T]</script><p>那么Lagrange函数就可以写做：</p>
<script type="math/tex; mode=display">
    L = \sum_{i=1}^{d'} p_i^T M p_i - \sum_{i=1}^{d'} \lambda_i (p_i^T p_i - 1)</script><p>对$p_i$求导可得:</p>
<script type="math/tex; mode=display">
    \frac{\partial L}{\partial p_i} = 2M p_i = 2\lambda_i p_i</script><p>即$p_i$应当是$M$的特征向量，回代目标函数可得:</p>
<script type="math/tex; mode=display">
    target = \sum_{i=1}^{d'} \lambda_i</script><p>又因为我们是期望目标函数最小，因此只需要取矩阵$M$的前$d’$个最小的特征值(非0)作为矩阵$Z$的行向量即可。</p>
<h3 id="实验部分"><a href="#实验部分" class="headerlink" title="实验部分"></a>实验部分</h3><h4 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h4><p>将MNIST手写数字数据集应用PCA从28*28维降到1维和2维的效果图如下:<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/pca1.png" alt="PCA:1维"><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/pca2.png" alt="PCA:2维"></p>
<h4 id="MDS"><a href="#MDS" class="headerlink" title="MDS"></a>MDS</h4><p>给若干城市之间的乘车时间信息作为相似度矩阵，然后还原这些城市的坐标。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/mds.png" alt="MDS"></p>
<h4 id="ISOMAP"><a href="#ISOMAP" class="headerlink" title="ISOMAP"></a>ISOMAP</h4><p>三维空间中的流形数据降到二维<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/Z3.png" alt="流形数据"><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/Z20.png" alt="ISOMAP降维"></p>
<h4 id="LLE"><a href="#LLE" class="headerlink" title="LLE"></a>LLE</h4><p>三维空间中的流形数据降到二维<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/LLE.png" alt="流形数据"><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/k10.png" alt="LLE降维"></p>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>PCA, ISOMAP, MDS, LLE</tag>
      </tags>
  </entry>
  <entry>
    <title>非监督学习</title>
    <url>/2020/09/11/fei-jian-du-xue-xi/</url>
    <content><![CDATA[<p>这部分总结下传统统计学习的最后一部分内容——非监督学习，非监督学习又称无监督学习，我们前面讲的大部分算法都是需要样本的标签的，通过标签来构造损失函数，进而进行模型学习，但在有的情况下我们并没有数据的标签，这种情况下我们就什么都不能做了么？当然不是，对于无标签数据，我们仍旧可以开展一部分工作，比如：</p>
<ul>
<li>概率模型估计 </li>
<li>数据降维</li>
<li>数据聚类</li>
</ul>
<p>由于概率模型估计算法在前面已经讲过了(<a href="https://xuejy19.github.io/2020/07/30/EM/">EM算法</a>、<a href="https://xuejy19.github.io/2020/07/27/概率密度函数估计/#more">概率密度函数估计</a>)，这里就不再赘述，本文主要简单介绍下无监督学习问题的思想。</p>
<span id="more"></span>
<h3 id="无监督学习思想"><a href="#无监督学习思想" class="headerlink" title="无监督学习思想"></a>无监督学习思想</h3><p>无监督学习是从无标注的数据中学习数据的统计规律或者说内在结构的机器学习，主要包括聚类、降维、概率估计，<strong>无监督学习可以用于数据分析或者监督学习预处理</strong>。<br>无监督学习使用无标注数据$U = { x<em>1, x_2, \dots, x_N}$学习或训练，其中$x_i，i = 1,2,\dots,N$, 是样本，由特征向量组成。无监督学习的模型是函数$z = g</em>{\theta}(x)$ , 条件概率分布$P<em>{\theta}(z|x)$，或条件概率分布$P</em>{\theta}(x|z)$。其中$x \in X$是输入，表示样本； $z \in Z$是输出，表示对样本的分析结果，可以是类别、转换、概率；$\theta$是参数。<br>无监督学习是一个困难的任务，因为数据没有标注，也就是没有人为的引导，机器需要自己从数据中找出规律。模型的输入$x$在数据中可以观测，而输出$z$隐藏在数据中。无监督学习通常需要大量的数据，因为对数据隐藏的规律的发现需要足够的观测。<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/Unsupervised.jpg" alt="机器学习算法划分"></p>
<p>后面将会有两片文章分别介绍降维算法和聚类算法。</p>
]]></content>
      <categories>
        <category>统计学习</category>
      </categories>
      <tags>
        <tag>降维，聚类，概率密度估计</tag>
      </tags>
  </entry>
  <entry>
    <title>风光摄影</title>
    <url>/2020/11/27/feng-guang-she-ying/</url>
    <content><![CDATA[<p>这一篇文章就跟随校风光摄影的大佬来了解一下风光摄影的一些知识，该部分按照以下三部分进行组织: </p>
<ul>
<li>风光摄影拍什么 </li>
<li>前期工作 </li>
<li>实用技术 <span id="more"></span>
</li>
</ul>
<h3 id="风光摄影拍什么"><a href="#风光摄影拍什么" class="headerlink" title="风光摄影拍什么"></a>风光摄影拍什么</h3><h4 id="校园摄影"><a href="#校园摄影" class="headerlink" title="校园摄影"></a>校园摄影</h4><p>在清华园里可以拍什么景色: </p>
<ul>
<li>四季景观 </li>
<li>日出月落 </li>
<li>人文活动 </li>
<li>校园地标 </li>
</ul>
<h5 id="四季景观"><a href="#四季景观" class="headerlink" title="四季景观"></a>四季景观</h5><ul>
<li><p>春<br><strong>春$\cdot$樱花友谊林</strong><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E6%A8%B1%E8%8A%B1%E6%9E%97.png" alt="樱花友谊林"></p>
</li>
<li><p>夏<br>晚霞，5月25日前后<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E6%99%9A%E9%9C%9E.png" alt="晚霞"><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%A4%A7%E7%A4%BC%E5%A0%82.png" alt="大礼堂"></p>
</li>
<li><p>秋<br>银杏，二校门前,雕塑苑  爬山虎,红叶,工字厅门前<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E9%93%B6%E6%9D%8F.png" alt="银杏"></p>
</li>
<li><p>冬<br>清华学堂，水木清华，大礼堂，夜里下雪开闪光灯，情人坡<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%86%AC-%E6%B8%85%E5%8D%8E%E5%AD%A6%E5%A0%82.png" alt="清华学堂"><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%86%AC-%E9%97%AA%E5%85%89%E7%81%AF.png" alt="雪花-闪光灯"></p>
</li>
</ul>
<h5 id="日出月落"><a href="#日出月落" class="headerlink" title="日出月落"></a>日出月落</h5><p>晨雾,头一天下过雨<br>拍星轨比较推荐: 西操<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%9F%8E%E5%B8%82-%E6%9C%88.png" alt="月"></p>
<h5 id="人文活动"><a href="#人文活动" class="headerlink" title="人文活动"></a>人文活动</h5><p>文图、猫猫、路牌、校庆期间、高1楼、艺博</p>
<h4 id="城市摄影"><a href="#城市摄影" class="headerlink" title="城市摄影"></a>城市摄影</h4><p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E6%97%A7%E9%87%91%E5%B1%B1.png" alt="旧金山"></p>
<h4 id="旅行摄影"><a href="#旅行摄影" class="headerlink" title="旅行摄影"></a>旅行摄影</h4><p>主要拍地标</p>
<h4 id="星空摄影"><a href="#星空摄影" class="headerlink" title="星空摄影"></a>星空摄影</h4><p>银河、星轨、流星雨、银河拱桥<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E9%95%BF%E5%9F%8E-%E9%93%B6%E6%B2%B3%E6%8B%B1%E6%A1%A5.png" alt="长城-银河拱桥"></p>
<h4 id="延时摄影"><a href="#延时摄影" class="headerlink" title="延时摄影"></a>延时摄影</h4><p>加上了时间的维度，比较震撼<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%BB%B6%E6%97%B6%E6%91%84%E5%BD%B1.png" alt="延时摄影"></p>
<h3 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h3><h4 id="摄影计划"><a href="#摄影计划" class="headerlink" title="摄影计划"></a>摄影计划</h4><ul>
<li>挑选样片<br>500px, 图虫<ul>
<li>寻找灵感 </li>
<li>同机位复现</li>
<li>原创性 </li>
</ul>
</li>
<li>查找机位 <ul>
<li>确认图片位置 </li>
<li>预估交通时间</li>
<li>通过EXIF信息确认焦段 </li>
<li>确认拍摄位置可前往</li>
</ul>
</li>
<li>确认天气 <ul>
<li>天气预报软件: 彩云天气、墨迹天气 </li>
<li>Windy: 云图 </li>
<li>莉景天气 </li>
<li>plan it(巧摄)</li>
</ul>
</li>
<li>整备器材 </li>
</ul>
<h4 id="现场判断与操作"><a href="#现场判断与操作" class="headerlink" title="现场判断与操作"></a>现场判断与操作</h4><ul>
<li>焦段选择</li>
<li><p>拍摄方式 </p>
<ul>
<li>多帧堆栈 </li>
<li>全景拼接 <ul>
<li>拼接接缝 </li>
<li>使用三脚架</li>
<li>参数尽量一致</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/%E5%85%A8%E6%99%AF%E6%8B%BC%E6%8E%A5.png" alt="全景拼接"></p>
<ul>
<li>景深合成<br>拍摄出全景深图片</li>
<li>延时摄影 <ul>
<li>拍摄间隔</li>
<li>尽量拍摄长时间，广角</li>
</ul>
</li>
</ul>
</li>
<li><p>如何拍出一张完美的前期 </p>
<ul>
<li>多拍几张，防止抖动</li>
<li>通过不同参数，拿到画面的不同部分 </li>
<li>留下足够多裁剪空间  </li>
</ul>
</li>
<li><p>超广角镜头 </p>
<ul>
<li>通常指20mm焦段以下镜头</li>
<li>16-35mm</li>
<li>透视，近大远小</li>
<li>引导线构造</li>
<li>前景、中景、远景</li>
</ul>
</li>
<li><p>HDR-High dynamic range<br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/HDR.png" alt="HDR"><br><img src="https://raw.githubusercontent.com/xuejy19/xuejy19.github.io/source/Img/HDR%E6%8B%8D%E6%91%84.png" alt="HDR拍摄"></p>
</li>
<li><p>前期与后期的关系 </p>
<ul>
<li>前期服务于后期 </li>
<li>后期依赖于前期</li>
</ul>
</li>
</ul>
<h3 id="晚霞怎么拍"><a href="#晚霞怎么拍" class="headerlink" title="晚霞怎么拍"></a>晚霞怎么拍</h3><ul>
<li>夏季为晚霞多发的季节 </li>
<li>地景选择 <ul>
<li>地面机位</li>
<li>爬楼 </li>
</ul>
</li>
<li>逆光环境下的拍摄方法</li>
</ul>
<h3 id="朝阳怎么拍"><a href="#朝阳怎么拍" class="headerlink" title="朝阳怎么拍"></a>朝阳怎么拍</h3><ul>
<li>选择合适的拍摄点 </li>
<li>特写/局部/大场景</li>
<li>鬼影的解决方案 </li>
</ul>
]]></content>
      <categories>
        <category>点滴生活</category>
      </categories>
      <tags>
        <tag>风光摄影</tag>
      </tags>
  </entry>
</search>
